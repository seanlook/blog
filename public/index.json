[{"content":"visit xgknight.com\n","permalink":"http://localhost:1313/2023/01/my-first-post/","summary":"\u003cp\u003evisit xgknight.com\u003c/p\u003e","title":"My First Post"},{"content":"这是针对公司内部的一个分享，主题是去年10月份就想好的，中间因为一些项目，也包括自己的拖延症，ppt一直没准备好。\n在临近快要辞职的时候，还是想兑现一下承诺，加班加点完成了。\n分享的内容包括：\nbinlog介绍 我们有不少项目依赖于binlog同步数据，所以对binlog的格式以及内部结构进行了简单介绍\ninnodb事务的提交过程 主要是两阶段提交的一些概念和原理，与下面的组提交原理一起，方便后面对崩溃恢复机制的理解\n组提交 着重介绍组提交的概念，以及它的实现。为下面的并行复制做铺垫\n介绍MySQL复制流程 种类包括异步复制、半同步复制、增强半同步复制和并行复制，顺便结束了复制延迟常见的原因\n基于上面的原理，介绍主库、从库分别在异常宕机的情况下，如何保证数据一致的\n高可用类型 这部分由于时间的关系，没有准备，并且本身也是一个很大课题，所以干脆就去掉了\n演示稿中穿插了一些思考题，感兴趣的朋友不妨思考思考。\n{% pdf http://github.com/seanlook/sean-notes-comment/raw/main/static/mysql-replication-and-consistency.pdf 1000 800 %}\n原文连接地址：http://xgknight.com/2018/03/22/mysql-ppt-replication-and-consistency/\n","permalink":"http://localhost:1313/2018/03/mysql-ppt-replication-and-consistency/","summary":"\u003cp\u003e这是针对公司内部的一个分享，主题是去年10月份就想好的，中间因为一些项目，也包括自己的拖延症，ppt一直没准备好。\u003c/p\u003e\n\u003cp\u003e在临近快要辞职的时候，还是想兑现一下承诺，加班加点完成了。\u003c/p\u003e","title":"MySQL复制与数据一致性 分享"},{"content":"关于数据库分页查询的话题，网上谈论的很多，但开发人员在使用上还是习惯以往的思路。\n比如我们有个电话记录表：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 CREATE TABLE `t_tel_record` ( `f_id` bigint(20) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;流水号\u0026#39;, `f_qiye_id` bigint(20) NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;企业\u0026#39;, `f_callno` varchar(20) DEFAULT NULL COMMENT \u0026#39;主叫号码\u0026#39;, `f_calltono` varchar(30) DEFAULT NULL COMMENT \u0026#39;被叫号码\u0026#39;, `f_Starttime` datetime NOT NULL COMMENT \u0026#39;开始时间\u0026#39;, `f_Endtime` datetime DEFAULT NULL COMMENT \u0026#39;结束时间\u0026#39;, `f_Calltime` mediumint(8) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;通话时间\u0026#39;, `f_user_id` bigint(20) NOT NULL COMMENT \u0026#39;员工用户\u0026#39;, `f_path` varchar(200) DEFAULT NULL COMMENT \u0026#39;语音文件路径\u0026#39;, `f_crm_id` bigint(20) NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;客户库id\u0026#39;, `f_call_type` tinyint(4) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;0:未知，1:为呼入类型，2:呼出类型\u0026#39;, PRIMARY KEY (`f_id`), KEY `idx_endtime_userid` (`f_Endtime`,`f_user_id`,`f_qiye_id`), KEY `idx_crmid` (`f_crm_id`), KEY `idx_qiye_user_calltime` (`f_qiye_id`,`f_Starttime`), KEY `idx_calltono` (`f_calltono`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 1 2 3 4 5 6 7 8 9 10 11 12 查询第1页的数据： SELECT * FROM t_tel_record WHERE f_qiye_id=xxx ORDER BY f_Starttime DESC LIMIT 0,100 当数据量很大，需要查询第10000页的数据： SELECT * FROM t_tel_record WHERE f_qiye_id=xxx ORDER BY f_Starttime DESC LIMIT 999900,100 -- 或者 OFFSET 999900 LIMIT 100 MySQL的 limit m,n 工作原理就是先读取符合where条件的前面m+n条记录，然后抛弃前m条，返回后面n条，所以m越大，偏移量越大，性能就越差。这也是大部分ORM框架生成的分页sql。\n还有数据不准确的问题产生。\n要优化这类sql大抵有三种方法：\n利用索引来排序 利用覆盖索引避免回表 想办法去掉大offset 利用索引来排序 这是写sql的基础的优化手段，利用二级索引的有序性，避免filesort。考虑索引 KEY a_b_c (a, b, c) :\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ORDER may get resolved using Index – ORDER BY a – ORDER BY a,b – ORDER BY a, b, c – ORDER BY a DESC, b DESC, c DESC WHERE and ORDER both resolved using index: – WHERE a = const ORDER BY b, c – WHERE a = const AND b = const ORDER BY c – WHERE a = const ORDER BY b, c – WHERE a = const AND b \u0026gt; const ORDER BY b, c ORDER will not get resolved uisng index (file sort) – ORDER BY a ASC, b DESC, c DESC /* mixed sort direction */ – WHERE g = const ORDER BY b, c /* a prefix is missing */ – WHERE a = const ORDER BY c /* b is missing */ – WHERE a = const ORDER BY a, d /* d is not part of index */ 当然不是说利用索引排序性能就一定好，由于MySQL优化器的局限性，也会出现选择选择糟糕的index scan执行计划，见 MySQL order by limit 走错索引(range-\u0026gt;indexscan) ，using filesort也有可能比 index scan 要快。\n利用覆盖索引避免回表 我们先来理解一下回表的概念：\nMySQL是一个B+Tree结构的聚集索引组织表 每一行记录都有个rowid，要么是主键，要么是非空唯一索引，要么是内部分配的ROWID 二级索引是在表的一个或多个字段联合起来，创建的用于快速检索数据行的“字典”，这个有序的字典结构也是B+Tree 每个二级索引元组的结构后面，都会自带存储相应行记录的rowid，以便定位数据物理位置 如果一个查询采用的索引上，包含了 select 之后所需要返回的列，那么MySQL可直接从索引上返回数据；如果select 要返回的字段只要有一行没在索引中，则需要根据索引对应的rowid，进行回表获取数据。这部分数据有可能在内存，也有可能在磁盘。 当然实际情况要比上面的复杂，比如MySQL内部有ICP和MRR、BKA优化访问的手段，覆盖索引也就不需要使用了。\n如果你的分页SQL where条件和select返回列刚好都在同一个索引上，那在这一部分讲的方法没什么好优化的了。由此也应该可以得到启发，** select只返回需要的行，不要返回多余的行，禁止select * **，这些开发规范都是有依据的。\n利用Covering index优化分页的方法，先用一个子查询把符合条件主键id集合查出来，然后与原表join取出其它列：\n1 2 3 4 5 6 7 8 9 SELECT * FROM t_tel_record t1 INNER JOIN ( SELECT f_id FROM t_tel_record WHERE f_qiye_id = xxx ORDER BY f_id DESC LIMIT 999900, 100 ) t2 ON t1.f_id = t2.f_id 子查询部分利用覆盖索引只返回主键(rowid)，但不是每次都有好运气，原where条件放到子查询就能很快，毕竟它还是需要过滤999900条数据。\n上面的sql还出现了它的一个变种：\n1 2 3 4 5 6 7 8 9 10 11 12 13 min_id = SELECT f_id FROM t_tel_record WHERE f_qiye_id = xxx ORDER BY f_id DESC LIMIT 999900, 1 SELECT * FROM t_tel_record t1 WHERE f_qiye_id = xxx AND f_id \u0026lt; {min_id} + 1 ORDER BY f_id DESC LIMIT 100 第一条语句利用覆盖索引获取到该页最小id(如果是升序就是最大id)\n第二条语句利用主键和其它过滤条件，获取该页数据。\n上面两种方式都有一定的优化效果，具体还是要看业务本身的复杂度。\n无offset翻页 上面的变种已经提供了一个很好的思路：\n程序端或者客户端，保留当前页的最小id、最大id（id是主键），这并不是什么难事 降序情况下，每次提取下一页的数据时，f_id \u0026lt; min_id order by f_id desc limit 100; 上一页 f_id \u0026gt; max_id order by f_id desc limit 100 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 第一页：（降序） SELECT * FROM t_tel_record t1 WHERE f_qiye_id = xxx ORDER BY f_id DESC LIMIT 100 获取结果集最大最小id：一般是第一条和最后一条，或者 max_id=max(f_id), min_id=min(f_id) 下一页（如果有）： SELECT * FROM t_tel_record t1 WHERE f_qiye_id = xxx AND f_id \u0026lt; {min_id} -- min_id变量 ORDER BY f_id DESC LIMIT 100 上一页（如果有）： SELECT * FROM t_tel_record t1 WHERE f_qiye_id = xxx AND f_id \u0026gt; {max_id} -- max_id变量 ORDER BY f_id DESC LIMIT 100 没有第几页之说，更不存在【跳转x页】这种深度分页，只有【上一页】【下一页】，所以用户体验上有差别。这种分页方式，使用f_id过滤数据，而f_id是主键，速度是很快的，性能不会随着页数的增大而变慢。\n反转分页 降序分页的时候，如果用户直接点击最后一页，或者上面的第10000页实际就是倒数第2页，那就没有必要取这么大的offset，转换成升序，性能就与正向前几页效率一样高了。\n如下图所示，很容易理解。\n在几万页的情况下翻到最后一页，用户不太关心最后一页是100条还是99条：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 最后一页：（降序） SELECT * FROM ( SELECT * FROM t_tel_record t1 WHERE f_qiye_id = xxx ORDER BY f_id ASC LIMIT 100) AS t ORDER BY f_id DESC 倒数第二页：(以此类推) SELECT * FROM ( SELECT * FROM t_tel_record t1 WHERE f_qiye_id = xxx ORDER BY f_id ASC LIMIT 100, 100) AS t ORDER BY f_id DESC 分页不存在大一统的绝对优化方法，有时候需要产品层面来回避技术难题，比如前5页显示页号，便于跳页，实现上用offset；大于5页只能上下翻页，实现上用无offset方法；最后几页使用反转翻页实现：\n包括前面所有优化方法，都没有提供 记录总数 这样的显示，大数据量count对MySQL来说实在不擅长。即使是Google搜索引擎也只提供 约xx条结果 。\n抛开数据量谈实现，也就太天真的。\n不精确分页 其实再想想 order by xxx limit m,n 场景：\n展示列表或搜索结果 内部统计或者导出业务 第2种场景，比如扫描一组数据或者全部数据，业务批量导出数据，并不是严格的分页，换句话讲，开发的目的是将数据分批取出，每批的数据量是不是一样并不重要，甚至顺序也不重要，而在批量取数据的实现反而引入了两个可能限制性能的条件。\n比如有个扫描全表统计数据的功能，范围、等值条件比较复杂，无法很好的使用索引（比如范围搜索可能会使索引其它列失效）。下面直接按 f_Starttime 每5分钟切片，可以较好的利用(f_qiye_id,f_Starttime)索引\n1 2 3 SELECT * FROM t_tel_record WHERE f_Starttime \u0026gt;= \u0026#39;2018-03-16 08:00:01\u0026#39; AND f_Starttime \u0026lt; \u0026#39;2018-03-16 08:05:01\u0026#39; ORDER BY f_Starttime DESC 分页优化陷阱 order by id 与 order by f_Starttime 按照主键与按照二级索引排序，它们对优化器的影响是非常大的。\n在order by 主键时，MySQL优化器很“喜欢”直接用主键，而放弃where条件可能具有更好过滤效果（但有filesort）的执行计划。 在order by 二级索引的某个字段时，MySQL优化器表现比较正常，虽然遇到where条件的范围索引容易失去索引排序，但好歹有可能采用覆盖索引。 正因为第1点的影响，所有再某些分页sql优化时，可考虑 order by id 改成具有接近排序效果的其它字段，比如id是自增，时间字段也是增长。\n第一页和最后一页非常慢 考虑下面两个sql: （都采用上面的 f_id \u0026gt; max_id 的优化方法）\nsql1:\n1 2 3 4 - f_Starttime上没有可用索引 SELECT f_qiye_id,f_id,f_money,f_type,f_callno,f_calltono,f_Starttime,f_Endtime, f_Calltime,f_status, f_num,f_result,f_time,f_user_id,f_is400,f_crm_log,f_code, f_path,f_crm_id,f_telbox_id,f_mp3_len, f_in_out_type, f_call_type FROM d_ec_telecom7.t_tel_record_201710 WHERE f_id \u0026gt; 0 and (f_Starttime\u0026gt;=\u0026#39;2017-10-25 00:00:00\u0026#39; and f_Starttime\u0026lt;=\u0026#39;2017-10-26 00:00:00\u0026#39;) ORDER BY f_id ASC LIMIT 1000 sql2:\n1 2 3 SELECT f_log_id,f_crm_id,f_user_id,f_qiye_id,f_creat_time,f_send_time,f_end_time,f_do_type, f_static_time,f_go_web,f_type,f_contact_num,f_share,f_record_type,f_provice,f_city,f_is_addclient, f_is_customer,f_ontime_flag,f_msg_type,f_id,f_style,f_operate_type,f_from,f_sendmsg FROM d_ec_contact.t_crm_contact_at201708 WHERE f_log_id \u0026gt; 3815923707 and (f_creat_time\u0026gt;=\u0026#39;2017-08-01 00:00:00\u0026#39; and f_creat_time\u0026lt;=\u0026#39;2017-08-02 00:00:00\u0026#39;) ORDER BY f_log_id ASC LIMIT 1000 都是导出性质的sql，开发反应每当扫描开始的第一页（如sql1）和最后一页（如sql2），都变的贼慢，然而中间页的数据拉取都在几十毫秒级别。\n我们分析一下sql1慢的原因\nf_Starttime上没有索引，执行计划如下： f_id是个全局id，单调递增。应该说与f_Starttime是保持相同的趋势增长的，因为正是这样决定了中间页都较快 仔细观察f_Starttime条件，是从10月份表中获取 10.25 日全天数据。执行计划几乎就是根据主键全表扫描，因为f_id\u0026gt;0的条件需要扫描10.1，10.2，\u0026hellip; 10.24，之后终于在10.25的第一个f_id找到，通过where条件过滤。可想而知有多慢 第一页取出后，拿f_id的最大值，去取第二页，因为f_id与f_Starttime是保持相同趋势增长，所以扫过的所有记录都满足where条件，很快返回（另外主键扫描是顺序IO，取1000是很快的） 最后一页也是同样，当最后一页不满1000条时，f_id已经超出f_Starttime范围右边了，后面虽然已经没有满足f_Starttime条件的记录，但根据主键还是要一扫到底。 （要判断行数是否小于1000，如果不判断还会拿最后一页的最大值去查询，返回结果0，无谓的耗时） 优化第一页和优化最后一页的方法其实是类似的。第一页在f_Starttime无索引的情况下，无论如何都是很难提高效率的，除非你用专门的一段代码去猜f_id的起始值。我们这个例子还特殊点，f_id的组成是 timestamp + incr_1 ，根据f_Starttime范围直接就得到 f_id 的近似值作为下界。\n同理，最后一页根据f_Starttime得到最大值，转换为 timestamp × 1000000000 + 99999 作为上界。\nsql2慢的原因有点不一样：\nf_creat_time上是有一个索引 (f_creat_time,f_operate_type) 的，看一下它的执行计划： 像本文前面说的，一个范围条件，再 order by 主键，优化器选择了主键扫描，而非范围扫描再filesort （一天数据量约320万） 优化办法：\n比如去7月份表查个最大值 \u0026hellip;use index(idx_creattime) \u0026hellip; order by f_creat_time ASC 关于分页优化，具体问题具体分析。\n** 参考 **\nhttps://mariadb.com/kb/en/library/pagination-optimization/ http://www.cnblogs.com/wy123/p/7003157.html https://blog.jamespan.me/2015/01/22/trick-of-paging-query 本文链接地址：http://xgknight.com/2018/03/21/mysql-pagination-no-offset/\n","permalink":"http://localhost:1313/2018/03/mysql-pagination-no-offset/","summary":"\u003cp\u003e关于数据库分页查询的话题，网上谈论的很多，但开发人员在使用上还是习惯以往的思路。\u003c/p\u003e\n\u003cp\u003e比如我们有个电话记录表：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e 1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 7\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 8\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 9\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e10\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e11\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e12\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e13\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e14\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e15\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e16\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e17\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e18\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-mysql\" data-lang=\"mysql\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"k\"\u003eCREATE\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eTABLE\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003et_tel_record\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003ef_id\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kt\"\u003ebigint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e20\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eunsigned\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eNOT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"no\"\u003eNULL\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eDEFAULT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;0\u0026#39;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eCOMMENT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;流水号\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003ef_qiye_id\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kt\"\u003ebigint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e20\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eNOT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"no\"\u003eNULL\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eDEFAULT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;0\u0026#39;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eCOMMENT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;企业\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003ef_callno\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kt\"\u003evarchar\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e20\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eDEFAULT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"no\"\u003eNULL\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eCOMMENT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;主叫号码\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003ef_calltono\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kt\"\u003evarchar\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e30\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eDEFAULT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"no\"\u003eNULL\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eCOMMENT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;被叫号码\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003ef_Starttime\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kt\"\u003edatetime\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eNOT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"no\"\u003eNULL\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eCOMMENT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;开始时间\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003ef_Endtime\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kt\"\u003edatetime\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eDEFAULT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"no\"\u003eNULL\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eCOMMENT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;结束时间\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003ef_Calltime\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kt\"\u003emediumint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e8\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eunsigned\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eNOT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"no\"\u003eNULL\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eDEFAULT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;0\u0026#39;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eCOMMENT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;通话时间\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003ef_user_id\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kt\"\u003ebigint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e20\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eNOT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"no\"\u003eNULL\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eCOMMENT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;员工用户\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003ef_path\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kt\"\u003evarchar\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e200\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eDEFAULT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"no\"\u003eNULL\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eCOMMENT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;语音文件路径\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003ef_crm_id\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kt\"\u003ebigint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e20\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eNOT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"no\"\u003eNULL\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eDEFAULT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;0\u0026#39;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eCOMMENT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;客户库id\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003ef_call_type\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kt\"\u003etinyint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eunsigned\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eNOT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"no\"\u003eNULL\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eDEFAULT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;0\u0026#39;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eCOMMENT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;0:未知，1:为呼入类型，2:呼出类型\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"k\"\u003ePRIMARY\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eKEY\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003ef_id\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"k\"\u003eKEY\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003eidx_endtime_userid\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003ef_Endtime\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003ef_user_id\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003ef_qiye_id\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"k\"\u003eKEY\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003eidx_crmid\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003ef_crm_id\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"k\"\u003eKEY\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003eidx_qiye_user_calltime\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003ef_qiye_id\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003ef_Starttime\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"k\"\u003eKEY\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003eidx_calltono\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003ef_calltono\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kp\"\u003eENGINE\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eInnoDB\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eDEFAULT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kp\"\u003eCHARSET\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eutf8mb4\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e 1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 7\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 8\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 9\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e10\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e11\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e12\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-fallback\" data-lang=\"fallback\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e查询第1页的数据：\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e SELECT * FROM t_tel_record\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e WHERE f_qiye_id=xxx\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e ORDER BY f_Starttime DESC\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e LIMIT 0,100\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e当数据量很大，需要查询第10000页的数据：\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e SELECT * FROM t_tel_record\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e WHERE f_qiye_id=xxx\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e ORDER BY f_Starttime DESC\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e LIMIT 999900,100  -- 或者 OFFSET 999900 LIMIT 100\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003eMySQL的 limit m,n 工作原理就是先读取符合where条件的前面m+n条记录，然后抛弃前m条，返回后面n条，所以m越大，偏移量越大，性能就越差。这也是大部分ORM框架生成的分页sql。\u003c/p\u003e","title":"MySQL分页优化"},{"content":"1. slave_exec_mode 参数作用 slave_exec_mode 可以在主从复制中遇到 duplicate-key 和 no-key-found 错误时，自动覆盖或者略过binlog里面这个row_event，避免报错停止复制。\n这个参数原本是解决像 NDB Cluster 多节点写入冲突的情况，也可以在普通主从、双主、环形复制等情况下解决冲突，保持幂等性。幂等性怎么定义，感兴趣的可以阅读The differences between IDEMPOTENT and AUTO-REPAIR mode）。\nset global slave_exec_mode=IDEMPOTENT （可以动态修改）使从库运行在 幂等模式，对1062，1032等不同的错误类型，有不同的处理：\nwrite_row event 遇到主键冲突或唯一索引冲突，这一行被覆写(delete + insert)。 delete时候不是full value match，仅需要主键或唯一索引找到记录则删除 delete_row event 遇到记录不存在，忽略这一行 update_row event 修改唯一索引导致的冲突，忽略这一行 注意：\nidempotent 模式都是对有疑问的行进行replace或ignore，不影响其它row。 idempotent 模式要求表上必须要有主键 binlog必须是 FULL RBR 模式 2. slave-skip-errors 这个参数不能在线修改，只能加到配置文件里面或者启动的时候带上--slave-skip-errors=1032,1062。除非你真的理解它skip掉了什么，否则不建议使用。\n讲一个我所遇到的坑。在我们的一个分库项目中，需要把一个database里面的数据拆成32份，于是做了个主从，把从库里面不需要的那份删除，但复制过来肯定会报 HA_ERR_KEY_NOT_FOUND 错误，于是这也是所期望的，就设置了--slave-skip-errors=1032。\n但接下来就出现 1062:HA_ERR_FOUND_DUPP_KEY 错误！从库只会删数据，不会写入和更新，怎么会出现重复数据？读者不妨试想一下为什么。\n这里做个说明：\n1 2 3 4 5 6 7 8 ① insert into t values (1, \u0026#39;a\u0026#39;), (2, \u0026#39;b\u0026#39;), (3, \u0026#39;c\u0026#39;); ② begin; ③ delete from t where id=1; ④ delete from t where id in (1, 2, 3); ⑤ insert into t where (3, \u0026#39;c\u0026#39;), (4, \u0026#39;d\u0026#39;), (5, \u0026#39;e\u0026#39;); ⑥ update t set ... id=1; ⑦ commit; 事务包括显式事务和隐式事务(transaction)，语句①落在binlog里面也会有begin和end 一个事物可以包含多个语句(statement) 一个语句可以影响多行(row)，但属于一个event 一个语句在binlog里面有多个event (row log event, table map event, xid event\u0026hellip;) event在binlog里面以 event group 组合起来\n事务引擎如 InnoDB，event group 就一个事务；非事务引擎如 MyISAM，event group就是一条语句 slave-skip-errors 参数作用的是 statement，上面的slave_exec_mode作用的是row 比如上面那段sql在RBR复制到从库时发现④的 id=2 不存在：\nslave_exec_mode: ④里面的 id=2 略过，id=1,3 正常删除，事务里其它sql(row event)都正常重放\nslave-skip-errors=1032: 从库也会一直从 begin 执行到 end ，但④里面的 id=3 会跳过（跳过的是这个statement，而 id=1 会依然删除，不是原子操作），事务里其它sql正常重放。\n这就导致了我上面那个问题，id=3应该是被删除的但被跳过，下面在插入 id=3 的记录就 1062 了。如果再把 1062 也加入到 skip-errors，那么数据肯定会出现的丢失，是不可取的。\n相关验证可以看后文。\n3. sql_slave_skip_counter MySQL主从复制出现异常的时候，如不及时处理，延迟的时间会越来越长，所以有时候哪怕允许极少量的数据不一致，也要让数据继续同步，往往会用到 sql_slave_skip_counter 参数来跳过异常事件。 用法:\n1 2 3 4 5 mysql\u0026gt; show slave status\\G -- 1062可以看到是哪条记录重复 mysql\u0026gt; slave stop; mysql\u0026gt; set GLOBAL SQL_SLAVE_SKIP_COUNTER=1; mysql\u0026gt; slave start; sql_slave_skip_counter=1\n跳过一个 event group。前面讲到对InnoDB而言，就是跳过一个事务。 如果当前 binlog postion 落在 event group 中间，那么就一直跳到这个事务末尾。 sql_slave_skip_counter=N (N\u0026gt;1)\n跳过 N 个 event。对不同的binlog版本会加入不同的event类型。\n比如上图在 pos 199 出现error，如果设置 set global sql_slave_skip_counter=3，那么就会以此跳过 199,264,332，每跳过一个 Skip_Counter 减去1，减到 Skip_Counter=1 的时候，如果pos还在事务中间，那么那么就一直跳到该事务末尾。 (同样，在事务中出现异常之前的修改，不会回滚) 4. GTID复制异常处理 主从开启了GTID（select @@gtid_mode），就不能再用 sql_slave_skip_counter 来跳过错误，需要注册一个空gtid event来代替原本执行报错的event。比如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 mysql\u0026gt; show slave status\\G *************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 10.153.173.149 Master_User: replicator Master_Port: 3027 Connect_Retry: 60 Master_Log_File: mysql-bin.014670 Read_Master_Log_Pos: 181716556 Relay_Log_File: slave-relay.028871 Relay_Log_Pos: 166693104 Relay_Master_Log_File: mysql-bin.014670 Slave_IO_Running: Yes Slave_SQL_Running: No Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 1032 Last_Error: Could not execute Update_rows event on table mysql.user; Can\u0026#39;t find record in \u0026#39;user\u0026#39;, Error_code: 1032; handler error HA_ERR_KEY_NOT_FOUND; the event\u0026#39;s master log mysql-bin.014670, end_log_pos 166693925 Skip_Counter: 0 Exec_Master_Log_Pos: 166692941 Relay_Log_Space: 688 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: NULL Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 1032 Last_SQL_Error: Could not execute Update_rows event on table mysql.user; Can\u0026#39;t find record in \u0026#39;user\u0026#39;, Error_code: 1032; handler error HA_ERR_KEY_NOT_FOUND; the event\u0026#39;s master log mysql-bin.014670, end_log_pos 166693925 Replicate_Ignore_Server_Ids: Master_Server_Id: 1088575531 Master_UUID: 108f89d5-d74f-11e7-942f-7cd30ac4755e Master_Info_File: mysql.slave_master_info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Slave has read all relay log; waiting for the slave I/O thread to update it Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: 108f89d5-d74f-11e7-942f-7cd30ac4755e:8077-122925776 Executed_Gtid_Set: 108f89d5-d74f-11e7-942f-7cd30ac4755e:1-122925773, 8b101f33-f327-11e7-89c3-7cd30ac333bc:1-1425, fba62795-d74e-11e7-942e-7cd30ac4e7fc:1-630905526 Auto_Position: 0 1 row in set (0.00 sec) 跳过处理：\n1 2 3 4 5 mysql\u0026gt; stop slave; mysql\u0026gt; set gtid_next=\u0026#39;108f89d5-d74f-11e7-942f-7cd30ac4755e:122925774\u0026#39;; mysql\u0026gt; begin; commit; -- empty trx mysql\u0026gt; set gtid_next=\u0026#39;AUTOMATIC\u0026#39;; -- auto position mysql\u0026gt; start slave; 上面 gtid_next 的值 108f89d5-d74f-11e7-942f-7cd30ac4755e:122925774 是个会话级变量。\nuuid是 Retrieved_Gtid_Set 的uuid，一般是 Master_UUID 的值，但如果是级联复制(master -\u0026gt; slavel1 -\u0026gt; slave2)，那么要找到出错事务最原先在哪执行的 trx_id(或叫position)是 master 上正常执行的最大id + 1，即Executed_Gtid_Set里面master uuid执行过的最大值 122925773 + 1 5. pt-slave-restart pt-slave-restart 可以快速方便的恢复主从复制错误，并且支持普通 file:postion 和 GTID 模式。\n修复的原理就是运行上面的 sql_slave_skip_counter 和 gtid_next，只是它可以自动的帮DBA识别错误码，或者匹配error_msg，stop/start slave，并且默认情况下它是一直运行 检测+修复。\n1 pt-slave-restart --user=dbuser --password=xxxx --socket=/var/lib/mysql/mysql.sock --error-numbers=1032,1677,1051 几点说明一下：\n--sleep\npt-slave-restart 循环检查 show slave status 的间隔时间。如果发现有异常，下次sleep time将减半，因为它假设当前有异常，那么下一个event很有可能也异常。\n--master_uuid\n级联复制下指定了 master_uuid 才能知道事件原始来自于哪里，好让pt-slave-restart知道在哪个 max_trx_id 上面 + 1。\n在gtid模式下，pt-slave-restart 不能用在多线程复制下（即 slave_parallel_workers\u0026gt;0），因为它不知道这个GTID错误是从库哪个sql线程产生的。\n以上所有处理错误的方法，在跳过后，都需要进行数据一致性修复(pt-table-sync)，或者重做从库。\n6. 手动处理复制错误并修复 这种处理思路是写程序实现，遇到1032错误，在主库Binlog里面解析出before image，在从库插入，再stop/start slave；遇到1062错误，在从库删除这条数据（可以根据主库binlog after image取数据，也可以根据duplicate key中提示的重复记录），再stop/start/slave。\n不需要skip操作，也不需要后续修复数据（只是不会因为有跳过event而产生不一致），如果从主库拿binl log或者从库拿relay log有困难，也可使用 pymysql-replication 来伪装成从库拿到出错的 binlog postion 的内容，解析再用。\n当然为保险起见，已经出现不一致的还是要 pt-table-checksum 跑一下。\n7. 附: 测试 slave_skip_errors, slave_exec_mode 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 CREATE TABLE `t_repl_test` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(30) DEFAULT NULL, `age` int(11) DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `uk_name` (`name`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 insert into t_repl_test values(1,\u0026#39;a\u0026#39;,10), (2,\u0026#39;b\u0026#39;,20), (3,\u0026#39;c\u0026#39;,30), (4,\u0026#39;d\u0026#39;,40),(5,\u0026#39;e\u0026#39;,50); # 初始化测试数据 # master: delete from t_repl_test where id=2; # slave: delete from t_repl_test where id=3; insert into t_repl_test values(2,\u0026#39;b\u0026#39;,20); 每次测试前，数据都初始化成下面的：\n7.1 delete 测试 1. slave_skip_errors=1032,1062\nslave:\n1 2 3 4 5 6 7 mysql\u0026gt; select @@slave_skip_errors, @@slave_exec_mode; +---------------------+-------------------+ | @@slave_skip_errors | @@slave_exec_mode | +---------------------+-------------------+ | 1032,1062 | STRICT | +---------------------+-------------------+ 1 row in set (0.00 sec) mysql\u0026gt; delete from t_repl_test where id in (1,3,4); Query OK, 3 rows affected (0.00 sec)\nmysql\u0026gt; delete from t_repl_test where id in (5); Query OK, 1 row affected (0.01 sec)\nmysql\u0026gt; commit; Query OK, 0 rows affected (0.00 sec) 在从库，1和5被删除，4被跳过了，skip_error=1032作用在statement上，并且已经部分成功了的statement 不会回滚。\n2. slave_exec_mode=IDEMPOTENT\n复原。不是设置skip, 设置idempotent， slave:\n1 2 3 4 5 6 7 8 9 10 11 12 13 mysql\u0026gt; select @@slave_skip_errors, @@slave_exec_mode; +---------------------+-------------------+ | @@slave_skip_errors | @@slave_exec_mode | +---------------------+-------------------+ | OFF | IDEMPOTENT | +---------------------+-------------------+ mysql\u0026gt; select * from t_repl_test; +----+------+------+ | id | name | age | +----+------+------+ | 2 | b | 20 | +----+------+------+ 这次1, 4, 5都被删除，也就是4是一个 statement 里面某一个row_event，没有受到 id=3 error 1032的影响。\n注意\n如果slave同时设置 slave_skip_errors 和 slave_exec_mode，那么优先生效的是 slave_skip_errors。\n7.2 insert 1. slave_skip_errors=1032,1062 slave_exec_mode=STRICT\nmysql\u0026gt; insert into t_repl_test values(8,\u0026lsquo;h\u0026rsquo;,80); Query OK, 1 row affected (0.01 sec)\nmysql\u0026gt; commit; mysql\u0026gt; select * from t_repl_test; +\u0026mdash;-+\u0026mdash;\u0026mdash;+\u0026mdash;\u0026mdash;+ | id | name | age | +\u0026mdash;-+\u0026mdash;\u0026mdash;+\u0026mdash;\u0026mdash;+ | 1 | a | 10 | | 2 | b | 20 | | 4 | d | 40 | | 5 | e | 50 | | 6 | f | 60 | | 8 | h | 80 | +\u0026mdash;-+\u0026mdash;\u0026mdash;+\u0026mdash;\u0026mdash;+\n6成功，2和7失败，8成功。与delete作用范围一致。\n2. slave_skip_errors=OFF slave_exec_mode=IDEMPOTENT\nslave:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 mysql\u0026gt; select @@slave_skip_errors, @@slave_exec_mode; +---------------------+-------------------+ | @@slave_skip_errors | @@slave_exec_mode | +---------------------+-------------------+ | OFF | IDEMPOTENT | +---------------------+-------------------+ mysql\u0026gt; select * from t_repl_test; +----+------+------+ | id | name | age | +----+------+------+ | 1 | a | 10 | | 2 | bb | 200 | | 4 | d | 40 | | 5 | e | 50 | | 6 | f | 60 | | 7 | g | 70 | | 8 | h | 80 | +----+------+------+ 6, 7, 8 都插入成功，id=2的id=2被更新。所以从库在 idempotent 模式下遇到1062，是replace操作。\n3. slave_skip_errors=OFF slave_exec_mode=IDEMPOTENT unique_key\n再来看一个好玩的（id是主键，name是唯一索引）: 从库应用relay log遇到 Duplicate entry 错误有不同处理动作。\nmysql\u0026gt; insert into t_repl_test values(9,\u0026lsquo;b\u0026rsquo;,200); Query OK, 1 row affected (0.00 sec)\nmysql\u0026gt; update t_repl_test set name=\u0026lsquo;e\u0026rsquo; where id=4; Query OK, 1 row affected (0.01 sec) Rows matched: 1 Changed: 1 Warnings: 0\nmysql\u0026gt; select * from t_repl_test; +\u0026mdash;-+\u0026mdash;\u0026mdash;+\u0026mdash;\u0026mdash;+ | id | name | age | +\u0026mdash;-+\u0026mdash;\u0026mdash;+\u0026mdash;\u0026mdash;+ | 1 | a | 10 | | 3 | c | 30 | | 4 | e | 40 | | 9 | b | 200 | +\u0026mdash;-+\u0026mdash;\u0026mdash;+\u0026mdash;\u0026mdash;+ 4 rows in set (0.00 sec) mysql\u0026gt; select * from t_repl_test; +\u0026mdash;-+\u0026mdash;\u0026mdash;+\u0026mdash;\u0026mdash;+ | id | name | age | +\u0026mdash;-+\u0026mdash;\u0026mdash;+\u0026mdash;\u0026mdash;+ | 1 | a | 10 | | 4 | d | 40 | | 5 | e | 50 | | 9 | b | 200 | +\u0026mdash;-+\u0026mdash;\u0026mdash;+\u0026mdash;\u0026mdash;+ 4 rows in set (0.00 sec)\n第一条 insert 值在从库上 name=b 已经存在，违反唯一约束，所以被 replace 掉了。\n第二条 update 值在从库上 name=e 已经存在，违反唯一约束，在从库 被忽略 了。看从从库的imdepotent错误日志:\n1 2 3 2018-02-02 14:50:35 24325 [Warning] Slave SQL: Could not execute Update_rows event on table d_ec_crmlog.t_repl_test; Duplicate entry \u0026#39;e\u0026#39; for key \u0026#39;uk_name\u0026#39;, Error_code: 1062; handler error HA_ERR_FOUND_DUPP_KEY; the event\u0026#39;s master log mysql-bin.000015, end_log_pos 27072, Error_code: 1062 为什么会有这个行为，可以从源码里面找到答案：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 Write_rows_log_event::do_before_row_operations() if ((slave_exec_mode == SLAVE_EXEC_MODE_IDEMPOTENT) || (m_table-\u0026gt;s-\u0026gt;db_type()-\u0026gt;db_type == DB_TYPE_NDBCLUSTER)) { /* We are using REPLACE semantics and not INSERT IGNORE semantics when writing rows, that is: new rows replace old rows. We need to inform the storage engine that it should use this behaviour. */ /* Tell the storage engine that we are using REPLACE semantics. */ thd-\u0026gt;lex-\u0026gt;duplicates= DUP_REPLACE; /* Pretend we\u0026#39;re executing a REPLACE command: this is needed for InnoDB and NDB Cluster since they are not (properly) checking the lex-\u0026gt;duplicates flag. */ thd-\u0026gt;lex-\u0026gt;sql_command= SQLCOM_REPLACE; /* Do not raise the error flag in case of hitting to an unique attribute */ m_table-\u0026gt;file-\u0026gt;extra(HA_EXTRA_IGNORE_DUP_KEY); ... } 本文链接地址：http://xgknight.com/2018/03/11/mysql-replication-error-and-idempotent/\n","permalink":"http://localhost:1313/2018/03/mysql-replication-error-and-idempotent/","summary":"\u003ch1 id=\"1-slave_exec_mode-参数作用\"\u003e1. slave_exec_mode 参数作用\u003c/h1\u003e\n\u003cp\u003e\u003ccode\u003eslave_exec_mode\u003c/code\u003e 可以在主从复制中遇到 duplicate-key 和 no-key-found 错误时，自动覆盖或者略过binlog里面这个row_event，避免报错停止复制。\u003c/p\u003e\n\u003cp\u003e这个参数原本是解决像 NDB Cluster 多节点写入冲突的情况，也可以在普通主从、双主、环形复制等情况下解决冲突，保持幂等性。幂等性怎么定义，感兴趣的可以阅读\u003ca href=\"http://http://blog.wl0.org/2016/05/the-differences-between-idempotent-and-my-suggested-auto-repair-mode/\"\u003eThe differences between IDEMPOTENT and AUTO-REPAIR mode\u003c/a\u003e）。\u003c/p\u003e","title":"MySQL主从复制idempotent模式以及同步错误处理预案"},{"content":"MySQL Binlog 里面记录了每行数据的变更，开发有时候需要根据这些变更的时间、中间值去查问题，是bug导致的，还是用户操作引发的。然而原始binlog内容不利于检索，有段时间使用阿里RDS企业版DMS数据追踪的功能，也能完成这个工作，甚至生成回滚sql，后由于收费以及容量不够的缘故，放弃不用。\n本文所介绍的就是基于外面开源的各类组件，整合起来，达到类似数据追踪的功能 —— binlog 可视化。 功能类似：10分钟搭建MySQL Binlog分析+可视化方案\n1. 主要技术 项目地址： https://github.com/seanlook/maxwell-graylog\ndocker\n使用容器来实现资源的申请和释放，毕竟这类检索binlog内容的需求不多。 本文基于阿里云的容器服务。\nmaxwell\n从mysql server获取binlog和字段信息，组装成json流。建议先阅读 http://xgknight.com/2018/01/13/maxwell-binlog/\n官网：http://maxwells-daemon.io/\ngraylog\n代替ELK技术栈的日志收集、处理、展示平台。社区版够用，需要自行安装，也可以把 graylog 换成 ELK stack。\n官网：https://www.graylog.org/\nnxlog\nnxlog 是用 C 语言写的一个开源日志收集处理软件，它是一个模块化、多线程、高性能的日志管理解决方案，支持多平台。\n参考：http://blog.csdn.net/weixin_29477879/article/details/52183746\nrabbitmq\n一款开源消息队列中间件，采用Erlang语言开发，RabbitMQ是AMQP(Advanced Message Queueing Protocol)的标准实现。建议先阅读 http://xgknight.com/2018/01/06/rabbitmq-introduce/ 。\n你也可以把消息队列换成kafka。\n2. 使用说明 2.1 举例 查看 some3 库 2018-01-22 13:00:00 ~ 2018-01-22 13:00:00 之间，表 t_ecsome_detail 的binlog变化，graylog根据AMQP协议从rabbitmq取binlog json流\n提前创建一个 Swarm容器集群，名字叫 maxwell。\n在【编排模板】里选择 maxwell-graylog-rabbitmq，【创建应用】下一步修改编排模板： （只修改 environment 里面的变量值）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 mysql-binlogsvr: image: registry-vpc.cn-hangzhou.aliyuncs.com/workec/mysql_binlogsvr:1.1.3 volumes: - maxwellgraylog_db_data:/var/lib/mysql environment: DBINSTANCE_ID: rm-bp19t9it7c2998633 START_TIME: \u0026#39;2018-01-22 13:00:00\u0026#39; END_TIME: \u0026#39;2018-01-22 14:00:00\u0026#39; ACCESS_ID: LTAIXKHm0v6ob5P4 ACCESS_SECRET: F7g***************Nll19no MYSQL_ROOT_PASSWORD: strongpassword maxwell-svr: image: registry-vpc.cn-hangzhou.aliyuncs.com/workec/maxwell_graylog:1.1.3 depends_on: - mysql-binlogsvr environment: producer: rabbitmq MYSQL_HOST: MYSQL_USER: MYSQL_PASSWORD: MYSQL_HOST_GIT: db_some_shard3 include_dbs: include_tables: t_ecsome_detail include_column_values: init_position: rabbitmq_host: 10.81.xx.xxx rabbitmq_virtual_host: /maxwell rabbitmq_user: admin rabbitmq_pass: admin kafka_server: kafka_producer_partition_by: database MAXWELL_OPTS: volumes: - maxwellgraylog_db_data:/var/lib/mysql links: - mysql-binlogsvr:mysql_binlogsvr 2.2 变量/参数说明： DBINSTANCE_ID\n需要分析哪个实例的binlog。必须提供 ACCESS_ID, ACCESS_SECRET\n从OSS下载该实例binlog的key，这个key的用户需要RDS的读权限。必须提供 START_TIME, END_TIME\n需要分析 binlog 大致位于哪个时间段。请尽可能的精确，如果时间范围过大，可能耗时非常久。3个binlog入完graylog大约6分钟。不能保持示例默认的值\n如果你想从 MYSQL_HOST 直接在线拉取binlog，则不要设置设置 START_TIME 和 END_TIME，程序会一致从当前位置持续读取。 MYSQL_ROOT_PASSWORD\nmysql binlogsvr 的root的密码。默认为 strongpassword producer\n指定maxwell产生的binlog json流输出到哪里，完整的支持file, rabbitmq, kafka MYSQL_HOST, MYSQL_USER, MYSQL_PASSWORD\n它在两种情况下使用： 前面的START_TIME、END_TIME留空，这里的 MYSQL_HOST 代表的是maxwell直接连接的地址，持续获取binlog。maxwell的 schema_database 也在这个库上(monitor，用户需要有读写这个db的权限) 前面的START_TIME、END_TIME有值，并且没有设置 MYSQL_HOST_GIT，那么 MYSQL_HOST 代表的是从这个地址拉取表结构，相当于maxwell的 schema_host 地址（当然获取binlog还是从 mysql_binlogsvr ） MYSQL_HOST_GIT, MYSQL_HOST_GIT_COMMIT\n从git仓库拉取表结构信息，MYSQL_HOST_GIT指定仓库里面实例目录名，MYSQL_HOST_GIT_COMMIT可以满足指定某个 提交 时候的表机构版本。在 START_TIME, END_TIME 有设置的情况下才有效。\n仓库见：http://xgknight.com/2016/11/28/mysql-schema-gather-structure/ rabbitmq_host, rabbitmq_virtual_host, rabbitmq_user, rabbitmq_pass, rabbitmq_exchange_type\n在 producer=rabbitmq 才有效。这些rabbitmq_xxx选项，与maxwell配置文件里面的完全相同 过滤选项\ninclude_dbs, include_tables, include_column_values\n与maxwell配置文件里面的完全相同。这里没有列出 exclude_xxx 相关过滤项，如果要指定，请使用 MAXWELL_OPTS\nexclude_columns，去除哪些列是值不予展示，可用于脱敏。\n支持的值参考maxwell的配置文件里面正则说明。 kafka_server\n在 rabbitmq=kafka 时有效。对应 maxwell 的 kafka.bootstrap.servers 选项\n其它选项如果要指定，可以使用MAXWELL_OPTS MAXWELL_OPTS\n因为现有 environment 变量没有覆盖所有的maxwell选项，所有其它选项可以直接像 maxwell 命令行参数一样，指定在 MAXWELL_OPTS 里面。 创建完后，可以看到两个容器：\n其中 maxwell-svr 在等待 mysql_binlogsvr 就绪:\n1 2 3 maxwell-graylog-rabbitmq-some3_maxwell-svr_1 | 2018-01-26T11:58:08.424411112Z waiting for mysql_binlogsvr prepared maxwell-graylog-rabbitmq-some3_maxwell-svr_1 | 2018-01-26T11:58:28.427993770Z waiting for mysql_binlogsvr prepared maxwell-graylog-rabbitmq-some3_maxwell-svr_1 | 2018-01-26T11:58:48.431136523Z binlog download is done, wait more seconds for mysql_binlogsvr ready mysql-binlogsvr 在初始化 mysql server 的数据，下载binlog。完成的标志是在 /var/lib/mysql/initialized.lock里面写入 1 或 2，来通知 maxwell-svr。（1和2的意义见下面的Dockerfile说明） 在 maxwell-svr 日志里面看到 INFO BinlogConnectorLifecycleListener - Binlog connected. 字样，表示已经在binlog往外推。\n此时在 graylog 里面就可以看到输出内容了: http://graylog.workec.com:3003/search?q=gl2_source_input%3A5a655c3ba002a0526615062a\u0026amp;relative=0\n处理速度大概在 10000msg/s，在graylog里面没有看到新数据进来，就代表分析完成。 现在比较麻烦的地方在于，处理完结束后，销毁容器容易，但前面创建的持久存储卷，阿里云的容器服务并不会删除本地的卷，它所提供的存储推荐是 OSS,NAS,云盘 这些存储服务，然后要为它单独创建子账号，单独对某个盘、bucket授权，十分麻烦。\n本地卷并不能自动的删除，如果下次启动这个binlog分析服务，因为挂在的是同样的 db_data，里面已经有脏数据，所以需要手动删除 主机上的 rm -rf /var/lib/docker/volumes/maxwellgraylog_db_data/_data/*\n2.3 其它编排模板 上面的示例，是基于 maxwell-graylog-rabbitmq 的编排模板，已经自定义了一下compose模板：\nmaxwell-graylog-rabbitmq\n依赖于外部 rabbitmq server，需要明确指定 rabbitmq_host 等信息。\n第一次使用，通过rabbitmq-init-for-maxwell.sh去初始化 maxwell-graylog 所需要的exchange,queue等。\nmaxwell-graylog-rabbitmq-nodeps\n会比上面的多起一个容器： rabbitmq-server，但是它的数据要通过容器集群的LB，才能被外面的graylog服务消费。 它的 rabbitmq_host被指定为maxwell-rabbitmq-server (container link)\nmaxwell-graylog-file\n不适用消息队列，直接写入文件，通过 nxlog 将数据推到 graylog，所以会多出一个 nxlog 容器 多出三个 environment variabeles:\ngraylogserver\nnxlog将“日志”上报的 graylog server 地址 graylog_maxwell_gelf_port\ngraylog 节点为接收这个消息监听的端口 (NXlog Outputs) graylog_maxwell_source_collector\ngraylog 为这个消息定义好的collecter名字 （collecter是graylog的入口，在它之上定义流转、拆解、存储等流程） graylog的配置方法和搜索使用，见后文。\nmaxwell-graylog-kafka\n使用 kafka 作为消息队列。需要指定现有的 kafka_server 。\n这个编排模板，没有提供很详细的实现，请结合 MAXWELL_OPTS 使用。\n提示：\n在使用时，如果容器启动失败，观察日志后，一般可以放心的直接重启容器，已做良好的修复处理。 选择哪个模板和设置什么变量值，主要考虑两个因素：从哪里获取binlog，maxwell将binlog生产到哪里 输出到file，nxlog读取的交给graylog处理的压力会非常大，可能会导致graylog响应慢。输出到rabbitmq，可以控制流入graylog的速度(Allow throttling this input?) 2.4 docker-compose.yml 阿里云的编排模板，与标准的 docker compose 并不完全一样。在 docker-compose 目录中，提供了6种编排方案，可使用自建的docker平台来做。 4个容器和变量的组合，应对不同的场景：\ndocker-compose.file.yml\n启动 mysql-binlogsvr, maxwell-svr, nxlog-svr 三个容器，binlog数据写入file。\ndocker-compose.file-schema.yml\n启动 mysql-binlogsvr, maxwell-svr, nxlog-svr 三个容器，binlog数据写入file。\n表结构从 schema_host 获取，而不是git仓库。monitor用户需要 REPLICATION SLAVE, REPLICATION CLIENT 权限。\ndocker-compose.rabbitmq.yml\n启动 mysql-binlogsvr, maxwell-svr 两个容器，binlog数据写入现有rabbitmq。\ndocker-compose.rabbitmq-nodeps.yml\n启动 mysql-binlogsvr, maxwell-svr, rabbitmq-server 三个容器，binlog数据写入rabbitmq容器。\n不依赖外部rabbitmq。\ndocker-compose.rabbitmq-nobinlog-svr.yml\n启动 mysql-binlogsvr, maxwell-svr, rabbitmq-server 三个容器，binlog数据写入rabbitmq容器。\nmysql-binlogsvr启动后会停止，这里直接从 MYSQL_HOST 在线持续拉取binlog，用户需要能够读取表结构的权限。\ndocker-compose.kafka.yml\n启动 mysql-binlogsvr, maxwell-svr 两个容器，binlog数据写入现有kafka。\n也可以逐个启动容器，不适用 docker-compose.yml。各个容器详情见后文。\n3. graylog配置和使用 生成的binlog json流要在graylog里面可视化展示，还需要对graylog设置。下面分别以 file 和 rabbitmq 的输出为例。\n3.1 Input: file 上面已经通过 maxwell容器 将数据写入了 output_file=/var/lib/mysql/maxwell_binlog_stream.json.log，又通过 nxlog容器 tail监控这个日志文件。\n创建一个 GELF TCP Input [System / Inputs] -\u0026gt; [Inputs]\n勾选 Global 表示所有的 graylog 集群节点，都可以接收这个日志，Port： 12201 便是监听的端口。前文编排模板里面要求提供的参数 graylogserver 和 graylog_maxwell_gelf_port，就是从这来的。\n那么 Collecter graylog_maxwell_source_collector 呢，可以任意设置一个字符串。在标准的 graylog 配置流程里面，collecter 就是一个 nxlog 进程，一般一台机器就一个 nxlog，所以collecter对应的其实是收集日志的机器。\nnxlog 是一个单独的组件，与graylog没多大关系，而为了将两者整合在一起，需要 graylog-sidecar 来下发 nxlog 的配置，告诉它日志目录在哪、怎么读取日志。\n所以我们的docker容器只需要nxlog进程，不需要graylog-sidecar来交代配置，也就不需要在graylog Web界面配置NXLog Outputs/Inputs，而是直接通过变量传递来完成 nxlog.conf 模板的配置。\n下面的过程实际是不需要的，只是为了理解如何生成 nxlog.conf。\nCreate configuration 给这个 configuration 设置 tags 例如maxwell_binlog。\ngraylog-sidecar 会把 tag 打给某个机器(collecter)，告诉nxlog或其他收集组件，当前机器有哪几种日志需要收集\n编写 NXLog Outputs 相当于 nxlog.conf 中 \u0026lt;Output\u0026gt;部分，Host、Port 即第1步里面的graylog接收binlog json流而监听的地址和端口。 Type选择 [NXLog]GELF TCP output。\n编写 NXLog Inputs 相当于 nxlog.conf 中 \u0026lt;Input\u0026gt;部分，这里指定日志输入来源于文件,Type选择[NXLog]file input\nForward to 设置刚才创建的 Output File，要收集的日志路径为/var/lib/mysql/maxwell_binlog_stream.json.log Pool Interval，即检查日志文件的间隔时间。剩下的保持默认\n使用 JSON extractor 解析message 经过上面几步，启动maxwell和nxlog服务/容器之后，在graylog的 WebUI 上找到第1步建的Input，就可以看到有日志进来了。\n选择任意一个message，[Create extractor for field message] -\u0026gt; [JSON]，将json数据解压出来，存储，便可以快速根据字段名来搜索binlog内容。\n3.2 Input: rabbitmq 使用rabbitmq更简单，不需要nxlog，直接在第1步里，把新建GELF TCP改成Raw/Plaintext AMQP。\n需要填写的就是AMQP协议里broker, port, user, exchange, queue, routing_key。 就可以在binlog里面，可视化看到binlog内容了。\n3.3 在graylog里面搜索binlog日志 搜索语法：http://docs.graylog.org/en/2.4/pages/queries.html\n例如，查看 t_ecsome_detail 表中 f_some_id=1242036566 在给定时间内的变化过程：\n1 gl2_source_input:5a38cc9bd56c001305aaefc0 AND data_f_some_id: 1242036566 OR old_f_some_id: 1242036566 例如使用Quick values功能，快速得到全国各地区对t_ecsome_detail表的操作量：\n1 gl2_source_input:5a38cc9bd56c001305aaefc0 AND NOT data_f_company_region: 0 我们有做db分库，查看各个分库下的请求量数据是不是平均的，database: quick value：\n4. 容器镜像说明：Dockerfile 本节是关于细节实现的部分，与上面的介绍会略有重复。\n4.1 Dockerfile.binlogsvr 承载 binlog 的mysql server服务。\n它首先根据提供的数据库实例信息、日期时间信息，去OSS拉取已经上传的binlog到本地，修改 mysql-bin.index文件，提供binlog来源。\n因为容器停止或者销毁后，内部的数据也随之丢失，所以需要一个主机上的目录来挂在到容器中，做数据的持久化，我们把这个数据卷命名为 db_data 。\nbinlogsvr-entrypoint.sh\n容器入口。因为 mysql server 启动第一次都要进行初始化，假如容器启动失败，再次启动时不需要再次初始化。\n脚本内通过 lockfile=/var/lib/mysql/initialized.lock 区分三种工作模式：\nlockfile 存在：mysql server 已经初始化 lockfile 内容为0：mysql server 作为binlogsvr lockfile 内容为2: binlog已经下载完成。避免重启容器导致重复下载binlog lockfile 内容为1：该容器无用，因为判断 START_TIME 和 END_TIME 为空。实际上表示后续maxwell 拉取，是直接从原 MYSQL_HOST 读取，不需要该binlogsvr\nlockfile 里面的值会被 maxwell 容器读取，以便决定工作模式 download_binlog.py\n从阿里OSS下载binlog，需要提供 DBINSTANCE_ID 和 时间界限。\nrequirements.txt：python环境依赖\nmysql_3306.cnf\nbinlogsvr的启动配置文件\n4.2 Dockerfile.maxwell maxwell服务容器，主版本1.12.0，加上修改了点内容：https://github.com/seanlook/maxwell\nmaxwell-entrypoint.sh\n容器入口。会等待 mysql_binlogsvr 初始化完成，maxwell的结构、postion等信息存放在binlogsvr的 monitor 库。\nwork_mode=1: 直接从 MYSQL_HOST 拉取binlog，不需要binlogsvr，可以实现持续读取现网的binlog work_mode=0: 从 mysql_binlogsvr 拉取binlog\n该模式下因为 binlogsvr 里并没有maxwell需要的表结构，支持两种方法： 如果设置了 MYSQL_HOST_GIT，表示从我们的git仓库里面拉取表结构 否则从 MYSQL_HOST 拉取表结构，对应maxwell变量 schema_host 。即这个时候的 MYSQL_HOST 不是指定binlog来源，而是表结构来源。 如果都没设置，异常退出 maxwell启动时需要指定 init_position，即从binlog_svr哪个binlog位置开始拉取：\n如果从直接从原数据库实例拉取，则指定为最新的binlog起始点； 如果为 binlogsvr 拉取，则指定为下载的binlog最小的那个binlog起始点； 在容器启动的时候，也可以直接指定 init_postion ，优先生效。\nlockfile=/var/lib/mysql/initialized_maxwell.lock 表示已经通过 init_postion 启动，如果重启maxwell容器，应该从上次停止的地方继续。 容器启动时，可以指定 producer 为 file, rabbitmq, kafka，根据对应的生产者，应该设置子选项。见后文。\nmaxwell-retrive-tablemeta.sh\n从git拉取所需要的表结构，并用 myloader 工具导入到 binlogsvr 。\n因为考虑到需求通常要过滤表，所以这里也这会在 binlogsvr 创建需要的表结构。\n如果指定了 MYSQL_HOST_GIT_COMMIT，可以拉取git上历史表结构。\nid_rsa：文件是拉起表结构用的 ssh key。\nmaxwell-src-1.12.0.tar.gz:\n已下载的maxwell包，会通过maven编译。\n4.3 Dockerfile.nxlog 在 producer=file 时，maxwell产生的binlog stream 是文件，要把文件放到 graylog 用到 nxlog 。\n它也会挂在 db_data，读取 output_file=/var/lib/mysql/maxwell_binlog_stream.json.log 内容，发送到 graylog server 。\ngraylogserver: graylog server 地址\ngraylog_maxwell_gelf_port: 在graylog提前配置好的接收maxwell数据的端口\ngraylog_maxwell_source_collector: 对应graylog的 collector id.\n配置graylog 方法见后文。\nnxlog-entrypoint.sh\n容器入口。主要是对 /etc/nxlog/nxlog.conf 进行变量替换。\n提示：也会读取 /var/lib/mysql/maxwell_instance_id 里面由 mysql_binlogsvr 传递过来的 instance_id 作为 message 的一部分\nnxlog.conf\nnxlog的配置文件模板，用于替换成上面的变量。\n4.4 Dockerfile.rabbitmq 在 producer=rabbitmq 时，maxwell需要 rabbitmq server 作为队列。\n这里提供两种使用方法：\n如果已经有现成的 rabbitmq ，则自己创建 vhost, exchange, user，需要提供的内容见 rabbitmq-init-formaxwell.sh\n如果没有rabbitmq，则通过这个 Dockerfile 创建 rabbitmq server container\nrabbitmq-entrypoint.sh\n容器入口。只是为了调用 rabbitmq-init-formaxwell.sh，在rabbitmq起来后，创建 --vhost=/maxwell --username=admin --password=admin,exchange=maxwell.binlog queue=maxwell_binlog binding_key=# 给maxwell和graylog使用。\n在后台通过 wait-for-it.sh 来同步等待 rabbitmq ok.\n4.5 build image 1 2 3 4 5 6 7 8 9 docker build -f Dockerfile.binlogsvr . -t registry-vpc.cn-hangzhou.aliyuncs.com/workec/mysql_binlogsvr:1.1.3 docker build -f Dockerfile.maxwell . -t registry-vpc.cn-hangzhou.aliyuncs.com/workec/maxwell_graylog:1.1.3 docker build -f Dockerfile.nxlog . -t registry-vpc.cn-hangzhou.aliyuncs.com/workec/maxwell_nxlog:0.4.3 docker build -f Dockerfile.rabbitmq . -t registry-vpc.cn-hangzhou.aliyuncs.com/workec/maxwell_rabbitmq:0.4.3 docker push registry-vpc.cn-hangzhou.aliyuncs.com/workec/mysql_binlogsvr:1.1.3 docker push registry-vpc.cn-hangzhou.aliyuncs.com/workec/maxwell_graylog:1.1.3 docker push registry-vpc.cn-hangzhou.aliyuncs.com/workec/maxwell_nxlog:0.4.3 docker push registry-vpc.cn-hangzhou.aliyuncs.com/workec/maxwell_rabbitmq:0.4.3 参考\n原文连接地址：http://xgknight.com/2018/01/25/maxwell-graylog/\n","permalink":"http://localhost:1313/2018/01/maxwell-graylog/","summary":"\u003cp\u003eMySQL Binlog 里面记录了每行数据的变更，开发有时候需要根据这些变更的时间、中间值去查问题，是bug导致的，还是用户操作引发的。然而原始binlog内容不利于检索，有段时间使用阿里RDS企业版DMS数据追踪的功能，也能完成这个工作，甚至生成回滚sql，后由于收费以及容量不够的缘故，放弃不用。\u003c/p\u003e","title":"Binlog可视化搜索：实现类似阿里RDS数据追踪功能"},{"content":"应用场景：同 http://xgknight.com/2017/09/05/mysql-binlog-subscribe-simple-for-dba/ ，但更灵活：\n实时同步部分表到另外一个数据库实例 比如在数据库迁库时，将当天表的数据同步到新库，模拟阿里云dms数据传输的功能，相当于在测试环境演练，减少失误。 另外还可以从新库反向同步增量数据到老库，解决测试环境多项目测试引起数据库冲突的问题。\n正式切库时的回滚措施 比如数据库迁移项目，切换期间数据写向新库，但如果切换失败需要回滚到老库，就需要把这段时间新增的数据同步回老库（启动消费程序），这就不需要程序段再考虑复杂的回滚设计。\n数据库闪回 关于数据库误操作的闪回方案，见 文章MySQL根据离线binlog快速闪回 。binlog2sql的 -B 选项可以将sql反向组装，生产回滚sql。如果需要完善的闪回功能，要进一步开发，提高易用性。\nbinlog搜索功能 目前组内一版的binlog搜索功能，是离线任务处理的方式，好处是不会占用太大空间，缺点是处理时间较长。通过实时binlog解析过滤的方式，入ES可以快速搜索。需要进一步开发完善。 结合graylog可以实现阿里云RDS类似的数据追踪功能。见 http://xgknight.com/2018/01/25/maxwell-graylog/\nrabbitmq介绍：http://xgknight.com/2018/01/06/rabbitmq-introduce/\nmaxwell介绍：http://xgknight.com/2018/01/13/maxwell-binlog/\n数据已经生成，要完成 MySQL binlog 增量数据同步，还差一个消费者程序，将rabbitmq里面的消息取出来，在目标库重放：\n** https://github.com/seanlook/pydbsync ** 目前这个增量程序重放动作是：\nbinlog里面 insert 和 update 行，都变成 replace into binlog里面 delele ，变成 delete ignore xxx limit 1 alter/create，原封不动 所以如果表上没有主键或者唯一索引，是非常难搞定的，原本的update变成 replace into 多插入一条数据。当然如果把 update 事件改成 update tables set f1=v1,f2=v2 where f1=v1,f2=vv2 limit 1 也没毛病。\n使用python3，安装rabbitmq 的python客户端即可：pip install pika\nconfig.py\n增量程序的配置文件\ndb_info: 指定要写入的目标db rabbitmq_conn_info: 增量数据的来源，rabbitmq连接信息 rabbitmq_queue_bind: 指定怎么划分队列\n默认共用一个队列，按照范例的的格式，根据表的binlog变更量，来划分队列 binary_columns: 指定有哪些是二进制列，因为需要根据提供的信息 base64_decode 成真实数据 1 2 select TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME, DATA_TYPE from information_schema.`COLUMNS` where DATA_TYPE in (\u0026#39;binary\u0026#39;, \u0026#39;varbinary\u0026#39;, \u0026#39;blob\u0026#39;, \u0026#39;bit\u0026#39;, \u0026#39;tinyblob\u0026#39;, \u0026#39;mediumblob\u0026#39;, \u0026#39;longblob\u0026#39;) 没有则留空 timestamp_columns: 指定哪些是timestamp类型的列，因为要处理时区的问题 1 select TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME, DATA_TYPE from information_schema.`COLUMNS` where DATA_TYPE = \u0026#39;timestamp\u0026#39; 没有则留空 dbname_rewrite: 是否修改同步前后的 database name。 没有修改则留空 mysql_sync.py 启动同步。可以用多线程，或多进程 默认线程/进程数与 rabbitmq_queue_bind 指定的队列数相同。\npydbsync.py 通用的增量同步的核心程序。\nbinlog_consumer.py 是做some分库过程中用的核心程序，因为要对来自binlog的数据，根据 f_some_id 取模，插入到不同的 d_ec_someX 上，需要许多的特殊处理。 原文连接地址：http://xgknight.com/2018/01/14/rabbitmq-maxwell-consumer/\n","permalink":"http://localhost:1313/2018/01/rabbitmq-maxwell-consumer/","summary":"\u003cp\u003e应用场景：同 \u003ca href=\"http://xgknight.com/2017/09/05/mysql-binlog-subscribe-simple-for-dba/\"\u003ehttp://xgknight.com/2017/09/05/mysql-binlog-subscribe-simple-for-dba/\u003c/a\u003e ，但更灵活：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e实时同步部分表到另外一个数据库实例\n比如在数据库迁库时，将当天表的数据同步到新库，模拟阿里云dms数据传输的功能，相当于在测试环境演练，减少失误。\n另外还可以从新库反向同步增量数据到老库，解决测试环境多项目测试引起数据库冲突的问题。\u003c/p\u003e","title":"基于MySQL binlog增量数据同步方案(maxwell+rabbimt+pydbsync)"},{"content":"1. 介绍 Maxwell 是java语言编写的能够读取、解析MySQL binlog，将行更新以json格式发送到 Kafka、RabbitMQ、AWS Kinesis、Google Cloud Pub/Sub、文件，有了增量的数据流，可以想象的应用场景实在太多了，如ETL、维护缓存、收集表级别的dml指标、增量到搜索引擎、数据分区迁移、切库binlog回滚方案，等等。\n它还提供其它功能：\n支持SELECT * FROM table 的方式做全量数据初始化 支持主库发生failover后，自动恢复binlog位置（GTID） 灵活的对数据进行分区，解决数据倾斜的问题。kafka支持 database, table, column等级别的数据分区 它的实现方式是伪装成MySQL Server的从库，接收binlog events，然后根据schemas信息拼装，支持ddl,xid,rows等各种event. maxwell由 zendesk 开源：https://github.com/zendesk/maxwell ，而且维护者相当活跃。\n网上已有人对 Alibaba Cannal, Zendesk Maxwell, Yelp mysql_streamer进行对比，见文后参考 实时抓取MySQL的更新数据到Hadoop。\n类似功能的还有：http://debezium.io/docs/connectors/mysql/\n安装 使用 maxwell 非常简单，只需要jdk环境\n1 2 3 4 5 6 7 yum install -y java-1.8.0-openjdk-1.8.0.121-1.b13.el6.x86_64 curl -sLo - https://github.com/zendesk/maxwell/releases/download/v1.12.0/maxwell-1.12.0.tar.gz \\ | tar zxvf - cd maxwell-1.12.0 # 默认寻找当前目录下的 config.properties 配置文件 要求 mysql server binlog格式是 ROW， row_image 是 FULL。感受一下输出结果\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 mysql\u0026gt; update test.e set m = 5.444, c = now(3) where id = 1; { \u0026#34;database\u0026#34;:\u0026#34;test\u0026#34;, \u0026#34;table\u0026#34;:\u0026#34;e\u0026#34;, \u0026#34;type\u0026#34;:\u0026#34;update\u0026#34;, \u0026#34;ts\u0026#34;:1477053234, \u0026#34;commit\u0026#34;: true, ... \u0026#34;data\u0026#34;:{ \u0026#34;id\u0026#34;:1, \u0026#34;m\u0026#34;:5.444, \u0026#34;c\u0026#34;:\u0026#34;2016-10-21 05:33:54.631000\u0026#34;, \u0026#34;comment\u0026#34;:\u0026#34;I am a creature of light.\u0026#34; }, \u0026#34;old\u0026#34;:{ \u0026#34;m\u0026#34;:4.2341, \u0026#34;c\u0026#34;:\u0026#34;2016-10-21 05:33:37.523000\u0026#34; } } mysql\u0026gt; create table test.e ( ... ) { \u0026#34;type\u0026#34;:\u0026#34;table-create\u0026#34;, \u0026#34;database\u0026#34;:\u0026#34;test\u0026#34;, \u0026#34;table\u0026#34;:\u0026#34;e\u0026#34;, \u0026#34;def\u0026#34;:{ \u0026#34;database\u0026#34;:\u0026#34;test\u0026#34;, \u0026#34;charset\u0026#34;:\u0026#34;utf8mb4\u0026#34;, \u0026#34;table\u0026#34;:\u0026#34;e\u0026#34;, \u0026#34;columns\u0026#34;:[ {\u0026#34;type\u0026#34;:\u0026#34;int\u0026#34;, \u0026#34;name\u0026#34;:\u0026#34;id\u0026#34;, \u0026#34;signed\u0026#34;:true}, {\u0026#34;type\u0026#34;:\u0026#34;double\u0026#34;, \u0026#34;name\u0026#34;:\u0026#34;m\u0026#34;}, {\u0026#34;type\u0026#34;:\u0026#34;timestamp\u0026#34;, \u0026#34;name\u0026#34;:\u0026#34;c\u0026#34;, \u0026#34;column-length\u0026#34;:6}, {\u0026#34;type\u0026#34;:\u0026#34;varchar\u0026#34;, \u0026#34;name\u0026#34;:\u0026#34;comment\u0026#34;, \u0026#34;charset\u0026#34;:\u0026#34;latin1\u0026#34;} ], \u0026#34;primary-key\u0026#34;:[ \u0026#34;id\u0026#34; ] }, \u0026#34;ts\u0026#34;:1477053126000, \u0026#34;sql\u0026#34;:\u0026#34;create table test.e ( id int(10) not null primary key auto_increment, m double, c timestamp(6), comment varchar(255) charset \u0026#39;latin1\u0026#39; )\u0026#34;, \u0026#34;position\u0026#34;:\u0026#34;master.000006:800050\u0026#34; } data是 After image, old 是 Before image。 insert 只有后镜像，delete只有前镜像（data） type是语句类型：insert, update, delete, database-create, database-alter, database-drop, table-create, table-alter, table-drop 。\n基本配置 config.properties 配置文件里面的所有选项，都可以在启动 maxweill ./bin/maxwell 是指定，覆盖配置文件的内容。这里只讲一些常用的。\nmysql options host 指定从哪个地址的mysql获取binlog\nreplication_host 如果指定了 replication_host，那么它是真正的binlog来源的mysql server地址，而那么上面的host用于存放maxwell表结构和binlog位置的地址。 将两者分开，可以避免 replication_user 往生产库里写数据。\nschema_host 从哪个host获取表结构。binlog里面没有字段信息，所以maxwell需要从数据库查出schema，存起来。 schema_host一般用不到，但在binlog-proxy场景下就很实用。比如要将已经离线的binlog通过maxwell生成json流，于是自建一个mysql server里面没有结构，只用于发送binlog，此时表机构就可以制动从 schema_host 获取。\ngtid_mode 如果 mysql server 启用了GTID，maxwell也可以基于gtid取event。如果mysql server发生failover，maxwell不需要手动指定newfile:postion\n正常情况下，replication_host 和 schema_host都不需要指定，只有一个 --host。\nschema_database 使用这个db来存放 maxwell 需要的表，比如要复制的databases, tables, columns, postions, heartbeats. filtering include_dbs 只发送binlog里面这些databases的变更，以,号分隔，中间不要包含空格。 也支持java风格的正则，如 include_tables=db1,/db\\\\d+/，表示 db1, db2, db3\u0026hellip;这样的。（下面的filter都支持这种regex） 提示：这里的dbs指定的是真实db。比如binlog里面可能 use db1 但 update db2.ttt，那么maxwell生成的json database 内容是db2。\nexclude_dbs 排除指定的这些 databbases\ninclude_tables 只发送这些表的数据变更。不只需要指定 database.\nexclude_tables 排除指定的这些表\nexclude_columns 不输出这些字段。如果字段名在row中不存在，则忽略这个filter。\ninclude_column_values 1.12.0新引入的过滤项。只输出满足 column=values 的行，比如 include_column_values=bar=x,foo=y，如果有bar字段，那么只输出值为x的行，如果有foo字段，那么只输出值为y的行。\n如果没有对应字段，如只有bar=x没有foo字段，那么也成立。（即不是 或，也不是 与）\nblacklist_dbs 一般不用。blacklist_dbs字面上难以与exclude_dbs 分开，官网的说明也是模棱两可。\n从代码里面看出的意思是，屏蔽指定的这些dbs,tables的结构变更，与行变更过滤，没有关系。它应对的场景是，某个表上频繁的有ddl，比如truncate。\n因为往往我们只需要观察部分表的变更，所以要注意这些 include 与 exclude 的关系，记住三点：\n只要 include 有值，那么不在include里面的都排除 只要在 exclude 里面的，都排除 其它都正常输出 举个比较极端的例子：\n1 2 3 4 5 # database: db1,db2,db3,mydb ① include_dbs=db1,/db\\\\d+/ ② exclude_dbs=db2 ③ inlcude_tables=t1,t2,t3 ④ exclude_tables=t3 配置了 include_dbs，那么mydb不在里面，所以排除； 配置了 exclude_dbs，那么db2排除。剩下db1,db3 同样对 tables，剩下t1,t2 所以db1.t1, db1.t2, db3.t1, db3.t2是筛选后剩下可输出的。如果没有指定include_dbs，那么mydb.t1也可以输出。\nformatting output_ddl 是否在输出的json流中，包含ddl语句。默认 false output_binlog_position 是否在输出的json流中，包含binlog filename:postion。默认 false output_commit_info 是否在输出的json流里面，包含 commit 和 xid 信息。默认 true\n比如一个事物里，包含多个表的变更，或一个表上多条数据的变更，那么他们都具有相同的 xid，最后一个row event输出 commit:true 字段。这有利于消费者实现 事务回放，而不仅仅是行级别的回放。 output_thread_id 同样，binlog里面也包含了 thread_id ，可以包含在输出中。默认 false\n消费者可以用它来实现更粗粒度的事务回放。还有一个场景是用户审计，用户每次登陆之后将登陆ip、登陆时间、用户名、thread_id记录到一个表中，可轻松根据thread_id关联到binlog里面这条记录是哪个用户修改的。 monitoring 如果是长时间运行的maxwell，添加monitor配置，maxwell提供了http api返回监控数据。\n其它 init_position 手动指定maxwell要从哪个binlog，哪个位置开始。指定的格式FILE:POSITION:HEARTBEAT。只支持在启动maxwell的命令指定，比如 --init_postion=mysql-bin.0000456:4:0。 maxwell 默认从连接上mysql server的当前位置开始解析，如果指定 init_postion，要确保文件确实存在，如果binlog已经被purge掉了，可能需要想其它办法。见 Binlog可视化搜索：实现类似阿里RDS数据追踪功能 2. 选择合适的生产者 Maxwell是将binlog解析成json这种比较通用的格式，那么要去用它可以选择输出到哪里，比如Kafka, rabbitmq, file等，总之送到消息队列里去。每种 Producer 有自己对应的选项。\n2.1 file 1 2 producer=file output_file=/tmp/mysql_binlog_data.log 比较简单，直接指定输出到哪个文件output_file。有什么日志收集系统，可以直接从这里拿。\n2.2 rabbitmq rabbitmq 是非常流行的一个AMQP协议的消息队列服务，相关介绍请参考 rabbitmq入门\n1 2 3 4 5 6 7 8 9 10 11 producer=rabbitmq rabbitmq_host=10.81.xx.xxx rabbitmq_user=admin rabbitmq_pass=admin rabbitmq_virtual_host=/some0 rabbitmq_exchange=maxwell.some rabbitmq_exchange_type=topic rabbitmq_exchange_durable=true rabbitmq_exchange_autodelete=false rabbitmq_routing_key_template=%db%.%table% 上面的参数都很容易理解，1.12.0版本新加入rabbitmq_message_persistent控制发布消息持久化的参数。 rabbitmq_routing_key_template是按照 db.tbl 的格式指定 routing_key，在创建队列时，可以根据不同的表进入不同的队列，提高并行消费而不乱序的能力。\n因为rabbitmq搭建起来非常简单，所以我习惯用这个。\n2.3 kafka kafka是maxwell支持最完善的一个producer，并且内置了 多个版本的 kafka client(0.8.2.2, 0.9.0.1, 0.10.0.1, 0.10.2.1 or 0.11.0.1)，默认 kafka_version=0.11.0.1\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 producer=kafka # 指定kafka brokers 地址 kafka.bootstrap.servers=hosta:9092,hostb:9092 # kafka主题可以是固定的，可以是 `maxwell_%{database}_%{table}` 这种按表去自动创建的动态topic kafka_topic=maxwell # ddl单独使用的topic ddl_kafka_topic=maxwell_ddl # kafka和kenesis都支持分区，可以选择根据 database, table, primary_key, 或者column的值去做partition # maxwell默认使用database，在启动的时候会去检查是否topic是否有足够多数量的partitions，所以要提前创建好 # bin/kafka-topics.sh --zookeeper ZK_HOST:2181 --create \\ # --topic maxwell --partitions 20 --replication-factor 2 producer_partition_by=database # 如果指定了 producer_partition_by=column, 就需要指定下面两个参数 # 根据user_id,create_date两列的值去分区，partition_key形如 1178532016-10-10 18:29:04 producer_partition_columns=user_id,create_date # 如果不存在user_id或create_date，则按照database分区: producer_partition_by_fallback=database maxwell会读取kafka.开头的参数，设置到连接参数里，比如kafka.acks=1,kafka.retries=3等\n2.4 redis redis也有简单的发布订阅(pub/sub)功能\n1 2 3 4 5 6 7 producer=redis redis_host=10.47.xx.xxx redis_port=6379 # redis_auth=redis_auth redis_database=0 redis_pub_channel=maxwell 但是试用一番之后，发现如果订阅没有连上去的话，所有pub的消息是会丢失的。所以最好使用push/pop去实现。\n3. 注意事项 下面的是在使用过程中遇到的一些小问题，做下总结。\ntimestamp column maxwell对时间类型（datetime, timestamp, date）都是当做字符串处理的，这也是为了保证数据一致(比如0000-00-00 00:00:00这样的时间在timestamp里是非法的，但mysql却认，解析成java或者python类型就是null/None)。\n如果MySQL表上的字段是 timestamp 类型，是有时区的概念，binlog解析出来的是标准UTC时间，但用户看到的是本地时间。比如 f_create_time timestamp 创建时间是北京时间2018-01-05 21:01:01，那么mysql实际存储的是2018-01-05 13:01:01，binlog里面也是这个时间字符串。如果不做消费者不做时区转换，会少8个小时。被这个狠狠坑了一把。\n与其每个客户端都要考虑这个问题，我觉得更合理的做法是提供时区参数，然后maxwell自动处理时区问题，否则要么客户端先需要知道哪些列是timestamp类型，或者连接上原库缓存上这些类型。\nbinary column maxwell可以处理binary类型的列，如blob、varbinary，它的做法就是对二进制列使用 base64_encode，当做字符串输出到json。消费者拿到这个列数据后，不能直接拼装，需要 base64_decode。\n表结构不同步 如果是拿比较老的binlog，放到新的mysql server上去用maxwell拉去，有可能表结构已经发生了变化，比如binlog里面字段比 schema_host 里面的字段多一个。目前这种情况没有发现异常，比如阿里RDS默认会为 无主键无唯一索引的表，增加一个__##alibaba_rds_rowid##__，在 show create table 和 schema里面都看不到这个隐藏主键，但binlog里面会有，同步到从库。\n另外我们有通过git去管理结构版本，如果真有这种场景，也可以应对。\n大事务binlog 当一个事物产生的binlog量非常大的时候，比如迁移日表数据，maxwell为了控制内存使用，会自动将处理不过来的binlog放到文件系统\n1 2 3 4 5 6 7 8 9 10 11 12 Using kafka version: 0.11.0.1 21:16:07,109 WARN MaxwellMetrics - Metrics will not be exposed: metricsReportingType not configured. 21:16:07,380 INFO SchemaStoreSchema - Creating maxwell database 21:16:07,540 INFO Maxwell - Maxwell v?? is booting (RabbitmqProducer), starting at Position[BinlogPosition[mysql-bin.006235:24980714], lastHeartbeat=0] 21:16:07,649 INFO AbstractSchemaStore - Maxwell is capturing initial schema 21:16:08,267 INFO BinlogConnectorReplicator - Setting initial binlog pos to: mysql-bin.006235:24980714 21:16:08,324 INFO BinaryLogClient - Connected to rm-xxxxxxxxxxx.mysql.rds.aliyuncs.com:3306 at mysql-bin.006235/24980714 (sid:637 9, cid:9182598) 21:16:08,325 INFO BinlogConnectorLifecycleListener - Binlog connected. 03:15:36,104 INFO ListWithDiskBuffer - Overflowed in-memory buffer, spilling over into /tmp/maxwell7935334910787514257events 03:17:14,880 INFO ListWithDiskBuffer - Overflowed in-memory buffer, spilling over into /tmp/maxwell3143086481692829045events 但是遇到另外一个问题，overflow随后就出现异常EventDataDeserializationException: Failed to deserialize data of EventHeaderV4，当我另起一个maxwell指点之前的binlog postion开始解析，却有没有抛异常。事后的数据也表明并没有数据丢失。\n问题产生的原因还不明，Caused by: java.net.SocketException: Connection reset，感觉像读取 binlog 流的时候还没读取到完整的event，异常关闭了连接。这个问题比较顽固，github上面类似问题都没有达到明确的解决。（这也从侧面告诉我们，大表数据迁移，也要批量进行，不要一个insert into .. select 搞定）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 03:18:20,586 INFO ListWithDiskBuffer - Overflowed in-memory buffer, spilling over into /tmp/maxwell5229190074667071141events 03:19:31,289 WARN BinlogConnectorLifecycleListener - Communication failure. com.github.shyiko.mysql.binlog.event.deserialization.EventDataDeserializationException: Failed to deserialize data of EventHeaderV4{time stamp=1514920657000, eventType=WRITE_ROWS, serverId=2115082720, headerLength=19, dataLength=8155, nextPosition=520539918, flags=0} at com.github.shyiko.mysql.binlog.event.deserialization.EventDeserializer.deserializeEventData(EventDeserializer.java:216) ~[mys ql-binlog-connector-java-0.13.0.jar:0.13.0] at com.github.shyiko.mysql.binlog.event.deserialization.EventDeserializer.nextEvent(EventDeserializer.java:184) ~[mysql-binlog-c onnector-java-0.13.0.jar:0.13.0] at com.github.shyiko.mysql.binlog.BinaryLogClient.listenForEventPackets(BinaryLogClient.java:890) [mysql-binlog-connector-java-0 .13.0.jar:0.13.0] at com.github.shyiko.mysql.binlog.BinaryLogClient.connect(BinaryLogClient.java:559) [mysql-binlog-connector-java-0.13.0.jar:0.13 .0] at com.github.shyiko.mysql.binlog.BinaryLogClient$7.run(BinaryLogClient.java:793) [mysql-binlog-connector-java-0.13.0.jar:0.13.0 ] at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121] Caused by: java.net.SocketException: Connection reset at java.net.SocketInputStream.read(SocketInputStream.java:210) ~[?:1.8.0_121] at java.net.SocketInputStream.read(SocketInputStream.java:141) ~[?:1.8.0_121] at com.github.shyiko.mysql.binlog.io.BufferedSocketInputStream.read(BufferedSocketInputStream.java:51) ~[mysql-binlog-connector- java-0.13.0.jar:0.13.0] at com.github.shyiko.mysql.binlog.io.ByteArrayInputStream.readWithinBlockBoundaries(ByteArrayInputStream.java:202) ~[mysql-binlo g-connector-java-0.13.0.jar:0.13.0] at com.github.shyiko.mysql.binlog.io.ByteArrayInputStream.read(ByteArrayInputStream.java:184) ~[mysql-binlog-connector-java-0.13 .0.jar:0.13.0] at com.github.shyiko.mysql.binlog.io.ByteArrayInputStream.readInteger(ByteArrayInputStream.java:46) ~[mysql-binlog-connector-jav a-0.13.0.jar:0.13.0] at com.github.shyiko.mysql.binlog.event.deserialization.AbstractRowsEventDataDeserializer.deserializeLong(AbstractRowsEventDataD eserializer.java:212) ~[mysql-binlog-connector-java-0.13.0.jar:0.13.0] at com.github.shyiko.mysql.binlog.event.deserialization.AbstractRowsEventDataDeserializer.deserializeCell(AbstractRowsEventDataD eserializer.java:150) ~[mysql-binlog-connector-java-0.13.0.jar:0.13.0] at com.github.shyiko.mysql.binlog.event.deserialization.AbstractRowsEventDataDeserializer.deserializeRow(AbstractRowsEventDataDeserializer.java:132) ~[mysql-binlog-connector-java-0.13.0.jar:0.13.0] at com.github.shyiko.mysql.binlog.event.deserialization.WriteRowsEventDataDeserializer.deserializeRows(WriteRowsEventDataDeserializer.java:64) ~[mysql-binlog-connector-java-0.13.0.jar:0.13.0] at com.github.shyiko.mysql.binlog.event.deserialization.WriteRowsEventDataDeserializer.deserialize(WriteRowsEventDataDeserializer.java:56) ~[mysql-binlog-connector-java-0.13.0.jar:0.13.0] at com.github.shyiko.mysql.binlog.event.deserialization.WriteRowsEventDataDeserializer.deserialize(WriteRowsEventDataDeserializer.java:32) ~[mysql-binlog-connector-java-0.13.0.jar:0.13.0] at com.github.shyiko.mysql.binlog.event.deserialization.EventDeserializer.deserializeEventData(EventDeserializer.java:210) ~[mysql-binlog-connector-java-0.13.0.jar:0.13.0] ... 5 more 03:19:31,514 INFO BinlogConnectorLifecycleListener - Binlog disconnected. 03:19:31,590 WARN BinlogConnectorReplicator - replicator stopped at position: mysql-bin.006236:520531744 -- restarting 03:19:31,595 INFO BinaryLogClient - Connected to rm-xxxxxx.mysql.rds.aliyuncs.com:3306 at mysql-bin.006236/520531744 (sid:6379, cid:9220521) tableMapCache 前面讲过，如果我只想获取某几个表的binlog变更，需要用 include_tables 来过滤，但如果mysql server上现在删了一个表t1，但我的binlog是从昨天开始读取，被删的那个表t1在maxwell启动的时候是拉取不到表结构的。然后昨天的binlog里面有 t1 的变更，因为找不到表结构给来组装成json，会抛异常。\n手动在 maxwell.tables/columns 里面插入记录是可行的。但这个问题的根本是，maxwell在binlog过滤的时候，只在处理row_event的时候，而对 tableMapCache 要求binlog里面的所有表都要有。\n自己提交了一个commit，可以在做 tableMapCache 的时候也仅要求缓存 include_dbs/tables 这些表： https://github.com/seanlook/maxwell/commit/2618b70303078bf910a1981b69943cca75ee04fb\n提高消费性能 再用rabbitmq时，routing_key 是 %db%.%table%，但某些表产生的binlog增量非常大，就会导致各队列消息量很不平均，目前因为还没做到事务xid或者thread_id级别的并发回放，所以最小队列粒度也是表，尽量单独放一个队列，其它数据量小的合在一起。\n参考\nhttp://maxwells-daemon.io/config/ 实时抓取MySQL的更新数据到Hadoop MySQL CDC, Streaming Binary Logs and Asynchronous Triggers 原文连接地址：http://xgknight.com/2018/01/13/maxwell-binlog/\n","permalink":"http://localhost:1313/2018/01/maxwell-binlog/","summary":"\u003ch2 id=\"1-介绍\"\u003e1. 介绍\u003c/h2\u003e\n\u003cp\u003eMaxwell 是java语言编写的能够读取、解析MySQL binlog，将行更新以json格式发送到 Kafka、RabbitMQ、AWS Kinesis、Google Cloud Pub/Sub、文件，有了增量的数据流，可以想象的应用场景实在太多了，如ETL、维护缓存、收集表级别的dml指标、增量到搜索引擎、数据分区迁移、切库binlog回滚方案，等等。\u003c/p\u003e","title":"自建Binlog订阅服务 —— Maxwell"},{"content":"rabbitmq可以用一本书取讲，这里只是介绍一些使用过程中，常用到的基本的知识点。 官方文档覆盖的内容，非常全面：http://www.rabbitmq.com/documentation.html 。\n1. 介绍 RabbitMQ，即消息队列系统，它是一款开源消息队列中间件，采用Erlang语言开发，RabbitMQ是AMQP(Advanced Message Queueing Protocol)的标准实现。\nAMQP是一个公开发布的异步消息的规范，是提供统一消息服务的应用层标准高级消息队列协议，为面向消息的中间件设计.消息中间件主要用于组件之间的解耦，消息的发送者无需知道消息使用者的存在，反之亦然。\nhttps://www.rabbitmq.com/tutorials/amqp-concepts.html\n相对于JMS(Java Message Service)规范来说，JMS使用的是特定语言的APIs，而消息格式可自由定义，而AMQP对消息的格式和传输是有要求的，但实现不会受操作系统、开发语言以及平台等的限制。\nJMS和AMQP还有一个较大的区别：JMS有队列(Queues)和主题(Topics)两种消息传递模型，发送到 JMS队列 的消息最多只能被一个Client消费，发送到 JMS主题 的消息可能会被多个Clients消费；AMQP只有队列(Queues)，队列的消息只能被单个接受者消费，发送者并不直接把消息发送到队列中，而是发送到Exchange中，该Exchage会与一个或多个队列绑定，能够实现与JMS队列和主题同样的功能。\n另外还有一种 MQTT协议，意为消息队列遥测传输，是IBM开发的一个即时通讯协议。由于其维护一个长连接以轻量级低消耗著称，所以常用于移动端消息推送服务开发。MQTT是基于TCP的应用层协议封装，实现了异步Pub/Sub，在物联网（IoT）应用广泛。\nRabbitMQ可通过库、插件的形式，支持JMS和MQTT协议。参考：http://geek.csdn.net/news/detail/71894\n1.1 主要概念 Broker\n接收和分发消息的应用，RabbitMQ Server就是Message Broker\nExchange\nmessage到达broker的第一站，根据分发规则，匹配查询表中的routing key，分发消息到queue中去。常用的类型有：direct, topic, fanout。\n如果没有队列绑定到exchange上，那么该exchange上的消息都会被丢弃，因为它不存储消息又不知道该怎么处理消息。\nQueue\n消息队列载体，每个消息都会被投入到一个或多个队列\nBinding\n在exchange和queue之间建立关系就叫Binding，消费者声明队列的时候一般会指定routing_key，也可以叫binding_key。Binding信息被保存到exchange中的查询表中，用于message的分发依据。\nRouting Key\n这里区分一下binding和routing: binding是一个将exchange和queue关联起来的动作，routing_key可以理解成队列的一个属性，表示这个队列接受符合该routing_key的消息，routing_key需要在发送消息的时候指定。\nVhost\n于多租户和安全因素设计的，把AMQP的基本组件划分到一个虚拟的分组中，类似于网络中的namespace概念。当多个不同的用户使用同一个RabbitMQ server提供的服务时，可以划分出多个vhost，每个用户在自己的vhost创建exchange／queue等\nProducer\n消息生产者，就是投递消息的程序。只负责把消息发送exchange，附带一些消息属性。\nConsumer\n消息消费者，就是接受消息的程序。\nChannel\n如果每一次访问RabbitMQ都建立一个Connection，在消息量大的时候建立TCP Connection的开销将是巨大的，效率也较低。\nChannel是在connection内部建立的逻辑连接，如果应用程序支持多线程，通常每个thread创建单独的channel进行通讯，AMQP method包含了channel id帮助客户端和message broker识别channel，所以channel之间是完全隔离的。Channel作为轻量级的Connection极大减少了操作系统建立TCP connection的开销。\n1.2 对比 rabbitmq activemq rocketmq kafka zeromq redis\ncelery 待续\n2. 安装配置 CentOS 6.7，安装3.6.14最新稳定版本：\n1 2 3 4 wget https://packages.erlang-solutions.com/erlang-solutions-1.0-1.noarch.rpm rpm -Uvh erlang-solutions-1.0-1.noarch.rpm rpm --import https://dl.bintray.com/rabbitmq/Keys/rabbitmq-release-signing-key.asc yum install -y socat 如果机器上有epel源，先把它禁用掉：enabled=0，否则会默认从这个源按照低版本rabbitmq 。 如果已安装老版本，可能需要卸载 rpm -qa|grep erlang|awk '{print \u0026quot;yum remove -y \u0026quot;$1}'|sh 。 继续\n1 2 3 4 wget http://packages.erlang-solutions.com/rpm/centos/6/x86_64/erlang-20.1-1.el6.x86_64.rpm wget https://www.rabbitmq.com/releases/rabbitmq-server/v3.6.14/rabbitmq-server-3.6.14-1.el6.noarch.rpm yum localinstall -y erlang-20.1-1.el6.x86_64.rpm rabbitmq-server-3.6.14-1.el6.noarch.rpm 确保本地主机名能够正常解析出自己的ip，或 127.0.0.1. （ping rabbitmq-01）\n1 2 3 4 5 6 7 8 9 10 11 12 13 ulimit -S -n 4096 ulimit -n 65534 # limits.conf cat /etc/security/limits.conf * soft nofile 65535 * hard nofile 65535 # 从配置文件模板创建配置文件 sudo cp -a /usr/share/doc/rabbitmq-server-3.6.14/rabbitmq.config.example /etc/rabbitmq/rabbitmq.config # 启动 /etc/init.d/rabbitmq-server restart 默认用户名密码 guest/guest， 具有vhost / 的所有权限，只能在本地访问。 队列元数据及内容信息，默认在目录 /var/lib/rabbitmq/mnesia 下。\n2.1 配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 启用管理插件 rabbitmq-plugins enable rabbitmq_management # /etc/rabbitmq/rabbitmq.config 配置 [ {rabbit, [%% {tcp_listeners, [5672]}, {vm_memory_high_watermark, 0.6}, %% {vm_memory_high_watermark_paging_ratio, 0.5}, {hipe_compile, true} ]}, {rabbitmq_management, [%% Preload schema definitions from a previously exported definitions file. See ]} ]. %%是Erlang的注释符号。\nvm_memory_high_watermark RabbitMQ在使用当前机器的40%以上内存时候，会发出内存警告，并阻止RabbitMQ所有连接（producer连接）。这个阈值便由 vm_memory_high_watermark 控制 vm_memory_high_watermark_paging_ratio 当内存中的数据达到一定数量后，他需要被page out出来。比如默认这个ratio=0.5，机器内存8G，于是 memory watermark=0.4 * 8G几即 3.2G。3.2G * paging_raio = 1.6G，当消息挤压的量达到1.6G后，开始paging到磁盘上。 一搬不去改它。 hipe_compile 开启Erlang HiPE编译选项（相当于Erlang的jit技术），能够提高性能20%-50%。在Erlang R17后HiPE已经相当稳定，RabbitMQ官方也建议开启此选项。 开启之后，每次启动 rabbitmq-server，需要多花1分钟左右。 看下 rabbitmqctl status 信息，混个眼熟：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 Status of node \u0026#39;rabbit@rabbitmq-01\u0026#39; [{pid,6232}, {running_applications, [{rabbitmq_management,\u0026#34;RabbitMQ Management Console\u0026#34;,\u0026#34;3.6.14\u0026#34;}, {rabbitmq_management_agent,\u0026#34;RabbitMQ Management Agent\u0026#34;,\u0026#34;3.6.14\u0026#34;}, {rabbitmq_web_dispatch,\u0026#34;RabbitMQ Web Dispatcher\u0026#34;,\u0026#34;3.6.14\u0026#34;}, {cowboy,\u0026#34;Small, fast, modular HTTP server.\u0026#34;,\u0026#34;1.0.4\u0026#34;}, {rabbitmq_consistent_hash_exchange,\u0026#34;Consistent Hash Exchange Type\u0026#34;, \u0026#34;3.6.14\u0026#34;}, {rabbitmq_sharding,\u0026#34;RabbitMQ Sharding Plugin\u0026#34;,\u0026#34;3.6.14\u0026#34;}, {rabbit,\u0026#34;RabbitMQ\u0026#34;,\u0026#34;3.6.14\u0026#34;}, {amqp_client,\u0026#34;RabbitMQ AMQP Client\u0026#34;,\u0026#34;3.6.14\u0026#34;}, {rabbit_common, \u0026#34;Modules shared by rabbitmq-server and rabbitmq-erlang-client\u0026#34;, \u0026#34;3.6.14\u0026#34;}, {os_mon,\u0026#34;CPO CXC 138 46\u0026#34;,\u0026#34;2.4.3\u0026#34;}, {mnesia,\u0026#34;MNESIA CXC 138 12\u0026#34;,\u0026#34;4.15.1\u0026#34;}, {cowlib,\u0026#34;Support library for manipulating Web protocols.\u0026#34;,\u0026#34;1.0.2\u0026#34;}, {compiler,\u0026#34;ERTS CXC 138 10\u0026#34;,\u0026#34;7.1.2\u0026#34;}, {recon,\u0026#34;Diagnostic tools for production use\u0026#34;,\u0026#34;2.3.2\u0026#34;}, {syntax_tools,\u0026#34;Syntax tools\u0026#34;,\u0026#34;2.1.3\u0026#34;}, {crypto,\u0026#34;CRYPTO\u0026#34;,\u0026#34;4.1\u0026#34;}, {stdlib,\u0026#34;ERTS CXC 138 10\u0026#34;,\u0026#34;3.4.2\u0026#34;}, {kernel,\u0026#34;ERTS CXC 138 10\u0026#34;,\u0026#34;5.4\u0026#34;}]}, {os,{unix,linux}}, {erlang_version, \u0026#34;Erlang/OTP 20 [erts-9.1] [source] [64-bit] [smp:4:4] [ds:4:4:10] [async-threads:64] [hipe] [kernel-poll:true]\\n\u0026#34;}, {memory, [{connection_readers,0}, {connection_writers,0}, {connection_channels,0}, {connection_other,8864}, {queue_procs,48686248}, {queue_slave_procs,0}, {plugins,14194848}, {other_proc,12618480}, {metrics,323944}, {mgmt_db,12627800}, {mnesia,701856}, {binary,22261264}, {msg_index,634656}, {allocated_unused,364165712}, {reserved_unallocated,0}, {total,596238336}]}, {alarms,[]}, {listeners, [{clustering,25672,\u0026#34;::\u0026#34;},{amqp,5672,\u0026#34;0.0.0.0\u0026#34;},{http,15672,\u0026#34;0.0.0.0\u0026#34;}]}, {vm_memory_calculation_strategy,rss}, {vm_memory_high_watermark,0.6}, {vm_memory_limit,4952820940}, {disk_free_limit,50000000}, {disk_free,1626125135872}, {file_descriptors, [{total_limit,65435}, {total_used,58}, {sockets_limit,58889}, {sockets_used,0}]}, {processes,[{limit,1048576},{used,446}]}, {run_queue,0}, {uptime,1232025}, {kernel,{net_ticktime,60}}] 2.2 命令行 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 添加新的 vhost rabbitmqctl add_vhost /some0 rabbitmqctl list_vhost # 添加登录用户 admin rabbitmqctl add_user admin admin rabbitmqctl list_users # 设置为管理员角色 rabbitmqctl set_user_tags admin administrator # 设置权限 rabbitmqctl set_permissions -p /some0 admin \u0026#39;.*\u0026#39; \u0026#39;.*\u0026#39; \u0026#39;.*\u0026#39; rabbitmqctl list_permissions -p /some0 rabbitmqctl list_user_permissions admin 在开始介绍概念之前，先可以从Web UI上来认识一下rabbitmq: rabbitmq overview 首页监控面板:\nrabbitmq 客户端的连接信息:\n某个channel的详情:\nexchanges信息:\nqueues信息:\n策略定义:\n3. Exchange类型 AMQP 0-9-1 定义了四种内置类型的exchange type: direct, fanout, topic, header。exchange除了类型以外，还可以指定一些属性：\nName: 交换器名字。一般以 . 号分隔以作区分 Durability: 持久化的exchange在broker重启之后依然存在。相对应是 transient exchange Auto-delete: 如果设置了该属性，在最后一个队列unbound之后，exchange会自动删除 Arguments: 可以用在满足插件扩展上 alternate-exchange\nRabbitMQ自己扩展的功能，不是AMQP协议定义的。\nAlternate Exchange属性的作用，创建Exchange指定该 x-arguments 的alternate-exchange 属性，发送消息的时候根据route key没有找到可以投递的队列，这就会将此消息路由到 Alternate Exchange 属性指定的 Exchange (就是一个普通的exchange)上了。\n比如把MySQL的binlog订阅出来，因为里面有许多表，每个表的dml行数有多有少。我们可以将变更量多的表单独放到一个队列，其它表一起放到一个队列，就可以为原始的exchange添加 alternate-exchange 属性，将其它表的数据重新投递到另一个exchange。\n3.1 fanout fanout类型的exchange是最容易理解的，它会把来自生产者的消息广播到所有绑定的queues上。这种情况一般会把消息的routing_key设置为空''，甚至不关心队列的名字。如下图：\namq.gen-RQ6...和amq.gen-As8...是消费者随机生成了两个队列，绑定到fanout exchange上，C1,C2会各自收到一模一样的消息。\n3.2 direct direct类型的exchange转发消息到队列里，是直接基于消息的routing key。\nC1在声明队列的时候，指定routing_key=error。C2的队列上绑定了info,error,warning三个key。 于是error类型的消息会被同时发送到C1,C2（准确的说是两个队列上），而info,warning类型的消息只发送到队列amqp.gen-Agl...。\n如果要达到Round-Robin轮询效果，即两个Consumer依次从同一个队列里取消息，那么可以在声明队列的时候指定相同的 queue name，rabbitmq会自动均衡的发送消息给多个Consumer，可水平扩展消费者的处理能力（如果要保证处理顺序，得设置prefetch_count=1）。\n3.3 topic topic类型的exchange大大提升了消息路由的灵活性。不像fanout那样无脑的全部转发，也不像direct那样指定所有的routing_key，否则不匹配的key的消息就会被丢弃。 比如有一个收集日志的系统，模块包括auth/cron/kernel/app1/app2，日志级别包括error,info,warning。现在要把所有模块的error日志规整在一起，可以设计routing_key: \u0026lt;module\u0026gt;.\u0026lt;severity\u0026gt; (auth.error, auth.info, \u0026hellip;, app1.error, app1.info\u0026hellip;)，然后设置queue的binding_key=\u0026rsquo;*.error'\ntopic exchange 会根据 . 划分word，有以下两种正则符号用于匹配routing_key：\n*: 代表一个word #: 代表0个或多个word 拿官网的例图来说：\u0026lt;敏捷度\u0026gt;.\u0026lt;颜色\u0026gt;.\u0026lt;物种\u0026gt;\n上图创建了3个bindings:\n队列Q1的binding_key=*.orange.*，即对所有橙色的动物感兴趣 队列Q2绑定了*.*.rabbit和lazy.#，即订阅了所有和兔子相关的消息，以及反应迟钝的动物 于是：\nrouting_key为quick.orange.rabbit的消息，会被发送到两个队列 routing_key为lazy.orange.elephant的消息，也会被发送到两个队列 routing_key为quick.orange.fox的消息，只会发送到Q1 routing_key为lazy.brown.fox的消息，只会发送到Q2 routing_key为lazy.pink.rabbit的消息，只会发送到Q2。虽然匹配到了lazy.#和*.*.rabbit，但只会发送一次 routing_key为quick.brown.fox的消息，会被丢弃，因为没有任何绑定的队列得到匹配 routing_key为lazy.orange.male.rabbit的消息，还是会发送到Q2，因为 lazy.# 然而orange、quick.orange.male.rabbit，也破坏了约定，但没得到匹配，消息丢弃。 routing_key为#，接受所有消息，相当于fanout exchange routing_key没有*和#时，相当于direct exchange 3.4 headers header类型的exchange用的不多，是在routing_key不能满足使用场景的情况下(如routing_key必须是字符串)，在消息的头部加入一个或多个key/value，然后在声明队列的时候也指定要绑定的header。\nbinding的时候有个参数x-match，指定headers所有的k/v都要匹配成功（all）还是任意一个匹配则接受（any）。\n3.5 x-consistent-hash 这是个第三方插件形式存在的exchange，目前已内置于rabbitmq：https://github.com/rabbitmq/rabbitmq-consistent-hash-exchange\nx-consistent-hash类型的exchange可以根据routing_key，用一致性哈希算法，将消息路由到不同的队列上。它可以尽可能的保证每个队列上的消息数量相同，也可以随时添加更多的队列来“分流”，并且能保证同一个routing_key会进入相同的queue。\n要达到这样的效果，queue routing key必须是一个字符串类型的数字。比如Q1:routing_key=\u0026lsquo;10\u0026rsquo;, Q2:routing_key=\u0026lsquo;20\u0026rsquo;，那么消息就会按照1:2的比例，发送到Q1,Q2。\n3.6 x-modulus-hash 第三方插件形成存在的exchange，从3.6.0版本开始，也内置到了rabbitmq发行版：https://github.com/rabbitmq/rabbitmq-sharding\nx-modulus-hash类型的exchange与 x-consistent-hash 很像，也叫 sharding exchange，即将message在多个队列之间进行分区发送。它的实现方法是根据 routing_key 先获得hash，再用 Hash mod N 得到队列，N就是绑定到exchange上的队列个数。\n4. Queue属性 Queue 要先于 Exchange 创建，否则生产者发布的消息，在没有绑定队列之前，会丢失。 已存在的Queue可以重复declare，但前提是属性要相同。\nName: 队列名称。可以在应用里面指定，或者交给broker生成\nDurable：持久化的Queue在broker重启之后，依然存在。 注意，这里的持久化与消息持久无关。是个 property\nExclusive: 为True时，表示当Consumer的Connection端口之后，队列自动删除。一般由broker生成的随机队列名，指定这个选项 。 排他队列是基于连接可见的，同一连接的不同信道是可以同时访问同一个连接创建的排他队列的\nAuto-delete: 当最后一个consumer取消订阅之后，队列自动删除\nArguments: 设置可选的一些参数，如\nx-message-ttl\n消息在队里里最大存活时间，超过这个ttl就会被丢弃。单位毫秒\nx-max_length\n队列里最多容纳的消息个数，超过这个值，则会从队列头部drop掉消息\nx-max-priority\n设置了这个参数，就表示这是一个具有优先级的队列。它的值是可定义的优先级最大值，一般10以内就够了。 在生产商Publish消息的时候，消息Property上可设置Priority\nx-queue-mode\n这个参数是控制是否为\u0026quot;延迟队列\u0026quot;，Lazy Queue是在3.6.0引入的，它会尽量把消息存在磁盘上，节省内存 RabbitMQ一开始的设计初衷，是做异步、解耦，所以会把消息放在内存里面，以便快速的发送给消费者（持久化类型的消息会同时存在于磁盘和内存缓存中）。\n如果用它来暂时存放大量消息，而不消费或者消费太慢，会导致性能明显下降，因为为了释放内存，消息得swap到磁盘上 —— 会阻塞队列接收新消息。如果内存使用达到broker设置的 water-mark，也会拒绝接收新消息。\nLazy Queue(x-queue-mode=lazy)的作用就是一接收到新消息，马上存到文件系统，完全避免了前面提到的内存占用。这会增加磁盘I/O（顺序的），与处理持久化类型的消息很相似。\nx-dead-letter-exchange\n死信。当消息在一个队列中变成死信后，它能被重新publish到另一个Exchange，这个Exchange就是DLX。消息变成死信一向有以下几种情况：\n消息被拒绝（basic.reject or basic.nack）并且requeue=false 消息TTL过期 队列达到最大长度 DLX也是一下正常的Exchange同一般的Exchange没有区别，它能在任何的队列上被指定，实际上就是设置某个队列的属性，当这个队列中有死信时，RabbitMQ就会自动的将这个消息重新发布到设置的Exchange中去，进而被路由到另一个队列。\n死信被重新 requeue 时，可以改变它的routing_key，以便新的队列处理，routing_key用x-dead-letter-routing-key指定，如果不指定则继续使用消息原来的routing_key。\n5. Message属性 routing_key\n路由关键字，exchange根据这个关键字进行消息投递 delivery_mode 1: Non-persistent，消息不持久化到磁盘，尽快被消费掉。重启broker之后消息丢失 2: Persistent，消息持久化。当然被取走的消息，也就不存在了 headers\n消息头信息，key/value形式，可以认为给消息打上了各种各样的标签。可用于代替 routing_key 去路由（结合headers来下的exchange），或者第三方插件使用。 properties\n实际上 headers 和 delivery_mode 也是properties的一部分，因为使用较多，所以单独拿出去。这里也只提几个： priority\n消息优先级。数字，优先级高的消息会排在队列头部 correlation_id 和 reply_to\n这两个一般用于实现服务间RPC调用， 即生产者发起请求到rabbitmq队列，等待处理结果返回，消费者处理完消息后返回结果给调用方。\nreply_to 在消息里面告诉消费者，处理完的结果放到哪个队列，调用方根据 correlation_id 找到结果。详情参考 https://www.rabbitmq.com/tutorials/tutorial-six-python.html expiration\n消息自身的Time-To-Live，用的较少，也叫 Per-Message TTL In Publisher.\n前面提到，队列的arguemnts可以设置 x-message-ttl ，也叫 Per-Queue Message TTL In Queues.消息是否过期以两者的最小值为准，并且消息自身过期时间到了之后，不会自动从队列删除，而是在发送给消费者的时候丢弃。\n队列自身也有个 x-expires，它指的是队列在多久没有消费者连上来，超过这个时间后队列自动删除。 payload: 消息正文 6. 插件 RabbitMQ支持插件式的来扩展功能。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 列举server上安装的所有插件 # rabbitmq-plugins list Configured: E = explicitly enabled; e = implicitly enabled | Status: * = running on rabbit@rabbitmq-01 |/ [e*] amqp_client 3.6.14 [e*] cowboy 1.0.4 [e*] cowlib 1.0.2 [ ] rabbitmq_amqp1_0 3.6.14 [ ] rabbitmq_auth_backend_ldap 3.6.14 [ ] rabbitmq_auth_mechanism_ssl 3.6.14 [E*] rabbitmq_consistent_hash_exchange 3.6.14 [ ] rabbitmq_event_exchange 3.6.14 [ ] rabbitmq_federation 3.6.14 [ ] rabbitmq_federation_management 3.6.14 [ ] rabbitmq_jms_topic_exchange 3.6.14 [E*] rabbitmq_management 3.6.14 [e*] rabbitmq_management_agent 3.6.14 [ ] rabbitmq_management_visualiser 3.6.14 [ ] rabbitmq_mqtt 3.6.14 [ ] rabbitmq_random_exchange 3.6.14 [ ] rabbitmq_recent_history_exchange 3.6.14 [E*] rabbitmq_sharding 3.6.14 [ ] rabbitmq_shovel 3.6.14 [ ] rabbitmq_shovel_management 3.6.14 [ ] rabbitmq_stomp 3.6.14 [ ] rabbitmq_top 3.6.14 [ ] rabbitmq_tracing 3.6.14 [ ] rabbitmq_trust_store 3.6.14 [e*] rabbitmq_web_dispatch 3.6.14 [ ] rabbitmq_web_mqtt 3.6.14 [ ] rabbitmq_web_mqtt_examples 3.6.14 [ ] rabbitmq_web_stomp 3.6.14 [ ] rabbitmq_web_stomp_examples 3.6.14 [ ] sockjs 0.3.4 启用插件 # rabbitmq-plugins enable plugin-name 下面是几个常用插件：\nrabbitmq_management\n管理 rabbitmq server 的插件，提供给予HTTP的API和 WebUI，提供管理exchanges、管理queues、管理users、管理policies，监控，发布/接收消息。功能强大，基本是必定开启的插件。 开启管理插件后，也可以选择不使用Web界面，从 http://localhost:15672/cli/rabbitmqadmin 下载 rabbitmqadmin 命令行工具，它用在一些脚本里面会很方便。（提示： rabbitmqctl 是不能创建exchange和queue，但rabbitmqadmin可以）\nrabbitmq_federation 与MySQL Federated 存储引擎很相似，可以认为 federated exchange 是其它exchange(也叫upstream exchange)的“软连接”、“流量复制”。消息是被publish到上游exchange，然后消费者是从其它broker上的federated exchange订阅消息。 Federated exchanges/queues 是通过 AMQP 协议的Erlang客户端从真实broker里面取数据(不会消费源数据)，可以实现跨网络的消息提取，或者将不同地方的消息汇总到一处。应用场景有 broker / cluster 数据迁移，模仿真实数据的线下测试。\nrabbitmq_shovel shovel插件就是一个 消费者 + 生产者：从一个queue消费内容，发送到另一个exchange上，甚至可以对消息做些转换。你可以自己实现将消息从源broker消费，重新publish到另一个exchange，但shovel帮我们做好了。\nrabbitmq_mqtt 实现了 MQTT 3.1 协议的adapter，如文章开头所述。\nrabbitmq_consistent_hash_exchange 一致性hash exchange，如前文所述。\n6. 策略 Policy 首先为什么rabbitmq会有策略这个东西。\n前面我们讲到，queue和exchange有一些固定属性，如durable、exclusive、auto-delete等，还有一些可选参数，也叫x-arguments，如x-max-length、x-queue-mode。这些都是客户端在定义队列和交换器时指定的。\n如果事后想修改 TTL 或者 queue length limit ，那么得修改应用、重新部署，甚至涉及到删除队列，重新declare。Policy就是解决这个痛点的，在服务端对匹配的 exchanges 或者 queues 设置参数，无需动应用。更多请参考 https://www.rabbitmq.com/parameters.html\n一个 policy 包含以下内容：\nname: 策略名字 pattern: 对哪些queues(exchanges)的应用策略，正则表达式 definition: 策略内容定义，key/value形式（也可以认为是JSON格式） apply-to: 策略应用在什么身上，queues、exchanges、all。默认是all priority: 策略优先级，默认0 每个exchange/queue只能“注入”一个policy，所以如果要设置多个策略，把key/value组合成json，定义在一起。设置完成会马上生效，包括后面新创建的exchange、queues。\n1 2 3 4 5 6 7 8 将exchange设置为 alternate exchange:(策略名：AE) rabbitmqctl set_policy -p /some0 AE \u0026#34;^maxwell.some3$\u0026#34; \u0026#39;{\u0026#34;alternate-exchange\u0026#34;:\u0026#34;maxwell.AE\u0026#34;}\u0026#39; --apply-to exchanges 将vhost /some0 的所有队列都设置成 Lazy Queue rabbitmqctl set_policy -p /some0 Lazy \u0026#34;^\u0026#34; \u0026#39;{\u0026#34;queue-mode\u0026#34;:\u0026#34;lazy\u0026#34;}\u0026#39; --apply-to queues 队列名匹配 \u0026#39;two-messages\u0026#39; 的队列，设置最大队列消息数为2，超过之后的行为是 禁止接收新消息（与之对应的是 drop-head: 删除头部老的消息） rabbitmqctl set_policy my-pol \u0026#34;^two-messages$\u0026#34; \u0026#39;{\u0026#34;max-length\u0026#34;:2,\u0026#34;overflow\u0026#34;:\u0026#34;reject-publish\u0026#34;}\u0026#39; --apply-to queues 7. 消息可靠性 有的系统要保证消息不允许丢失，甚至不允许重复，有的系统追求的是高性能，所以要在性能和可靠性之间权衡。rabbitmq在多个层面提供消息可靠性保证。\n7.1 持久化 声明持久化的exchange: channel.exchange_delcare(exchange_name, durable) 声明持久化的队列：channel.queueDeclare(queue_name, durable, exclusive, auto_delete, arguments) 发布的持久化消息，投递模式为2： delivery_mode=2\nhttp://www.rabbitmq.com/reliability.html persistent\n7.1 ack \u0026amp; confirm 持久化保证了在broker或者机器出现异常的时候，消息不会丢失，要保证发送者在pub消息、接收sub消息时出现网络异常，客户端也应该有相应的处理。\nConsumer Delivery Acknowledgements rabbitmq对Consumer处理消息提供 acknowledgements 确认机制，客户端通过basic.consume注册到broker(push)，或者通过basic.get pull 消息，都可以在指定是否开启ack。\ndelivery tags是实现 ack 的关键，RabbitMQ会用 basic.deliver 方法向消费者推送消息，这个方法携带了一个 delivery tag，它是单调递增的正整数，在一个channel中唯一代表了一次投递。\n确认模式包括自动确认和手动确认。 自动确认就是rabbitmq一旦把消息发送出去后，就认为成功，完成确认。此模式性能最高，只要消费者能处理的过来，但自然降低了消息到达处理的可靠性，比如一个消息还在路上，消费者的TCP连接或者channel就关闭了，那么消息也就丢失。如果消费者处理不过来，可能会导致消息在客户端挤压，内存过载，引发异常。所以自动确认一般用在消息比较平稳、客户端能处理的来的系统。\n手动确认，就是客户端需要自己发送确认命令，包括：\nbasic.ack —— 确认成功，客户端成功处理 basic.nack —— 确认失败，客户端处理失败，但依然删掉消息 basic.reject —— 确认失败，客户端处理失败，消息不删除，可重新发送。 手动确认模式，可以控制消息处理的速度（流控QoS），通过 prefetch 设置该channel上最大没有确认的消息数，server会等待有空闲的配额时才继续发送给消费者。 手动确认模式如果不设置 prefetch_count，那么消费者可能会接收许多的消息但未ack，从而导致内存耗尽，所以这点需要小心。正常来说，100-300是个比较可控的范围。（当然如果是 pull 模式，就不存在QoS一说）\nbasic.ack和basic.nack可以设置 multiple 字段，批量确认来减少网络传输。比如说在信道 ch 上有 delivery tags 5, 6, 7, 8 没有确认，当客户端发回的确认帧是8并且 multiple=true，那么5-8的tags都被ack。\n在启用手动确认时，发生网络连接断开或者消费者崩溃，而无法返回 ack/nack 命令时，（检测方法是 heartbead）rabbitmq会自动将没有确认的消息 requeue，所以客户端处理消息时，最好能满足幂等性，即能够重复处理这些消息。\nPublisher Confirms rabbitmq对Producer发布消息提供 confirm 机制：客户端可以发送一个 confirm.select 命令将channel设置成confirm工作模式。 所有在该信道上面发布的消息都将会被指派一个唯一的ID(从1开始)，一旦消息被投递到所有匹配的队列之后，broker就会发送一个确认给生产者(basic.ack)，这就使得生产者知道消息已经正确到达目的队列了。如果消息和队列是可持久化的，那么确认消息会在将消息写入磁盘之后发出，broker回传给生产者的确认消息中delivery-tag域包含了确认消息的序列号。\n如果RabbitMQ因为自身内部错误导致消息丢失，就会发送一条nack消息，生产者应用程序同样可以在回调方法中处理该nack消息，确保消息不会再发送之前就丢失。\n然后对于需要持久化的消息的确认，不能完全保证数据被刷到磁盘上，因为每个消息调用 fsync 的带来的IO代价太高，rabbitmq会每隔几百毫秒，批量将消息从文件系统缓存 fsync 刷到磁盘。（了解MySQL的话对这个应该不陌生）\n7.2 事务 RabbitMQ 实现了AMQP 0-9-1协议里的事务，这样说唯一能确保消息不丢失的方式，信道可以设置成 transaction 模式：发布消息，commit/rollback消息。\n但是事务在这里太重了，而且会极大的降低性能。不用。\n7.3 rabbitmq分布式 待聊\n5. python使用示例 https://pika.readthedocs.io/en/0.10.0/intro.html\n下面的示例是使用Maxwell或者MySQL binlog增量流，json数据进入rabbitmq，然后通过 pika —— python版本的rabbitmq client，重新组装成sql，达到数据增量同步的效果。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 def binlog_sync(self): logger.info(\u0026#34;connect to rabbitmq server [%s], vhost=%s\u0026#34;, rabbitmq_conn_info.get(\u0026#39;host\u0026#39;), rabbitmq_conn_info.get(\u0026#39;vhost\u0026#39;, \u0026#39;/\u0026#39;)) ## rabbitmq 用户认证信息 credentials = pika.PlainCredentials(rabbitmq_conn_info.get(\u0026#39;user\u0026#39;, \u0026#39;guest\u0026#39;), rabbitmq_conn_info.get(\u0026#39;password\u0026#39;, \u0026#39;guest\u0026#39;) ) ## rabbitmq tcp连接 connection = pika.BlockingConnection( pika.ConnectionParameters( host=rabbitmq_conn_info.get(\u0026#39;host\u0026#39;), port=rabbitmq_conn_info.get(\u0026#39;port\u0026#39;, 5672), virtual_host=rabbitmq_conn_info.get(\u0026#39;vhost\u0026#39;, \u0026#39;/\u0026#39;), credentials=credentials ) ) ## rabbitmq 信道，避免频繁tcp断连 channel = connection.channel() # exchange_name = \u0026#39;maxwell.some\u0026#39; + str(self.corpmod) # exchange_other = \u0026#39;maxwell.AE\u0026#39; logger.info(\u0026#34;declare mq exchange [%s], type=[%s]\u0026#34;, self.exchange_name, self.exchange_type) ## 创建 exchange，如果已经存在相同名字，就不会重复创建，但要求属性要相同 ## 指定exchange_type，durable, arguments 。这里的alternate-exchange放到策略里从创建，因为目前maxwell作为消费者，没有支持arguemnts参数 channel.exchange_declare(exchange=self.exchange_name, exchange_type=self.exchange_type, durable=True, # arguments={\u0026#39;alternate-exchange\u0026#39;: exchange_other} ) \u0026#34;\u0026#34;\u0026#34; channel.exchange_declare(exchange=exchange_other, exchange_type=\u0026#39;topic\u0026#39;, durable=True) # alternative exchange channel.queue_declare(queue=\u0026#39;ae_other\u0026#39;, durable=True) channel.queue_bind(exchange=exchange_other, queue=\u0026#39;ae_other\u0026#39;, routing_key=\u0026#39;d_ec_some.*\u0026#39;) \u0026#34;\u0026#34;\u0026#34; logger.info(\u0026#34;declare queue name=[%s]\u0026#34;, self.queue_name) ## 创建 queue，如果以经存在相同名字的队列，则不会创建，但要求属性相同，否则报错 ## 指定了 lazy queue channel.queue_declare(queue=self.queue_name, durable=True, arguments={\u0026#39;x-queue-mode\u0026#39;: \u0026#39;lazy\u0026#39;}) ## 将routing_key 绑定到队列上 for key in self.queue_bind_key: logger.info(\u0026#34;bind routing_key [%s] to queue [%s]\u0026#34;, key, self.queue_name) channel.queue_bind(exchange=self.exchange_name, queue=self.queue_name, routing_key=key) # consume callback, internal ## 客户端处理消息 def callback(ch, method, properties, body): # print(\u0026#34; [x] Received %s\u0026#34; % body) logger.debug(\u0026#34;Received message: %s\u0026#34;, body) try: data_row = json.loads(body.decode(\u0026#39;utf-8\u0026#39;)) self.process_data(data_row) if ret == -2: # requeue ## 处理异常，如Ctrl+C断开，重新排队 logger.warning(\u0026#34;message data: %s (requeue)\u0026#34;, data_row) ch.basic_nack(delivery_tag=method.delivery_tag, requeue=True) # return except ValueError as e: logger.error(\u0026#34;proces Error: %s(skip)\u0026#34;, e) logger.error(\u0026#34; received data: %s\u0026#34;, body) ## 处理异常，但跳过 ch.basic_ack(delivery_tag=method.delivery_tag) except Exception as e: logger.error(\u0026#34;proces Error: %s(skip)\u0026#34;, e) logger.error(\u0026#34; message data: %s\u0026#34;, data_row) ch.basic_ack(delivery_tag=method.delivery_tag) else: ## 发送确认成功 ch.basic_ack(delivery_tag=method.delivery_tag) ## 设置最多 50 个未确认 channel.basic_qos(prefetch_count=50) # 开始消费，拿到的消息调用callback处理 channel.basic_consume(callback, queue=self.queue_name, no_ack=False) # print(\u0026#39; [*] Waiting for messages. To exit press CTRL+C\u0026#39;) logger.info(\u0026#34;start comsuming\u0026#34;) 参考\nhttps://www.rabbitmq.com/tutorials/amqp-concepts.html http://www.rabbitmq.com/admin-guide.html https://geewu.gitbooks.io/rabbitmq-quick/content/index.html http://blog.csdn.net/anzhsoft/article/details/19607841 http://dbaplus.cn/news-141-1464-1.html 原文连接地址：http://xgknight.com/2018/01/06/rabbitmq-introduce/\n","permalink":"http://localhost:1313/2018/01/rabbitmq-introduce/","summary":"\u003cp\u003erabbitmq可以用一本书取讲，这里只是介绍一些使用过程中，常用到的基本的知识点。\n官方文档覆盖的内容，非常全面：http://www.rabbitmq.com/documentation.html 。\u003c/p\u003e","title":"RabbitMQ 入门"},{"content":"SchemaSync是个能够在mysql数据库之间，比较并生成表结构差异的工具，项目地址 https://github.com/mmatuson/SchemaSync 。\nSchemaSync介绍与使用 因为工作中经常需要在各个环境之间同步表结构，特别是生产与测试环境之间，长时间的运行后，总会有不一致的。测试环境的表结构一般是测试验证功能之后没有问题，然后通过工单的形式由DBA在生产环境修改。但生产库的结构，如修改索引，紧急修改字段长度，久而久之就会与测试环境有差异，需要同步到测试环境。\n又或者有多套测试环境之间要保持结构同步，又比如同一类db（分库）的情况下，比较schema之间的对象差异。\nSchemaSync不仅限于表结构，它可以处理的对象还有：视图、事件、存储过程、函数、触发器、外键，与 mysql-utilities 相当。但 SchemaSync 更适合于实践：\n默认不会同步 AUTO_INCREMENT 和 COMMENT`，有选项可以控制 对不存在的对象会生成对应的CREATE，对多余的对象会生成DROP 对生成 alter\u0026hellip;column 的sql，是有列顺序的 安装简单，相比mysqldiff，要安装mysql-connector-python和一整套mysql-utilities工具 当然前两点在我自己的 mysqldiff 版本里，已经加入了支持，见 MySQL数据库表结构同步之mysqldiff\nSchemaSync安装：\n1 2 （使用virtualenv） $ pip install mysql-python pymysql schemaobject schemasync SchemaObject也是同一个作者的，专门用于操作数据库对象的库，于是schemasync只需要获取对象，比较差异，然后调用schemaobect生成sql。（SchemaObject依赖pymysql，SchemaSync依赖MySQLdb，其实可以用同一个）\nSchemaSync用法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 $ schemasync --help Usage: schemasync [options] \u0026lt;source\u0026gt; \u0026lt;target\u0026gt; source/target format: mysql://user:pass@host:port/database A MySQL Schema Synchronization Utility Options: -h, --help show this help message and exit -V, --version show version and exit. -r, --revision increment the migration script version number if a file with the same name already exists. -a, --sync-auto-inc sync the AUTO_INCREMENT value for each table. -c, --sync-comments sync the COMMENT field for all tables AND columns -D, --no-date removes the date from the file format --charset=CHARSET set the connection charset, default: utf8 --tag=TAG tag the migration scripts as \u0026lt;database\u0026gt;_\u0026lt;tag\u0026gt;. Valid characters include [A-Za-z0-9-_] --output-directory=OUTPUT_DIRECTORY directory to write the migration scrips. The default is current working directory. Must use absolute path if provided. --log-directory=LOG_DIRECTORY set the directory to write the log to. Must use absolute path if provided. Default is output directory. Log filename is schemasync.log 示例：\n1 2 3 4 $ schemasync mysql://ecuser:dbpass@10.x.xxx.141:3307/d_dbtest mysql://ecuser:dbpass@192.168.x.xxx:3306/d_dbtest --tag=BASE Migration scripts created for mysql://192.168.x.xxx/d_dbtest Patch Script: /home/zx/SchemaSync/d_dbtest_BASE.20171111.patch.sql Revert Script: /home/zx/SchemaSync/d_dbtest_BASE.20171111.revert.sql 第一个是source db，第二个是target db，是标准的 connection string url 格式。 --tag, --no-date：都是控制生成的ddl文件名格式。\n问题修复与增强 有两个小问题都是在SchemaObject里面，而且都有人 提交patch 但还没合并到主干：\nADD INDEX 语法错误，alter table t ADD INDEX ON t，不需要这个ON。在不用alter table而直接 ADD INDEX 才要。 schemaobject 生成 DEFAULT 'xx' 时不支持python3。当然文件里也只说了支持2.6,2.7 目前我们的做法是对 schemaobject/index.py 大概170行的地方，手动修改，也懒的fork自己的分支：\n1 2 - return \u0026#34;DROP INDEX `%s` ON `%s`\u0026#34; % (self.name, self.parent.name) + return \u0026#34;DROP INDEX `%s`\u0026#34; % (self.name) 另一个增强是如果我想比较一个实例下面的所有database，SchemaSync是要手动一个一个去运行，于是拉了个自己的分支，支持 mysql://user:pass@host:port/* 的格式，自动遍历实例下面所有的schema（忽略mysql,information_schema,performance_schema,sys），然后递归调用自身。使用起来就方便多了。\n代码地址：https://github.com/seanlook/SchemaSync\n1 2 3 4 5 6 7 8 9 10 11 12 13 $ schemasync mysql://ecuser:dbpass@10.x.xxx.141:3307/* mysql://ecuser:dbpass@192.168.x.xxx:3306/* --tag=BASE Migration scripts created for mysql://192.168.x.xxx/d_ec_admin Patch Script: /home/zx/SchemaSync/d_ec_admin_BASE.20171110.patch.sql Revert Script: /home/zx/SchemaSync/d_ec_admin_BASE.2017110.revert.sql ... MySQL Error 1049: Unknown database \u0026#39;d_ec_package_bak_1027\u0026#39; (Ignore) # 对db在目标库不存在的情况，忽略，不会CREAETE DATABASE ... Migration scripts created for mysql://192.168.x.xxx/d_ec_package Patch Script: /home/zx/SchemaSync/d_ec_package_BASE.20171110.patch.sql Revert Script: /home/zx/SchemaSync/d_ec_package_BASE.20171110.revert.sql $ cat *_BASE.20171110.patch.sql \u0026gt; target_schema_BASE.20171110.patch.sql 生成结构后不要盲目去执行同步，还要审查一遍，否则把不改删的字段删了就惨了。 还有，如果你在目标表上只是改变了列名，那么schema比较的时候，也是先drop在add，这个风险要自己把握。\n如果要安装这个增强后的版本，请使用这种方式安装：\n1 pip install git+https://github.com/seanlook/SchemaSync.git 原文连接地址：http://xgknight.com/2017/11/02/mysql_schemasync/\n","permalink":"http://localhost:1313/2017/11/mysql_schemasync/","summary":"\u003cp\u003eSchemaSync是个能够在mysql数据库之间，比较并生成表结构差异的工具，项目地址 \u003ca href=\"https://github.com/mmatuson/SchemaSync\"\u003ehttps://github.com/mmatuson/SchemaSync\u003c/a\u003e  。\u003c/p\u003e\n\u003ch1 id=\"schemasync介绍与使用\"\u003eSchemaSync介绍与使用\u003c/h1\u003e\n\u003cp\u003e因为工作中经常需要在各个环境之间同步表结构，特别是生产与测试环境之间，长时间的运行后，总会有不一致的。测试环境的表结构一般是测试验证功能之后没有问题，然后通过工单的形式由DBA在生产环境修改。但生产库的结构，如修改索引，紧急修改字段长度，久而久之就会与测试环境有差异，需要同步到测试环境。\u003c/p\u003e","title":"MySQL数据库表结构同步之SchemaSync"},{"content":"生产库遇到过好几例本文要讨论的案例，而且比较棘手。简而言之，有类似这样的查询 SELECT * FROM t1 where t1.f2\u0026gt;1 and t2.f2\u0026lt;100 order by t1.id，id是主键，条件里面有个range查询，就会造成优化器是选择主键，还是选择filesort问题，有些特殊情况就会选错索引，比如为了回避内存排序，选择了主键扫描，导致原本走范围过滤再sort 500ms勉强可以结束的查询，5分钟不出结果。\n下面具体来这个案例。\n1. 背景 阿里云RDS，5.6.16-log。 表 d_ec_someextend.t_tbl_test_time_08:\n1 2 3 4 5 6 7 8 CREATE TABLE `t_tbl_test_time_08` ( `f_some_id` int(11) unsigned DEFAULT \u0026#39;0\u0026#39;, `f_qiye_id` int(11) DEFAULT \u0026#39;0\u0026#39;, `f_type` tinyint(3) DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;有效联系类型 1: QQ联系，2:拨打电话，3:发送邮件，4:发送短信，5:添加跟进记录，6:拜访客户，7:EC联系，8:更新客户阶段\u0026#39;, `f_contact_time` timestamp NULL DEFAULT \u0026#39;1970-01-01 16:00:01\u0026#39;, UNIQUE KEY `some_qiye_type` (`f_some_id`,`f_qiye_id`,`f_type`), KEY `f_contact_time` (`f_contact_time`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 表索引信息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 mysql\u0026gt; show table status like \u0026#34;t_tbl_test_time_08\u0026#34;; +-----------------------+--------+---------+------------+----------+----------------+-------------+-----------------+--------------+-----------+----------------+---------------------+-------------+------------+--------------------+----------+----------------+---------+--------------+ | Name | Engine | Version | Row_format | Rows | Avg_row_length | Data_length | Max_data_length | Index_length | Data_free | Auto_increment | Create_time | Update_time | Check_time | Collation | Checksum | Create_options | Comment | Block_format | +-----------------------+--------+---------+------------+----------+----------------+-------------+-----------------+--------------+-----------+----------------+---------------------+-------------+------------+--------------------+----------+----------------+---------+--------------+ | t_tbl_test_time_08 | InnoDB | 10 | Compact | 19264318 | 45 | 882900992 | 0 | 2176843776 | 752877568 | NULL | 2017-10-25 20:27:08 | NULL | NULL | utf8mb4_general_ci | NULL | | | Original | +-----------------------+--------+---------+------------+----------+----------------+-------------+-----------------+--------------+-----------+----------------+---------------------+-------------+------------+--------------------+----------+----------------+---------+--------------+ 1 row in set mysql\u0026gt; show index from t_tbl_test_time_08; +--------------------+------------+-----------------+--------------+----------------+-----------+-------------+----------+--------+------+------------+---------+---------------+ | Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment | +--------------------+------------+-----------------+--------------+----------------+-----------+-------------+----------+--------+------+------------+---------+---------------+ | t_tbl_test_time_08 | 0 | some_qiye_type | 1 | f_some_id | A | 19264318 | NULL | NULL | YES | BTREE | | | | t_tbl_test_time_08 | 0 | some_qiye_type | 2 | f_qiye_id | A | 19264318 | NULL | NULL | YES | BTREE | | | | t_tbl_test_time_08 | 0 | some_qiye_type | 3 | f_type | A | 19264318 | NULL | NULL | YES | BTREE | | | | t_tbl_test_time_08 | 1 | f_contact_time | 1 | f_contact_time | A | 9632159 | NULL | NULL | YES | BTREE | | | +--------------------+------------+-----------------+--------------+----------------+-----------+-------------+----------+--------+------+------------+---------+---------------+ 4 rows in set 问题查询：\n1 2 3 4 select f_some_id from d_ec_some1.t_tbl_test_time_08 where f_qiye_id=5077665 and f_type=9 and f_contact_time \u0026gt; \u0026#39;2017-10-17 14:23:49\u0026#39; and f_contact_time \u0026lt; \u0026#39;2017-10-17 14:23:53\u0026#39; order by f_some_id limit 300 该表的其它查询：\n1 2 3 4 5 6 7 8 9 10 11 12 SELECT `c`.`f_some_id`, max(f_contact_time) AS `time` FROM `d_ec_some`.`t_some_relation` AS `r` LEFT JOIN `d_ec_someextend`.`t_tbl_test_time_10` AS `c` ON c.f_some_id=r.f_some_id AND c.f_type in(1,2,3,4,5,6,7) WHERE (r.f_qiye_id=\u0026#39;4047065\u0026#39; and r.f_user_id=\u0026#39;4047064\u0026#39; and c.f_some_id is not null) GROUP BY `f_some_id` ORDER BY `time` desc LIMIT 20 -- group-by, order-by select f_some_id, f_type, f_contact_time from d_ec_some1.t_tbl_test_time_08 where f_qiye_id = 1181333 and f_type \u0026gt; 0 and f_type \u0026lt; 11 and f_some_id \u0026gt; 263047293 and f_some_id \u0026lt; 780306437 order by f_some_id -- 分页 2. explain 问题查询执行计划：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 mysql\u0026gt; explain extended select f_some_id from d_ec_some1.t_tbl_test_time_08 where f_qiye_id=5077665 and f_type=9 and f_contact_time \u0026gt; \u0026#39;2017-10-17 14:23:49\u0026#39; and f_contact_time \u0026lt; \u0026#39;2017-10-17 14:23:53\u0026#39; order by f_some_id limit 300; +----+-------------+-----------------------+-------+----------------+---------------+---------+------+-------+----------+-------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-----------------------+-------+----------------+---------------+---------+------+-------+----------+-------------+ | 1 | SIMPLE | t_tbl_test_time_08 | index | f_contact_time | some_qiye_type | 12 | NULL | 16032 | 2248.49 | Using where | +----+-------------+-----------------------+-------+----------------+---------------+---------+------+-------+----------+-------------+ 1 row in set -- 指定一个索引 mysql\u0026gt; explain extended select f_some_id from d_ec_some1.t_tbl_test_time_08 use index(f_contact_time) where f_qiye_id=5077665 and f_type=9 and f_contact_time \u0026gt; \u0026#39;2017-10-17 14:23:49\u0026#39; and f_contact_time \u0026lt; \u0026#39;2017-10-17 14:23:53\u0026#39; order by f_some_id limit 300; +----+-------------+-----------------------+-------+----------------+----------------+---------+------+--------+----------+---------------------------------------------------------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-----------------------+-------+----------------+----------------+---------+------+--------+----------+---------------------------------------------------------------+ | 1 | SIMPLE | t_tbl_test_time_08 | range | f_contact_time | f_contact_time | 5 | NULL | 360478 | 100 | Using index condition; Using where; Using MRR; Using filesort | +----+-------------+-----------------------+-------+----------------+----------------+---------+------+--------+----------+---------------------------------------------------------------+ 1 row in set 解释： 第一个explain结果里面，type=index，表示 full index scan。注意这里看到的 index 不代表“查询用到索引了”。全索引扫描比全表扫描并不好到拿去，甚至更慢（因为随机IO）。是否用到正确的索引要看key那一列: some_qiye_type 索引定义是 (f_some_id,f_qiye_id,f_type)，从key_len=12看得出这三列都用上了（12=4+5+3）。但实际这个执行计划需要200多秒。\n第二个explain，在sql里面指定了 use index(f_contact_time)，依据是where条件里面f_contact_time的范围固定4s，猜想数据量不会很大，过滤效果会比较好。 解释器结果，type=range，表示是个范围查找(“范围”涵盖的种类不止\u0026lt;/\u0026gt;)，使用的索引是 f_contact_time(f_contact_time)。Extra列:\nUsing index condition: 用到了索引下推特性。Using where是回表拿数据。关于ICP见文后参考。 Using MRR: 用到了 Multi-Range Read 优化特性。mysql在通过二级索引范围查找的时候，得到的记录在物理上是无序的，为了减少去获取数据的随机IO，它会在内存缓冲区里面先根据rowid快速排序，然后顺序IO去拉取数据。（这个缓冲区大小参数由 read_rnd_buffer_size 控制） Using filesort: 需要内存排序。对应 order by f_some_id rows扫描虽然36w行，比前面的 16032 要多，但这个执行计划实际运行只需要0.7s，要快将近300倍。\n但MySQL优化器默认选择了第一个更慢的执行计划，它的理由是走 some_qiye_type 索引不需要内存排序，候选的 f_contact_time 被淘汰。mysql是基于cost的，所以在想是不是有什么参数可以改变optimizer的行为，让它filesort。 （这里提一下，这类查询该表上非常多，绝大部分都走的是 f_contact_time，偶尔会有几条走some_qiye_type。这种执行计划不稳定的查询，实际带来的风险是会很高的，可能会拖垮db）\n这里我们祭出优化sql的两大法宝：profiling和optimizer_trace，来尝试找出是什么因素。\nprofiling：可以定位出sql从接受到返回结果，时间都耗在哪里 optimizer_trace: 跟踪优化器的成本评估过程，可以情况的看到它如何从多个候选索引里，做出选择 3. profiling 先来看两种查询计划 profiling 的结果。\nprofiling 默认\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 mysql\u0026gt; set profiling=1; mysql\u0026gt; select f_some_id from d_ec_some1.t_tbl_test_time_08 where f_qiye_id=5077665 and f_type=9 and f_contact_time \u0026gt; \u0026#39;2017-10-17 14:23:49\u0026#39; and f_contact_time \u0026lt; \u0026#39;2017-10-17 14:23:53\u0026#39; order by f_some_id limit 300; mysql\u0026gt; show profile block io,cpu for query 1; +----------------------+------------+------------+------------+--------------+---------------+ | Status | Duration | CPU_user | CPU_system | Block_ops_in | Block_ops_out | +----------------------+------------+------------+------------+--------------+---------------+ | starting | 0.000121 | 0 | 0 | 0 | 0 | | checking permissions | 3.2E-5 | 0 | 0 | 0 | 0 | | Opening tables | 3.7E-5 | 0 | 0 | 0 | 0 | | init | 4.2E-5 | 0 | 0 | 0 | 0 | | System lock | 2.9E-5 | 0 | 0 | 0 | 0 | | optimizing | 3.3E-5 | 0 | 0 | 0 | 0 | | statistics | 0.005796 | 0 | 0.000999 | 448 | 0 | | preparing | 4.3E-5 | 0 | 0 | 0 | 0 | | Sorting result | 2.8E-5 | 0 | 0 | 0 | 0 | | executing | 2.7E-5 | 0 | 0 | 0 | 0 | | Sending data | 172.824522 | 189.040262 | 2.441629 | 1504928 | 6896 | | end | 8.3E-5 | 0 | 0 | 0 | 0 | | query end | 3E-5 | 0 | 0 | 0 | 0 | | closing tables | 3.3E-5 | 0 | 0 | 0 | 0 | | freeing items | 7E-5 | 0 | 0 | 0 | 0 | | logging slow query | 3.1E-5 | 0 | 0 | 0 | 0 | | Opening tables | 3.4E-5 | 0 | 0 | 0 | 0 | | System lock | 7E-5 | 0 | 0 | 0 | 8 | | cleaning up | 9.5E-5 | 0 | 0 | 0 | 0 | +----------------------+------------+------------+------------+--------------+---------------+ 19 rows in set mysql\u0026gt; show status like \u0026#34;Handler%\u0026#34;; +----------------------------+---------+ | Variable_name | Value | +----------------------------+---------+ | Handler_commit | 1 | | Handler_delete | 0 | | Handler_discover | 0 | | Handler_external_lock | 4 | | Handler_mrr_init | 0 | | Handler_prepare | 0 | | Handler_read_first | 1 | | Handler_read_key | 1 | | Handler_read_last | 0 | | Handler_read_next | 9430930 | | Handler_read_prev | 0 | | Handler_read_rnd | 0 | | Handler_read_rnd_next | 0 | | Handler_rollback | 0 | | Handler_savepoint | 0 | | Handler_savepoint_rollback | 0 | | Handler_update | 0 | | Handler_write | 1 | +----------------------------+---------+ 18 rows in set profiling use index:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 mysql\u0026gt; set profiling=1; mysql\u0026gt; select .... use index(f_contact_time) mysql\u0026gt; show profile block io,cpu for query 1; +----------------------+----------+----------+------------+--------------+---------------+ | Status | Duration | CPU_user | CPU_system | Block_ops_in | Block_ops_out | +----------------------+----------+----------+------------+--------------+---------------+ | starting | 0.00013 | 0 | 0 | 0 | 0 | | checking permissions | 3.4E-5 | 0 | 0 | 0 | 0 | | Opening tables | 4.5E-5 | 0 | 0 | 0 | 0 | | init | 4.6E-5 | 0 | 0 | 0 | 0 | | System lock | 3E-5 | 0 | 0 | 0 | 0 | | optimizing | 3.9E-5 | 0 | 0 | 0 | 0 | | statistics | 0.000109 | 0 | 0 | 0 | 0 | | preparing | 5.5E-5 | 0 | 0 | 0 | 0 | | Sorting result | 3.1E-5 | 0 | 0 | 0 | 0 | | executing | 3.2E-5 | 0 | 0 | 0 | 0 | | Sending data | 3.4E-5 | 0 | 0 | 0 | 0 | | Creating sort index | 1.703224 | 1.718739 | 0.012999 | 0 | 0 | | end | 8.4E-5 | 0 | 0 | 0 | 0 | | query end | 3.2E-5 | 0 | 0 | 0 | 0 | | closing tables | 3.9E-5 | 0 | 0 | 0 | 0 | | freeing items | 7.3E-5 | 0 | 0 | 0 | 0 | | logging slow query | 3.2E-5 | 0 | 0 | 0 | 0 | | Opening tables | 5E-5 | 0 | 0 | 0 | 0 | | System lock | 6.9E-5 | 0 | 0 | 0 | 8 | | cleaning up | 4.1E-5 | 0 | 0 | 0 | 0 | +----------------------+----------+----------+------------+--------------+---------------+ 20 rows in set set profiling=0; mysql\u0026gt; show status like \u0026#34;Handler%\u0026#34;; +----------------------------+--------+ | Variable_name | Value | +----------------------------+--------+ | Handler_commit | 1 | | Handler_delete | 0 | | Handler_discover | 0 | | Handler_external_lock | 6 | | Handler_mrr_init | 0 | | Handler_prepare | 0 | | Handler_read_first | 0 | | Handler_read_key | 188156 | | Handler_read_last | 0 | | Handler_read_next | 188155 | | Handler_read_prev | 0 | | Handler_read_rnd | 188155 | | Handler_read_rnd_next | 0 | | Handler_rollback | 0 | | Handler_savepoint | 0 | | Handler_savepoint_rollback | 0 | | Handler_update | 0 | | Handler_write | 1 | +----------------------------+--------+ 18 rows in set 第一个profiling 看到第一个profiling里面 Sending data 时间最长，第二个 Creating sort index 最久\n1 2 3 4 5 Sending data: The thread is reading and processing rows for a SELECT statement, and sending data to the client. Because operations occurring during this state tend to perform large amounts of disk access (reads), it is often the longest-running state over the lifetime of a given query. Creating sort index The thread is processing a SELECT that is resolved using an internal temporary table Sending data 很具有误导性，它不仅表示发送数据到客户端，还包括“收集”数据，即mysql根据索引条件检索完数据后，得到一堆rowid，再根据rowid回表拿数据，有可能还要对数据过滤、排序，所以抛开网络因素，sending data时间长表明有大量的读磁盘操作，是非常笼统的一个状态。 下面的status里面\nHandler_read_first: 索引里面第一条记录被读取的次数，为1，说明做了一次索引全扫描。与前面 explain 结果 type=index 是一致的。\nHandler_read_key：根据索引定位到一行记录的次数。这个值越高，说明使用到了高效的索引。\nHandler_read_next： Number of requests to read the next row in key order, incremented if you are querying an index column with a range constraint or if you are doing an index scan.\n即根据索引key的顺序，依次去获取行数据的次数。 这个值在这里非常的大，表明Server读取从头读取索引 (f_some_id,f_qiye_id,f_type) key的 9430930 行数据之后，找到了300个满足条件的记录，并且已是排好顺序。在这里值会随着limit的增大而增大。\n第二个profiling\nHandler_read_rnd： The number of requests to read a row based on a fixed position. This value is high if you are doing a lot of queries that require sorting of the result. You probably have a lot of queries that require MySQL to scan entire tables or you have joins that don\u0026rsquo;t use keys properly.\n随机读取行数据的次数，可以认为是有一堆没有顺序的主键，要依次去读取数据的次数（随机IO）。一般在有内存排序的时候，后者join查询的副表关联字段上没有好的索引，这个值都会比较高。\n经过计算，条件满足 f_contact_time \u0026gt; '2017-10-17 14:23:49' and f_contact_time \u0026lt; '2017-10-17 14:23:53' 的记录有188155 个，因此根据索引依次读取到的行数 Handler_read_key=188155。\n这里有两个疑问个人没有解开：\n既然有MRR，Handler_read_rnd为什么还这么高呢，不应该是是顺序IO了？ 这里不太肯定，两种可能：一是MRR不影响这个计数；第二种可能是，我们这个表上没有主键，唯一索引也不满足所有列都NOT NULL定义，也就是这个表的主键实际是innodb内部维持增长的rowid，使用MRR之后，rowid有序但并不连续，读取行的随机性没有得到大的改善。 Using index condition 在这里有点费解，因为似乎没有where条件可以下推，f_contact_time索引只有 f_contact_time 这一列。 上面的分析过程只能知道实际执行过程是怎样的，直接从explain也能看出结果，这里是顺便理解一下 Hander_read_xxx, MRR, ICP 的含义，大部分sql优化都不用不到profiling和status。\n4. optimizer_trace 再看 optimizer_trace 跟踪的结果：(因为trace的信息太长，放到github gist上了)\ndefault： https://gist.github.com/seanlook/fe7d9065b1c05e766d88b4a5c3babb65 use index：https://gist.github.com/seanlook/b687daf63c8babee96f567c123cb9ddd optimizer_trace包含三个步骤，下面是本次trace简化的结构：\njson_preparation json_optimization condition_processing equality_propagation constant_propagation trivial_condition_removal table_dependencies ref_optimizer_key_uses rows_estimation range_analysis table_scan potential_range_indices chosen_range_access_summary considered_execution_plans best_access_path attaching_conditions_to_tables attached_conditions_computation rechecking_index_usage clause_processing refine_plan pushed_index_condition access_type reconsidering_access_paths_for_index_ordering plan_changed access_type, index json_execution 可以看到上面default与use index两次的trace，前大半部分都是一样的，候选索引都是 access_type=range, index=f_contact_time，就在 reconsidering_access_paths_for_index_ordering 的地方，“一票否决”，从而选择了 access_type=index_scan, index=some_qiye_type。\n搜索 reconsidering_access_paths_for_index_ordering 可以在mysql或percona的官网上，找到四五个相关的 bug report ：\n#70245，#78997，percona#1362212，#74602 网上提及比较多的是 #70245，调整参数 eq_range_index_dive_limit 可解决这个问题。我们也遇到过这个案例，见 MySQL 5.6 查询优化器新特性的“BUG” 。但是本文的例子满足range的个数达到18w(explain估算是36w)，也试着加大这个参数从2到800000，都没作用。\n#74602 这个说的是low_limit导致的，刚好在 optimizer_trace 里面的 rechecking_index_usage:recheck_reason:low_limit 。 测试神奇的发发现，上面的查询limit有个分解值，会选择不同的索引： （https://gist.github.com/seanlook/64990b956bf986eaeece5b26055f2f18 limit 8168后默认选择filesort的trace）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 mysql\u0026gt; explain select f_some_id from d_ec_some1.t_tbl_test_time_08 where f_qiye_id=5077665 and f_type=9 and f_contact_time \u0026gt; \u0026#39;2017-10-17 14:23:49\u0026#39; and f_contact_time \u0026lt; \u0026#39;2017-10-17 14:23:53\u0026#39; order by f_some_id limit 8167; +----+-------------+-----------------------+-------+----------------+----------------+---------+------+--------+-------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+-------------+-----------------------+-------+----------------+----------------+---------+------+--------+-------------+ | 1 | SIMPLE | t_tbl_test_time_08 | index | f_contact_time | some_qiye_type | 12 | NULL | 414115 | Using where | +----+-------------+-----------------------+-------+----------------+----------------+---------+------+--------+-------------+ 1 row in set mysql\u0026gt; explain select f_some_id from d_ec_some1.t_tbl_test_time_08 where f_qiye_id=5077665 and f_type=9 and f_contact_time \u0026gt; \u0026#39;2017-10-17 14:23:49\u0026#39; and f_contact_time \u0026lt; \u0026#39;2017-10-17 14:23:53\u0026#39; order by f_some_id limit 8168; +----+-------------+-----------------------+-------+----------------+----------------+---------+------+--------+---------------------------------------------------------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+-------------+-----------------------+-------+----------------+----------------+---------+------+--------+---------------------------------------------------------------+ | 1 | SIMPLE | t_tbl_test_time_08 | range | f_contact_time | f_contact_time | 5 | NULL | 360478 | Using index condition; Using where; Using MRR; Using filesort | +----+-------------+-----------------------+-------+----------------+----------------+---------+------+--------+---------------------------------------------------------------+ 1 row in set 具体为啥这样，bug里面没说，只是提到5.7已修复，5.6应该不会修复。\n5. 解决办法 其实做sql优化，执行计划不稳定这种，是不容易搞定的，因为并不是这个sql所有都会慢，而是不同值的特征，走不同的索引，会偶发性的慢。优化索引的时候，反而容易把原本较快的查询的索引改掉，造成更大的灾难。\n本文的sql便是如此。从业务那边了解到，f_contact_time范围是固定4s，99%的情况，这个索引效率很高，但是正好有一大批数据(18万) f_contact_time=\u0026lsquo;2017-10-17 14:23:51\u0026rsquo;，导致优化器做出了自己以为更优的决定。\n那么解决这个问题，就是要去掉干扰因素，或者提供更优的选项给它。\n去掉干扰因素 干扰它的索引是 some_qiye_type，是个唯一索引，因为恰好f_some_id开头，索引优化器想当然的用它来避免排序。 去掉这个干扰因素就是调换 f_qiye_id,f_some_id的顺序。调换顺序还有个好处，有f_qiye_id等值条件，可以用在索引检索上。 但是它的负面作用有两个： 原本这个表上有 f_some_id 的等值、join ref以及分页查询，调换索引这两个字段顺序后，全都变成慢查询 f_qiye_id作为第一列，满足条件的值可能会有上百万，对这个查询的改观不大 提供更优的索引 添加索引 (f_qiye_id,f_contact_time) 看起来不错。这样一来，该类查询都会走这个索引 另外这个表上只有一个唯一索引，而且该唯一索引有字段允许null，所以没有主键。 加一个自增主键 f_id bigint unsigned not null 修改f_some_id字段为 f_some_id bigint unsigned NOT NULL 修改f_qiye_id字段为 f_qiye_id int unsigned NOT NULL 修改字段f_type字段为 tinyint NOT NULL 总之一句话：所有（作为索引的）字段，都定义为NOT NULL，f_some_id全部定义为bigint。最终表结构：\n1 2 3 4 5 6 7 8 9 10 CREATE TABLE `t_tbl_test_time_16` ( `f_id` bigint(20) unsigned NOT NULL AUTO_INCREMENT, `f_some_id` bigint(20) unsigned NOT NULL, `f_qiye_id` int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39;, `f_type` tinyint(3) NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;有效联系类型 1: QQ联系，2:拨打电话，3:发送邮件，4:发送短信，5:添加跟进记录，6:拜访客户，7:EC联系，8:更新客户阶段\u0026#39;, `f_contact_time` timestamp NOT NULL DEFAULT \u0026#39;1970-01-01 16:00:01\u0026#39;, PRIMARY KEY(f_id), UNIQUE KEY `some_qiye_type` (`f_some_id`,`f_qiye_id`,`f_type`) USING BTREE, KEY `idx_qiye_time` (`f_qiye_id`,`f_contact_time`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 或者唯一索引变成联合主键（关于自增主键与联合主键的选择，参考 http://xgknight.com/2016/05/13/mysql-innodb-primary_key/ ）\n1 2 3 4 5 6 7 8 9 CREATE TABLE `t_tbl_test_time_16` ( `f_some_id` bigint(20) unsigned NOT NULL, `f_qiye_id` int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39;, `f_type` tinyint(3) NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;有效联系类型 1: QQ联系，2:拨打电话，3:发送邮件，4:发送短信，5:添加跟进记录，6:拜访客户，7:EC联系，8:更新客户阶段\u0026#39;, `f_contact_time` timestamp NOT NULL DEFAULT \u0026#39;1970-01-01 16:00:01\u0026#39;, PRIMARY KEY(`f_qiye_id`,`f_some_id`,`f_type`), KEY `idx_qiye_time` (`f_qiye_id`,`f_contact_time`), KEY `idx_some`(`f_some_id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 原文连接地址：http://xgknight.com/2017/10/26/mysql-bad-plan-order_by-limit/\n","permalink":"http://localhost:1313/2017/10/mysql-bad-plan-order_by-limit/","summary":"\u003cp\u003e生产库遇到过好几例本文要讨论的案例，而且比较棘手。简而言之，有类似这样的查询 \u003ccode\u003eSELECT * FROM t1 where t1.f2\u0026gt;1 and t2.f2\u0026lt;100 order by t1.id\u003c/code\u003e，id是主键，条件里面有个range查询，就会造成优化器是选择主键，还是选择filesort问题，有些特殊情况就会选错索引，比如为了回避内存排序，选择了主键扫描，导致原本走范围过滤再sort 500ms勉强可以结束的查询，5分钟不出结果。\u003c/p\u003e","title":"MySQL order by limit 走错索引(range-\u003eindexscan)"},{"content":"1. 现象 生产环境数据库在某一刻突然发现大量活跃连接，而且大部分状态是 updating 。问题出现在周六上午，持续了大概三四分钟，得益于我们自己的快照程序，拿到了当时现场的的processlist, 锁等待关系，innodb status 信息：(经过脱敏处理)\ninnodb_status.txt片段： var_mydb_snapshot.html （也可以通过 pt-stalk 收集）\n首先在 Lock Waits Info 一节，看到每行的trx_id(事务)的role分为 Blocker(引起阻塞的线程) 与 Blockee（被阻塞者）；最后一列 blocking_trx_id 在role是Blockee时才有值，代表谁阻塞了当前事务。 根据上面的关系，可以得出以下结论：\n事务 19705811640 运行了231s，阻塞了19706118937、19706124453、19706124752，而这些事务都在做同一个UPDATE语句 被锁定的记录是 mydb.mytable1表的主键索引值为 5317885 行 事务 19706124752 既被阻塞，也阻塞了别人19706125253 不难发现 19705811640 应该最先运行的事务，且对其它事务产生了链式阻塞，它的thread_id是 9898630，来源IP 但是当你兴冲冲的找到引起阻塞的事务 19705811640 在做什么事情时，发现它没有任何sql的信息，lock info以及processlist里面都是None。那么有哪些情况会导致在会话是活跃的，但sql的内容为空：\n执行show processlist的时候，刚好在事务里面两个sql的中间 sql已经执行完成，但长时间没有提交 2. 初步分析 其实这个现象已经遇到过很多次了，第1个原因常发生在 大量单条记录更新 的情况，一个sql在一个事务里循环执行10000次，即使每条都很快，但大部分时间都在网络传输上，（可以改成批量的形式）。在本案例基本上能确定的是第2个原因：事务开启之后，sql也执行了，但中间又做别的事情去了。那么怎样才能知道这个事务是什么内容呢？两个方向去找：\n从来源ip上的应用程序的日志里分析 binlog里面分析 应用程序日志里可以看 10:21:00 ~ 10:26:00 之间，mydb.mytable1 表上主键id=5317885 在做什么事情。因为我们上了听云，在听云APM里面也可以清楚的看到这个时间点的哪个方法慢： 响应时间230多秒，从“相关SQL”里面看到操作的记录内容，确定就是它了(根据innodb status快照时间 - ACTIVE 230.874 sec，倒推得到的时间与这里刚好吻合)。从接口名称也清楚的知道是在进行禁用用户的操作，猜想： 禁用用户的逻辑上有先挪到回收站，再删资料、删权限、删关系，清理缓存等等一系列操作，放在事务里保证他们的原子性，似乎是合理的。但为什么执行了将近4分钟还没有提交呢，分析相关的sql效率都很高。\n有三种情况：\n这个事务执行到一半，它需要操作的数据被别人锁住，等待了这么久 类似事务要操作5000条数据，但是一条一条的操作，然后一起提交（已出现过类似的例子） 事务务执行完成很快，但调用其它接口迟迟没有返回，导致事务没提交。 不会是1和2，因为从一开始的分析看到事务 19705811640 都是在阻塞别人，而不是受害者。那么结合上图中有个有两个操作redis的接口执行时间占比96%，可以下定论了：\n在禁用用户时，开启了一个事务，四五个增删改很快完成，但是操作redis缓存过程比较慢，也包含在了事务代码之间，长时间没有提交。前端用户操作的时候因为迟迟没有响应，进行了多次重复点击操作，因为影响的还是同一行记录，所以只能等待前面的锁释放。\nBingo，跟最初的设想一样。但是，开发检查代码之后告诉我，没有用事务！那前面的猜想和结论都不成立了。\n3. 论证 于是走另外一个思路，分析binlog。如果binlog里面记录那条记录修改(设置禁用标志)和删除（真正删除）的时间是 10:21:58，说明数据库操作那时候就完成；如果是10:25:xx，说明最后才提交。为了弄明白这个问题，也为了搞情况事务的内容到底是什么，解析当时的binlog。（阿里云rds的数据追踪功能本来挺好用，但这一次用着报内部错误）\n还记得前面那个thread_id吗，可以用在这里过滤(也可以用记录值)：\n1 2 3 4 5 6 7 $ mysqlbinlog --base64-output=decode-rows -vv --start-datetime=\u0026#34;2017-09-16 10:21:00\u0026#34; --stop-datetime=\u0026#34;2017-09-16 10:27:00\u0026#34; mysql-bin.010743 \u0026gt; mysql-bin.010743.sql $ grep -B5 -A200 \u0026#34;thread_id=9898630\u0026#34; mysql-bin.010743.sql \u0026gt; mysql-bin.010743.sql.txt $ ./summarize_binlogs.sh \u0026gt; mysql-bin.010743.sql.xid # 会比较慢 $ cat mysql-bin.010743.sql.xid|grep Transaction|awk \u0026#39;{if($19\u0026gt;0)print}\u0026#39; [Transaction total : 10 Insert(s) : 1 Update(s) : 0 Delete(s) : 9 Xid : 99370218911 period : 190 ] [Transaction total : 10 Insert(s) : 1 Update(s) : 0 Delete(s) : 9 Xid : 99370268888 period : 236 ] 上面的 summarize_binlogs.sh 脚本来源于《MySQL运维内参》，可以汇总分析binlog里面事务的执行时间。\nmysql-bin.010743.sql.txt:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 # at 112037144 #170916 10:25:54 server id 1508836346 end_log_pos 112037192 CRC32 0x25216430 GTID [commit=yes] SET @@SESSION.GTID_NEXT= \u0026#39;56506509-b971-11e6-8c19-6c92bf2c8aaf:10306353216\u0026#39;/*!*/; # at 112037192 #170916 10:21:58 server id 1508836346 end_log_pos 112037268 CRC32 0x9cddeec2 Query thread_id=9898630 exec_time=0 error_code=0 SET TIMESTAMP=1505528518/*!*/; SET @@session.sql_mode=2097152/*!*/; BEGIN /*!*/; # at 112037268 #170916 10:21:58 server id 1508836346 end_log_pos 112037342 CRC32 0x373641db Table_map: `mydb`.`mytable01_del` mapped to number 950163 # at 112037342 #170916 10:21:58 server id 1508836346 end_log_pos 112037460 CRC32 0x4bba2efb Write_rows: table id 950163 flags: STMT_END_F BINLOG \u0026#39; xoq8WRP6A+9ZSgAAAN6NrQYAAJN/DgAAAAEACWRfZWNfdXNlcgAKdF91c2VyX2RlbAAMCAgICBEB CAgRCA8IBAAAyAAAAdtBNjc= xoq8WRf6A+9ZdgAAAFSOrQYAAJN/DgAAAAEADP//APEL/VAAAAAAAP0kUQAAAAAACKpYGQQAAAAK /VAAAAAAAFm8isYAAAAAAAAAAAAAAAAAAAAAADojUQAAAAAADOW+kOaxn+e6oue7hOE3BAAAAAAA +y66Sw== \u0026#39;/*!*/; ### INSERT INTO `mydb`.`mytable01_del` # at 112037460 #170916 10:21:58 server id 1508836346 end_log_pos 112037542 CRC32 0x7b55174a Table_map: `mydb`.`mytable1` mapped to number 950159 # at 112037542 #170916 10:21:58 server id 1508836346 end_log_pos 112037636 CRC32 0x3bdcebf7 Delete_rows: table id 950159 flags: STMT_END_F BINLOG \u0026#39; xoq8WRP6A+9ZUgAAAKaOrQYAAI9/DgAAAAEACWRfZWNfdXNlcgAOdF91c2VyX2FjY291bnQADAgC Dw8BARISAQMBDwiAABAAAADwADgBShdVew== xoq8WRn6A+9ZXgAAAASPrQYAAI9/DgAAAAEADP//APD9JFEAAAAAAAAACzE3NjA1MTEwMjgwEDc9 OokVkE7wcJ6AvWQXyZMEAJmc6TjAmZzs458AAAAAAAAA9+vcOw== \u0026#39;/*!*/; ### DELETE FROM `mydb`.`mytable1` ...... # at 112038300 #170916 10:25:54 server id 1508836346 end_log_pos 112038331 CRC32 0x01b508cf Xid = 99370268888 COMMIT/*!*/; binlog格式当中，一个事务最先记录的是GTID事件，而这个GTID的值只有在提交的时候才会生成，binlog里面的GTID时间的时间10:25:54就是事务提交的时间。 Xid在最末尾，时间也是10:25:54。但中间该事务的其它binlog事件，像UpdateRows/DeleteRows/InsertRows，前面的时间10:21:58是事务开始的时间。中间有4分钟的空档，与前面redis操作4分钟不谋而合。\n这下就更加明朗了：有显式的开启事务。但开发说没有用事务，又该怎么解释呢？\n不同的语言，不同的框架，使用事务的方式不一样。数据库里面开启显式事务有两种方式，一是设置 set autocommit=0，二是运行start transaction。两者都要显式调用commit命令提交事务。 为了证实程序的确用了事务，在测试环境应用服务器模拟用户的操作，然后抓包：\n1 2 3 4 5 6 7 8 9 10 11 12 $ sudo tcpdump -s 0 -l -w - dst your_db_ipaddr and port 3306 -i eth0 \u0026gt; mysql_3306.tcp $ strings mysql_3306.tcp|grep -n commit 28:SET autocommit=0 123:commit 124:SET autocommit=1 222:SET autocommit=0 257:commit 258:SET autocommit=1 268:SET autocommit=0 333:SET autocommit=1 399:commit 400:SET autocommit=1 有发送 set autocommit=0，这下更放心了。开发再次回去检查，发现在Spring框架的时，在类上面用 @Transactional 的方式做了事务，而常规的做法是把注解加在类的方法上，导致忽略了这个因素。\n4. 解决 解决办法是把需要做事务控制的地方放到Services接口级别，让redis清理缓存的操作在事务之外，或者异步清理。（但也要考虑这样做会有什么负面影响） 另外，Redis操作慢，是否是设计上的问题。（听云监控里面显示该事务里面调用了1300次）\n5. 总结 首先根据但是的现场快照，分析锁等待关系；根据以前的经验，怀疑是“大”事务中有无关的调用；根据程序日志和听云分析出对应的接口；但开发说没有事务，于是进一步通过分析binlog，经过tcp抓包，拿出证据；最后解决。\n我们经常说，尽量少用大事务，但由于现在开发都是基于各种框架，使用事务的方式被封装，要理解它们的用法。其次，我们上面的事务并不大，每个sql更新都很快，但是却把其它调用也写在事务里面，就容易阻塞而长时间不提交，也许这样做的初衷是操作db与清理redis缓存放在一个事务里，要么都成功，要么都失败，但是这种分布式设计就不合理（当然有办法是可以做到，这里不展开）。\n本文即是一个大事务锁的分析案例，也展示了引用各种工具，去分析论证的过程。\n本文链接地址：http://xgknight.com/2017/10/17/mysql-big-trx-lock-case/\n","permalink":"http://localhost:1313/2017/10/mysql-big-trx-lock-case/","summary":"\u003ch1 id=\"1-现象\"\u003e1. 现象\u003c/h1\u003e\n\u003cp\u003e生产环境数据库在某一刻突然发现大量活跃连接，而且大部分状态是 \u003ccode\u003eupdating\u003c/code\u003e 。问题出现在周六上午，持续了大概三四分钟，得益于我们自己的快照程序，拿到了当时现场的的processlist, 锁等待关系，innodb status 信息：(经过脱敏处理)\u003c/p\u003e","title":"“大”事务引起的锁等待分析案例"},{"content":"1. 现象，内存使用大 首先说一下最近遇到的一个现象，因为分库的缘故，单实例里面的表的数量增加了20倍，总数将近达到10000个。在开发环境明显感觉到执行简单查询都很慢，在processlist里面看到状态 opening table 达到好几秒但数据库并没有什么负载。本能的想到应该要加大 table_open_cache，可是加大后发现MySQL刚启动 RES 就占用了2.5G内存，之前才500-600M的样子。\n只是将 table_open_cache 从默认的2000，增加到10000（先不论这个值合不合理），就独占了2G的内存，这对于生产环境内存浪费是不可接受的。还好，关于这个问题的讨论有不少，感兴趣的话可以阅读 #bug 68287, #bug 68514, 12015-percona-5-6-14-56-very-high-memory-usage。\nOracle官方工程师并不认为这是个bug，导致初始化分配这么多内存的原因是，开启了 Performance_Schema 。P_S测量数据库的性能指标，需要提前一次性分配内存，而不是随着数据库运行逐渐申请内存。\n下表是不同参数组合下内存占用的测试结果： （注：可以通过这个来查看PFS里面哪些占内存比较多，mysql -hxxxx -Pxxx -uxx -pxx -e \u0026quot;show engine performance_schema status\u0026quot;|grep memory|sort -nr -k3 |head ）\n对于 table_open_cache 设置的非常大的情况下，即使还有许多cache多余，但P_S都需要分配这个数量的内存。解决这个内存大的问题有3个方向：\ntable_open_cache, table_definition_cache, max_connections 设置合理 关闭 performance_schema 保持 PFS 开启，关闭测量 max_table_instances和max_table_handles performance_schema_max_table_instances: 最大测量多少个表对象\n对应 (pfs_table_share).memory，我的环境里固定 277600000 bytes performance_schema_max_table_handles: 最大打开表的总数\n对应(pfs_table).memory，随着 table_open_cache 的增大而增大 关闭的方法是在my.cnf里面设置以上变量为 0 。默认是 -1 ，表示 autosize，即根据 table_open_cache/table_def_cache/max_connections 的值自动设置，相关代码 pfs_autosize.cc：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 PFS_sizing_data *estimate_hints(PFS_global_param *param) { if ((param-\u0026gt;m_hints.m_max_connections \u0026lt;= MAX_CONNECTIONS_DEFAULT) \u0026amp;\u0026amp; (param-\u0026gt;m_hints.m_table_definition_cache \u0026lt;= TABLE_DEF_CACHE_DEFAULT) \u0026amp;\u0026amp; (param-\u0026gt;m_hints.m_table_open_cache \u0026lt;= TABLE_OPEN_CACHE_DEFAULT)) { /* The my.cnf used is either unchanged, or lower than factory defaults. */ return \u0026amp; small_data; } if ((param-\u0026gt;m_hints.m_max_connections \u0026lt;= MAX_CONNECTIONS_DEFAULT * 2) \u0026amp;\u0026amp; (param-\u0026gt;m_hints.m_table_definition_cache \u0026lt;= TABLE_DEF_CACHE_DEFAULT * 2) \u0026amp;\u0026amp; (param-\u0026gt;m_hints.m_table_open_cache \u0026lt;= TABLE_OPEN_CACHE_DEFAULT * 2)) { /* Some defaults have been increased, to \u0026#34;moderate\u0026#34; values. */ return \u0026amp; medium_data; } /* Looks like a server in production. */ return \u0026amp; large_data; } 在阿里RDS中，performance_schema_max***系列变量不能单独disable，只能全局关闭PFS。这里我们尝试寻求一个合理table_cache的范围。\n那么 table_open_cache 与 table_definition_cache 设置一个什么值才算合理呢？\n2. 理解 table_open_cache 与 table_definition_cache 来理解一下 table_open_cache 到底是来干嘛的，文档里或者网上的文章，通通解释是“用于控制MySQL Server能同时打开表的最大个数”。如果继续问这个个数怎么算呢？\n我来尝试解答一下。MySQL是多线程的，多个会话上有可能会同时访问同一个表，mysql是允许这些会话各自独立的打开这个表，而表最终都是磁盘上的数据文件。(默认假设innodb_file_per_table=1)，打开文件需要获取文件描述符(File Descriptor)，为了加快这个open table的速度，MySQL在Server层设计了这个cache：\nThe idea behind this cache is that most statements don\u0026rsquo;t need to go to a central table definition cache to get a TABLE object and therefore don\u0026rsquo;t need to lock LOCK_open mutex. Instead they only need to go to one Table_cache instance (the specific instance is determined by thread id) and only lock the mutex protecting this cache. DDL statements that need to remove all TABLE objects from all caches need to lock mutexes for all Table_cache instances, but they are rare.\ntable_cache 减少了表级别 LOCK_open 这个互斥量的获取，改用获取 表对象缓存实例 列表的mutex。简化成如下过程：\n假设当前并发200个连接，table_open_cache=200，其中有50连接都在访问同一张表 mysql内部维护了一个 unused_table_list，在a表上的请求结束后，会把这个thread刚才用过的 table object 放入unused_table_list 每个表有个key，可以通过hash快速定位到表a的所有可用object，如果后面一下子100个连接上来访问表a，内部会先从 unused_table_list 去找这个表已经缓存过的对象(get_table)，比如前50个可以直接拿来用(unlink_unused_table) 后50个则需要调用系统内核，拿到文件描述符。 用完之后会，放回到unused_table_list，并将这个表的key放到hash表的前面。 如果缓存的对象个数超过了 table_open_cache，则会通过LRU算法，把认为不用的表对象逐出。 从上面的过程应该很容易理解 table_open_cache 与 table_definition_cache 的区别。\ntable_def_cache 也是一个key/value形式的hash表，但每个表只有一个值，值/对象的内容就是表的元数据信息(Data Dictionay，frm文件里面的信息)，如表结构、字段、索引，它是一个全局的结构，并且不占用文件描述符。 而table_open_cache的key/value的值是一个列表，表示这个表的多个 Table_cache_element，他们共用这个表的 definition (代码层定义为TABLE_SHARE对象)。 (注：我们在row格式的binlog里面看到的 table_map_id 就是在 TABLE_SHARE 里面定义的，表结构变更、缓存被逐出，都会导致 table_map_id 递增。)\n2.1 源码说明 源代码里面关键函数\nsql_base.cc:\nopen_table() 打开表的入口 打开之前会判断mdl锁条件满不满足，再调用 get_table() 尝试从cache里面获取 如果找到，还要判断版本信息，goto table_found 如果没找到，注意get_table()接收了一个 table_share 参数，即使没找到table cache，也努力获取table definition，如果拿到table_share则要获取一次LOCK_open互斥量，增加表的引用计数。 make a new table: 调用 open_table_from_share() 从磁盘上打开表 调用 add_used_table() 将表对象放入缓存，table_open_cache_misses++ get_table_share() 从 table definition cache 获取表定义信息 如果cache中没有，则调用 table.cc:open_table_def() 从文件系统上读取 table_cache.h:Table_cache::\nm_unused_tables\n该列表内容是table cache中没有被其它线程使用的table object。最近使用过的table object会被添加到列表的尾部，头部就成为最近没被使用的(LRU) m_table_count\ntable objects个数，包括正在使用中，以及unused\n所有table cache instances中这个count加起来，就是 Open_tables 的结果 get_table() 根据key(表名)从cache hash里面获取 unused table object\n得到之后，将这个object从列表unlink掉，并且放入used table list add_used_table() 将新创建的 table object 放入table cache\n这是说明当前连接要打开的表在cache里面没有，所以要自己打开，并且放入used table list release_table() 用完后将表对象放回table cache的unused列表\n如果table_share版本比较旧，则直接remove掉 remove_table() free_unused_tables_if_necessary() 每次 add_used_table() 都会调用，判断是否需要从 table cache object list清除多余的cache，需要锁定LOCK_open。调用remove_table()\n清除条件：m_table_count \u0026gt; table_cache_size / table_cache_instances table.cc:\nopen_table_from_share() 根据 table_share 信息来打开表。调用 outparam-\u0026gt;file-\u0026gt;ha_open()，too many files opened 错误在这里抛出 open_table_def() 从 frm 中读取表定义 以上过程没有考虑视图、临时表、分区表。table_cache虽然会有额外的内存开销，但简化了对表状态的维护，打开表这个动作因为省去了获取 LOCK_open mutex 以及直接操作打开数据文件，而变得高效。 这部分参考taobao数据库内核月报的2篇文章，会比较清晰：\nopen file limits： http://mysql.taobao.org/monthly/2015/08/07/ MySQL表定义缓存：http://mysql.taobao.org/monthly/2015/08/10/ 3 设置参考因素 3.1 table_open_cache table_open_cache 默认值 Version\u0026lt;=5.6.7: 400, Version\u0026gt;=5.6.8: 2000，设定它的值有3个因素：\n最大并发连接数 这是最重要的考量。假设业务高峰期 活跃并发 连接是200，60%是单表查询，30%是两个表join，5%是三个表join，5%会创建临时表。那么table_open_cache可以是： 200 × (60% × 1 + 30% × 2 + 5% × 3 + 5% × 2) = 290 当然这里不是要如何精确的计算，只是说明有哪些需要考虑的。网上有大部分文章都讲设置 max_connections * N，N是sql里面表的最大个数，我个人觉得如果max_connections值超过2000的话，就不要这样算，因为max_connection一般是不允许达到的，高峰期活跃并发连接数才是比较好的基准。\n存储引擎\nMyISAM引擎\n因为myisam数据文件和索引是分开存放的，所以第一次打开表时需要2个描述符，后续如果并发2个会话访问该表，另一个会话只需要多开一个数据文件的描述符。索引文件描述符可被线程共享。因此它所需要的 table_cache 的值并不是简单上面的值的2倍，而是跟表的访问分布有关。当然现在已经几乎不用MyISAM引擎了。\nMerge引擎也类似，因为Merge表可以有多个底层表，需要多个文件描述符。\nInnoDB引擎\ntable_open_cache对InnoDB引擎其实作用不大，它是Server层的机制，而InnoDB不依赖server层去管理表空间，它使用自己的内部函数去打开ibd，创建handler来操作表。（handler只是内存对象，不牵涉文件操作。从实验结果看来，innodb每个表最多只有一个File Descriptor打开，myisam表如果并发访问一个表，会打开多个FD并cache起来）\n注： flush tables 命令会关闭所有当前打开的表对象缓存/handler，所以状态变量 open_tables 会置0，但opened_tables(_definition)、Table_open_cache_misses(_hits)只会在实例重启后置0。对MyISAM引擎来说，它还会释放MYI/MYD文件描述符，而InnoDB引擎则不会释放ibd文件描述符。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 mysql\u0026gt; show variables like \u0026#34;table_%\u0026#34;; +----------------------------+-------+ | Variable_name | Value | +----------------------------+-------+ | table_definition_cache | 1400 | | table_open_cache | 2000 | | table_open_cache_instances | 1 | +----------------------------+-------+ 3 rows in set mysql\u0026gt; show global status like \u0026#34;%open%\u0026#34;; +----------------------------+-----------+ | Variable_name | Value | +----------------------------+-----------+ | Com_ha_open | 0 | | Com_show_open_tables | 0 | | Innodb_num_open_files | 364 | -- 打开的ibd文件的数量，打开后一般不会关闭，除非超过了 innodb_open_files 的设定 | Open_files | 52 | -- 打开的常规文件数量，如slow_log,error_log等，不包含socket和具体存储引擎有关的文件，所以一般都无需关注这个，它与innodb_open_files也没关系 | Open_streams | 0 | | Open_table_definitions | 470 | -- 当前缓存了多少.frm文件 | Open_tables | 448 | -- 当前table_cache里面缓存的table object数量 | Opened_files | 35617170 | | Opened_table_definitions | 117134 | | Opened_tables | 117409 | -- 自总MySQL启动以来打开表的总次数，如果在缓存中找到直接使用，不会增加这个值 | Slave_open_temp_tables | 0 | | Table_open_cache_hits | 130148442 | | Table_open_cache_misses | 117404 | | Table_open_cache_overflows | 0 | +----------------------------+-----------+ 14 rows in set mysql\u0026gt; flush tables; Query OK, 0 rows affected mysql\u0026gt; show global status like \u0026#34;%open%\u0026#34;; +----------------------------+-----------+ | Variable_name | Value | +----------------------------+-----------+ | Com_ha_open | 0 | | Com_show_open_tables | 0 | | Innodb_num_open_files | 364 | | Open_files | 4 | | Open_streams | 0 | | Open_table_definitions | 6 | | Open_tables | 6 | | Opened_files | 35617220 | | Opened_table_definitions | 117140 | | Opened_tables | 117415 | | Slave_open_temp_tables | 0 | | Table_open_cache_hits | 130148523 | | Table_open_cache_misses | 117410 | | Table_open_cache_overflows | 0 | +----------------------------+-----------+ 14 rows in set opened_tables\n根据第一步的最大并发数设定的值不一定准确，在MySQL运行一段时间后，可以观察 opened_tables 增加的速度，决定是否需要扩大 table_open_cache。如果查询里面有许多要用到temporary table，这个值也会增加的很快，此时也可以比较 Table_open_cache_hits 与 Table_open_cache_misses 的值，正常的话 hits/(hits+misses ) 应该在99.9%以上。 还有一个标准，Open_tanles的值如果与 table_open_cache很接近，那么也要考虑增大 table_open_cache 。\n但不要设置的太大，大部分情况不要超过10000，原因一是如第一部分看到，performance_schema会分配过多内存；二是cache的查找速度会因为越来越多而变慢；三是某些情况不缓存也许更好，比如几万张表，他们都很均匀的被使用，如果不全部缓存起来，那么缓存始终会被不断的逐出更新，效率反而更低。\n3.2 table_definition_cache 与 innodb_open_files 至于 table_definition_cache，默认值是 400 + (table_open_cache / 2)，默认最大2000。如果实际表的数据量比较多，最好是能够把元数据全部cache起来，设置与表的总数量差不多大就行。\nInnoDB engine层有自己参数 innodb_open_files，限制同时打开 ibd 文件的句柄数，作用与 table_definition_cache 相同，逐出策略也是一样采用LRU算法。innodb读取INNODB_SYS_TABLES,INNODB_SYS_COLUMNS,INNODB_SYS_FIELDS,INNODB_SYS_INDEXES等数据字典，放入 table_dict 。当需要访问这个表的时候，创建 handler 对象。 这两个变量本身没啥关系，但是设置不合理的时候mysql会改变它的值：\ninnodb_open_files的值如果设置大于 open_files_limit，且大于table_open_cache，那么会自动设置为table_def_cache大小。innobase\\handler\\ha_innodb.cc：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 if (innobase_open_files \u0026lt; 10) { innobase_open_files = 300; if (srv_file_per_table \u0026amp;\u0026amp; table_cache_size \u0026gt; 300) { innobase_open_files = table_cache_size; } } if (innobase_open_files \u0026gt; (long) open_files_limit) { fprintf(stderr, \u0026#34;innodb_open_files should not be greater\u0026#34; \u0026#34; than the open_files_limit.\\n\u0026#34;); if (innobase_open_files \u0026gt; (long) table_cache_size) { innobase_open_files = table_cache_size; } } 这里顺便提一下 open_file_limit, 它限制的是mysqld进程总共能够打开文件描述符的个数，是个Server层的参数，它的值应该要小于服务器的最大限制，否则OS层报错会比mysql error log报错更惨。 关于它的计算公式，网上有很多，不属本文的内容，感兴趣可以参考 http://www.cnblogs.com/zhoujinyi/archive/2013/01/31/2883433.html\n参考\nhttp://hidba.org/?p=170 https://dev.mysql.com/doc/refman/5.6/en/table-cache.html http://mysql.taobao.org/monthly/2015/08/07/ https://dev.mysql.com/doc/dev/mysql-server/8.0.0/classTable__cache.html http://www.orczhou.com/index.php/2010/10/mysql-open-file-limit/ 本文链接地址：http://xgknight.com/2017/10/13/mysql-table_open_cache_file_limits/\n","permalink":"http://localhost:1313/2017/10/mysql-table_open_cache_file_limits/","summary":"\u003ch1 id=\"1-现象内存使用大\"\u003e1. 现象，内存使用大\u003c/h1\u003e\n\u003cp\u003e首先说一下最近遇到的一个现象，因为分库的缘故，单实例里面的表的数量增加了20倍，总数将近达到10000个。在开发环境明显感觉到执行简单查询都很慢，在processlist里面看到状态 opening table 达到好几秒但数据库并没有什么负载。本能的想到应该要加大 \u003ccode\u003etable_open_cache\u003c/code\u003e，可是加大后发现MySQL刚启动 RES 就占用了2.5G内存，之前才500-600M的样子。\u003c/p\u003e","title":"table_open_cache 与 table_definition_cache 对MySQL(内存)的影响"},{"content":"1. 现象 某日下午下班后低峰期，现网MySQL一个库突然报出大量慢sql，状态是 statistics，但是过后拿这些sql去执行的时候，实际很快。处于 statistics 状态的线程有个特征：查询的都是视图，但看监控那个时间段并没有明显的update/detele/insert。通过我们的快照程序，去分析当时的 innodb status，发现如下信息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 SEMAPHORES ---------- OS WAIT ARRAY INFO: reservation count 17208994 --Thread 139964610234112 has waited at srv0srv.cc line 2132 for 14.00 seconds the semaphore: X-lock (wait_ex) on RW-latch at 0x1635a00 created in file dict0dict.cc line 900 a writer (thread id 139964610234112) has reserved it in mode wait exclusive number of readers 1, waiters flag 0, lock_word: ffffffffffffffff Last time read locked in file row0purge.cc line 720 Last time write locked in file /home/admin/146_20161018140650857_13830810_code/rpm_workspace/storage/innobase/srv/srv0srv.cc line 2132 OS WAIT ARRAY INFO: signal count 256984450 Mutex spin waits 626367674, rounds 2776951802, OS waits 1973672 RW-shared spins 149944457, rounds 1650148561, OS waits 3972058 RW-excl spins 72090467, rounds 2017802579, OS waits 11148264 Spin rounds per wait: 4.43 mutex, 11.01 RW-shared, 27.99 RW-excl ... FILE I/O -------- I/O thread 0 state: waiting for i/o request (insert buffer thread) I/O thread 1 state: waiting for i/o request (log thread) I/O thread 2 state: waiting for i/o request (read thread) I/O thread 3 state: doing file i/o (read thread) ev set I/O thread 4 state: waiting for i/o request (read thread) I/O thread 5 state: doing file i/o (read thread) ev set I/O thread 6 state: doing file i/o (write thread) ev set I/O thread 7 state: waiting for i/o request (write thread) I/O thread 8 state: waiting for i/o request (write thread) I/O thread 9 state: waiting for i/o request (write thread) Pending normal aio reads: 18 [0, 12, 0, 6] , aio writes: 1 [1, 0, 0, 0] , ibuf aio reads: 0, log i/o\u0026#39;s: 0, sync i/o\u0026#39;s: 0 Pending flushes (fsync) log: 0; buffer pool: 0 1346747614 OS file reads, 2869418806 OS file writes, 524616747 OS fsyncs 22 pending preads, 1 pending pwrites 6.00 reads/s, 16384 avg bytes/read, 0.00 writes/s, 0.00 fsyncs/s ... ROW OPERATIONS -------------- 0 queries inside InnoDB, 0 queries in queue 38 read views open inside InnoDB Main thread process no. 34414, id 139964610234112, state: enforcing dict cache limit Number of rows inserted 2546811699, updated 1708150459, deleted 1004154696, read 413168628410 0.00 inserts/s, 0.00 updates/s, 0.00 deletes/s, 54.19 reads/s 2. 分析 从上面的信息知道 Thread 139964610234112 是主线程，在源码 srv0srv.cc:2132 行的地方等待信号14s，这个信号是在 dict0dict.cc:900 地方创建的 RW-latch 排它锁。那么奇怪了，主线程自己在等待自己的互斥锁。 由于环境是阿里云的RDS(基于MySQL 5.6.16-log 版本)，拿不到他们的代码，找来 5.6.35 的来看，行号对不上。但好在上段信息的最后面有一个 Main thread state: enforcing dict cache limit，发现在 srv0srv.cc 函数 srv_master_do_active_tasks() 约2137行的位置：\n1 2 3 4 5 6 if (cur_time % SRV_MASTER_DICT_LRU_INTERVAL == 0) { srv_main_thread_op_info = \u0026#34;enforcing dict cache limit\u0026#34;; srv_master_evict_from_table_cache(50); MONITOR_INC_TIME_IN_MICRO_SECS( MONITOR_SRV_DICT_LRU_MICROSECOND, counter_time); } 应该是在调用 srv_master_evict_from_table_cache() 从innodb table cache里面清理缓存的地方waiting（这里不是一定会清理，而是先判断空间够不够用，参数50表示只扫描 unused_table list的50%）。 srv_master_evict_from_table_cache()：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 srv_master_evict_from_table_cache( /*==============================*/ ulint\tpct_check)\t/*!\u0026lt; in: max percent to check */ { ulint\tn_tables_evicted = 0; rw_lock_x_lock(\u0026amp;dict_operation_lock); dict_mutex_enter_for_mysql(); n_tables_evicted = dict_make_room_in_cache( /** 在dict0dict.cc里面 **/ innobase_get_table_cache_size(), pct_check); dict_mutex_exit_for_mysql(); rw_lock_x_unlock(\u0026amp;dict_operation_lock); return(n_tables_evicted); } 就是在 rw_lock_x_lock(\u0026amp;dict_operation_lock) 这个地方获取Latch的时候等待了14s，这个锁就是在数据字典模块 dict0dict.cc:dict_init() 约1065行的地方创建的，与innodb status输出基本一致。 关于 dict_operation_lock 直接看注释吧：\n1 2 3 4 5 6 7 8 /** @brief the data dictionary rw-latch protecting dict_sys table create, drop, etc. reserve this in X-mode; implicit or backround operations purge, rollback, foreign key checks reserve this in S-mode; we cannot trust that MySQL protects implicit or background operations a table drop since MySQL does not know of them; therefore we need this; NOTE: a transaction which reserves this must keep book on the mode in trx_t::dict_operation_lock_mode */ 在尝试把表定义逐出缓存时获取的是 dict_operation_lock X-mode lock，可是从已有的信息里看不到另一个数据字典锁是什么。 之前是怀疑是不是 table_definition_cache, table_open_cache, innodb_open_files 设置小了，视图一般是多表join，更容易消耗打开表的数量，导致不断的逐出cache而导致锁征用。但是检查一番并没发现什么问题，更何况是14s的等待。关于它们的设置和关系，可以参考我的文章 table_open_cache 与 table_definition_cache 对MySQL的影响 。\n那么得换个思路了，processlist里面有13个长时间处于 statistics 状态的线程，表示正在计算统计数据，以制定一个查询执行计划。 如果一个线程处于这种状态很长一段时间，可能是磁盘IO性能很差，或者磁盘在执行其他工作。\n此时注意到最上面的信息里有 Pending normal aio reads: 18 [0, 12, 0, 6] ，有18个读IO被挂起(实际从监控图 innodb_data_pending_reads看来，有达到过50)，四个read thread有三个处于忙碌状态。再有 innodb_buffer_pool_pages_flushed 在出异常前10s没有任何变化，也就是没有成功的将脏数据刷盘动作。另外这是一个从库，出异常前10s有出现过瞬间20多秒延迟： (这一切关注的都是 18:59:05 之前的数据，之后的时间，一般恢复了都会有瞬间的读行数上涨，这个时候别把它们反当做起因)\n3. 结论 结合上面的 enforcing dict cache limit 和 statistics IO pending，找到两个有关的bug report:\nhttps://bugs.launchpad.net/percona-server/+bug/1500176 https://bugs.mysql.com/bug.php?id=84424 第一个是使用 pt-online-schema-change 去更改分区表的结构，可能会出现，但目前bug状态是Undecided，我们的环境没有分区表，没外键，也没有改表动作。 第二个其实 Not a bug：\n1 2 3 4 5 6 7 8 9 Thank you for your bug report. This is, however, not a bug, but a very well known issue. You have to do several things in order to alleviate the problem: * increase the additional memory pool （注：这里我认为不应该是additional memory pool，而是 buffer_pool，因为现在innodb内存管理基本是调用系统malloc，即innodb_use_sys_malloc=ON，参考https://dev.mysql.com/doc/refman/5.7/en/innodb-performance-use_sys_malloc.html） * increase total number of file handles available to MySQL * increase number of file handles for InnoDB * improve performance of the I/O on your operating system 说到底就是数据库服务器IO遇到问题了，可以通过增加 buffer_pool 来缓存更多的数据，或者提高服务器IO能力，这个范围就广了： https://dev.mysql.com/doc/refman/5.6/en/optimizing-innodb-diskio.html 。 然而生产服务器都运行了1年之久，高峰期都没出现过IO问题，现在何况低峰期，也没有人为操作。那这个锅只能交给阿里RDS了：怀疑是实例所在物理机磁盘有抖动。\n分析这么久得出这个结论，却不能做什么，因为我们没办法看到服务器级别的IO stats。其实想到去年也有实例出现过几例类似 statistics 问题，向阿里云提工单确认物理机状态，得到的结论都是：“是的，物理机有抖动。需要申请迁移实例吗”，但是从来拿不到依据。如果自己能看到OS级别的监控，其实都不需要本文这么冗长的分析。\n参考\nhttps://dba.stackexchange.com/questions/55969/statistics-state-in-mysql-processlist http://mysqlinternals.blogspot.com/2015/05/list-of-background-operations-performed.html http://imysql.com/2015/06/10/mysql-faq-processlist-thread-states.shtml http://imysql.com/2016/11/20/mysql-faq-what-cause-diskio-so-high.shtml 本文链接地址：http://xgknight.com/2017/09/23/rds_disk_io_troubleshooting/\n","permalink":"http://localhost:1313/2017/09/rds_disk_io_troubleshooting/","summary":"\u003ch1 id=\"1-现象\"\u003e1. 现象\u003c/h1\u003e\n\u003cp\u003e某日下午下班后低峰期，现网MySQL一个库突然报出大量慢sql，状态是 \u003ccode\u003estatistics\u003c/code\u003e，但是过后拿这些sql去执行的时候，实际很快。处于 statistics 状态的线程有个特征：查询的都是视图，但看监控那个时间段并没有明显的update/detele/insert。通过我们的快照程序，去分析当时的 innodb status，发现如下信息：\u003c/p\u003e","title":"MySQL实例阻塞分析一例(线程statistics状态)"},{"content":"本程序基于大众点评github项目 binlog2sql 二次开发而来，可以实现对源库的binlog实时接收，并组装成增量sql。\n原项目默认是把sql输出到控制台，二次开发后的版本把sql放入redis队列，根据需要由另一个程序消费到目标库，模拟了一个“从库”。 在测试时--stop-never在qa环境没有作用，添加了在 BinLogStreamReader 实例里面加入 blocking=True 来保证源源不断的接受binlog而不中断。\n另外也加入了更改目标库名的功能，比如原库叫d_my1，生成的sql目标库名是 d_my2 。\n项目地址：https://github.com/seanlook/binlog2sql\n应用场景 目前想到以下应用场景：\n实时同步部分表到另外一个数据库实例 比如在数据库迁库时，将当天表的数据同步到新库，模拟阿里云dms数据传输的功能，相当于在测试环境演练，减少失误。 另外还可以从新库反向同步增量数据到老库，解决测试环境多项目测试引起数据库冲突的问题。\n正式切库时的回滚措施 比如数据库迁移项目，切换期间数据写向新库，但如果切换失败需要回滚到老库，就需要把这段时间新增的数据同步回老库（启动消费程序），这就不需要程序段再考虑复杂的回滚设计。\n数据库闪回 关于数据库误操作的闪回方案，见 文章MySQL根据离线binlog快速闪回 。binlog2sql的 -B 选项可以将sql反向组装，生产回滚sql。如果需要完善的闪回功能，要进一步开发，提高易用性。\nbinlog搜索功能 目前组内一版的binlog搜索功能，是离线任务处理的方式，好处是不会占用太大空间，缺点是处理时间较长。通过实时binlog解析过滤的方式，入ES可以快速搜索。需要进一步开发完善。\n使用方法 安装好python2.7虚拟环境，安装必要模块：pymysql, mysql-replication, redis, rq\n1 pip install -r requirements.txt 注意：pymysqlreplication 库在处理 \u0026lsquo;0000-00-00 00:00:00\u0026rsquo; 时有些不尽人意，可能会导致生产的sql在目标库执行失败，还有对datetime(6)类型有个bug，也对它进行了修复，地址：https://github.com/seanlook/python-mysql-replication 。\n准备一个redis用于存放sql队列，在环境变量里面设置redis地址\n1 export REDIS_URL=\u0026#39;redis://localhost:6379\u0026#39; 在主库执行 show master status 得到binlog开始的文件名和postion，然后开始订阅：\n1 2 3 4 5 6 7 8 9 10 11 12 binlog2sql原版使用时： $ ~/.pyenv/versions/2.7.10/envs/py2_binlog/bin/python binlog2sql.py -h192.168.1.185 -P3306 -uecuser -pecuser \\ -d d_ec_contact --tables t_crm_contact_at \\ --start-file=\u0026#39;mysql-bin.000001\u0026#39; --start-datetime=\u0026#39;2017-08-30 12:30:00\u0026#39; --start-position=6529058 \\ --stop-never \u0026gt; contact0.sql 加入订阅功能后： $ ~/.pyenv/versions/2.7.10/envs/py2_binlog/bin/python binlog2sql.py -h192.168.1.185 -P3306 -uecuser -pecuser \\ -d d_ec_contact:d_ec_crm --tables t_crm_contact_at t_crm_remark_today \\ --start-file=\u0026#39;mysql-bin.000001\u0026#39; --start-datetime=\u0026#39;2017-08-30 12:30:00\u0026#39; --start-position=6529058 \\ --dest-dsn h=10.0.200.195,P=3307,u=ecuser,p=ecuser --stop-never \u0026gt; contact0.sql -d d_ec_contact:d_ec_crm 表上生成目标sql映射关系，如果不改变库名，就不需要 : 指定，与原版兼容。\n--dest-dsn: 表示目标库的地址和认证信息。\n这时在redis里面可以看到sql信息。如果需要在目标库重放，则启动消费程序：（在代码目录下面）\n1 ~/.pyenv/versions/2.7.10/envs/py2_binlog/bin/rq worker 待数据追上之后，可以看到几乎是实时同步的。\n本文链接地址：http://xgknight.com/2017/09/05/mysql-binlog-subscribe-simple-for-dba/\n","permalink":"http://localhost:1313/2017/09/mysql-binlog-subscribe-simple-for-dba/","summary":"\u003cp\u003e本程序基于大众点评github项目 \u003ca href=\"https://github.com/danfengcao/binlog2sql\"\u003ebinlog2sql\u003c/a\u003e 二次开发而来，可以实现对源库的binlog实时接收，并组装成增量sql。\u003c/p\u003e\n\u003cp\u003e原项目默认是把sql输出到控制台，二次开发后的版本把sql放入redis队列，根据需要由另一个程序消费到目标库，模拟了一个“从库”。\n在测试时\u003ccode\u003e--stop-never\u003c/code\u003e在qa环境没有作用，添加了在 BinLogStreamReader 实例里面加入 \u003ccode\u003eblocking=True\u003c/code\u003e 来保证源源不断的接受binlog而不中断。\u003c/p\u003e","title":"一个简单的数据订阅程序(for DBA)"},{"content":"早前折腾博客的时候，在众多评论系统中选择了多说，用了2年结果多说倒闭了，也算是影响了网络上众多的站点。\n于是在16年的时候把评论换成了网易云跟帖，以为有网易这个靠山，体验虽然差点但是不会轻易关闭。云跟帖还提供了从多说直接导入的工具，随意旧的评论直接弄过来了。\n可谁想不到一年，网易云跟帖也关闭了。\n现在不怎么去折腾博客这玩意了，往里面写写东西才是王道，所以就决定直接把评论系统换成国外的 disqus，总不至于国内种种原因关闭了，代价就是要懂得科学上网，考虑博客的受众都是IT同仁，也就只好这样了。\n然而被坑了，网上有许多文章和工具可以从多说迁移到disqus，但是几乎没看到从网易云跟帖迁移到disqus，三者导出的评论格式不一样。云跟帖导出的是 json，disqus导入是扩展的Wordpress格式。\n在拖了3个月后，找到了从网易云跟帖备份出来的旧评论文件，简单用python转换了一下，现在可以用了。\nWXR格式：https://help.disqus.com/customer/portal/articles/472150-custom-xml-import-format\n转换代码gist地址：https://gist.coding.net/u/seanlook/c395cda7c5f4421b85efcd898a8fdf21 (comments_convert.py)\n云跟帖导出文件命名为 gentie163.py，懒得用python处理，直接修改这个文件的内容为 python 字典定义：\n1 2 3 4 sed -i \u0026#39;s/\u0026#34;url\u0026#34;:\u0026#34;xgknight.com/\u0026#34;url\u0026#34;:\u0026#34;http:\\/\\/xgknight.com/g\u0026#39; gentie163.py sed -i \u0026#39;s/false/False/g\u0026#39; gentie163.py sed -i \u0026#39;s/:null/:\u0026#34;\u0026#34;/g\u0026#39; gentie163.py sed -i \u0026#39;s/^/comments = /\u0026#39; gentie163.py 字典直接转xml比较容易：http://python3-cookbook.readthedocs.io/zh_CN/latest/c06/p05_turning_dictionary_into_xml.html#\n转换后的文件为 data_output.xml:\n1 # python3 comments_convert.py 在这个页面导入：https://seanlook.disqus.com/admin/discussions/import/platform/generic/\n可在页面 https://import.disqus.com/ 看到import进度，包括失败信息。（不要重复导入）\n说明：\ndisqus每篇文章有个thread_idendifier，这里处理直接根据文章的时间戳转换来用，不影响 dsq:remote是设置单点登录，没去深究，直接丢弃这个属性了 头像信息丢失(因为sso) 本文链接地址：http://xgknight.com/2017/08/29/blog_migrate_gentie163_disqus/\n","permalink":"http://localhost:1313/2017/08/blog_migrate_gentie163_disqus/","summary":"\u003cp\u003e早前折腾博客的时候，在众多评论系统中选择了多说，用了2年结果多说倒闭了，也算是影响了网络上众多的站点。\u003c/p\u003e\n\u003cp\u003e于是在16年的时候把评论换成了网易云跟帖，以为有网易这个靠山，体验虽然差点但是不会轻易关闭。云跟帖还提供了从多说直接导入的工具，随意旧的评论直接弄过来了。\u003c/p\u003e","title":"网易云跟帖迁移评论到disqus"},{"content":"mysqldiff mysql官方有个 mysql-utilities 工具集，其中 mysqldiff 可用于比较两个db之间的表结构。 mysqldiff的语法格式是：\n1 $ mysqldiff --server1=user:pass@host:port:socket --server2=user:pass@host:port:socket db1.object1:db2.object1 db3:db4 这个语法有两个用法：\ndb1:db2：如果只指定数据库，那么就将两个数据库中互相缺少的对象显示出来，不比较对象里面的差异。这里的对象包括表、存储过程、函数、触发器等。 如果db1与db2名字相同，可以只指定 db1 db1.object1:db2.object1：如果指定了具体表对象，那么就会详细对比两个表的差异，包括表名、字段名、备注、索引、大小写等所有的表相关的对象。\n如果两边db和对象名都相同，可以只指定 db1.object1 接下来看一些主要的参数：\n--server1：配置server1的连接。 --server2：配置server2的连接。 --character-set：配置连接时用的字符集，如果不显示配置默认使用character_set_client。 --width：配置显示的宽度。 --skip-table-options：保持表的选项不变，即对比的差异里面不包括表名、AUTO_INCREMENT、ENGINE、CHARSET等差异。 -d DIFFTYPE,--difftype=DIFFTYPE：差异的信息显示的方式，有 [unified|context|differ|sql]，默认是unified。如果使用sql，那么就直接生成差异的SQL，这样非常方便。 --changes-for=：修改对象。例如 \u0026ndash;changes-for=server2，那么对比以sever1为主，生成的差异的修改也是针对server2的对象的修改。 --show-reverse：在生成的差异修改里面，同时会包含server2和server1的修改。 --force：完成所有的比较，不会在遇到一个差异之后退出 -vv：便于调试，输出许多信息 -q：quiet模式，关闭多余的信息输出 问题修复与增强 但是试用下来，发现有以下几大问题\n对象在一方不存在时，比对结果是 object does not exist，而我们通常需要的是，生产 CREATE/DROP XXX 语句 要比对一个db下面所有的对象（table, view, event, proc, func, trigger），要手动挨个 db1.t1, db2.v2\u0026hellip;，而 db1:db2只是检查对象是否存在，不会自动比较db1与db2下的所有对象 比较时，auto_increment应该忽略，但是 mysqldiff 只提供 --skip-table-options ，忽略全部表选项，包括 auto_increment, engine, charset等等。 严重bug T1: idx1(f1,f2), T2: idx1(f1)，这种索引会生成 ADD INDEX idx(f2) T1: idx2(f1,f2), idx3(f3,f4), T2: idx4(f5)，这种组合索引，有可能生成的会乱序 这两个bug与mysqldiff的设计有关系，个人觉得它把比较和生产差异sql完全分开，复杂化了。它得到差异结果之后，生成sql又从db捞各种元数据来组装，其实从差异diff里面就可以获得组装需要的数据，也不容易出现隐藏的bug。参考实现 https://github.com/hidu/mysql-schema-sync\n针对上面几大问题，花了两天的时间阅读并修改了 mysqldiff 以及相关依赖的代码，都一一解决。 修复后的地址：https://github.com/seanlook/mysql-utilities/commits/master (mysql-utilities不像percona-toolkit那样每个工具都是All In One，需要改动mysqldiff.py意外的依赖模块)\n默认情况与官方的 mysqldiff 完全兼容，新增3个选项\n--include-create：是否生成创建对象(表等)的语句，而不是仅告知对象不存在。只有在 --difftype=sql 时有效。默认False --include-drop：是否生成DROP对象的语句，针对对象在原db不存在，而仅目标db存在的情况。只有在指定了--include-create 时起作用。drop操作因为比较危险，默认False，所以多加了这个选项 --skip-opt-autoinc：比较时跳过AUTO_INCREMNT。默认False 比较对象是，指定 db1.* 或 db1.*:db2.* 时，会比较他们所有的对象差异，而不仅显示缺少的对象 使用注意 比较时，尽量选择mysql版本相近的实例，比如mysql与mariadb比较，相同的表结构 show create table xxx 时可能得到不同的结果： mariadb会把int字段 default \u0026lsquo;0\u0026rsquo; 自动改成 default 0 CURRENT_TIMESTAMP会显示成 current_timestamp() 字段 default NULL 时，mysql connector/python 查 information_schema.COLUMNS.COLUMN_DEFAULT 字段为 ‘NULL’ （带引号的字符），而不是None（即查出来是NULL），导致与mysql版本用不一样 字段注释 COMMENT '是否批准加入群 默认1批准 0拒绝\\0e=''t_user_g\\0' ，是成立的，正常\\0后面的都是没用的，但有个 ' 号，会导致生产sql时有多余的 ' 好，直接执行会失败。 所以，字段注释要规范，不要带入这些乱起乱七八糟的字符，特别是用IDE建表时，完成后在命令行 show create table xxx 看一下。 演示对比 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 mysqldiff --server1=ecdba:xx@yyyy:3305 --server2=ecdba:xx@yyyy:3305 mydb1.t_user:mydb2.t_user --changes-for=server2 --difftype=sql # WARNING: Using a password on the command line interface can be insecure. # server1 on 10.xx.xx.127: ... connected. # server2 on 10.xx.xx.127: ... connected. # Comparing mydb1.t_user to mydb2.t_user [FAIL] # Transformation for --changes-for=server2: # ALTER TABLE `mydb2`.`t_user` DROP INDEX idx_corpid, ADD INDEX idx_corpid_deptid (f_corp_id,f_dept_id), ADD INDEX idx_dept (f_dept_id); # Compare failed. One or more differences found. 这个地方原版里面会将idx_corpid_deptid生成 ADD INDEX idx_corpid_deptid(f_corp_id), ADD INDEX idx_corpid_deptid(f_dept_id)。这里已修复 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 原版： mydb1.t_test1:mydb2.t_test1 --changes-for=server2 --difftype=sql # WARNING: Using a password on the command line interface can be insecure. # server1 on 10.xx.xx.127: ... connected. # server2 on 10.xx.xx.127: ... connected. ERROR: The object mydb2.t_test1 does not exist. 新选项 --include-create --include-drop mydb1.t_test1:mydb2.t_test1 --changes-for=server2 --difftype=sql --include-create --include-drop # WARNING: Using a password on the command line interface can be insecure. # server1 on 10.xx.xx.127: ... connected. # server2 on 10.xx.xx.127: ... connected. USE mydb2; CREATE TABLE `t_test1` ( `id` int(11) DEFAULT NULL ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4\u0026#39;; \u0026#39; # Compare failed. One or more differences found. 新选项，修改changes-for后，生成drop mydb1.t_test1:mydb2.t_test1 --changes-for=server1 --difftype=sql --include-create --include-drop # WARNING: Using a password on the command line interface can be insecure. # server1 on 10.xx.xx.127: ... connected. # server2 on 10.xx.xx.127: ... connected. DROP TABLE IF EXISTS mydb1.t_test1; # Compare failed. One or more differences found. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 mydb1.t_user_face:mydb2.t_user_face --changes-for=server2 --difftype=sql --include-create --include-drop # WARNING: Using a password on the command line interface can be insecure. # server1 on 10.xx.xx.127: ... connected. # server2 on 10.xx.xx.127: ... connected. # Comparing mydb1.t_user_face to mydb2.t_user_face [FAIL] # Transformation for --changes-for=server2: # ALTER TABLE `mydb2`.`t_user_face` DROP INDEX idx_tt2, DROP INDEX idx_corp_time, DROP COLUMN f_test, ADD INDEX idx_corp_time (f_corp_id,f_modify_time), CHANGE COLUMN f_corp_id f_corp_id int(11) unsigned NOT NULL COMMENT \u0026#39;企业id\u0026#39;, CHANGE COLUMN f_user_id f_user_id int(11) unsigned NOT NULL COMMENT \u0026#39;用户id\u0026#39;, AUTO_INCREMENT=123434, COLLATE=utf8mb4_general_ci; # Compare failed. One or more differences found. 这个地方原版处理 idx_corp_time 时，因为第一列索引字段相同，会生成 ADD INDEX idx_corp_time(f_modify_time)。这里已修复 新选项 --skip-option-autoinc mydb1.t_user_face:mydb2.t_user_face --changes-for=server1 --difftype=sql --include-create --include-drop --skip-option-autoinc # WARNING: Using a password on the command line interface can be insecure. # server1 on 10.xx.xx.127: ... connected. # server2 on 10.xx.xx.127: ... connected. # Comparing mydb1.t_user_face to mydb2.t_user_face [FAIL] # Transformation for --changes-for=server1: # ALTER TABLE `mydb1`.`t_user_face` DROP INDEX idx_corp_time, ADD UNIQUE INDEX idx_tt2 (f_user_id,f_modify_time), ADD INDEX idx_corp_time (f_corp_id), CHANGE COLUMN f_corp_id f_corp_id int(10) unsigned NOT NULL COMMENT \u0026#39;企业id\u0026#39;, CHANGE COLUMN f_user_id f_user_id int(10) unsigned NOT NULL COMMENT \u0026#39;用户id\u0026#39;, ADD COLUMN f_test varchar(20) NOT NULL DEFAULT \u0026#39;\u0026#39; AFTER f_url, COLLATE=utf8_general_ci; # Compare failed. One or more differences found. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 直接指定db，原版预修改版处理相同 mydb1:mydb2 --changes-for=server2 --difftype=sql # WARNING: Using a password on the command line interface can be insecure. # server1 on 10.xx.xx.127: ... connected. # server2 on 10.xx.xx.127: ... connected. # WARNING: Objects in server1.mydb1 but not in server1.mydb2: # TABLE: t_test1 # WARNING: Objects in server1.mydb2 but not in server1.mydb1: # VIEW: view_test # TABLE: t_test2 # Compare failed. One or more differences found. 指定 db.* ，处理相同 mydb1.*:mydb2.* --changes-for=server2 --difftype=sql # WARNING: Using a password on the command line interface can be insecure. # server1 on 10.xx.xx.127: ... connected. # server2 on 10.xx.xx.127: ... connected. ERROR: The object mydb1.* does not exist. 指定 db.* 和 --include-create ，依次处理全部对象，包括过程，视图等 mydb1.*:mydb2.* --changes-for=server2 --difftype=sql --difftype=sql --include-create --include-drop --skip-option-autoinc # WARNING: Using a password on the command line interface can be insecure. # server1 on 10.xx.xx.127: ... connected. # server2 on 10.xx.xx.127: ... connected. # WARNING: Objects in server1.mydb1 but not in server1.mydb2: # TABLE: t_test1 # WARNING: Objects in server1.mydb2 but not in server1.mydb1: # VIEW: view_test # TABLE: t_test2 # Comparing mydb1.t_user_face to mydb2.t_user_face [FAIL] # Transformation for --changes-for=server2: # ALTER TABLE `mydb2`.`t_user_face` DROP INDEX idx_tt2, DROP INDEX idx_corp_time, DROP COLUMN f_test, ADD INDEX idx_corp_time (f_corp_id,f_modify_time), CHANGE COLUMN f_corp_id f_corp_id int(11) unsigned NOT NULL COMMENT \u0026#39;企业id\u0026#39;, CHANGE COLUMN f_user_id f_user_id int(11) unsigned NOT NULL COMMENT \u0026#39;用户id\u0026#39;, COLLATE=utf8mb4_general_ci; DROP VIEW IF EXISTS mydb2.view_test; USE mydb2; CREATE TABLE `t_test1` ( `id` int(11) DEFAULT NULL ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4\u0026#39;; \u0026#39; # Comparing mydb1.t_user to mydb2.t_user [FAIL] # Transformation for --changes-for=server2: # ALTER TABLE `mydb2`.`t_user` DROP INDEX idx_corpid, ADD INDEX idx_corpid_deptid (f_corp_id,f_dept_id), ADD INDEX idx_dept (f_dept_id); # Comparing mydb1.proc_test to mydb2.proc_test [FAIL] # Transformation for --changes-for=server2: # DROP PROCEDURE IF EXISTS `mydb2`.`proc_test`; DELIMITER // CREATE DEFINER=`ecdba`@`%` PROCEDURE `mydb2`.`proc_test` () CONTAINS SQL SQL SECURITY DEFINER BEGIN select 1; END// DELIMITER ; DROP TABLE IF EXISTS mydb2.t_test2; # Compare failed. One or more differences found. 原文连接地址：http://xgknight.com/2017/08/05/mysql_mysqldiff/\n","permalink":"http://localhost:1313/2017/08/mysql_mysqldiff/","summary":"\u003ch1 id=\"mysqldiff\"\u003emysqldiff\u003c/h1\u003e\n\u003cp\u003emysql官方有个 \u003ca href=\"https://dev.mysql.com/doc/mysql-utilities/1.6/en/mysql-utils-install-rpm.html\"\u003emysql-utilities 工具集\u003c/a\u003e，其中 mysqldiff 可用于比较两个db之间的表结构。\nmysqldiff的语法格式是：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-fallback\" data-lang=\"fallback\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e$ mysqldiff --server1=user:pass@host:port:socket --server2=user:pass@host:port:socket db1.object1:db2.object1 db3:db4\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e这个语法有两个用法：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003edb1:db2\u003c/code\u003e：如果只指定数据库，那么就将两个数据库中互相缺少的对象显示出来，不比较对象里面的差异。这里的对象包括表、存储过程、函数、触发器等。\n如果db1与db2名字相同，可以只指定 \u003ccode\u003edb1\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003edb1.object1:db2.object1\u003c/code\u003e：如果指定了具体表对象，那么就会详细对比两个表的差异，包括表名、字段名、备注、索引、大小写等所有的表相关的对象。\u003cbr\u003e\n如果两边db和对象名都相同，可以只指定 \u003ccode\u003edb1.object1\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e接下来看一些主要的参数：\u003c/p\u003e","title":"MySQL数据库表结构同步之mysqldiff"},{"content":"前些天在公司内部进行了一次 ProxySQL主题的介绍 《ProxySQL数据库中间件使用实践》，因为proxysql是我调研并引入公司的，有必要跟本组开发同学，进行一个正式的介绍和使用说明，以及我们当前的应用情况。\n分享比较偷懒，直接拿来proxysql作者renecannao在 Percona Live Europe 2016 上的PPT，是一个非常全面又具有点睛作用的演示稿了。\n{% pdf http://github.com/seanlook/sean-notes-comment/raw/main/static/ProxySQL-Tutorials-PerconaLive.pdf 1000 800 %}\nPPT来源：https://www.percona.com/live/17/sessions/proxysql-tutorial\n另外一个觉得也还不错：https://www.slideshare.net/MyDBOPS/proxysql-for-mysql\n\u0026ndash; 我只是ppt的搬运工\n原文连接地址：http://xgknight.com/2017/07/19/proxysql-tutorials-ec/\n","permalink":"http://localhost:1313/2017/07/proxysql-tutorials-ec/","summary":"\u003cp\u003e前些天在公司内部进行了一次 ProxySQL主题的介绍 《ProxySQL数据库中间件使用实践》，因为proxysql是我调研并引入公司的，有必要跟本组开发同学，进行一个正式的介绍和使用说明，以及我们当前的应用情况。\u003c/p\u003e","title":"ProxySQL PPT分享"},{"content":"ProxySQL能监控的信息不多，而且大部分是统计信息，不是性能数据。\n1 2 3 4 5 6 7 8 9 10 11 12 13 mysql\u0026gt; show tables from stats; +--------------------------------+ | tables | +--------------------------------+ | global_variables | | stats_mysql_commands_counters | | stats_mysql_connection_pool | | stats_mysql_global | | stats_mysql_processlist | | stats_mysql_query_digest | | stats_mysql_query_digest_reset | | stats_mysql_query_rules | +--------------------------------+ 主要关心的指标都在表 stats_mysql_global 里面，源代码 diamond 目录下有个 proxysqlstat.py 脚本，是通过SHOW MYSQL STATUS命令，由diamond收集进程将指标上报到Graphite。有以下几个Metrics：\n并发数 Active_Transactions Questions 连接相关 Client_Connections_connected Server_Connections_connected Server_Connections_aborted 内存相关 Query_Cache_Entries Query_Cache_Memory_bytes SQLite3_memory_bytes ConnPool_memory_bytes 流量相关 mysql_backend_buffers_bytes mysql_frontend_buffers_bytes mysql_session_internal_bytes 其它 MySQL_Monitor_Workers MySQL_Thread_Workers 但是这些远远不够，还有以下更值得关心的指标： 表 stats_mysql_connection_pool:\n对后端DB请求的网络延时 Latency 对后端各个DB的请求数 Queries 后端各个DB的当前活跃连接数 ConnUsed 后端DB的状态 status 表 stats_mysql_processlist:\n每个用户的当前的连接数 表 stats_mysql_query_digest:\n各个类型的sql请求量比例、趋势 在我们的环境下使用的是 InfluxDB + Grafana，通过telegraf收集上报。上述所有的监控脚本见仓库 https://github.com/seanlook/proxysql_tools ：\nproxysql_stats.py:\n收集 stats_mysql_global 和 stats_mysql_connection_pool 中的信息，打印出 influxdb 数据上报格式 proxysql_stats_digest.py:\n收集 sql digest，收集的信息用于展示每类sql的执行趋势。 因为数据是累计值，所以这里做了增量计算，然后一方面上报给influxdb，一方面存入mysql，可以做更多用途。mysql的表结构 proxysql_stats_digest.sql 。 建议收集频率不要过高，比如10分钟一次。 grafana_proxysql_stats.json:\nGrafana Dashboard，直接导入可用 。 除此外，还需要对proxysql进程的监控，如内存占用、CPU使用，这部分通过telegraf的 procstat 插件去做：\n1 2 3 4 5 6 7 8 9 10 11 12 [[inputs.procstat]] exe = \u0026#34;proxysql\u0026#34; [[inputs.exec]] # the command to run command = \u0026#34;/etc/telegraf/telegraf.d/proxysql_stats.py\u0026#34; ## Timeout for each command to complete. timeout = \u0026#34;10s\u0026#34; data_format = \u0026#34;influx\u0026#34; 对后端DB status和proxysql端口存活，设置告警。这样就有一个相对完整的ProxySQL监控方案了。\n面板示例：\n原文连接地址：http://xgknight.com/2017/07/16/mysql-proxysql-monitor/\n","permalink":"http://localhost:1313/2017/07/mysql-proxysql-monitor/","summary":"\u003cp\u003eProxySQL能监控的信息不多，而且大部分是统计信息，不是性能数据。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e 1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 7\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 8\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 9\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e10\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e11\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e12\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e13\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-gdscript3\" data-lang=\"gdscript3\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003emysql\u003c/span\u003e\u003cspan class=\"o\"\u003e\u0026gt;\u003c/span\u003e \u003cspan class=\"n\"\u003eshow\u003c/span\u003e \u003cspan class=\"n\"\u003etables\u003c/span\u003e \u003cspan class=\"n\"\u003efrom\u003c/span\u003e \u003cspan class=\"n\"\u003estats\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e+--------------------------------+\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e \u003cspan class=\"n\"\u003etables\u003c/span\u003e                         \u003cspan class=\"o\"\u003e|\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e+--------------------------------+\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e \u003cspan class=\"n\"\u003eglobal_variables\u003c/span\u003e               \u003cspan class=\"o\"\u003e|\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e \u003cspan class=\"n\"\u003estats_mysql_commands_counters\u003c/span\u003e  \u003cspan class=\"o\"\u003e|\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e \u003cspan class=\"n\"\u003estats_mysql_connection_pool\u003c/span\u003e    \u003cspan class=\"o\"\u003e|\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e \u003cspan class=\"n\"\u003estats_mysql_global\u003c/span\u003e             \u003cspan class=\"o\"\u003e|\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e \u003cspan class=\"n\"\u003estats_mysql_processlist\u003c/span\u003e        \u003cspan class=\"o\"\u003e|\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e \u003cspan class=\"n\"\u003estats_mysql_query_digest\u003c/span\u003e       \u003cspan class=\"o\"\u003e|\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e \u003cspan class=\"n\"\u003estats_mysql_query_digest_reset\u003c/span\u003e \u003cspan class=\"o\"\u003e|\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e \u003cspan class=\"n\"\u003estats_mysql_query_rules\u003c/span\u003e        \u003cspan class=\"o\"\u003e|\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e+--------------------------------+\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e主要关心的指标都在表 \u003ccode\u003estats_mysql_global\u003c/code\u003e 里面，源代码 diamond 目录下有个 \u003cem\u003eproxysqlstat.py\u003c/em\u003e 脚本，是通过\u003ccode\u003eSHOW MYSQL STATUS\u003c/code\u003e命令，由diamond收集进程将指标上报到Graphite。有以下几个Metrics：\u003c/p\u003e","title":"ProxySQL监控方案"},{"content":"MySQL的高可用方案现在如 MHA, Galera, InnoDB Cluster，一旦在上游使用中间件之后，中间件本身可能成为单点。所以本文要介绍的是对于ProxySQL自身高可用的方案对比。 首先ProxySQL自身是通过Angel进程的形式运行，即proxysql如果有崩溃，主进程会自动拉起来。但如果是无响应或者网络故障，则需要另外的机制去做到服务的高可用。本文总结了四种方法。\nProxySQL有关介绍，请参考： http://xgknight.com/2017/04/10/mysql-proxysql-install-config/\n1. 与应用一起部署 所有部署应用的地方，都会部署proxysql节点，当这个proxysql挂掉之后，只影响本机的应用。而且不需要多经过一层网络。 但带来的问题是，如果应用节点很多，proxy的数量也会增加：\n会导致proxysql的配置不容易管理 proxysql对后端db健康检查的请求成倍增加 限制每个用户或后端db的 max_connections 特性用不了 2. 集中式部署，多ip引用 后端一个db集群，对应中间两个以上的 proxysql 节点，前端应用配置多个ip地址，随机挑选一个使用，完全无状态。仅需要多经过一次网络代理。 这种方式的好处是，不需要再对数据库这种基础服务，多引入一个软件来实现高可用（如下节的keepalive或consul），由应用端获取数据库连接的代码逻辑处理。\n但是因为proxysql访问地址是写在配置文件里面的，如果一个节点挂掉，随机挑选还是会落地这个失败的节点。所以优化方案是，ip列表里面默认取某一个，失败之后再选取下一个重试。\n示例代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 proxysql_addr_list = [\u0026#39;192.168.1.175\u0026#39;, \u0026#39;192.168.1.176\u0026#39;, \u0026#39;192.168.1.177\u0026#39;] proxysql_addr_list_len = 3 hostname = \u0026#39;this_hostname_for_hash_loadbalance\u0026#39; def get_dbconnection(): list_index = hash(hostname) % proxysql_addr_list_len dbconn = None try: dbconn = DBConnect(dbhost=proxysql_addr_list[ list_index ], dbport=3306) # timeout 1000ms except: if (list_index + 1) == proxysql_addr_list_len: list_index = -1 # like Circular Array dbconn = DBConnec(dbhost=proxysql_addr_list[ list_index + 1 ], dbport=3306) # if failed again, through exception return dbconn 上述并不完美，比如可以改用环形数组轮巡，允许重试其它更多的ip。\n能不能不进行多IP引用呢？ 为了避免后端引用IP的单点，可以将上面第1种和这里的第2中结合起来，改进的部署方案：（见文后参考链接） 即在原来的基础上，App上的proxysql后端，挂的还是ProxySQL集群。\n我个人没有验证这样的方案，如果要用需要充分验证proxysql互连的时候，有没有bug。\n3. 经典 keepalived 引入keepalived，通过VIP访问两个以上的proxysql节点，既可以减少一次网络传输，又可以实现proxysql自身的高可用，而且甚至不用关心脑裂的问题，因为proxysql配置完全一样，是无状态的，脑裂了也无妨。 你也可能意识到，这种方式一次只能一个proxysql提供服务，另一个proxysql节点始终处于备用状态。如果配合LVS或haproxy做负载均衡，部署架构又会多出一层网络请求，而且越发复杂（VIP不在proxysql节点上漂，而是在两个lvs之间）。 使用keepalived的前提是，局域网允许发组播包。这在阿里云ECS经典网络下是不允许的，如果有其它类似方式，如SLB也是可行的。目前测试环境采用是 haproxy + keepalived 的方式。\n4. Consul服务发现 如果上面的方式都不适用，那么可以进一步考虑使用第三方的服务发现组件。\n4.1 介绍 Consul用于实现分布式系统的服务发现与配置，我们将所有proxysql节点注册到consul上作为一个服务来提供，由 Consul agent Server 来判断proxysql节点的存活，每个应用节点上都安装 Consul agent Client 来供应用获取可用地址。\n这样部署架构的好处是：\n不需要多一层负载均衡，多一层网络链路 不需要部署大量的proxysql节点 App或者ProxySQL节点上的Consul故障，不影响其它节点。Consul Server集群的天生具备高可用 ProxySQL故障会被Consul检查到，踢除故障节点，并通知给所有consul agent 可以利用Consul的DNS接口实现简单的负载均衡 其实consul所做的与本文第2节的类似：自动提出不可用的节点，只是一个是被动、手动，一个是主动、自动。 下面简单演示一下。\n4.2 部署示例 Consul Server节点的安装在此略过，网上有不少文章，直接进入到在ProxySQL节点安装配置Consul。\nConsul agent:\napps-1: 10.0.201.168 apps-2: 10.0.201.220 apps-3: 10.0.201.156 ProxySQL node: 每个节点上运行了两个proxysql进程 7033: crm0, 7133: crm1\nproxysql-1 : 192.168.1.170 proxysql-2 : 192.168.1.171 配置 proxysql 节点上的Consul 配置 proxysql-1 节点上的Consul：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 $ sudo vim /etc/consul.d/config.json { \u0026#34;data_dir\u0026#34;: \u0026#34;/opt/consul\u0026#34;, \u0026#34;datacenter\u0026#34;: \u0026#34;Office_test\u0026#34;, \u0026#34;log_level\u0026#34;: \u0026#34;INFO\u0026#34;, \u0026#34;node_name\u0026#34;: \u0026#34;proxysql-1\u0026#34;, \u0026#34;retry_join\u0026#34;: [ \u0026#34;10.0.201.168\u0026#34;, \u0026#34;10.0.201.220\u0026#34;, \u0026#34;10.0.201.156\u0026#34; ], \u0026#34;telemetry\u0026#34;: { \u0026#34;statsd_address\u0026#34;: \u0026#34;10.0.201.34:8125\u0026#34;, \u0026#34;statsite_prefix\u0026#34;: \u0026#34;proxysql-1\u0026#34; }, \u0026#34;dns_config\u0026#34;: { \u0026#34;only_passing\u0026#34;: true } \u0026#34;acl_datacenter\u0026#34;: \u0026#34;Office_test\u0026#34;, \u0026#34;acl_default_policy\u0026#34;: \u0026#34;deny\u0026#34;, \u0026#34;encrypt\u0026#34;: \u0026#34;XXXXxxxx==\u0026#34; } $ sudo vi /etc/consul.d/proxysql.json {\u0026#34;services\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;proxysql_crm0\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;proxysql\u0026#34;, \u0026#34;address\u0026#34;: \u0026#34;192.168.1.170\u0026#34;, \u0026#34;port\u0026#34;: 7133, \u0026#34;tags\u0026#34;: [\u0026#34;test\u0026#34;, \u0026#34;crm0\u0026#34;], \u0026#34;check\u0026#34;: { \u0026#34;interval\u0026#34;: \u0026#34;5s\u0026#34;, \u0026#34;tcp\u0026#34;: \u0026#34;192.168.1.170:7033\u0026#34;, \u0026#34;timeout\u0026#34;: \u0026#34;1s\u0026#34; }, \u0026#34;enableTagOverride\u0026#34;: false, \u0026#34;token\u0026#34;: \u0026#34;xxxxxxxx-xxxx\u0026#34; }, { \u0026#34;id\u0026#34;: \u0026#34;proxysql_crm1\u0026#34;, \u0026#34;address\u0026#34;: \u0026#34;192.168.1.170\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;proxysql\u0026#34;, \u0026#34;port\u0026#34;: 7133, \u0026#34;tags\u0026#34;: [\u0026#34;test\u0026#34;, \u0026#34;crm1\u0026#34;], \u0026#34;check\u0026#34;: { \u0026#34;interval\u0026#34;: \u0026#34;5s\u0026#34;, \u0026#34;tcp\u0026#34;: \u0026#34;192.168.1.170:7133\u0026#34;, \u0026#34;timeout\u0026#34;: \u0026#34;1s\u0026#34; }, \u0026#34;enableTagOverride\u0026#34;: false, \u0026#34;token\u0026#34;: \u0026#34;xxxxxxxx-xxxx\u0026#34; } ]} 启动consul\n1 sudo consul agent -config-dir /etc/consul \u0026amp; 查看日志\nproxysql-2 节点上的Consul配置根据上面的内容去改。\n4.4 使用方式 先来看下效果：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 [root@proxysql-1 ~]# dig @127.0.0.1 -p 8600 crm0.proxysql.service.consul SRV ; \u0026lt;\u0026lt;\u0026gt;\u0026gt; DiG 9.8.2rc1-RedHat-9.8.2-0.62.rc1.el6_9.2 \u0026lt;\u0026lt;\u0026gt;\u0026gt; @127.0.0.1 -p 8600 crm0.proxysql.service.consul SRV ; (1 server found) ;; global options: +cmd ;; Got answer: ;; -\u0026gt;\u0026gt;HEADER\u0026lt;\u0026lt;- opcode: QUERY, status: NOERROR, id: 65293 ;; flags: qr aa rd; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 2 ;; WARNING: recursion requested but not available ;; QUESTION SECTION: ;crm0.proxysql.service.consul.\tIN\tSRV ;; ANSWER SECTION: crm0.proxysql.service.consul. 0\tIN\tSRV\t1 1 7033 proxysql-1.node.office_test.consul. crm0.proxysql.service.consul. 0\tIN\tSRV\t1 1 7033 proxysql-2.node.office_test.consul. ;; ADDITIONAL SECTION: proxysql-1.node.office_test.consul. 0 IN A\t192.168.1.170 proxysql-2.node.office_test.consul. 0 IN A\t192.168.1.171 ;; Query time: 3 msec ;; SERVER: 127.0.0.1#8600(127.0.0.1) ;; WHEN: Fri May 26 17:01:38 2017 ;; MSG SIZE rcvd: 157 看到域名 crm0.proxysql.service.consul 解析出来有两个可用地址 192.168.1.170，192.168.1.171，SRV记录还带出了端口信息（其实这里的端口对每个proxysql是固定/已知的，所以可不用SRV记录搜索）。\n在应用端想要连接proxysql使用的方式大致有3种：\nDNS接口 需要将各自开发语言的DNS解析库嵌入到项目，指定 127.0.0.1:8600 为dns地址来解析上面的 crm0.proxysql.service.consul 域名。这种方式会增加开发的复杂度。\n另一种方式是将应用服务器的默认DNS Server配置成本地consul的内置dns地址，并且consul设置 recursors 选项，来处理解析 consul. 以外的域名。这样对运维改动比较大。\n1 2 3 4 5 \u0026#34;recursors\u0026#34;: [ \u0026#34;10.143.22.116\u0026#34;, \u0026#34;10.143.22.118\u0026#34;, \u0026#34;114.114.114.114\u0026#34; ] HTTP接口 通过 API 的方式获取services信息：\n1 $ curl -X GET \u0026#39;http://10.0.201.156:8500/v1/health/service/proxysql?tag=crm1\u0026amp;passing=true\u0026#39; 可以获取到 crm1 库的proxysql所有健康的 Node 和 Service 信息，然后任取一个使用。\n但并不需要每一次访问proxysql都需要请求api，可以定时（如每隔10s）去请求，缓冲在本地或者变量里；在处理数据库连接的时候发现连接ProxySQL错误，则再主动触发一次向Consul请求新的地址，再重连。\n需要考虑的是访问API的地址如果是IP，往往也是单点。另者，java这类jvm语言修改配置后往往需要重启，也不简单。\nconsul-template直接生成数据库连接的配置文件 consul-template通过事先定义好的模板，根据发现服务的健康状态，生成最新可用的配置文件，然后下发。\n如果大但的想一下，各个服务或者语言的配置文件并不相同，直接生成一份 hosts 文件是最简单的，然后通过配置管理工具统一下发应用。也不需要关心是否需要重启应用。\nconsul watch Consul watch 功能，可以检测到service变化之后，主动调用一个脚本，脚本可以去更新数据库配置信息，根据需要决定是否重启，后者生成hosts。与consul-template思想是相同的。\n因为 watch 是通过阻塞式HTTP长连接请求的方式，实时获取到service的监控状态，所以有问题时反馈还比较及时。\n1 2 3 4 5 6 7 \u0026#34;watches\u0026#34;:[{ \u0026#34;type\u0026#34;: \u0026#34;service\u0026#34;, \u0026#34;service\u0026#34;: \u0026#34;proxysql\u0026#34;, \u0026#34;tag\u0026#34;: \u0026#34;crm0\u0026#34;, \u0026#34;passingonly\u0026#34;: true, \u0026#34;handler\u0026#34;: \u0026#34;sh /tmp/consul_watch_test.sh\u0026#34; }] /tmp/consul_watch_test.sh 脚本里或者python，可以做一些更新数据库配置文件、发送邮件等工作。\n参考\nhttps://www.percona.com/blog/2016/09/16/consul-proxysql-mysql-ha/ https://www.percona.com/blog/2017/01/19/setup-proxysql-for-high-availability-not-single-point-failure/ https://www.slideshare.net/DerekDowney/proxysql-tutorial-plam-2016 (本文部分图片出自该PPT) 原文连接地址：http://xgknight.com/2017/07/15/mysql-proxysql-ha-consul/\n","permalink":"http://localhost:1313/2017/07/mysql-proxysql-ha-consul/","summary":"\u003cp\u003eMySQL的高可用方案现在如 MHA, Galera, InnoDB Cluster，一旦在上游使用中间件之后，中间件本身可能成为单点。所以本文要介绍的是对于ProxySQL自身高可用的方案对比。\n首先ProxySQL自身是通过Angel进程的形式运行，即proxysql如果有崩溃，主进程会自动拉起来。但如果是无响应或者网络故障，则需要另外的机制去做到服务的高可用。本文总结了四种方法。\u003c/p\u003e","title":"ProxySQL高可用方案"},{"content":"近期一直在思考sql上线审核该怎么做，刚好接触到 ProxySQL 这个中间件，内置了一个计算sql指纹的功能，但是没有记录原始的sql语句。当前正有个紧急的拆库项目也希望知道库上所有的查询。于是把ProxySQL的代码下了回来研究了几天，改了把，加入了两个功能：\n在 stats_mysql_query_digest 表上增加 query_text 字段，当第一次出现这个digest_text时，把原始sql记录下来。 修改计算指纹的模块，对 IN或者 VALUES 后面的多个 ? 合并。这个是目前 c_tokenizer.c 文件里没有做的，用到底1点上可以避免重复记录。 效果： 多个 ? 被折叠成 ?,，有些意外情况时 ??，因为后面一些多余空格的缘故，没有像 pt-fingerprint 那样完全模糊化，像这里digest就保留了大小写、去除重复空格、保留 ` 分隔符。但仅有的几种意外情况是可以接受的。\n后面的 query_text 列也有些未知情况，就是末尾会加上一些奇怪的字符，还在排除，但大体不影响需求。\n代码是基于最新 v1.3.6 稳定版修改的，查看变更 https://github.com/sysown/proxysql/compare/v1.3.6...seanlook:v1.3.7-querysample_digest\n多个 ? 合并只涉及到 c_tokenizer.c 文件，分别在flag=4（处理 'abc','def' 的情况）和flag=5（处理 1,2, 3 的情况）加入判断：\n1 2 3 4 5 6 // wrap two more ? to one ?, if (*(p_r_t-2) == \u0026#39;?\u0026#39; \u0026amp;\u0026amp; (*(p_r_t-1) ==\u0026#39; \u0026#39; || *(p_r_t-1) == \u0026#39;,\u0026#39; || *(p_r_t-1) == \u0026#39;?\u0026#39;)){ *(p_r-1) = \u0026#39;,\u0026#39;; } else *p_r++ = \u0026#39;?\u0026#39;; 然后在 line:450 左右 COPY CHAR 的时候进行一次过滤：\n1 2 3 4 5 6 7 8 // COPY CHAR // ================================================= // wrap two more ? to ?, if ((*s == \u0026#39; \u0026#39; || *s == \u0026#39;,\u0026#39;) \u0026amp;\u0026amp; (*(p_r_t-1) == \u0026#39;?\u0026#39; || *(p_r_t-1) == \u0026#39;,\u0026#39; || *(p_r_t-1) == \u0026#39; \u0026#39;)) { if (*(p_r_t-1) == \u0026#39; \u0026#39; \u0026amp;\u0026amp; *(p_r_t-2) == \u0026#39;?\u0026#39;) *(p_r-1) = \u0026#39;,\u0026#39;; // p_r may be changed in line:435:is_digit_string } else { 这部分代码调试花了不少功夫，一是理清逻辑，而是意外情况处理。变量的用途注释不清晰，几年没写C，不得不动用 gdb 来跟踪调试，怀念大学时用IDE的日子。\n加 query_text 字段，在用 gdb 理清c++函数间调用关系的之后，改起来还是比较容易：\nMySQL_Session.cpp:Query_Info::init 里面会将连接会话的sql信息临时存起来 MySQL_Session.cpp:Query_Info::query_parser_init 调用 Qurey_Processor.cpp:Query_Processor::query_parser_init，里面会调用上面 c_tokenizer.c 来处理digest_text并计算得到digest 继而是 Query_Processor 类骨规则路由函数 process_mysql_query，但这与我们的改动无关 路由完成后，调用 query_parser_update_counters 函数来更新统计信息，改动从这里开始。从 sess 里拿到原始的sql，把地址传递给 update_query_digest() Query_Processor::update_query_digest 方法会判断当前digest是否已存在 digest_umap.find(qp-\u0026gt;digest_total) 如果不是第一次出现，则更新 last_seen 时间 如果是第一次出现，则 new QP_query_digest_stats 对象，就在这个地方把sql传过去。（Query_Processor.cpp:1026,1028） 在 QP_query_digest_stats 加入 query_text 字段并在析构函数里初始化，同时记得free掉 这个地方一度出现 qt 的值在赋给 query_text 的时候，被莫名的吃掉，猜想应该是内存分配的时候被擦掉了，请了公司C++大神涛哥一起调试看了下，是传过来长度截取不对。 现在是没有这个问题，但是会随机性出现本文开头所说，sql末尾出现意外字符。还需要进一步排查。 修改操作sqlite的命令 Query_Processor.cpp：SQLite3_result * Query_Processor::get_query_digests() ProxySQL_Admin.cpp：修改 stats_mysql_query_digest 表定义，以及插入sql的模板。 这个地方参数漏了一个导致proxysql crash，编译的时候建议把 Makefile中的 -O2 改成 -O0，这样gdb调试的时候不会优化输出，容易跟踪。 这些改动对于c++程序员来说，小菜一碟，但对于我一个DBA来说，总算啃下来了。主要是考虑功能急用，提交 issue 等作者renecannao发版也是太慢。 现在可以愉快的收集所有sql了，接下来就是新产生的sql进行自动化审核。\n以上两点特性对于升级来讲是无障碍的，因为 stats_mysql_query_stats 在内存里，重启之前字段就加上了，无需改动proxysql.db里面的内容。代码在我fork仓库的 v1.3.7-querysample_digest 分支，我也已提交 pull request 给作者合并。等消息中……\n原文连接地址：http://xgknight.com/2017/04/27/mysql-proxysql-patch-querytext-sample/\n","permalink":"http://localhost:1313/2017/04/mysql-proxysql-patch-querytext-sample/","summary":"\u003cp\u003e近期一直在思考sql上线审核该怎么做，刚好接触到 ProxySQL 这个中间件，内置了一个计算sql指纹的功能，但是没有记录原始的sql语句。当前正有个紧急的拆库项目也希望知道库上所有的查询。于是把ProxySQL的代码下了回来研究了几天，改了把，加入了两个功能：\u003c/p\u003e","title":"ProxySQL之改进patch：记录查询sql完整样例与合并digest多个?"},{"content":"本文会通过sysbench对ProxySQL进行基准测试，并与直连的性能进行对比。与此同时也对 Maxscale 和 Qihu360 Atlas 放在一起参考。 提示：压测前确保把query cache完全关掉。\n1. proxysql vs 直连 1.1 select nontrx 1 2 3 4 5 ./bin/sysbench --test=/root/sysbench2/sysbench/tests/db/oltp.lua --mysql-host=10.0.100.36 --mysql-port=6033 --mysql-user=myuser --mysql-password=mypass \\ --mysql-db=db15 --oltp-tables-count=20 --oltp-table-size=5000000 --report-interval=20 --oltp-dist-type=uniform --rand-init=on --max-requests=0 --oltp-test-mode=nontrx --oltp-nontrx-mode=select \\ --oltp-read-only=on --oltp-skip-trx=on --max-time=120 --num-threads=2 run num-threads依次加大 2 5 10 20 50 100 200 400 {% iframe http://www.tubiaoxiu.com/p.html?s=106165b0eeca215a\u0026amp;web_mode 900 700 %}\nsysbench线程并发数达到10以下，性能损失在30%以上；达到20，性能损失减少到10%左右。看到proxysql承载的并发数越高，性能损失越少；最好的时候在50线程数，相比直连损失5%。\n1.2 oltp dml 混合读写测试。proxysql结果图应该与上面相差无几，因为是主要好在计算 query digest 和规则匹配，与select无异，可参考下节的图示。\nsysbench 压测命令：\n1 2 3 4 5 6 ./bin/sysbench --test=/root/sysbench2/sysbench/tests/db/oltp.lua --mysql-host=10.0.100.34 --mysql-port=3306 --mysql-user=myuser --mysql-password=mypass \\ --mysql-db=db15 --oltp-tables-count=20 --oltp-table-size=5000000 --report-interval=20 --oltp-dist-type=uniform --rand-init=on --max-requests=0 --oltp-read-only=off --max-time=120 \\ --num-threads=2 run num-threads依次加大 2 5 10 16 20 50 100 200 400 分别对PrxoySQL, Maxscale, Atlas, 直连，四种情况做基准测试 2. proxysql vs maxscale vs atlas 作者自己也有指出，在客户端并发数不高的情况下，maxscale表现比proxysql要好。这里我也特意对maxscale和atlas一起做了个对比。配置基本是最小化的，没有很复杂的规则，只是中间转发。\nProxySQL (v1.3.5): mysql-threads=4 Atlas 360 (v2.2.1): event-threads=4 maxscale (v1.4.5): threads=4 ** 2.1 select nontrx ** oltp混合读写基准测试，没有复杂配置的情况下，ProxySQL与Maxscale神奇般的几乎重合，Qihu360的atlas要弱一些。\n** 2.2 oltp dml **\n原始数据： 3. rewrite vs non-rewrite 下面来测一下 query rewrite 对性能的影响，考虑到将来如果要分表，可以在ProxySQL这一层做，应用端无需改动表名。 为了达到效果，这里rewrite只是为表增加了个别名：\n1 2 3 -- proxysql admin cli update mysql_query_rules set match_pattern=\u0026#34;(.*)(sbtest\\d+)(.*)\u0026#34;,replace_pattern=\u0026#34;\\1\\2 as ttt \\3\u0026#34; where rule_id \u0026gt;=61 and rule_id \u0026lt;=92; load mysql query rules to run; sysbench num-threads=20 的结果：\nreplace? qps response time avg(ms) proxysql replace 15734.49 17.79 proxysql no-replace 16764.66 16.70 直连 18778.43 14.91 在20个并发线程下，有 rewrite 是 no-rewrite 性能的 93.9% 。测试线程数继续加大到 50，差别更小。\n4. lots of rules 测试ProxySQL定义的 query rules 数量（并匹配但不apply），对性能的影响。\n测试的规则时批量插入大量能匹配sysbench查询的规则，但 mysql_query_rules.apply=0 :\n1 2 3 4 insert into mysql_query_rules(active,schemaname,apply,flagIN) values (1,\u0026#39;db15\u0026#39;,0,0),(1,\u0026#39;db15\u0026#39;,0,0),(1,\u0026#39;db15\u0026#39;,0,0),(1,\u0026#39;db15\u0026#39;,0,0),(1,\u0026#39;db15\u0026#39;,0,0), ... # 2 100 200 400 800 1200 2000 这里偶然发现一个问题，flagIN=0的规则必须要在 !=0 的规则前面，否则flagOUT找不到下一个新链入口.(经作者回复是参数 mysql-query_processor_iterations 控制的) 下面的结果是 sysbench num-threads=20 的几轮数据：（由于结果接近，没作图）\nmatched rules QPS RT avg CPU% 2 16741.54 16.69 151 100 16743.54 16.69 152 200 16749.94 16.71 159 400 16556.09 16.91 176 800 16522.02 16.94 203 1200 16477.70 16.99 220 2000 16333.59 17.14 263 看到匹配到的规则随着增多，QPS变化不大，只是略微下降；平均响应时间增加在3%以内；倒是ProxySQL对CPU的负载增加比较明显，匹配的规则从 2 个增加到 2000，cpu使用增加了 74% 。\n参考：\nhttps://www.percona.com/blog/2017/04/10/proxysql-rules-do-i-have-too-many/#comment-10967989 原文连接地址：http://xgknight.com/2017/04/20/mysql-proxysql-performance-test/\n","permalink":"http://localhost:1313/2017/04/mysql-proxysql-performance-test/","summary":"\u003cp\u003e本文会通过sysbench对ProxySQL进行基准测试，并与直连的性能进行对比。与此同时也对 Maxscale 和 Qihu360 Atlas 放在一起参考。\n提示：压测前确保把query cache完全关掉。\u003c/p\u003e","title":"ProxySQL之性能测试对比"},{"content":"ProxySQL在连接池(persistent connection poll)的基础上，还有一个连接复用的概念 multiplexing connection，官方的wiki里没有很明确的说明，但在作者的一些 blog post 和 issue 里能找到解答： https://github.com/sysown/proxysql/issues/939#issuecomment-287489317\n由于SQL可以路由，一个客户端连接上来，可能会到多个 hostgroup 发起连接。复用的意思是，一个后端DB的连接，可以“同时”被多个客户端使用。\n传统的连接池，会在客户端断开连接（会话）后，把连接放回到池里。在ProxySQL中，由于连接复用，连接会在sql语句执行结束后，便将连接放回到池里（客户端会话可能并没有断开），这样便可大大提高后端连接的使用效率，而避免前段请求过大导致后端连接数疯长。\n但这样做有时候并不安全，比如应用端连接时指定了 set NAMES xxx，然后执行查询，那么由于multiplexing可能导致两个语句发到不同的DB上执行，继而没有按照预期的字符集执行。proxysql考虑到了这种情况：\n连接会话里创建了临时表，CREATE TEMPORARY table xxxx... select @开头的变量，如select @@hostname 手动开启了事务，start transaction, commit, rollback等等 连接设置了自己的用户变量，比如set names xxx, set autocommit x, set sql_mode=xxx, set v_uservar=xx等等 第1,2,3点会根据路由规则，会自动禁用multiplex，发到对应hostgroup后，连接未断开之前不会复用到其它客户端。具体是发到主库还是从库，与匹配的规则有关。 issue #941 和 #917 都有提到临时表丢失的问题，可以用不同的rule来避免\n下面对上面几点一一说明。\n1. 临时表与用户变量（验证 1, 2） 以下注意连接的会话窗口及执行顺序，admin打头的是在proxysql管理接口上执行。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 -- [session 1] mysql client proxysql (ecdba@10.0.100.36:6033) [(none)]\u0026gt; select 1; +---+ | 1 | +---+ | 1 | +---+ -- [session 2] proxysql admin cli select * from stats_mysql_processlist; Empty set (0.00 sec) 普通查询，session 1 没断开，但后端连接已放回连接池，所以看不到processlist。下面试验临时表： -- [session 1] mysql client proxysql (ecdba@10.0.100.36:6033) [(none)]\u0026gt; CREATE TEMPORARY TABLE db0.tbl_tmp(id int); Query OK, 0 rows affected (0.18 sec) -- [session 2] proxysql admin cli (admin@127.0.0.1:6032) [(none)]\u0026gt; select * from stats_mysql_processlist; +----------+-----------+-------+--------------------+-------------+----------+-----------+-------------+------------+--------------+----------+---------+---------+------+ | ThreadID | SessionID | user | db | cli_host | cli_port | hostgroup | l_srv_host | l_srv_port | srv_host | srv_port | command | time_ms | info | +----------+-----------+-------+--------------------+-------------+----------+-----------+-------------+------------+--------------+----------+---------+---------+------+ | 0 | 60 | ecdba | information_schema | 10.0.100.34 | 27058 | 100 | 10.0.100.36 | 41245 | 10.0.100.100 | 3307 | Sleep | 4506 | | +----------+-----------+-------+--------------------+-------------+----------+-----------+-------------+------------+--------------+----------+---------+---------+------+ 1 row in set (0.00 sec) 看到后端的连接没有释放回连接池，但是在 session 1 里select却看不到刚才创建的临时表： -- [session 1] (ecdba@10.0.100.36:6033) [(none)]\u0026gt; select * from db0.tbl_tmp; ERROR 1146 (42S02): Table \u0026#39;db0.tbl_tmp\u0026#39; doesn\u0026#39;t exist -- [session 2] (admin@127.0.0.1:6032) [(none)]\u0026gt; select * from stats_mysql_processlist; +----------+-----------+-------+--------------------+-------------+----------+-----------+------------+------------+----------+----------+---------+---------+------+ | ThreadID | SessionID | user | db | cli_host | cli_port | hostgroup | l_srv_host | l_srv_port | srv_host | srv_port | command | time_ms | info | +----------+-----------+-------+--------------------+-------------+----------+-----------+------------+------------+----------+----------+---------+---------+------+ | 0 | 60 | ecdba | information_schema | 10.0.100.34 | 27058 | 1000 | | | | | Sleep | 2002 | | +----------+-----------+-------+--------------------+-------------+----------+-----------+------------+------------+----------+----------+---------+---------+------+ 1 row in set (0.00 sec) select之后，发现上面的srv_host为空。下面往临时表里插数据，正常，且连接被 session 1 客户端持有： -- [session 1] (ecdba@10.0.100.36:6033) [(none)]\u0026gt; insert into db0.tbl_tmp values(1); Query OK, 1 row affected (0.01 sec) -- [session 2] (admin@127.0.0.1:6032) [(none)]\u0026gt; select * from stats_mysql_processlist; +----------+-----------+-------+--------------------+-------------+----------+-----------+-------------+------------+--------------+----------+---------+---------+------+ | ThreadID | SessionID | user | db | cli_host | cli_port | hostgroup | l_srv_host | l_srv_port | srv_host | srv_port | command | time_ms | info | +----------+-----------+-------+--------------------+-------------+----------+-----------+-------------+------------+--------------+----------+---------+---------+------+ | 0 | 60 | ecdba | information_schema | 10.0.100.34 | 27058 | 100 | 10.0.100.36 | 41245 | 10.0.100.100 | 3307 | Sleep | 2996 | | +----------+-----------+-------+--------------------+-------------+----------+-----------+-------------+------------+--------------+----------+---------+---------+------+ 1 row in set (0.00 sec) -- [session 1] (ecdba@10.0.100.36:6033) [(none)]\u0026gt; select 1; +---+ | 1 | +---+ | 1 | +---+ -- [session 2] (admin@127.0.0.1:6032) [(none)]\u0026gt; select * from stats_mysql_processlist; +----------+-----------+-------+--------------------+-------------+----------+-----------+------------+------------+----------+----------+---------+---------+------+ | ThreadID | SessionID | user | db | cli_host | cli_port | hostgroup | l_srv_host | l_srv_port | srv_host | srv_port | command | time_ms | info | +----------+-----------+-------+--------------------+-------------+----------+-----------+------------+------------+----------+----------+---------+---------+------+ | 0 | 60 | ecdba | information_schema | 10.0.100.34 | 27058 | 1000 | | | | | Sleep | 2303 | | +----------+-----------+-------+--------------------+-------------+----------+-----------+------------+------------+----------+----------+---------+---------+------+ 通过上面的过程可以看见，proxysql在遇到与会话本身相关的变量或操作时，自动禁用了multiplexing，并且针对整个会话有效，直到断开连接。另外，禁用了multiplexing，但路由规则依然生效，这就导致了select临时表时路由到了其它实例， Table xxx doesn\u0026rsquo;t exist。\n2. 显式start transaction (验证3) 第1,2点根据开发的习惯，都可以避免使用，但显式事务有时却不得不用，也做一个测试。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 为了效果明显，我将一个不相干的实例，分配同一个hostgroup_id，权重1:1 -- [session 1] (ecdba@10.0.100.36:6033) [(none)]\u0026gt; select * from db0.tbl_0; +-----+----------+--------+ | fid | username | corpid | +-----+----------+--------+ | 1 | db0 aa | 0 | | 2 | db0 aa | 16 | | 3 | db0 aa | 32 | +-----+----------+--------+ (ecdba@10.0.100.36:6033) [(none)]\u0026gt; select * from db0.tbl_0; ERROR 1146 (42S02): Table \u0026#39;db0.tbl_0\u0026#39; doesn\u0026#39;t exist (ecdba@10.0.100.36:6033) [(none)]\u0026gt; begin; -- 开启一个事务 (ecdba@10.0.100.36:6033) [(none)]\u0026gt; select * from db0.tbl_0; +-----+----------+--------+ | fid | username | corpid | +-----+----------+--------+ | 1 | db0 aa | 0 | | 2 | db0 aa | 16 | | 3 | db0 aa | 32 | +-----+----------+--------+ (ecdba@10.0.100.36:6033) [(none)]\u0026gt; select * from db0.tbl_0; ERROR 1146 (42S02): Table \u0026#39;db0.tbl_0\u0026#39; doesn\u0026#39;t exist 这就尴尬了，明显是在同一个事务里面，后端依然请求了多个backend。设置 transaction_persistent ： -- [session 2] (admin@127.0.0.1:6032) [(none)]\u0026gt; update mysql_users set transaction_persistent=1 where username=\u0026#39;ecdba\u0026#39;; (admin@127.0.0.1:6032) [(none)]\u0026gt; load mysql users to run; -- [session 1] (ecdba@10.0.100.36:6033) [(none)]\u0026gt; begin; Query OK, 0 rows affected (0.00 sec) (ecdba@10.0.100.36:6033) [(none)]\u0026gt; select * from db0.tbl_0; +-----+----------+--------+ | fid | username | corpid | +-----+----------+--------+ | 1 | db0 aa | 0 | | 2 | db0 aa | 16 | | 3 | db0 aa | 32 | +-----+----------+--------+ 反复执行多次还是上面的结果。 看到到后端连接的情况： -- [session 2] (admin@127.0.0.1:6032) [(none)]\u0026gt; select * from stats_mysql_processlist; +----------+-----------+-------+--------------------+-------------+----------+-----------+-------------+------------+--------------+----------+---------+---------+------+ | ThreadID | SessionID | user | db | cli_host | cli_port | hostgroup | l_srv_host | l_srv_port | srv_host | srv_port | command | time_ms | info | +----------+-----------+-------+--------------------+-------------+----------+-----------+-------------+------------+--------------+----------+---------+---------+------+ | 3 | 73 | ecdba | information_schema | 10.0.100.34 | 45030 | 100 | 10.0.100.36 | 6057 | 10.0.100.100 | 3307 | Sleep | 43046 | | +----------+-----------+-------+--------------------+-------------+----------+-----------+-------------+------------+--------------+----------+---------+---------+------+ 1 row in set (0.00 sec) 看到用户的 transaction_persistent 属性可以保证在同一个事务内的所有sql，都发向后端同一个db实例。如果它为0，同时一个hostgroup有多个可用slave，可能由于不同从库的延迟不一样，而查到不一致的数据。\ntransaction_persistent=1 时还注意一下隐藏的一点点细节，begin 开启事务后，事务内所有语句包括select，都路由到了主库，这是因为 begin 匹配规则选择的是主库，后续的查询都跟着走;而 transaction_persistent=0 时 bgein 由于路由规则作用，也发到了主库，但后续的select,update等是不受它约束，继续根据路由规则走。在 非 master-master 模式下，事务还是安全的。\n3.1 autocommit 会话变量 (验证4) 第 4 点略微有些复杂，开始之前先引用一段作者针对 issue #653 的回复：（不完全翻译）\nProxySQL doesn\u0026rsquo;t track user variable\nProxySQL不会记录 用户变量，当proxysql识别到 set @variable1 = 67 语句时，会自动禁用连接复用(disable multiplexing)，并根据路由规则选择后端节点（通常是写节点），执行完成后，连接不会放回连接池，直到disconnect。\nProxySQL tracks some session variables\nProxySQL会记录 会话变量，“记录” 的意思是，proxysql接收到这些会话变量后，不会马上从后端连接池去拿连接然后 set xxx （因为还没有足够的信息知道拿哪个用户哪个db的连接），而是在当前连接保存起来，等待下一个查询命令，然后一起发送到到后端。use dbname就是这样处理的。 当前，记录的只有 autocommit 和字符集变量、timezone。比如执行sql前发送一个 set autocommit=1，proxysql会马上返回一个 OK，代表它知道应用端设置了自动提交，等真正的dml请求过来时，它将与后端拿到的连接比较autocommit是否匹配，不匹配则先set再执行dml。\n当然现实还受到proxysql全局变量 mysql-enforce_autocommit_on_reads 的影响，即是否开启对读操作强制 autocommit。这个变量所解决的问题是，在同一个事务里既有 write 又有 read 且配置了读写分离的情况下，会导致在 读库 和 写库 各自开一个事务 (从库会set autocommit=0)，这就不合理了，所以把它设为 true 可以保证事务始终是一个。默认 false。 但是如上节所说，如果开启了 transaction_persistent=1，这个问题就不存在了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 -- [session 1] (ecdba@10.0.100.36:6033) [(none)]\u0026gt; set @variable1 = 67; -- [session 2] (admin@127.0.0.1:6032) [(none)]\u0026gt; show processlist; +-----------+-------+--------------------+-----------+---------+---------+------+ | SessionID | user | db | hostgroup | command | time_ms | info | +-----------+-------+--------------------+-----------+---------+---------+------+ | 79 | ecdba | information_schema | 100 | Sleep | 8008 | | +-----------+-------+--------------------+-----------+---------+---------+------+ 1 row in set (0.00 sec) 与后端的连接已建立。但如果没有路由规则匹配到，proxysql会选择该用户 default_hostgroup，一般是0，由于没有 HG 0 记录，这个set variables会失败： -- [session 1] (ecdba@10.0.100.36:6033) [(none)]\u0026gt; set @variable1 = 67; ERROR 9001 (HY000): Max connect timeout reached while reaching hostgroup 0 after 11462ms 同样情况下，set autocommit 和 set names 就很快返回，并且看不到后端有连接： (ecdba@10.0.100.36:6033) [(none)]\u0026gt; set session transaction isolation level read committed; Query OK, 0 rows affected (0.00 sec) (ecdba@10.0.100.36:6033) [(none)]\u0026gt; set autocommit=0; Query OK, 0 rows affected (0.00 sec) -- [session 2] (admin@127.0.0.1:6032) [(none)]\u0026gt; show processlist; Empty set (0.00 sec) -- [session 1] begin开启一个事务，验证 transaction_persistent： (ecdba@10.0.100.36:6033) [(none)]\u0026gt; UPDATE db0.tbl_0 set username=\u0026#39;db0 autocommit\u0026#39; where fid=3; Query OK, 1 row affected (0.00 sec) Rows matched: 1 Changed: 1 Warnings: 0 (ecdba@10.0.100.36:6033) [(none)]\u0026gt; select * from db0.tbl_0; +-----+----------------+--------+ | fid | username | corpid | +-----+----------------+--------+ | 1 | db0 aa | 0 | | 2 | db0 aa | 16 | | 3 | db0 autocommit | 32 | +-----+----------------+--------+ 3 rows in set (0.00 sec) (ecdba@10.0.100.36:6033) [(none)]\u0026gt; commit; Query OK, 0 rows affected (0.00 sec) 查看后端DB（主库）的 general_log：（都发到了主库） 9651978 Connect\tecdba@10.0.100.36 on information_schema 9651978 Query\tSET autocommit=0 9651978 Query\tUPDATE db0.tbl_0 set username=\u0026#39;db0 autocommit\u0026#39; where fid=3 9651978 Query\tselect * from db0.tbl_0 9651978 Query\tcommit 这也告诉我们，尽量不要在 proxy admin cli 里面执行 show slave status， set global xxx 这样的管理命令，你较难预知到后端在哪里执行的。\n3.2 字符集prepared会话变量 (验证4) 对字符集 set NAMES xxx, set character_set_client=xxx，处理方法与上面 set autocommit 是一样的，但是遇到使用 prepared statement 时需要特别提一下。\n首先ProxySQL所支持的字符集，在表 mysql_collations 可以看到，它是直接从本地安装的mysql client lib获取的，proxysql默认使用的是utf8，指的是在连接的时候默认认为客户端的字符集是utf8。\n根据 issue #780：https://github.com/sysown/proxysql/issues/780 的讨论，某些框架比如 Laravel 在通过PDO连接MySQL时，执行 prepared statement时会连同 set NAMES xx 一起发送，导致没有生效。经测试，该问题在 v1.3.5 中已不存在：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 -- [session 1] mysql -uecweb -pweber -h10.0.100.34 -P6033 --default-character-set=latin1 (ecweb@10.0.100.34:6033) [(none)]\u0026gt; select * from d_ec_crm.tttt; +-----+-------+ | fid | fname | +-----+-------+ | 1 | xx??? | +-----+-------+ latin1连接看utf8的数据，所以乱码。下面模拟 prepared statement 设置字符集： (ecweb@10.0.100.34:6033) [(none)]\u0026gt; PREPARE stmt FROM \u0026#39;SET NAMES utf8\u0026#39;; Query OK, 0 rows affected (0.00 sec) Statement prepared -- [session 2] (admin@127.0.0.1:6032) [(none)]\u0026gt; select * from stats_mysql_processlist; +----------+-----------+-------+--------------------+-------------+----------+-----------+-------------+------------+---------------+----------+---------+---------+------+ | ThreadID | SessionID | user | db | cli_host | cli_port | hostgroup | l_srv_host | l_srv_port | srv_host | srv_port | command | time_ms | info | +----------+-----------+-------+--------------------+-------------+----------+-----------+-------------+------------+---------------+----------+---------+---------+------+ | 1 | 50 | ecweb | information_schema | 10.0.100.34 | 46389 | 110 | 10.0.100.34 | 31946 | 192.168.1.229 | 3307 | Sleep | 35649 | | +----------+-----------+-------+--------------------+-------------+----------+-----------+-------------+------------+---------------+----------+---------+---------+------+ 直接执行还是乱码，也要在prepared ： (ecweb@10.0.100.34:6033) [(none)]\u0026gt; select * from d_ec_crm.tttt; +-----+-------+ | fid | fname | +-----+-------+ | 1 | xx??? | +-----+-------+ (ecweb@10.0.100.34:6033) [(none)]\u0026gt; PREPARE stmt FROM \u0026#39;select * from d_ec_crm.tttt\u0026#39;; Query OK, 0 rows affected (0.00 sec) Statement prepared (ecweb@10.0.100.34:6033) [(none)]\u0026gt; EXECUTE stmt; +-----+-------------+ | fid | fname | +-----+-------------+ | 1 | xx嘻嘻嘻 | +-----+-------------+ 注意到 PREPARE stmt FROM 'SET NAMES utf8' 发送之后，马上与后端建立了连接，而不像上节set names xx止步于proxysql。所以是自动禁用了 multiplexing。\n3.3 set sql_mode 作者明确表示 sql_mode 在 1.3.x 版本里不会track，也就是它完全按照路由规则走，不会像临时表或用户变量那样 disable multiplexing automaticly，也不像上面的会话变量那样 “记录” 然后一并发送。\n如果sql_mode确实对应用使用造成困扰，1.4版本里会修复，在此前估计只好将连接复用的特性全局禁用：\n1 2 3 SET mysql-multiplexing=\u0026#39;false\u0026#39;; LOAD MYSQL VARIABLES TO RUNTIME; SAVE MYSQL VARIABLES TO DISK; 参考 issue #916。禁用 multiplexing 后，就像一般的中间件连接池一样，维持或者释放连接。\n最后，关于 multiplexing 向作者提了一个特性 594#issuecomment-294703577 ：前端连接执行完一个查询，后端不马上把它返回连接池（复用），而是等待几秒，如果这个连接后续又有sql进来，就不需要重新从池里获取连接，还有检查一堆变量。renecannao 的回复非常及时，也确认 v1.4 会加上这个功能。\nupdated at 2017-07-27: 关于连接复用与连接池的差别，在后一次与作者的沟通中，更加明确了，见 #issue 1107: 问题始于发现环境中的connection pool没有起作用（禁用了multiplexing），因为一开始只是认为禁用了multiplexing，connection pool不会受影响。但实际不是的，在1.3.x版本里，禁用multiplexing，就相当于连接复用和连接池都没有了，前端应用在释放连接后，proxysql也把后端的连接释放了；在1.4.x版本里表现不同，禁用multiplexing后，前端连接释放，proxysql对后端的连接继续保持，并对连接重置以便重复利用。\n所以如果测试上没啥问题，建议开启连接复用，或者升级到 1.4.x 版本。\n原文连接地址：http://xgknight.com/2017/04/17/mysql-proxysql-multiplexing/\n","permalink":"http://localhost:1313/2017/04/mysql-proxysql-multiplexing/","summary":"\u003cp\u003eProxySQL在连接池(\u003cem\u003epersistent connection poll\u003c/em\u003e)的基础上，还有一个连接复用的概念 \u003cem\u003emultiplexing connection\u003c/em\u003e，官方的wiki里没有很明确的说明，但在作者的一些 blog post 和 issue 里能找到解答： \u003ca href=\"https://github.com/sysown/proxysql/issues/939#issuecomment-287489317\"\u003ehttps://github.com/sysown/proxysql/issues/939#issuecomment-287489317\u003c/a\u003e\u003c/p\u003e","title":"ProxySQL之连接复用（multiplexing）以及相关问题说明"},{"content":"本文演示使用ProxySQL来完成读写分离和后端分库的一个实际配置过程，安装及配置项介绍见前文 ProxySQL之安装及配置详解。\n环境\n1 2 3 4 5 6 7 8 9 10 11 instance0: 10.0.100.100 (db0,db2,db4,db6) instance1: 10.0.100.101 (db1,db3,db5,db7) instance2: 10.0.100.102 (db2,db6,db10,db14) instance3: 10.0.100.103 (db3,db7,db11,db15) instance0 slave: 192.168.10.4:3316 instance1 slave: 192.168.10.4:3326 instance2 slave: 192.168.10.4:3336 instance3 slave: 192.168.10.4:3346 proxysql node0: 10.0.100.36 现在想达到这样一个目的：客户端应用连接上 proxysql 的ip:port，连接时指定分库db名，执行sql时自动路由到对应的实例、对应的库。考虑下面的部署结构： 任何一个proxysql节点都是对等的，路由请求到后端instance的各个database上。\n1. 配置后端DB 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 -- proxysql admin cli insert into mysql_servers(hostgroup_id,hostname,port,weight,weight,comment) values (100, \u0026#39;10.0.100.100\u0026#39;, 3307, 1, \u0026#39;db0,ReadWrite\u0026#39;), (1000, \u0026#39;10.0.100.100\u0026#39;, 3307, 1, \u0026#39;db0,ReadWrite\u0026#39;),(1000, \u0026#39;192.168.10.4\u0026#39;, 3316, 9, \u0026#39;db0,ReadOnly\u0026#39;); insert into mysql_servers(hostgroup_id,hostname,port,weight,weight,comment) values (101, \u0026#39;10.0.100.101\u0026#39;, 3307, 1, \u0026#39;db1,ReadWrite\u0026#39;), (1001, \u0026#39;10.0.100.101\u0026#39;, 3307, 1, \u0026#39;db1,ReadWrite\u0026#39;),(1001, \u0026#39;192.168.10.4\u0026#39;, 3326, 9, \u0026#39;db1,ReadOnly\u0026#39;); insert into mysql_servers(hostgroup_id,hostname,port,weight,weight,comment) values (102, \u0026#39;10.0.100.102\u0026#39;, 3307, 1, \u0026#39;db2,ReadWrite\u0026#39;), (1002, \u0026#39;10.0.100.102\u0026#39;, 3307, 1, \u0026#39;db2,ReadWrite\u0026#39;),(1002, \u0026#39;192.168.10.4\u0026#39;, 3336, 9, \u0026#39;db2,ReadOnly\u0026#39;); insert into mysql_servers(hostgroup_id,hostname,port,weight,weight,comment) values (103, \u0026#39;10.0.100.103\u0026#39;, 3307, 1, \u0026#39;db3,ReadWrite\u0026#39;), (1003, \u0026#39;10.0.100.103\u0026#39;, 3307, 1, \u0026#39;db3,ReadWrite\u0026#39;),(1003, \u0026#39;192.168.10.4\u0026#39;, 3346, 9, \u0026#39;db3,ReadOnly\u0026#39;); 比如 100 是主库，则 1000 是从库，同时主库也可以处理 1/10 的读请求。\n2. 配置用户 1 2 3 4 -- proxysql admin cli insert into mysql_users(username, password,active,transaction_persistent) values(\u0026#39;user0\u0026#39;, \u0026#39;password0\u0026#39;, 1, 1),(\u0026#39;read1\u0026#39;, \u0026#39;password1\u0026#39;, 1, 1); 这里将 transaction_persistent 设置为1，如果不知道它的含义，请参考前文。\n要确保用户有能够登陆到后端的所有db的权限。\n3. 修改全局变量 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 -- proxysql admin cli set mysql-default_charset=\u0026#39;utf8mb4\u0026#39;; set mysql-query_retries_on_failure=0; set mysql-max_stmts_per_connection=1000; set mysql-eventslog_filename=\u0026#39;queries.log\u0026#39;; set monitor_slave_lag_when_null=7200; set mysql-ping_timeout_server=1500; set mysql-monitor_connect_timeout=1000; set mysql-default_max_latency_ms=2000; set mysql-monitor_username=\u0026#39;monitor\u0026#39;; set mysql-monitor_password=\u0026#39;monitor\u0026#39;; set mysql-server_version=\u0026#39;5.6.16\u0026#39;; 需要提前给 monitor 账号开通权限，一般共用监控数据库的权限就足够了。\n让上面所有的修改生效:\n1 2 3 4 5 6 7 8 9 10 11 12 -- proxysql admin cli -- 应用 load mysql users to runtime; load mysql servers to runtime; load mysql variables to runtime; -- 保存到磁盘 save mysql users to disk; save mysql servers to disk; save mysql variables to disk; save mysql users to mem; -- 可以屏蔽看到的明文密码 4. 添加路由规则 一般配置ProxySQL规则步骤是 issues #653 :\n配置proxysql，将所有sql都发到主库 分析表 stats_mysql_query_digest 里面哪几种查询占比高 筛选哪些些占比高的SELECT，可以路由到从库 修改 mysql_query_rules 里面的规则，使其生效。不要一味的把所有查询都路由到主库 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 -- [1] read\u0026amp;write split insert into mysql_query_rules(rule_id, active,match_digest,apply,flagOUT) values(49, 1,\u0026#39;^select\\s.*\\sfor update\u0026#39;,0,21); insert into mysql_query_rules(rule_id, active,match_digest,apply,flagOUT) values(50, 1,\u0026#39;^\\(?select\u0026#39;,0,20); insert into mysql_query_rules(rule_id, active,match_digest,negate_match_pattern,apply,flagOUT) values(60, 1,\u0026#39;^select\u0026#39;,1,0,21); -- 下面最好从rule_id 70开始，中间留空 -- [2] flag 20 read insert into mysql_query_rules(active,schemaname,destination_hostgroup,apply,flagIN,flagOUT) values (1,\u0026#39;db0\u0026#39;,1000,1,20,20), (1,\u0026#39;db1\u0026#39;,1001,1,20,20), (1,\u0026#39;db2\u0026#39;,1002,1,20,20), (1,\u0026#39;db3\u0026#39;,1003,1,20,20), (1,\u0026#39;db4\u0026#39;,1000,1,20,20), (1,\u0026#39;db5\u0026#39;,1001,1,20,20), (1,\u0026#39;db6\u0026#39;,1002,1,20,20), (1,\u0026#39;db7\u0026#39;,1003,1,20,20), (1,\u0026#39;db8\u0026#39;,1000,1,20,20), (1,\u0026#39;db9\u0026#39;,1001,1,20,20), (1,\u0026#39;db10\u0026#39;,1002,1,20,20), (1,\u0026#39;db11\u0026#39;,1003,1,20,20), (1,\u0026#39;db12\u0026#39;,1000,1,20,20), (1,\u0026#39;db13\u0026#39;,1001,1,20,20), (1,\u0026#39;db14\u0026#39;,1002,1,20,20), (1,\u0026#39;db15\u0026#39;,1003,1,20,20); -- [3] flag 21 write insert into mysql_query_rules(active,schemaname,destination_hostgroup,apply,flagIN,flagOUT) values (1,\u0026#39;db0\u0026#39;,100,1,21,21), (1,\u0026#39;db1\u0026#39;,101,1,21,21), (1,\u0026#39;db2\u0026#39;,102,1,21,21), (1,\u0026#39;db3\u0026#39;,103,1,21,21), (1,\u0026#39;db4\u0026#39;,100,1,21,21), (1,\u0026#39;db5\u0026#39;,101,1,21,21), (1,\u0026#39;db6\u0026#39;,102,1,21,21), (1,\u0026#39;db7\u0026#39;,103,1,21,21), (1,\u0026#39;db8\u0026#39;,100,1,21,21), (1,\u0026#39;db9\u0026#39;,101,1,21,21), (1,\u0026#39;db10\u0026#39;,102,1,21,21), (1,\u0026#39;db11\u0026#39;,103,1,21,21), (1,\u0026#39;db12\u0026#39;,100,1,21,21), (1,\u0026#39;db13\u0026#39;,101,1,21,21), (1,\u0026#39;db14\u0026#39;,102,1,21,21), (1,\u0026#39;db15\u0026#39;,103,1,21,21); -- [4] no schema given when connect insert into mysql_query_rules(rule_id,active,schemaname,apply,flagOUT) values(20,1,\u0026#39;information_schema\u0026#39;,0,302); -- [5] route according to dbX. insert into mysql_query_rules(rule_id,active,match_digest,destination_hostgroup,apply,flagIN,flagOUT) values(1000,1,\u0026#39;([\\s\\`])db(0|4|8|12)([\\.\\`])\u0026#39;,100,1,302,302); insert into mysql_query_rules(rule_id,active,match_digest,destination_hostgroup,apply,flagIN,flagOUT) values(1001,1,\u0026#39;([\\s\\`])db(1|5|9|13)([\\.\\`])\u0026#39;,101,1,302,302); insert into mysql_query_rules(rule_id,active,match_digest,destination_hostgroup,apply,flagIN,flagOUT) values(1002,1,\u0026#39;([\\s\\`])db(2|6|10|14)([\\.\\`])\u0026#39;,102,1,302,302); insert into mysql_query_rules(rule_id,active,match_digest,destination_hostgroup,apply,flagIN,flagOUT) values(1003,1,\u0026#39;([\\s\\`])db(3|7|11|15)([\\.\\`])\u0026#39;,103,1,302,302); -- [6] wrong usage insert into mysql_query_rules(rule_id,active,match_digest,apply,flagIN,flagOUT,error_msg,comment) values(1404,1,\u0026#39;^SELECT DATABASE\\(\\)$\u0026#39;,1,302,302,\u0026#39;You should specify schema name first\u0026#39;, \u0026#39;use db0 Take long when no schema given for connection\u0026#39;); -- [7] default route insert into mysql_query_rules(rule_id,active,apply, flagIN,flagOUT,error_msg,comment) values(9999,1,1, 302,302,\u0026#39;No query rules matched (by ProxySQL)\u0026#39;, \u0026#34;Don\u0026#39;t define the default hostgroup 0 for ME\u0026#34;); -- [8] LOAD MYSQL QUERY RULES TO RUN; SAVE MYSQL QUERY RULES TO DISK; 逐个解释：\n以 select 开头并且不是 for update 类型的SQL，进入到新的规则链flagOUT=20;\n其它诸如 insert, delete, update, replace, set, show 等语句，都进入到规则链flagOUT=21。 注：\u0026rsquo;^(?select\u0026rsquo; 规则匹配以select或 (select 开头的查询，但目前proxysql(1.3.6, 1.4.1)版本对以 ( 开头的查询不记录 stats_mysql_query_digest 表。#issue 1100\n有个小技巧，mysql_query_rules 表的rule_id有自增，但最好从中间某个数开始，因为一旦后续可能需要紧急在前面插入规则，从1开始就没空位了。\n这里大家可能有个顾虑，从库上可以执行 set NAMES xxx, set session sql_mode=xxx, SET autocommit=?, commit, rollback, START TRANSACTION, use dbx 这样的语句，不能全路由到主库吧？对此，另起了一篇文章 http://xgknight.com/2017/04/17/mysql-proxysql-multiplexing 。\nflagIN=20 是 只读链 的入口\n根据连接时指定的dbname，路由到对应的分库上。db0, db4, db8, db12 路由到 hostgroup_id=1000 ，db1, db5, db9, db16 路由到 hostgroup_id=1002 ，依次类推。 flagIN=flagOUT 则结束匹配。\nflagOUT=21 是 读写链的入口\n与上面的 [2] 类似，但是根据dbname路由到主库。\n当建立连接的时候没有指定dbname时，分两种情况\n使用连接的时候 use db0，因为mysql协议在每次 use dbname 时都会发送一个 SELECT DATABASE() 命令，第一次由于没有连接上后端任何DB，命令会执行超时失败，再次 use db0 是才成功。具体参考我所提的 issue #988 。 因此这里我为它添加了一个规则 [6]，遇到这种情况马上处理，而不用等待失败。 使用连接时从未有默认schema，添加规则 [5]，使用 schemaname.tablename 的形式匹配 schemaname，然后路由到对应的 hostgroup 。 因为没有定义 hostgroup 0，在意外情况什么规则都没匹配上时也依旧会等待失败，所以默认规则（默认路由）返回一个错误。 5. 效果演示 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 db0 与 db15 分别在两个实例上： (ecdba@10.0.100.36:6033) [(none)]\u0026gt; select * from db0.tbl_0; +-----+----------------+--------+ | fid | username | corpid | +-----+----------------+--------+ | 1 | db0 aa | 0 | | 2 | db0 aa | 16 | | 3 | db0 autocommit | 32 | +-----+----------------+--------+ 3 rows in set (0.00 sec) (ecdba@10.0.100.36:6033) [(none)]\u0026gt; select * from db15.tbl_0; +-----+-----------------------------+--------+ | fid | username | corpid | +-----+-----------------------------+--------+ | 1 | db15 c2dfdf地方大幅度d | 15 | | 2 | db15 c2dfdf地方大幅度d | 47 | | 3 | db15 c2dfdf地方大幅度d | 111 | +-----+-----------------------------+--------+ 3 rows in set (0.00 sec) 无法路由时，报错： (ecdba@10.0.100.36:6033) [(none)]\u0026gt; show databases; ERROR 1148 (42000): No query rules matched (by ProxySQL) 看到 rule 的命中数符合预期： -- proxysql admin cli (admin@127.0.0.1:6032) [(none)]\u0026gt; select active,hits, mysql_query_rules.rule_id, schemaname, match_digest, match_pattern, replace_pattern,destination_hostgroup hostgroup,s.comment,flagIn,flagOUT FROM mysql_query_rules NATURAL JOIN stats.stats_mysql_query_rules JOIN mysql_servers s on destination_hostgroup=hostgroup_id ORDER BY mysql_query_rules.rule_id; +--------+------+---------+--------------------+--------------+-------------------------------+-----------------+-----------+--------+---------+ | active | hits | rule_id | schemaname | match_digest | match_pattern | replace_pattern | hostgroup | flagIN | flagOUT | +--------+------+---------+--------------------+--------------+-------------------------------+-----------------+-----------+--------+---------+ | 1 | 3 | 20 | information_schema | NULL | NULL | NULL | NULL | 0 | 302 | | 1 | 0 | 50 | NULL | ^\\(*select | NULL | NULL | NULL | 0 | 20 | | 1 | 0 | 60 | NULL | ^select | NULL | NULL | NULL | 0 | 21 | | 1 | 0 | 61 | db0 | NULL | NULL | NULL | 1000 | 20 | 20 | | 1 | 0 | 62 | db1 | NULL | NULL | NULL | 1001 | 20 | 20 | | 1 | 0 | 63 | db2 | NULL | NULL | NULL | 1002 | 20 | 20 | | 1 | 0 | 64 | db3 | NULL | NULL | NULL | 1003 | 20 | 20 | .... | 1 | 0 | 77 | db0 | NULL | NULL | NULL | 100 | 21 | 21 | | 1 | 0 | 78 | db1 | NULL | NULL | NULL | 101 | 21 | 21 | | 1 | 0 | 79 | db2 | NULL | NULL | NULL | 102 | 21 | 21 | | 1 | 0 | 80 | db3 | NULL | NULL | NULL | 103 | 21 | 21 | ... | 1 | 0 | 92 | db15 | NULL | NULL | NULL | 103 | 21 | 21 | | 1 | 1 | 1000 | NULL | NULL | ([\\s\\`])db(0|4|8|12)([\\.\\`]) | NULL | 100 | 302 | 302 | | 1 | 0 | 1001 | NULL | NULL | ([\\s\\`])db(1|5|9|13)([\\.\\`]) | NULL | 101 | 302 | 302 | | 1 | 0 | 1002 | NULL | NULL | ([\\s\\`])db(2|6|10|14)([\\.\\`]) | NULL | 102 | 302 | 302 | | 1 | 1 | 1003 | NULL | NULL | ([\\s\\`])db(3|7|11|15)([\\.\\`]) | NULL | 103 | 302 | 302 | | 1 | 0 | 1404 | NULL | NULL | ^SELECT DATABASE\\(\\)$ | NULL | NULL | 302 | 302 | | 1 | 1 | 9999 | NULL | NULL | NULL | NULL | NULL | 302 | 302 | +--------+------+---------+--------------------+--------------+-------------------------------+-----------------+-----------+--------+---------+ 41 rows in set (0.01 sec) mysql\u0026gt; select rule_id,schemaname,match_digest,match_pattern,destination_hostgroup,negate_match_pattern,apply,flagIN,flagOUT,error_msg from mysql_query_rules; 切换数据库继续：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 (ecdba@10.0.100.36:6033) [(none)]\u0026gt; use db1; Database changed (ecdba@10.0.100.36:6033) [db1]\u0026gt; select * from tbl_0; +-----+----------+--------+ | fid | username | corpid | +-----+----------+--------+ | 1 | db1 bb | 1 | | 2 | db1 bb | 17 | | 3 | db1 bb | 33 | +-----+----------+--------+ 3 rows in set (0.01 sec) (ecdba@10.0.100.36:6033) [db1]\u0026gt; select * from `db5`.tbl_0; +-----+--------------------+--------+ | fid | username | corpid | +-----+--------------------+--------+ | 1 | db5 ces测试 kfjd | 5 | +-----+--------------------+--------+ db6并不在当前实例里： (ecdba@10.0.100.36:6033) [db1]\u0026gt; select * from db6.tbl_0; ERROR 1146 (42S02): Table \u0026#39;db6.tbl_0\u0026#39; doesn\u0026#39;t exist 现在show databases不会再报错： (ecdba@10.0.100.36:6033) [db1]\u0026gt; show databases; +--------------------+ | Database | +--------------------+ | information_schema | | db1 | | db13 | | db5 | | db9 | | mysql | | performance_schema | +--------------------+ 看到 stats 模块的统计信息： -- proxysql admin cli (admin@127.0.0.1:6032) [(none)]\u0026gt; select hostgroup,schemaname,username,digest,substr(digest_text,120,-120),count_star from stats_mysql_query_digest; +-----------+--------------------+----------+--------------------+--------------------------------------------+------------+ | hostgroup | schemaname | username | digest | substr(digest_text,120,-120) | count_star | +-----------+--------------------+----------+--------------------+--------------------------------------------+------------+ | 1002 | db2 | ecdba | 0x45033ED34D21EDF5 | select * from tbl_0 | 1 | | 102 | db2 | ecdba | 0x02033E45904D3DF0 | show databases | 1 | | 102 | db2 | ecdba | 0x99531AEFF718C501 | show tables | 1 | | 1001 | db1 | ecdba | 0x620B328FE9D6D71A | SELECT DATABASE() | 1 | | 1001 | db1 | ecdba | 0x903E7B5A87B51352 | select * from db6.tbl_0 | 1 | | 1001 | db1 | ecdba | 0x0CE250A1C0E2C539 | select * from `db5`.tbl_0 | 1 | | 1001 | db1 | ecdba | 0x45033ED34D21EDF5 | select * from tbl_0 | 1 | | 101 | db1 | ecdba | 0x02033E45904D3DF0 | show databases | 2 | | 102 | db2 | ecdba | 0x6F8289B2913564A0 | update tbl_0 set username=? where corpid=? | 1 | | 0 | information_schema | ecdba | 0x620B328FE9D6D71A | SELECT DATABASE() | 1 | | 101 | db1 | ecdba | 0x99531AEFF718C501 | show tables | 1 | | 0 | information_schema | ecdba | 0x02033E45904D3DF0 | show databases | 1 | | 1001 | db1 | ecdba | 0x7A3428659E1BFDC2 | select * from db5.tbl_0 | 1 | | 103 | information_schema | ecdba | 0xA951EB38FA9ED6A4 | select * from db15.tbl_0 | 1 | | 100 | information_schema | ecdba | 0xA132AEDEC5932600 | select * from db0.tbl_0 | 1 | | 0 | information_schema | ecdba | 0x594F2C744B698066 | select USER() | 1 | | 0 | information_schema | ecdba | 0x226CD90D52A2BA0B | select @@version_comment limit ? | 1 | +-----------+--------------------+----------+--------------------+--------------------------------------------+------------+ 17 rows in set (0.01 sec) 达到了读写分离和分实例分库的目的。\n6. 另一种规则写法 从上面可以看到，客户端应用在使用的时候，最好都要指定 database name ，上面是因为加了第 5 类规则才避免由于不指定db时所带来的问题，但始终要求对每个 分db 建立自己连接，或者查询之前 use dbname ，当然也可以在获取连接的时候，传递dbname过去，拿到带正确db的连接过来。\n那么其实还有一种办法，不需要指定连接db，而是采用注释 hint 的形式，传递给proxysql，然后来自动路由。将第 4 节的规则 [2],[3] 改成下面的形式：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 -- [1] read\u0026amp;write split -- instance0，read \u0026amp; write INSERT INTO mysql_query_rules (rule_id,active,match_pattern,apply,flagIN,flagOUT) VALUES (40,1,\u0026#34;\\/\\*\\s*shard_corp_mod=(0|4|8|12)\\s*\\*.\u0026#34;,0,0,20); INSERT INTO mysql_query_rules (rule_id,active,match_digest,destination_hostgroup,apply,flagIN,flagOUT) VALUES (50,1,\u0026#39;^select\u0026#39;,1000,1,20,20); INSERT INTO mysql_query_rules (active,match_digest,negate_match_pattern,destination_hostgroup,apply,flagIN,flagOUT) VALUES (1,\u0026#34;^select\u0026#34;,1,100,1,20,20); INSERT INTO mysql_query_rules (rule_id,active,match_pattern,apply,flagIN,flagOUT) VALUES (60,1,\u0026#34;\\/\\*\\s*shard_corp_mod=(1|5|9|13)\\s*\\*.\u0026#34;,0,0,21); INSERT INTO mysql_query_rules (active,match_digest,destination_hostgroup,apply,flagIN,flagOUT) VALUES (1,\u0026#39;^select\u0026#39;,1001,1,21,21); INSERT INTO mysql_query_rules (active,match_digest,negate_match_pattern,destination_hostgroup,apply,flagIN,flagOUT) VALUES (1,\u0026#34;^select\u0026#34;,1,101,1,21,21); INSERT INTO mysql_query_rules (rule_id,active,match_pattern,apply,flagIN,flagOUT) VALUES (70,1,\u0026#34;\\/\\*\\s*shard_corp_mod=(2|6|10|14)\\s*\\*.\u0026#34;,0,0,22); INSERT INTO mysql_query_rules (active,match_digest,destination_hostgroup,apply,flagIN,flagOUT) VALUES (1,\u0026#39;^select\u0026#39;,1002,1,22,22); INSERT INTO mysql_query_rules (active,match_digest,negate_match_pattern,destination_hostgroup,apply,flagIN,flagOUT) VALUES (1,\u0026#34;^select\u0026#34;,1,102,1,22,22); INSERT INTO mysql_query_rules (rule_id,active,match_pattern,apply,flagIN,flagOUT) VALUES (80,1,\u0026#34;\\/\\*\\s*shard_corp_mod=(3|7|11|15)\\s*\\*.\u0026#34;,0,0,23); INSERT INTO mysql_query_rules (active,match_digest,destination_hostgroup,apply,flagIN,flagOUT) VALUES (1,\u0026#39;^select\u0026#39;,1003,1,23,23); INSERT INTO mysql_query_rules (active,match_digest,negate_match_pattern,destination_hostgroup,apply,flagIN,flagOUT) VALUES (1,\u0026#34;^select\u0026#34;,1,103,1,23,23); -- [2] no /* shard_corp_mod=? */ given insert into mysql_query_rules(rule_id,active,match_digest,destination_hostgroup,apply,flagIN) values(1000,1,\u0026#39;([\\s\\`])db(0|4|8|12)([\\.\\`])\u0026#39;,100,1,0); insert into mysql_query_rules(rule_id,active,match_digest,destination_hostgroup,apply,flagIN) values(1001,1,\u0026#39;([\\s\\`])db(1|5|9|13)([\\.\\`])\u0026#39;,101,1,0); insert into mysql_query_rules(rule_id,active,match_digest,destination_hostgroup,apply,flagIN) values(1002,1,\u0026#39;([\\s\\`])db(2|6|10|14)([\\.\\`])\u0026#39;,102,1,0); insert into mysql_query_rules(rule_id,active,match_digest,destination_hostgroup,apply,flagIN) values(1003,1,\u0026#39;([\\s\\`])db(3|7|11|15)([\\.\\`])\u0026#39;,103,1,0); -- [3] wrong usage insert into mysql_query_rules(rule_id,active,schemaname,match_digest,apply,flagIN,error_msg,comment) values(1404,1,\u0026#39;information_schema\u0026#39;,\u0026#39;^SELECT DATABASE\\(\\)$\u0026#39;,1,0,\u0026#39;You should specify schema name first\u0026#39;, \u0026#39;use db0 Take long when no schema given for connection\u0026#39;); -- [7] default route insert into mysql_query_rules(rule_id,active,apply, flagIN,error_msg,comment) values(9999,1,1, 0,\u0026#39;No query rules matched (by ProxySQL)\u0026#39;, \u0026#34;Don\u0026#39;t define the default hostgroup 0 for ME\u0026#34;); -- [8] LOAD MYSQL QUERY RULES TO RUN; SAVE MYSQL QUERY RULES TO DISK; 注意这里[2][3]用的是 match_pattern，而上节用的是match_digest，因为proxysql在处理fingerprint的时候，会去掉注释。如果在命令行测试，要加 -c 避免 HINT 被过滤掉。\n使用时Hint放sql最后面，每个sql都要带mod或者指定实例：select * from db5.tbl_0 /* shard_corp_mod=5 */，真正实施起来，应用端的复杂度以及proxysql的性能，还是有待考虑的。\n关于这些路由规则的写法对ProxySQL性能的影响，欢迎继续阅读这边文章 ProxySQL之性能测试对比\n参考：\nhttps://severalnines.com/blog/how-proxysql-adds-failover-and-query-control-your-mysql-replication-setup https://www.percona.com/blog/2016/08/30/mysql-sharding-with-proxysql/ 原文连接地址：http://xgknight.com/2017/04/17/mysql-proxysql-route-rw_split/\n","permalink":"http://localhost:1313/2017/04/mysql-proxysql-route-rw_split/","summary":"\u003cp\u003e本文演示使用ProxySQL来完成读写分离和后端分库的一个实际配置过程，安装及配置项介绍见前文 \u003ca href=\"http://xgknight.com/2017/04/10/mysql-proxysql-install-config/\"\u003eProxySQL之安装及配置详解\u003c/a\u003e。\u003c/p\u003e\n\u003cp\u003e环境\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e 1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 7\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 8\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 9\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e10\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e11\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-fallback\" data-lang=\"fallback\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003einstance0: 10.0.100.100 (db0,db2,db4,db6)\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003einstance1: 10.0.100.101 (db1,db3,db5,db7)\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003einstance2: 10.0.100.102 (db2,db6,db10,db14)\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003einstance3: 10.0.100.103 (db3,db7,db11,db15)\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003einstance0 slave: 192.168.10.4:3316\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003einstance1 slave: 192.168.10.4:3326\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003einstance2 slave: 192.168.10.4:3336\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003einstance3 slave: 192.168.10.4:3346\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eproxysql node0: 10.0.100.36\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e现在想达到这样一个目的：客户端应用连接上 proxysql 的ip:port，连接时指定分库db名，执行sql时自动路由到对应的实例、对应的库。考虑下面的部署结构：\n\u003cimg alt=\"ProxySQL Deploy\" loading=\"lazy\" src=\"http://github.com/seanlook/sean-notes-comment/raw/main/static/proxysql-rw-lb-deploy.png\"\u003e\u003c/p\u003e","title":"ProxySQL之读写分离与分库路由演示"},{"content":"ProxySQL是一个高性能的MySQL中间件，拥有强大的规则引擎。具有以下特性：\n连接池，而且是 multiplexing 主机和用户的最大连接数限制 自动下线后端DB 延迟超过阀值 ping 延迟超过阀值 网络不通或宕机 强大的规则路由引擎 实现读写分离 查询重写 sql流量镜像 支持prepared statement 支持Query Cache 支持负载均衡，与gelera结合自动failover 集这么多优秀特性于一身，那么缺点呢就是项目不够成熟，好在作者一直在及时更新，并且受到 Percona 官方的支持。\n1. 安装 从 https://github.com/sysown/proxysql/releases 下载相应的版本。这里我选择 proxysql-1.3.5-1-centos67.x86_64.rpm，也是当前最新稳定版。\n1 yum localinstall proxysql-1.3.5-1-centos67.x86_64.rpm -y 可以马上启动了：\n1 2 /etc/init.d/proxysql start Starting ProxySQL: DONE! proxysql有个配置文件 /etc/proxysql.cnf，只在第一次启动的时候有用，后续所有的配置修改都是对SQLite数据库操作，并且不会更新到proxysql.cnf文件中。ProxySQL绝大部分配置都可以在线修改，配置存储在 /var/lib/proxysql/proxysql.db 中，后面会介绍它的在线配置的设计方式。\nproxysql 启动后会像 mysqld 一样，马上fork一个子进程，真正处理请求，而父进程负责监控子进程运行状况，如果crash了就拉起来。\n编译安装 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 安装高版本 gcc-4.8 # cd /etc/yum.repos.d # wget https://copr.fedoraproject.org/coprs/rhscl/devtoolset-3/repo/epel-6/rhscl-devtoolset-3-epel-6.repo \\ -O /etc/yum.repos.d/rhscl-devtoolset-3-epel-6.repo # yum install -y scl-utils policycoreutils-python # yum --disablerepo=\u0026#39;*\u0026#39; --enablerepo=\u0026#39;rhscl-devtoolset-3\u0026#39; install devtoolset-3-gcc devtoolset-3-gcc-c++ devtoolset-3-binutils # yum --enablerepo=testing-devtools-2-centos-6 install devtoolset-3-gcc devtoolset-3-gcc-c++ devtoolset-3-binutils 上一步会把 GCC 安装到以下目录 /opt/rh/devtoolset-3/root/usr/bin 接下来需要修改系统的配置，使默认的 gcc 和 g++ 命令使用的是新安装的版本。启用SCL环境中新版本GCC： # scl enable devtoolset-3 bash 现在查看 g++ 的版本号： # gcc --version 编译安装proxysql # cd proxysql-master # make # make install 2. 内置库表介绍 2.1 内置“库” 首先登陆到 proxysql 之后才能进一步配置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 $ export MYSQL_PS1=\u0026#34;(\\u@\\h:\\p) [\\d]\u0026gt; \u0026#34; $ mysql -uadmin -padmin -h127.0.0.1 -P6032 Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 2 Server version: 5.6.30 (ProxySQL Admin Module) (admin@127.0.0.1:6032) [(none)]\u0026gt; show databases; +-----+---------+-------------------------------+ | seq | name | file | +-----+---------+-------------------------------+ | 0 | main | | | 2 | disk | /var/lib/proxysql/proxysql.db | | 3 | stats | | | 4 | monitor | | +-----+---------+-------------------------------+ 默认管理端口是6032，客户端服务端口是6033。默认的用户名密码都是 admin。\nmain 是默认的\u0026quot;数据库\u0026quot;名，表里存放后端db实例、用户验证、路由规则等信息。表名以 runtime_开头的表示proxysql当前运行的配置内容，不能通过dml语句修改，只能修改对应的不以 runtime_ 开头的（在内存）里的表，然后 LOAD 使其生效， SAVE 使其存到硬盘以供下次重启加载。 disk 是持久化到硬盘的配置，sqlite数据文件。 stats 是proxysql运行抓取的统计信息，包括到后端各命令的执行次数、流量、processlist、查询种类汇总/执行时间，等等。 monitor 库存储 monitor 模块收集的信息，主要是对后端db的健康/延迟检查。 global_variables 有80多个变量可以设置，其中就包括监听的端口、管理账号、禁用monitor等，详细可参考 https://github.com/sysown/proxysql/wiki/Global-variables 。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 (admin@127.0.0.1:6032) [(none)]\u0026gt; show tables; +--------------------------------------+ | tables | +--------------------------------------+ | global_variables | | mysql_collations | | mysql_query_rules | | mysql_replication_hostgroups | | mysql_servers | | mysql_users | | runtime_global_variables | | runtime_mysql_query_rules | | runtime_mysql_replication_hostgroups | | runtime_mysql_servers | | runtime_mysql_users | | runtime_scheduler | | scheduler | +--------------------------------------+ 13 rows in set (0.00 sec) (admin@127.0.0.1:6032) [(none)]\u0026gt; show tables from stats; +--------------------------------+ | tables | +--------------------------------+ | global_variables | | stats_mysql_commands_counters | | stats_mysql_connection_pool | | stats_mysql_global | | stats_mysql_processlist | | stats_mysql_query_digest | | stats_mysql_query_digest_reset | | stats_mysql_query_rules | +--------------------------------+ 8 rows in set (0.00 sec) 2.2 表 mysql_servers 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 (admin@127.0.0.1:6032) [(none)]\u0026gt; show create table mysql_servers\\G *************************** 1. row *************************** table: mysql_servers Create Table: CREATE TABLE mysql_servers ( hostgroup_id INT NOT NULL DEFAULT 0, hostname VARCHAR NOT NULL, port INT NOT NULL DEFAULT 3306, status VARCHAR CHECK (UPPER(status) IN (\u0026#39;ONLINE\u0026#39;,\u0026#39;SHUNNED\u0026#39;,\u0026#39;OFFLINE_SOFT\u0026#39;, \u0026#39;OFFLINE_HARD\u0026#39;)) NOT NULL DEFAULT \u0026#39;ONLINE\u0026#39;, weight INT CHECK (weight \u0026gt;= 0) NOT NULL DEFAULT 1, compression INT CHECK (compression \u0026gt;=0 AND compression \u0026lt;= 102400) NOT NULL DEFAULT 0, max_connections INT CHECK (max_connections \u0026gt;=0) NOT NULL DEFAULT 1000, max_replication_lag INT CHECK (max_replication_lag \u0026gt;= 0 AND max_replication_lag \u0026lt;= 126144000) NOT NULL DEFAULT 0, use_ssl INT CHECK (use_ssl IN(0,1)) NOT NULL DEFAULT 0, max_latency_ms INT UNSIGNED CHECK (max_latency_ms\u0026gt;=0) NOT NULL DEFAULT 0, comment VARCHAR NOT NULL DEFAULT \u0026#39;\u0026#39;, PRIMARY KEY (hostgroup_id, hostname, port) ) 1 row in set (0.00 sec) (admin@127.0.0.1:6032) [(none)]\u0026gt; select * from mysql_servers; +--------------+--------------+------+--------+--------+-------------+-----------------+---------------------+---------+----------------+---------------+ | hostgroup_id | hostname | port | status | weight | compression | max_connections | max_replication_lag | use_ssl | max_latency_ms | comment | +--------------+--------------+------+--------+--------+-------------+-----------------+---------------------+---------+----------------+---------------+ | 100 | 10.0.100.100 | 3307 | ONLINE | 1 | 0 | 1000 | 0 | 0 | 0 | db0,ReadWrite | | 1000 | 10.0.100.100 | 3307 | ONLINE | 1 | 0 | 1000 | 0 | 0 | 0 | db0,ReadWrite | | 1000 | 192.168.10.4 | 3316 | ONLINE | 4 | 0 | 1000 | 0 | 0 | 0 | db0,ReadOnly | | 101 | 10.0.100.101 | 3307 | ONLINE | 1 | 0 | 1000 | 0 | 0 | 0 | db1,ReadWrite | | 1001 | 192.168.10.4 | 3326 | ONLINE | 1 | 0 | 1000 | 0 | 0 | 0 | db1,ReadOnly | +--------------+--------------+------+--------+--------+-------------+-----------------+---------------------+---------+----------------+---------------+ hostgroup_id: ProxySQL通过 hostgroup (下称HG) 的形式组织后端db实例。一个 HG 代表同属于一个角色 该表的主键是 (hostgroup_id, hostname, port)，可以看到一个 hostname:port 可以在多个hostgroup里面，如上面的 10.0.100.100:3307，这样可以避免 HG 1000 的从库全都不可用时，依然可以把读请求发到主库上。 一个 HG 可以有多个实例，即多个从库，可以通过 weight 分配权重 hostgroup_id 0 是一个特殊的HG，路由查询的时候，没有匹配到规则则默认选择 HG 0 status: ONLINE: 当前后端实例状态正常 SHUNNED: 临时被剔除，可能因为后端 too many connections error，或者超过了可容忍延迟阀值 max_replication_lag OFFLINE_SOFT: \u0026ldquo;软离线\u0026quot;状态，不再接受新的连接，但已建立的连接会等待活跃事务完成。 OFFLINE_HARD: \u0026ldquo;硬离线\u0026quot;状态，不再接受新的连接，已建立的连接或被强制中断。当后端实例宕机或网络不可达，会出现。 max_connections: 允许连接到该后端实例的最大连接数。不要大于MySQL设置的 max_connections 如果后端实例 hostname:port 在多个 hostgroup 里，以较大者为准，而不是各自独立允许的最大连接数。 max_replication_lag: 允许的最大延迟，主库不受这个影响，默认0。如果 \u0026gt; 0， monitor 模块监控主从延迟大于阀值时，会临时把它变为 SHUNNED 。 max_latency_ms: mysql_ping 响应时间，大于这个阀值会把它从连接池剔除（即使是ONLINE） comment: 备注，不建议留空。这有什么好讲呢，但是你可以通过它的内容如json格式的数据，配合自己写的check脚本，完成一些自动化的工作。 compression 和 use_ssl 顾名思义。\n2.3 表 mysql_users 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 (admin@127.0.0.1:6032) [(none)]\u0026gt; show create table mysql_users\\G *************************** 1. row *************************** table: mysql_users Create Table: CREATE TABLE mysql_users ( username VARCHAR NOT NULL, password VARCHAR, active INT CHECK (active IN (0,1)) NOT NULL DEFAULT 1, use_ssl INT CHECK (use_ssl IN (0,1)) NOT NULL DEFAULT 0, default_hostgroup INT NOT NULL DEFAULT 0, default_schema VARCHAR, schema_locked INT CHECK (schema_locked IN (0,1)) NOT NULL DEFAULT 0, transaction_persistent INT CHECK (transaction_persistent IN (0,1)) NOT NULL DEFAULT 0, fast_forward INT CHECK (fast_forward IN (0,1)) NOT NULL DEFAULT 0, backend INT CHECK (backend IN (0,1)) NOT NULL DEFAULT 1, frontend INT CHECK (frontend IN (0,1)) NOT NULL DEFAULT 1, max_connections INT CHECK (max_connections \u0026gt;=0) NOT NULL DEFAULT 10000, PRIMARY KEY (username, backend), UNIQUE (username, frontend)) 1 row in set (0.00 sec) (admin@127.0.0.1:6032) [(none)]\u0026gt; select * from mysql_users; +----------+-----------+--------+---------+-------------------+----------------+---------------+------------------------+--------------+---------+----------+-----------------+ | username | password | active | use_ssl | default_hostgroup | default_schema | schema_locked | transaction_persistent | fast_forward | backend | frontend | max_connections | +----------+-----------+--------+---------+-------------------+----------------+---------------+------------------------+--------------+---------+----------+-----------------+ | user0 | password0 | 1 | 0 | 0 | NULL | 0 | 1 | 0 | 1 | 1 | 10000 | | read1 | password1 | 1 | 0 | 0 | NULL | 0 | 1 | 0 | 1 | 1 | 10000 | +----------+-----------+--------+---------+-------------------+----------------+---------------+------------------------+--------------+---------+----------+-----------------+ 2 rows in set (0.00 sec) (admin@127.0.0.1:6032) [(none)]\u0026gt; select username,password,transaction_persistent,active,backend,frontend,max_connections from runtime_mysql_users; +----------+------------------------------+------------------------+--------+---------+----------+-----------------+ | username | password | transaction_persistent | active | backend | frontend | max_connections | +----------+------------------------------+------------------------+--------+---------+----------+-----------------+ | user0 | *FAB0955B2CE7AE2DAFEE46C3... | 1 | 1 | 0 | 1 | 10000 | | read1 | *88A287979B45658C6CE41FB9... | 1 | 1 | 0 | 1 | 10000 | | user0 | *FAB0955B2CE7AE2DAFEE46C3... | 1 | 1 | 1 | 0 | 10000 | | read1 | *88A287979B45658C6CE41FB9... | 1 | 1 | 1 | 0 | 10000 | +----------+------------------------------+------------------------+--------+---------+----------+-----------------+ 4 rows in set (0.00 sec) username, password: 连接后端db的用户密码。 这个密码你可以插入明文，也可以插入hash加密后的密文，proxysql会检查你插入的时候密码是否以 * 开头来判断，而且密文要在其它地方使用 PASSWORD()生成。 但到 runtime_mysql_users 里，都统一变成了密文，所以可以明文插入，再 SAVE MYSQL USERS TO MEM，此时看到的也是HASH密文。 active: 是否生效该用户。 default_hostgroup: 这个用户的请求没有匹配到规则时，默认发到这个 hostgroup，默认0 default_schema: 这个用户连接时没有指定 database name 时，默认使用的schema 注意表面上看默认为NULL，但实际上受到变量 mysql-default_schema 的影响，默认为 information_schema。关于这个参考我所提的 issue #988 transaction_persistent: 如果设置为1，连接上ProxySQL的会话后，如果在一个hostgroup上开启了事务，那么后续的sql都继续维持在这个hostgroup上，不伦是否会匹配上其它路由规则，直到事务结束。 虽然默认是0，但我建议还是设成1，虽然一般来说由于前段应用的空值，为0出问题的情况几乎很小。作者也在考虑默认设成 1，refer this issue #793 frontend, backend: 目前版本这两个都需要使用默认的1，将来有可能会把 * Client -\u0026gt; ProxySQL * (frontend) 与 * ProxySQL -\u0026gt; BackendDB * (backend)的认证分开。 从 runtime_mysql_users 表内容看到，记录数比 mysql_users 多了一倍，就是把前端认证与后端认证独立出来的结果。 fast_forward: 忽略查询重写/缓存层，直接把这个用户的请求透传到后端DB。相当于只用它的连接池功能，一般不用，路由规则 .* 就行了。 2.4 表 mysql_replication_hostgroups 1 2 3 4 5 CREATE TABLE mysql_replication_hostgroups ( writer_hostgroup INT CHECK (writer_hostgroup\u0026gt;=0) NOT NULL PRIMARY KEY, reader_hostgroup INT NOT NULL CHECK (reader_hostgroup\u0026lt;\u0026gt;writer_hostgroup AND reader_hostgroup\u0026gt;0), comment VARCHAR, UNIQUE (reader_hostgroup)) 定义 hostgroup 的主从关系。ProxySQL monitor 模块会监控 HG 后端所有servers 的 read_only 变量，如果发现从库的 read_only 变为0、主库变为1，则认为角色互换了，自动改写 mysql_servers 表里面 hostgroup 关系，达到自动 Failover 效果。\n目前这个表我是留空的，它与Gelera或PXC结合起来用比较合适。\n2.5 表 mysql_query_rules ProxySQL非常核心一个表，定义查询路由规则，参考 https://github.com/sysown/proxysql/wiki/MySQL-Query-Rules ：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 (admin@127.0.0.1:6032) [(none)]\u0026gt; show create table mysql_query_rules\\G *************************** 1. row *************************** table: mysql_query_rules Create Table: CREATE TABLE mysql_query_rules ( rule_id INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL, active INT CHECK (active IN (0,1)) NOT NULL DEFAULT 0, username VARCHAR, schemaname VARCHAR, flagIN INT NOT NULL DEFAULT 0, client_addr VARCHAR, proxy_addr VARCHAR, proxy_port INT, digest VARCHAR, match_digest VARCHAR, match_pattern VARCHAR, negate_match_pattern INT CHECK (negate_match_pattern IN (0,1)) NOT NULL DEFAULT 0, flagOUT INT, replace_pattern VARCHAR, destination_hostgroup INT DEFAULT NULL, cache_ttl INT CHECK(cache_ttl \u0026gt; 0), reconnect INT CHECK (reconnect IN (0,1)) DEFAULT NULL, timeout INT UNSIGNED, retries INT CHECK (retries\u0026gt;=0 AND retries \u0026lt;=1000), delay INT UNSIGNED, mirror_flagOUT INT UNSIGNED, mirror_hostgroup INT UNSIGNED, error_msg VARCHAR, log INT CHECK (log IN (0,1)), apply INT CHECK(apply IN (0,1)) NOT NULL DEFAULT 0, comment VARCHAR) 1 row in set (0.00 sec) rule_id: 表主键，自增。规则处理是以 rule_id 的顺序进行。 active: 只有 active=1 的规则才会参与匹配。 username: 如果非 NULL，只有连接用户是 username 的值才会匹配 schemaname: 如果非 NULL，只有查询连接使用的db是 schemaname 的值才会匹配。 注意如果是 NULL，不代表连接没有使用schema，而是不伦任何schema都进一步匹配。 flagIN, flagOUT, apply: 用来定义路由链 chains of rules 首先会检查 flagIN=0 的规则，以rule_id的顺序；如果都没匹配上，则走这个用户的 default_hostgroup 当匹配一条规则后，会检查 flagOUT 如果不为NULL，并且 flagIN != flagOUT ，则进入以flagIN为上一个flagOUT值的新规则链 如果不为NULL，并且 flagIN = flagOUT，则应用这条规则 如果为NULL，或者 apply=1，则结束，应用这条规则 如果最终没有匹配到，则找到这个用户的 default_hostgroup client_addr: 匹配客户端来源IP proxy_addr, proxy_port: 匹配本地proxysql的IP、端口。我目前没有想到它的应用场景，可能是把proxysql监听在多个接口上，分发到不同的业务？ digest: 精确的匹配一类查询。 match_digest: 正则匹配一类查询。query digest 是指对查询去掉具体值后进行“模糊化”后的查询，类似 pt-fingerprint / pt-query-digest 的效果。 match_pattern: 正则匹配查询。 以上都是匹配查询的规则，目前1.3.5使用的正则引擎只有 RE2 ，1.4版本可以通过变量 mysql-query_processor_regex 设置 RE2 或者 PCRE，且1.4开始默认是PCRE。 ProxySQL的作者 renecannao 自己推荐用 match_digest 。关于每条查询都会计算digest对性能的影响，我提出疑问后，作者在这篇文章ProxySQL Rules: Do I Have Too Many?的评论里做出了解释。大意是说计算query digest确实会有性能损失，但是确实proxysql里面非常重要特性，主要是两点： proxysql无法知道连接复用(multipexing)是否必须被自动禁用，比如连接里面有variables/tmp tables/lock table等特殊命令，是不能复用的。 完整的查询去匹配正则的效率，一般没有参数化后的查询匹配效率高，因为有很长的字符串内容需要处理。再者，SELECT * FROM randomtable WHERE comment LIKE ‘%INTO sbtest1 % FROM sbtest2 %’字符串里有类似这样的语句，很难排除误匹配。 negate_match_pattern: 反向匹配，相当于对 match_digest/match_pattern 的匹配取反。 re_modifiers: 修改正则匹配的参数，比如默认的：忽略大小写CASELESS、禁用GLOBAL 上面都是匹配规则，下面是匹配后的行为：\nreplace_pattern: 查询重写，默认为空，不rewrite。 rewrite规则要遵守 RE2::Replace 。 destination_hostgroup: 路由查询到这个 hostgroup。当然如果用户显式 start transaction 且 transaction_persistent=1，那么即使匹配到了，也依然按照事务里第一条sql的路由规则去走。 cache_ttl: 查询结果缓存的毫秒数。 proxysql这个 Query Cache 与 MySQL 自带的query cache不是同一个。proxysql query cache也不会关心后端数据是否被修改，它所做的就是针对某些特定种类的查询结果进行缓存，比如一些历史数据的count结果。一般不设。 timeout: 这一类查询执行的最大时间（毫秒），超时则自动kill。 这是对后端DB的保护机制，相当于阿里云RDS loose_max_statement_time 变量的功能，但是注意不同的是，阿里云这个变量的时间时不包括DML操作出现InnoDB行锁等待的时间，而ProxySQL的这个 timeout 是计算从发送sql到等待响应的时间。默认mysql-default_query_timeout给的是 10h . retries: 语句在执行时失败时，重试次数。默认由 mysql-query_retries_on_failure变量指定，为1 。 我个人建议把它设成0，即不重试。因为执行失败，对select而言很少见，主要是dml，但自己重试对数据不放心。 delay: 查询延迟执行，这是ProxySQL提供的限流机制，会让其它的查询优先执行。 默认值 mysql-default_query_delay，为0。我们一般不用，其实还是要配合应用端使用，比如这边延迟执行，但上层等待你返回，那前端不就堵住了，没准出现雪崩效应。 mirror_flagOUT,mirror_hostgroup 这两个高级了，目前这部分文档不全，功能是SQL镜像。顾名思义，就是把匹配到的SQL除了发送到 destination_hostgroup，同时镜像一份到这里的hostgroup，比如我们的测试库。比如这种场景，数据库要从5.6升级到5.7，要验证现有查询语句对5.7的适用情况，就可以把生产流量镜像到5.7新库上验证。 error_msg: 默认为NULL，如果指定了则这个查询直接被 block 掉，马上返回这个错误信息。 这个功能也很实用，比如线上突然冒出一个 “坏查询”，应用端不方便马上发版解决，我们就可以在这配置一个规则，把查询屏蔽掉，想正常的mysql报错那样抛异常。下一篇文章有演示。 multiplex: 连接是否复用。 关于这个，单独起一篇文章来写，传送门：http://xgknight.com/2017/04/17/mysql-proxysql-multiplexing/ log: 是否记录查询日志。可以看到log是否记录的对象是根据规则。 要开启日志记录，需要设置变量 mysql-eventslog_filename 来指定文件名，然后这个 log 标记为1。但是目前proxysql记录的日志是二进制格式，需要特定的工具才能读取： eventslog_reader_sample 。这个工具在源码目录 tools下面，我下载的1.3.5版本rpm表竟然还没有编译它。 参考 issue #561 Logging all queries 照 wiki Multi-layer-configuration-system 所说，在debug版本里应该有个 debug_levels 表来定义日志级别，但我没找到。据作者回复，上面的方式已过时，推荐 mysql-eventslog_filename。\n3. proxysql的多层配置设计 ProxySQL采用多层配置的设计来达到以下目的：\n允许在线应用配置项，而不需要重启proxysql 使用MySQL接口风格，来操作配置项，自定更新 如果配置有误，可以轻易回滚 RUNTIME 代表的是ProxySQL当前生效的配置，包括 global_variables, mysql_servers, mysql_users, mysql_query_rules。无法直接修改这里的配置，必须要从下一层load进来。 MEMORY 是平时在mysql命令行修改的 main 里头配置，可以认为是SQLite数据库在内存的镜像 DISK / CONFIG FILE 持久存储的那份配置，一般在$(DATADIR)/proxysql.db，在重启的时候会从硬盘里加载。 /etc/proxysql.cnf文件只在第一次初始化的时候用到，完了后，如果要修改监听端口，还是需要在管理命令行里修改，再 save 到硬盘。\n需要修改配置时，直接操作的是 MEMORAY，以下命令可用于加载或保存 users： （序号对应上图）\n1 2 3 4 5 [1]: LOAD MYSQL USERS TO RUNTIME / LOAD MYSQL USERS FROM MEMORY -- 常用 [2]: SAVE MYSQL USERS TO MEMORY / SAVE MYSQL USERS FROM RUNTIME [3]: LOAD MYSQL USERS TO MEMORY / LOAD MYSQL USERS FROM DISK [4]: SAVE MYSQL USERS TO DISK / SAVE MYSQL USERS FROM MEMORY -- 常用 [5]: LOAD MYSQL USERS FROM CONFIG 我比较习惯用 TO，记住往上层是 LOAD，往下层是 SAVE。\n以下命令加载或保存servers:\n1 2 3 4 5 [1]: LOAD MYSQL SERVERS TO RUNTIME -- 常用，让修改的配置生效 [2]: SAVE MYSQL SERVERS TO MEMORY [3]: LOAD MYSQL SERVERS TO MEMORY [4]: SAVE MYSQL SERVERS TO DISK -- 常用，将修改的配置持久化 [5]: LOAD MYSQL SERVERS FROM CONFIG 后面的使用方法也基本相同，一并列出。 以下命令加载或保存query rules:\n1 2 3 4 5 [1]: load mysql query rules to run -- 常用 [2]: save mysql query rules to mem [3]: load mysql query rules to mem [4]: save mysql query rules to disk -- 常用 [5]: load mysql query rules from config 以下命令加载或保存 mysql variables:\n1 2 3 4 5 [1]: load mysql variables to runtime [2]: save mysql variables to memory [3]: load mysql variables to memory [4]: save mysql variables to disk [5]: load mysql variables from config 以下命令加载或保存admin variables:\n1 2 3 4 5 [1]: load admin variables to runtime [2]: save admin variables to memory [3]: load admin variables to memory [4]: save admin variables to disk [5]: load admin variables from config 下一篇文章将演示ProxySQL读写分离与分库的路由规则编写：http://xgknight.com/2017/04/17/mysql-proxysql-route-rw_split/\n参考： https://severalnines.com/blog/mysql-load-balancing-proxysql-overview https://github.com/sysown/proxysql/wiki http://www.techietown.info/2017/01/mysql-readwrite-splitting-proxysql/ 原文连接地址：http://xgknight.com/2017/04/10/mysql-proxysql-install-config/\n","permalink":"http://localhost:1313/2017/04/mysql-proxysql-install-config/","summary":"\u003cp\u003eProxySQL是一个高性能的MySQL中间件，拥有强大的规则引擎。具有以下特性：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e连接池，而且是 \u003ca href=\"http://xgknight.com/2017/04/17/mysql-proxysql-multiplexing/\"\u003emultiplexing\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e主机和用户的最大连接数限制\u003c/li\u003e\n\u003cli\u003e自动下线后端DB\n\u003cul\u003e\n\u003cli\u003e延迟超过阀值\u003c/li\u003e\n\u003cli\u003eping 延迟超过阀值\u003c/li\u003e\n\u003cli\u003e网络不通或宕机\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e强大的规则路由引擎\u003c/li\u003e\n\u003cli\u003e实现读写分离\u003c/li\u003e\n\u003cli\u003e查询重写\u003c/li\u003e\n\u003cli\u003esql流量镜像\u003c/li\u003e\n\u003cli\u003e支持prepared statement\u003c/li\u003e\n\u003cli\u003e支持Query Cache\u003c/li\u003e\n\u003cli\u003e支持负载均衡，与gelera结合自动failover\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e集这么多优秀特性于一身，那么缺点呢就是项目不够成熟，好在作者一直在及时更新，并且受到 Percona 官方的支持。\u003c/p\u003e","title":"ProxySQL之安装及配置详解"},{"content":"这个清明假期，没有做特意的安排，4月1日晚上的时候冒出个想法——去爬七娘山。后来考虑天太热，便作罢了，正好抽一点时间整理些近来的事情。\n** 关于博客 很早在朋友圈看到 多说 要关闭的消息，不久后也收到了邮件。全国第一的评论系统，说倒就倒，到底是没有好的营收模式，看到网上一堆评论说挺惋惜的，但那么多用户评论数据在上面，价值可想而知，不应遭此地步。在2014年刚用 多说 的时候，就感觉到它后台基本上没有人在维护了，自身管理后台都有不少问题，提反馈也没响应。\n选择网易云跟帖，把它替换掉了，并把以前的评论数据迁移了过来，就是人和人对不上号，以前那些网友找不到自己的评论，抱歉了。不过能用就行，还是多添点内容，也已经过了纠结样式主题的年纪了。有时候看到后台的评论，或者通过其它途径辛苦找到我的，给我了继续写博的动力。\n再一个就是搜索功能，以前用的 swiftype 是在去年的时候，不免费了，只提供企业版。它提供的站内搜索引擎功能，十分强大，也很美观，后台管理能看到许多的分析数据，可是它偏偏就突然收费了，而且298$/m，不能接受。也是秉着能用的原则，装上了 hexo-generator-search 模块。\n网站统计，现在是cnzz和百度站长的都在用，看了下每天还是有个400-600的独立访客，想想要整一个稍微过得去的 about 页面了。见这里 http://xgknight.com/about/ 。同时也才最近才加上leancloud访问量显示功能。\n噢，对了，新加了个打赏的功能，孰知坚持写博不易，意思意思。 -- updated 2017-04-28 -- 把微信打赏改成了支付宝，这样方便知道对方是谁。\n** 关于职业 本职工作呢，是一名 DBA 。上周末听香港MySQL用户组主席 Ivan Ma 讲，他们那么没有很清楚的把职位分为是 MySQL DBA 还是 Oracle DBA，他们许多都是不论什么类型的数据库，包括nosql，都得上。我对自身的定位也是，MySQL可以是看家本领，必须深入理解，熟悉它的周边生态圈，积累优化经验。但是像Redis,Mongo,HBase甚至ES这些都必须要有一定的了解，还有像python/go一两门拿得出手的开发语言。\n相继前后有好几位同行通过微博、QQ、微信，找到我，请教些问题。有些可能我也并不能马上明确的回答，但是要么自己做个验证，也能很快有结论，要么提供一些建议、方向，或者一些风险点，总之尽我所能。一对一讨论，是能快速学习和加深理解非常有效的途径。\n在叶老师知数堂的优化班里，进去之前自己还是有一定基础的，主要是查一查知识的盲点，认识一些行业内的圈子。所以在群里，基本上不参与无关话题的讨论，偶尔回复技术相关的，再者也真没那个闲工夫。\n最近一直在处理一个矛盾——职业与工作。个人花工作时间来学习研究，与外部群体讨论，短时间内在工作上可能看不到效果。我们不像开发人员，开发有项目推动，我们基本上都是问题驱动，为了解决这个问题（无论是具体的，还是平台的，甚至架构的），当我们并没有处理经验的时候，往往需要了解和对比大量资料。但最后能有多少应用在工作中的，很难说。能解决一个问题，叫工作；解决好一个问题，叫职业。同样是解决，而且一般在任期内不会复发，显然后者对个人的投入和收获，都更大。\n我们的DBA工作充斥了许多的表结构审核、修改线上业务数据，以及慢sql优化、隐患问题追踪等等，也一直在思考一种好的工具平台，但是这样一个数据库运维体系的建立，前期要投入的精力和时间可想而知，而另一边，日常有源源不断的琐事或者问题要处理，到底何为紧急？虽然现在大部分工作，组内几个人好像都做得过来，但说实在的，人肉运维以及效率，都有许多可以改进的地方。然而就是需要在众多繁琐运维事务中，找个时间把该做的平台先做好。\n目前还是在摸索，并有些眉目了，开发工作看来也只能靠自己了……\n本文链接地址：http://xgknight.com/2017/04/02/qingming-2017/\n","permalink":"http://localhost:1313/2017/04/qingming-2017/","summary":"\u003cp\u003e这个清明假期，没有做特意的安排，4月1日晚上的时候冒出个想法——去爬七娘山。后来考虑天太热，便作罢了，正好抽一点时间整理些近来的事情。\u003c/p\u003e\n\u003ch2 id=\"-关于博客\"\u003e** 关于博客\u003c/h2\u003e\n\u003cp\u003e很早在朋友圈看到 多说 要关闭的消息，不久后也收到了邮件。全国第一的评论系统，说倒就倒，到底是没有好的营收模式，看到网上一堆评论说挺惋惜的，但那么多用户评论数据在上面，价值可想而知，不应遭此地步。在2014年刚用 多说 的时候，就感觉到它后台基本上没有人在维护了，自身管理后台都有不少问题，提反馈也没响应。\u003c/p\u003e","title":"清明闲扯"},{"content":"本文的ppt是3月25日在中国MySQL用户组2017深圳活动上，我所做的一个主题分享，关于实际生产使用mysql过程中与字符集有关的一些坑。\n这个总结其实自己去年一直也想去做，前后花了2个多月的时间，最后所有库无痛完成迁移转化。在2017年二月中下旬的时候微信上请教周董（去哪儿周彦韦大师）一个问题，因为以前也聊过一些，所以他突然问我要不要在3月份的活动上做个主题分享。当时有点不敢想，毕竟之前2次有关培训都是在公司内部的，而这次对外的分享，且不说台下听众有牛人存在，演讲嘉宾里面可各个都是大师级别的，所以当时没有马上答应。过了两天，偶然想到关于字符集这个经历可以讲一讲，不是为了展示自己有多牛B，只是分享下整个问题的处理经验，放低姿态。列了个提纲发给了周董，10分钟不到周董说定了。向经理请示了下没问题，这下赶着鸭子都得上了……\n毕竟第一次公开在这样的场合演讲，说不紧张肯定是假的，所以早早的就在准备ppt，一边回顾，一边画图。上阵前一天晚上还在对演示稿微调，并尽量控制时间。\n闲话不多说，PPT奉上：\n{% pdf http://github.com/seanlook/sean-notes-comment/raw/main/static/mysql-ppt-charset-conversion-acmug-sean.pdf 1000 800 %}\nIT大咖说有录视频：\nhttp://www.itdks.com/dakashuo/detail/700 后来自己复看了一下，没啥大毛病，内容都交代清楚了，就是感觉确实舞台经验，表述上还有待加强。\n同时这里是当天的活动掠影，阅读原文可看视频：\nACMUG 2017 Tech Tour 深圳站掠影 http://mp.weixin.qq.com/s/-QNRhnN0kBtLkiWVIUS-QQ 下方是中国MySQL用户组(ACMUG)的公众号，欢迎关注： 原文连接地址：http://xgknight.com/2017/03/27/mysql-ppt-charset-conversion-acmug/\n","permalink":"http://localhost:1313/2017/03/mysql-ppt-charset-conversion-acmug/","summary":"\u003cp\u003e本文的ppt是3月25日在中国MySQL用户组2017深圳活动上，我所做的一个主题分享，关于实际生产使用mysql过程中与字符集有关的一些坑。\u003c/p\u003e","title":"一次艰辛的字符集转换历程 ACMUG分享"},{"content":"在看线上一个 MySQL innodb status 时，发现有死锁信息，而且出现的频率还不低。于是分析了一下，把过程记录下来。\n1. 概要 表结构脱敏处理：\n1 2 3 4 5 6 7 8 9 10 11 12 13 CREATE TABLE t_mytb1 ( f_id int(11) unsigned NOT NULL AUTO_INCREMENT, f_fid int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39;, f_sid int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39;, f_mode varchar(32) NOT NULL DEFAULT \u0026#39;\u0026#39;, f_read int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39;, f_xxx1 int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39;, f_xxx2 int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39;, f_wx_zone int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39;, PRIMARY KEY (f_id), KEY idx_sid (f_sid), KEY idx_fid (f_fid) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 死锁信息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 LATEST DETECTED DEADLOCK ------------------------ 2017-02-28 13:58:29 7f25a3efd700 *** (1) TRANSACTION: TRANSACTION 4907718431, ACTIVE 0.010 sec fetching rows mysql tables in use 3, locked 3 LOCK WAIT 154 lock struct(s), heap size 30248, 10 row lock(s) LOCK BLOCKING MySQL thread id: 13589250 block 13589247 MySQL thread id 13589247, OS thread handle 0x7f25a17e3700, query id 27061926722 11.xx.52.xx ecweb Searching rows for update UPDATE `d_db1`.`t_mytb1` SET `f_read` = f_read+1 WHERE (f_fid=91243) AND (f_sid=100) AND (f_mode=\u0026#39;浏览器\u0026#39;) *** (1) WAITING FOR THIS LOCK TO BE GRANTED: RECORD LOCKS space id 13288 page no 375 n bits 352 index `PRIMARY` of table `d_db1`.`t_mytb1` trx id 4907718431 lock_mode X locks rec but not gap waiting Record lock, heap no 245 PHYSICAL RECORD: n_fields 10; compact format; info bits 0 0: len 4; hex 0000a63b; asc ;;; 1: len 6; hex 0001246304a7; asc $c ;; 2: len 7; hex 7f000ac0162428; asc $(;; 3: len 4; hex 00016470; asc dp;; 4: len 4; hex 00000064; asc d;; 5: len 9; hex e6b58fe8a788e599a8; asc ;; 6: len 4; hex 0000244f; asc $O;; 7: len 4; hex 0000007c; asc |;; 8: len 4; hex 00000000; asc ;; 9: len 4; hex 00000000; asc ;; *** (2) TRANSACTION: TRANSACTION 4907718435, ACTIVE 0.007 sec fetching rows mysql tables in use 3, locked 3 154 lock struct(s), heap size 30248, 3 row lock(s) MySQL thread id 13589250, OS thread handle 0x7f25a3efd700, query id 27061926757 11.xx.104.xxx ecweb Searching rows for update UPDATE `d_db1`.`t_mytb1` SET `f_read` = f_read+1 WHERE (f_fid=91248) AND (f_sid=100) AND (f_mode=\u0026#39;浏览器\u0026#39;) *** (2) HOLDS THE LOCK(S): RECORD LOCKS space id 13288 page no 375 n bits 352 index `PRIMARY` of table `d_db1`.`t_mytb1` trx id 4907718435 lock_mode X locks rec but not gap Record lock, heap no 245 PHYSICAL RECORD: n_fields 10; compact format; info bits 0 0: len 4; hex 0000a63b; asc ;;; -- 42555 1: len 6; hex 0001246304a7; asc $c ;; -- 4905436327 2: len 7; hex 7f000ac0162428; asc $(;; 3: len 4; hex 00016470; asc dp;; -- 91248 4: len 4; hex 00000064; asc d;; -- 100 5: len 9; hex e6b58fe8a788e599a8; asc ;; 6: len 4; hex 0000244f; asc $O;; -- 9295 7: len 4; hex 0000007c; asc |;; -- 124 8: len 4; hex 00000000; asc ;; 9: len 4; hex 00000000; asc ;; *** (2) WAITING FOR THIS LOCK TO BE GRANTED: RECORD LOCKS space id 13288 page no 202 n bits 1272 index `idx_sid` of table `d_db1`.`t_mytb1` trx id 4907718435 lock_mode X locks rec but not gap waiting Record lock, heap no 705 PHYSICAL RECORD: n_fields 2; compact format; info bits 0 0: len 4; hex 00000064; asc d;; -- 100 1: len 4; hex 0000a633; asc 3;; -- 42547 *** WE ROLL BACK TRANSACTION (2) 乍一看很奇怪，tx1和tx2 两个 UPDATE 各自以 f_fid 为条件更新的记录互不影响才对，即使 91243，91248 两个值有可能出现在同一条数据上（因为f_fid上是二级索引），那顶多也就是个更新锁等待，谁后来谁等待，怎么会出现互相争用对方已持有的锁，被死锁检测机制捕获？\n当然,把 update 语句拿到数据库中 EXPLAIN 一下就可以看出端倪。这里不妨先分析一下输出的锁情况：\n先看 Tx2 (对应trx id 4907718435) :\nRECORD LOCKS space id 13288 page no 375 n bits 352 告诉我们是表空间id 13288 (可从 information_schema.INNODB_SYS_DATAFILES 查到对应ibd文件) 即 t_mytb1 表，第 375 号页面的 245 位置的记录被锁，并且是 idx PRIMARY 上的记录锁（注：本实例隔离级别为RC）。 Tx2正持有这把记录锁。 因为是聚集索引，显示了完整记录 1 2 3 4 5 6 0: 主键f_id=42555 1: DB_TRX_ID = 4905436327 2: DB_ROLL_PTR指向undo记录的地址 3: f_fid=91248 4: f_sid=100 ... 然而Tx2还在等待一个记录锁（lock_mode X locks rec but not gap waiting），但这把锁来自二级索引 idx_sid 索引上的记录锁。在 RC 级别下没有GAP lock，行锁除了加在符合条件的二级索引 f_sid=100 上外，还会对主键加record lock。 二级索引值： 1 2 0: f_sid=100 1: 主键f_id=42547 明显它们是两条不同的记录。\n再看 Tx1（对应trx id 4907718431）\nTx1 事务等待的锁，就是上面 Tx2 已持有的记录锁 f_id=42555 。但是由于输出的关系，没有看到它持有的锁。既然这里出现死锁，可以推断，Tx1执行update时，已获得 f_id=42547 的记录锁，这样才导致死锁，否则的话只会出现一方等待。示意图如下：\nInnoDB最终选择回滚 Tx2 是可以理解的 —— 它只获得了一个记录锁，资源占用最少。目前还无法解释的是关于锁数量这一部分：\n1 2 mysql tables in use 3, locked 3 154 lock struct(s), heap size 30248, 3 row lock(s) 2. 死锁产生的原因 —— index merge 上面任何一个 update 的explain结果： 可以看到 EXTRA 列 Using intersect(idx_sid, idx_fid)。\n索引合并是 5.0 就引入的一种优化手段，意指在查询语句里，可以在一个表上使用多个索引，同时扫描，最后进行结果合并。上面的例子里，条件 f_fid=xxx and f_sid=xxx，因为表上有 f_fid 和 f_sid 两个单列索引，优化器在成本模型里进行估算，认为一边使用 f_fid=91243 索引扫描，一边使用 f_sid=100 索引扫描，然后对两个结果集取交集，会更快。结果在高并发更新情况下：\nTx2通过 f_fid 索引锁住了记录 42555，欲通过 f_sid 锁定另一条记录 42547 Tx1 已通过 f_sid 锁定 42547，欲通过 f_fid 锁住记录42555 死锁发生 关于索引合并 intersection 只是 索引合并中的一种，还有 union, sort_union 。可以用到 index_merge 是有比较苛刻的条件。\n首先是 Range 优先(\u0026gt;5.6.7)。比如 key1=1 or (key1=2 and key2=3)，其中key1是可以转化成 range scan 的，不会使用 index merge union 其次，Intersect和Union要符合 ROR，即 Rowid-Ordered-Retrival： Intersect和Union都需要使用的索引是ROR的，也就时ROWID ORDERED，即针对不同的索引扫描出来的数据必须是同时按照ROWID排序的，这里的 ROWID其实也就是InnoDB的主键(如果不定义主键，InnoDB会隐式添加ROWID列作为主键)。只有每个索引是ROR的，才能进行归并排序，你懂的。 当然你可能会有疑惑，查不记录后内部进行一次sort不一样么，何必必须要ROR呢，不错，所以有了SORT-UNION。SORT-UNION就是每个非ROR的索引 排序后再进行Merge \u0026ndash; 来自 http://www.cnblogs.com/nocode/archive/2013/01/28/2880654.html\n像 key1=v1 or key2=v2 ， key1与key2是单列索引，并且无其它索引可用，就有可能看到 Using Union(xx,xxx) 。更多内容可见参考链接。\n3. 解决 —— 加联合索引 解决这个死锁可能你也想到了，添加联合索引 idx_fid_sid(f_fid, f_sid)，这样一来查询会选择这一个索引，至于 idx_sid 这个单列索引还需不需要，看业务场景。\n另外，如果懂点业务的话，会发现这个更新之所以这么频繁，实际上是一个阅读量计数的功能，放到redis里可极大的提高并发能力，定时持久化到mysql表。\n最后提一句 index_merge 是有选项可以关闭的：\n1 2 mysql\u0026gt; select @@optimizer_switch; index_merge=on,index_merge_union=on,index_merge_sort_union=on,index_merge_intersection=on ... 如果优化器选择了index_merge，一般是索引没建好，我看不让它使用比较更好。\n** 参考文章 **\nMySQL优化器：index merge介绍 MySQL update use index merge(Using intersect) increase chances for deadlock https://dev.mysql.com/doc/refman/5.6/en/index-merge-optimization.html 原文链接地址：http://xgknight.com/2017/03/11/mysql-index_merge-deadlock/\n","permalink":"http://localhost:1313/2017/03/mysql-index_merge-deadlock/","summary":"\u003cp\u003e在看线上一个 MySQL innodb status 时，发现有死锁信息，而且出现的频率还不低。于是分析了一下，把过程记录下来。\u003c/p\u003e\n\u003ch2 id=\"1-概要\"\u003e1. 概要\u003c/h2\u003e\n\u003cp\u003e表结构脱敏处理：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e 1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 7\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 8\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 9\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e10\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e11\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e12\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e13\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-gdscript3\" data-lang=\"gdscript3\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eCREATE\u003c/span\u003e \u003cspan class=\"n\"\u003eTABLE\u003c/span\u003e \u003cspan class=\"n\"\u003et_mytb1\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"n\"\u003ef_id\u003c/span\u003e \u003cspan class=\"ne\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e11\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"n\"\u003eunsigned\u003c/span\u003e \u003cspan class=\"n\"\u003eNOT\u003c/span\u003e \u003cspan class=\"n\"\u003eNULL\u003c/span\u003e \u003cspan class=\"n\"\u003eAUTO_INCREMENT\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"n\"\u003ef_fid\u003c/span\u003e \u003cspan class=\"ne\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e11\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"n\"\u003eunsigned\u003c/span\u003e \u003cspan class=\"n\"\u003eNOT\u003c/span\u003e \u003cspan class=\"n\"\u003eNULL\u003c/span\u003e \u003cspan class=\"n\"\u003eDEFAULT\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;0\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"n\"\u003ef_sid\u003c/span\u003e \u003cspan class=\"ne\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e11\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"n\"\u003eunsigned\u003c/span\u003e \u003cspan class=\"n\"\u003eNOT\u003c/span\u003e \u003cspan class=\"n\"\u003eNULL\u003c/span\u003e \u003cspan class=\"n\"\u003eDEFAULT\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;0\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"n\"\u003ef_mode\u003c/span\u003e \u003cspan class=\"n\"\u003evarchar\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e32\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"n\"\u003eNOT\u003c/span\u003e \u003cspan class=\"n\"\u003eNULL\u003c/span\u003e \u003cspan class=\"n\"\u003eDEFAULT\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"n\"\u003ef_read\u003c/span\u003e \u003cspan class=\"ne\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e11\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"n\"\u003eunsigned\u003c/span\u003e \u003cspan class=\"n\"\u003eNOT\u003c/span\u003e \u003cspan class=\"n\"\u003eNULL\u003c/span\u003e \u003cspan class=\"n\"\u003eDEFAULT\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;0\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"n\"\u003ef_xxx1\u003c/span\u003e \u003cspan class=\"ne\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e11\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"n\"\u003eunsigned\u003c/span\u003e \u003cspan class=\"n\"\u003eNOT\u003c/span\u003e \u003cspan class=\"n\"\u003eNULL\u003c/span\u003e \u003cspan class=\"n\"\u003eDEFAULT\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;0\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"n\"\u003ef_xxx2\u003c/span\u003e \u003cspan class=\"ne\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e11\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"n\"\u003eunsigned\u003c/span\u003e \u003cspan class=\"n\"\u003eNOT\u003c/span\u003e \u003cspan class=\"n\"\u003eNULL\u003c/span\u003e \u003cspan class=\"n\"\u003eDEFAULT\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;0\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"n\"\u003ef_wx_zone\u003c/span\u003e \u003cspan class=\"ne\"\u003eint\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e11\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"n\"\u003eunsigned\u003c/span\u003e \u003cspan class=\"n\"\u003eNOT\u003c/span\u003e \u003cspan class=\"n\"\u003eNULL\u003c/span\u003e \u003cspan class=\"n\"\u003eDEFAULT\u003c/span\u003e \u003cspan class=\"s1\"\u003e\u0026#39;0\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"n\"\u003ePRIMARY\u003c/span\u003e \u003cspan class=\"n\"\u003eKEY\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ef_id\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"n\"\u003eKEY\u003c/span\u003e \u003cspan class=\"n\"\u003eidx_sid\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ef_sid\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  \u003cspan class=\"n\"\u003eKEY\u003c/span\u003e \u003cspan class=\"n\"\u003eidx_fid\u003c/span\u003e \u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ef_fid\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e \u003cspan class=\"n\"\u003eENGINE\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eInnoDB\u003c/span\u003e \u003cspan class=\"n\"\u003eDEFAULT\u003c/span\u003e \u003cspan class=\"n\"\u003eCHARSET\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"n\"\u003eutf8mb4\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e死锁信息：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e 1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 7\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 8\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 9\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e10\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e11\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e12\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e13\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e14\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e15\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e16\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e17\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e18\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e19\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e20\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e21\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e22\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e23\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e24\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e25\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e26\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e27\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e28\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e29\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e30\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e31\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e32\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e33\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e34\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e35\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e36\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e37\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e38\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e39\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e40\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e41\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e42\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e43\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e44\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e45\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e46\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e47\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e48\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e49\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e50\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e51\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-mysql\" data-lang=\"mysql\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"n\"\u003eLATEST\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eDETECTED\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eDEADLOCK\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"o\"\u003e----------------------\u003c/span\u003e\u003cspan class=\"c1\"\u003e--\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e2017-02-28 13:58:29 7f25a3efd700\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"o\"\u003e***\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eTRANSACTION\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"n\"\u003eTRANSACTION\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e4907718431\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eACTIVE\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"mi\"\u003e010\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003esec\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003efetching\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003erows\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"n\"\u003emysql\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kp\"\u003etables\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003ein\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003euse\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e3\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003elocked\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e3\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"k\"\u003eLOCK\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eWAIT\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e154\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003elock\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nf\"\u003estruct\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003es\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eheap\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003esize\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e30248\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e10\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003erow\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003elock\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003es\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"k\"\u003eLOCK\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eBLOCKING\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eMySQL\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ethread\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eid\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e13589250\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eblock\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e13589247\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"n\"\u003eMySQL\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ethread\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eid\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e13589247\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eOS\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ethread\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ehandle\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"n\"\u003ex7f25a17e3700\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003equery\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eid\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e27061926722\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e11\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003exx\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"mi\"\u003e52\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003exx\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eecweb\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eSearching\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003erows\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003efor\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eupdate\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"k\"\u003eUPDATE\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003ed_db1\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003et_mytb1\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kt\"\u003eSET\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003ef_read\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ef_read\u003c/span\u003e\u003cspan class=\"o\"\u003e+\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eWHERE\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ef_fid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e91243\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eAND\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ef_sid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e100\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eAND\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ef_mode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;浏览器\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"o\"\u003e***\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eWAITING\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eFOR\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eTHIS\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eLOCK\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eTO\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eBE\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eGRANTED\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"n\"\u003eRECORD\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eLOCKS\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003espace\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eid\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e13288\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003epage\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eno\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e375\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003en\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ebits\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e352\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eindex\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"k\"\u003ePRIMARY\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eof\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003etable\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003ed_db1\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003et_mytb1\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003etrx\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eid\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e4907718431\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003elock_mode\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003elocks\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003erec\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ebut\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003enot\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003egap\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ewaiting\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"n\"\u003eRecord\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003elock\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eheap\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eno\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e245\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ePHYSICAL\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eRECORD\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003en_fields\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e10\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ecompact\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eformat\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003einfo\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ebits\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003elen\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ehex\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e0000\u003c/span\u003e\u003cspan class=\"n\"\u003ea63b\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003easc\u003c/span\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"p\"\u003e;;;\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003elen\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e6\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ehex\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e0001246304\u003c/span\u003e\u003cspan class=\"n\"\u003ea7\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003easc\u003c/span\u003e\u003cspan class=\"w\"\u003e   \u003c/span\u003e\u003cspan class=\"err\"\u003e$\u003c/span\u003e\u003cspan class=\"n\"\u003ec\u003c/span\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"p\"\u003e;;\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e2\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003elen\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e7\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ehex\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e7\u003c/span\u003e\u003cspan class=\"n\"\u003ef000ac0162428\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003easc\u003c/span\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"err\"\u003e$\u003c/span\u003e\u003cspan class=\"p\"\u003e(;;\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e3\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003elen\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ehex\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e00016470\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003easc\u003c/span\u003e\u003cspan class=\"w\"\u003e   \u003c/span\u003e\u003cspan class=\"n\"\u003edp\u003c/span\u003e\u003cspan class=\"p\"\u003e;;\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003elen\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ehex\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e00000064\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003easc\u003c/span\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"n\"\u003ed\u003c/span\u003e\u003cspan class=\"p\"\u003e;;\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e5\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003elen\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e9\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ehex\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ee6b58fe8a788e599a8\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003easc\u003c/span\u003e\u003cspan class=\"w\"\u003e          \u003c/span\u003e\u003cspan class=\"p\"\u003e;;\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e6\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003elen\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ehex\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e0000244\u003c/span\u003e\u003cspan class=\"n\"\u003ef\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003easc\u003c/span\u003e\u003cspan class=\"w\"\u003e   \u003c/span\u003e\u003cspan class=\"err\"\u003e$\u003c/span\u003e\u003cspan class=\"n\"\u003eO\u003c/span\u003e\u003cspan class=\"p\"\u003e;;\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e7\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003elen\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ehex\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e0000007\u003c/span\u003e\u003cspan class=\"n\"\u003ec\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003easc\u003c/span\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\u003cspan class=\"p\"\u003e;;\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e8\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003elen\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ehex\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e00000000\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003easc\u003c/span\u003e\u003cspan class=\"w\"\u003e     \u003c/span\u003e\u003cspan class=\"p\"\u003e;;\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e9\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003elen\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ehex\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e00000000\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003easc\u003c/span\u003e\u003cspan class=\"w\"\u003e     \u003c/span\u003e\u003cspan class=\"p\"\u003e;;\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"o\"\u003e***\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e2\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eTRANSACTION\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"n\"\u003eTRANSACTION\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e4907718435\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eACTIVE\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"mi\"\u003e007\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003esec\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003efetching\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003erows\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"n\"\u003emysql\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kp\"\u003etables\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003ein\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003euse\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e3\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003elocked\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e3\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"mi\"\u003e154\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003elock\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nf\"\u003estruct\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003es\u003c/span\u003e\u003cspan class=\"p\"\u003e),\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eheap\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003esize\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e30248\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e3\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003erow\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003elock\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003es\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"n\"\u003eMySQL\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ethread\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eid\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e13589250\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eOS\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ethread\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ehandle\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"n\"\u003ex7f25a3efd700\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003equery\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eid\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e27061926757\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e11\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003exx\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"mi\"\u003e104\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003exxx\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eecweb\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eSearching\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003erows\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003efor\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eupdate\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"k\"\u003eUPDATE\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003ed_db1\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003et_mytb1\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kt\"\u003eSET\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003ef_read\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ef_read\u003c/span\u003e\u003cspan class=\"o\"\u003e+\u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eWHERE\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ef_fid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e91248\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eAND\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ef_sid\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"mi\"\u003e100\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eAND\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003ef_mode\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"s1\"\u003e\u0026#39;浏览器\u0026#39;\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"o\"\u003e***\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e2\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eHOLDS\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eTHE\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eLOCK\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eS\u003c/span\u003e\u003cspan class=\"p\"\u003e):\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"n\"\u003eRECORD\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eLOCKS\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003espace\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eid\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e13288\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003epage\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eno\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e375\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003en\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ebits\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e352\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eindex\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"k\"\u003ePRIMARY\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eof\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003etable\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003ed_db1\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003et_mytb1\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003etrx\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eid\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e4907718435\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003elock_mode\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003elocks\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003erec\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ebut\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003enot\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003egap\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"n\"\u003eRecord\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003elock\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eheap\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eno\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e245\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ePHYSICAL\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eRECORD\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003en_fields\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e10\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ecompact\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eformat\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003einfo\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ebits\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003elen\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ehex\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e0000\u003c/span\u003e\u003cspan class=\"n\"\u003ea63b\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003easc\u003c/span\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"p\"\u003e;;;\u003c/span\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"c1\"\u003e-- 42555\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003elen\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e6\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ehex\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e0001246304\u003c/span\u003e\u003cspan class=\"n\"\u003ea7\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003easc\u003c/span\u003e\u003cspan class=\"w\"\u003e   \u003c/span\u003e\u003cspan class=\"err\"\u003e$\u003c/span\u003e\u003cspan class=\"n\"\u003ec\u003c/span\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"p\"\u003e;;\u003c/span\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"c1\"\u003e-- 4905436327\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e2\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003elen\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e7\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ehex\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e7\u003c/span\u003e\u003cspan class=\"n\"\u003ef000ac0162428\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003easc\u003c/span\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"err\"\u003e$\u003c/span\u003e\u003cspan class=\"p\"\u003e(;;\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e3\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003elen\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ehex\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e00016470\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003easc\u003c/span\u003e\u003cspan class=\"w\"\u003e   \u003c/span\u003e\u003cspan class=\"n\"\u003edp\u003c/span\u003e\u003cspan class=\"p\"\u003e;;\u003c/span\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"c1\"\u003e-- 91248\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003elen\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ehex\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e00000064\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003easc\u003c/span\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"n\"\u003ed\u003c/span\u003e\u003cspan class=\"p\"\u003e;;\u003c/span\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"c1\"\u003e-- 100\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e5\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003elen\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e9\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ehex\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ee6b58fe8a788e599a8\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003easc\u003c/span\u003e\u003cspan class=\"w\"\u003e          \u003c/span\u003e\u003cspan class=\"p\"\u003e;;\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e6\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003elen\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ehex\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e0000244\u003c/span\u003e\u003cspan class=\"n\"\u003ef\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003easc\u003c/span\u003e\u003cspan class=\"w\"\u003e   \u003c/span\u003e\u003cspan class=\"err\"\u003e$\u003c/span\u003e\u003cspan class=\"n\"\u003eO\u003c/span\u003e\u003cspan class=\"p\"\u003e;;\u003c/span\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"c1\"\u003e-- 9295\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e7\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003elen\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ehex\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e0000007\u003c/span\u003e\u003cspan class=\"n\"\u003ec\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003easc\u003c/span\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"o\"\u003e|\u003c/span\u003e\u003cspan class=\"p\"\u003e;;\u003c/span\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"c1\"\u003e-- 124\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e8\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003elen\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ehex\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e00000000\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003easc\u003c/span\u003e\u003cspan class=\"w\"\u003e     \u003c/span\u003e\u003cspan class=\"p\"\u003e;;\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e9\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003elen\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ehex\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e00000000\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003easc\u003c/span\u003e\u003cspan class=\"w\"\u003e     \u003c/span\u003e\u003cspan class=\"p\"\u003e;;\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"o\"\u003e***\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e2\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eWAITING\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eFOR\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eTHIS\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eLOCK\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eTO\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eBE\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eGRANTED\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"n\"\u003eRECORD\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eLOCKS\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003espace\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eid\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e13288\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003epage\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eno\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e202\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003en\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ebits\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e1272\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003eindex\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003eidx_sid\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eof\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003etable\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003ed_db1\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"n\"\u003et_mytb1\u003c/span\u003e\u003cspan class=\"o\"\u003e`\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003etrx\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eid\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e4907718435\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003elock_mode\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eX\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003elocks\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003erec\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ebut\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003enot\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003egap\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ewaiting\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"n\"\u003eRecord\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003elock\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eheap\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eno\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e705\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ePHYSICAL\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eRECORD\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003en_fields\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e2\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ecompact\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eformat\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003einfo\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ebits\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003elen\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ehex\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e00000064\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003easc\u003c/span\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"n\"\u003ed\u003c/span\u003e\u003cspan class=\"p\"\u003e;;\u003c/span\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"c1\"\u003e-- 100\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e1\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003elen\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e4\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ehex\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"mi\"\u003e0000\u003c/span\u003e\u003cspan class=\"n\"\u003ea633\u003c/span\u003e\u003cspan class=\"p\"\u003e;\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003easc\u003c/span\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"mi\"\u003e3\u003c/span\u003e\u003cspan class=\"p\"\u003e;;\u003c/span\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"c1\"\u003e-- 42547\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"o\"\u003e***\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eWE\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eROLL\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eBACK\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nf\"\u003eTRANSACTION\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e2\u003c/span\u003e\u003cspan class=\"p\"\u003e)\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e乍一看很奇怪，tx1和tx2 两个 UPDATE 各自以 f_fid 为条件更新的记录互不影响才对，即使 91243，91248 两个值有可能出现在同一条数据上（因为f_fid上是二级索引），那顶多也就是个更新锁等待，谁后来谁等待，怎么会出现互相争用对方已持有的锁，被死锁检测机制捕获？\u003c/p\u003e\n\u003cp\u003e当然,把 update 语句拿到数据库中 EXPLAIN 一下就可以看出端倪。这里不妨先分析一下输出的锁情况：\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e先看 Tx2 (对应trx id 4907718435)\u003c/strong\u003e :\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003ccode\u003eRECORD LOCKS space id 13288 page no 375 n bits 352\u003c/code\u003e 告诉我们是表空间id 13288 (可从 \u003ccode\u003einformation_schema.INNODB_SYS_DATAFILES\u003c/code\u003e 查到对应ibd文件) 即 t_mytb1 表，第 375 号页面的 245 位置的记录被锁，并且是 idx PRIMARY 上的记录锁（注：本实例隔离级别为RC）。 Tx2正持有这把记录锁。\n因为是聚集索引，显示了完整记录\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e6\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-fallback\" data-lang=\"fallback\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e0: 主键f_id=42555\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e1: DB_TRX_ID = 4905436327\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e2: DB_ROLL_PTR指向undo记录的地址\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e3: f_fid=91248\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e4: f_sid=100\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e   ...\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003col start=\"2\"\u003e\n\u003cli\u003e然而Tx2还在等待一个记录锁（lock_mode X locks rec but not gap waiting），但这把锁来自二级索引 \u003ccode\u003eidx_sid\u003c/code\u003e 索引上的记录锁。在 RC 级别下没有GAP lock，行锁除了加在符合条件的二级索引 f_sid=100 上外，还会对主键加record lock。\n二级索引值：\u003c/li\u003e\n\u003c/ol\u003e","title":"index merge 引起的死锁分析"},{"content":"昨天突然有个客户说误操作，自己删除了大量数据，CTO直接将我拉到一个讨论组里，说要帮他们恢复数据。他们自己挖的坑，打算让开发那边根据业务日志去恢复，被告知只记录的删除主键这样的信息，物理删除，无能为力。\n上服务器看了下记录的日志，发现好几台上面都有被误删的记录输出。阿里RDS虽然可以克隆一个恢复到删除时间点前的实例，但这散落的几万个id找起来费力，还有就是几个表之间关联的数据也要恢复，觉得麻烦。\n想到 MySQL 的闪回方案。以前看过好几篇相关文章，甚至差点自己用python撸一个来解析binlog，反转得到回滚sql，实在没空，这下要急用了。赶紧找了下网上“现成的方案”。\n正文开始\nMySQL（含阿里RDS）快速闪回可以说是对数据库误操作的后悔药，flashback功能可以将数据库返回到误操作之前。但是即使oracle数据库也只支持短时间内的闪回。\n网上现有开源的MySQL闪回实现，原理都是解析binlog，生成反向sql: (必须为row模式)\n对于 delete 操作，生成insert （DELETE_ROWS_EVENT） 对于 update 操作，交换binlog里面值的顺序 （UPDATE_ROWS_EVENT） 对于 insert 操作，反向生成delete （WRITE_ROWS_EVENT） 对于多个event，要逆向生成sql 开源实现：\nhttps://github.com/58daojia-dba/mysqlbinlog_flashback https://github.com/danfengcao/binlog2sql/ 上面两种实现方式，都是通过 python-mysql-replication 包，模拟出原库的一个从库，然后 show binary logs 来获取binlog，发起同步binlog的请求，再解析EVENT。但是阿里云 RDS 的binlog在同步给从库之后，** 很快就被 purge 掉了 。如果要恢复 ** 昨天 的 ** 部分数据 **，两种方案都是拿不到binlog的。也就是闪回的时间有限。\n还有一些比较简单的实现，就是解析 binlog 物理文件，实现回滚，如 binlog-rollback.pl ，试过，但是速度太慢。\n为了不影响速度，又想使用比较成熟的闪回方案，我们可以这样做：\n借助一个自建的 mysqld 实例，将已purge掉的binlog拷贝到该实例的目录下 在自建实例里，提前创建好需要恢复的表（结构），因为工具需要连接上来从 information_schema.columns 获取元数据信息 拷贝的时候，可以替换掉mysql实例自己的binlog文件名，保持连续 可能要修改 mysql-bin.index，确保文件名还能被mysqld识别到 重启mysql实例，show binary logs 看一下是否在列表里面 接下来就可以使用上面任何一种工具，模拟从库，指定一个binlog文件，开始时间，结束时间，得到回滚SQL 再根据业务逻辑，筛选出需要的sql 总之就是借助另外一个mysql，把binlog event传输过来。温馨提示：\n两个实例间版本不要跨度太大 注意文件权限 如果原库开启了gtid，这个自建实例也要开启gtid 示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 python mysqlbinlog_back.py --host=\u0026#34;localhost\u0026#34; --username=\u0026#34;ecuser\u0026#34; --password=\u0026#34;ecuser\u0026#34; --port=3306 \\ --schema=dbname --tables=\u0026#34;t_xx1,t_xx2,t_xx3\u0026#34; -S \u0026#34;mysql-bin.000019\u0026#34; -E \u0026#34;2017-03-02 13:00:00\u0026#34; -N \u0026#34;2017-03-02 14:09:00\u0026#34; -I -U ===log will also write to .//mysqlbinlog_flashback.log=== parameter={\u0026#39;start_binlog_file\u0026#39;: \u0026#39;mysql-bin.000019\u0026#39;, \u0026#39;stream\u0026#39;: None, \u0026#39;keep_data\u0026#39;: True, \u0026#39;file\u0026#39;: {\u0026#39;data_create\u0026#39;: None, \u0026#39;flashback\u0026#39;: None, \u0026#39;data\u0026#39;: None}, \u0026#39;add_schema_name\u0026#39;: False, \u0026#39;start_time\u0026#39;: None, \u0026#39;keep_current_data\u0026#39;: False, \u0026#39;start_to_timestamp\u0026#39;: 1488430800, \u0026#39;mysql_setting\u0026#39;: {\u0026#39;passwd\u0026#39;: \u0026#39;ecuser\u0026#39;, \u0026#39;host\u0026#39;: \u0026#39;localhost\u0026#39;, \u0026#39;charset\u0026#39;: \u0026#39;utf8\u0026#39;, \u0026#39;port\u0026#39;: 3306, \u0026#39;user\u0026#39;: \u0026#39;ecuser\u0026#39;}, \u0026#39;table_name\u0026#39;: \u0026#39;t_xx1,t_xx2,t_xx3\u0026#39;, \u0026#39;skip_delete\u0026#39;: False, \u0026#39;schema\u0026#39;: \u0026#39;dbname\u0026#39;, \u0026#39;stat\u0026#39;: {\u0026#39;flash_sql\u0026#39;: {}}, \u0026#39;table_name_array\u0026#39;: [\u0026#39;t_xx1\u0026#39;, \u0026#39;t_xx2\u0026#39;, \u0026#39;t_xx3\u0026#39;], \u0026#39;one_binlog_file\u0026#39;: False, \u0026#39;output_file_path\u0026#39;: \u0026#39;./log\u0026#39;, \u0026#39;start_position\u0026#39;: 4, \u0026#39;skip_update\u0026#39;: True, \u0026#39;dump_event\u0026#39;: False, \u0026#39;end_to_timestamp\u0026#39;: 1488434940, \u0026#39;skip_insert\u0026#39;: True, \u0026#39;schema_array\u0026#39;: [\u0026#39;dbname\u0026#39;] } scan 10000 events ....from binlogfile=mysql-bin.000019,timestamp=2017-03-02T11:42:14 scan 20000 events ....from binlogfile=mysql-bin.000019,timestamp=2017-03-02T11:42:29 ... 提示： binlog为ROW格式，dml影响的每一行都会记录两个event：Table_map和Row_log。而table_map里面的table_id并不会影响它在哪个实例上应用，这个id可以认为是逻辑上，记录表结构版本的机制 —— 当它在 table_definition_cache 没有找到表定义时，id自增1，分配给要记录到binlog的表。\nmysqlbinlog_back.py 使用经验 ：\n务必指定库名、表明，开始的binlog文件名，起始时间，结束时间。可以加快scan的速度。 根据恢复的需要，选择 -I, -U, -D，指定回滚哪些类型的操作。 如果只是恢复部分表数据（非完全闪回），做不到关联表的正确恢复。比如需要恢复delete数据，但无法恢复业务里因为delete引起其它表更新的数据，除非完全闪回。 不支持表字段是 enum 类型的，比如 t_xx3 的f_do_type字段。可以把自建实例上的enum定义改成int。 参考\nhttp://dinglin.iteye.com/blog/1539167 http://www.penglixun.com/tech/database/mysql_flashback_feature.html/comment-page-1#comment-1207998 http://www.cnblogs.com/yuyue2014/p/3721172.html 本文链接地址：http://xgknight.com/2017/03/03/mysql-flashback_use_purged-binlog/\n","permalink":"http://localhost:1313/2017/03/mysql-flashback_use_purged-binlog/","summary":"\u003cp\u003e昨天突然有个客户说误操作，自己删除了大量数据，CTO直接将我拉到一个讨论组里，说要帮他们恢复数据。他们自己挖的坑，打算让开发那边根据业务日志去恢复，被告知只记录的删除主键这样的信息，物理删除，无能为力。\u003c/p\u003e\n\u003cp\u003e上服务器看了下记录的日志，发现好几台上面都有被误删的记录输出。阿里RDS虽然可以克隆一个恢复到删除时间点前的实例，但这散落的几万个id找起来费力，还有就是几个表之间关联的数据也要恢复，觉得麻烦。\u003c/p\u003e\n\u003cp\u003e想到 MySQL 的闪回方案。以前看过好几篇相关文章，甚至差点自己用python撸一个来解析binlog，反转得到回滚sql，实在没空，这下要急用了。赶紧找了下网上“现成的方案”。\u003c/p\u003e\n\u003cp\u003e正文开始\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eMySQL（含阿里RDS）快速闪回可以说是对数据库误操作的后悔药，flashback功能可以将数据库返回到误操作之前。但是即使oracle数据库也只支持短时间内的闪回。\u003c/p\u003e\n\u003cp\u003e网上现有开源的MySQL闪回实现，原理都是解析binlog，生成反向sql: (必须为row模式)\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e对于 delete 操作，生成insert （DELETE_ROWS_EVENT）\u003c/li\u003e\n\u003cli\u003e对于 update 操作，交换binlog里面值的顺序 （UPDATE_ROWS_EVENT）\u003c/li\u003e\n\u003cli\u003e对于 insert 操作，反向生成delete （WRITE_ROWS_EVENT）\u003c/li\u003e\n\u003cli\u003e对于多个event，要逆向生成sql\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e开源实现：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/58daojia-dba/mysqlbinlog_flashback\"\u003ehttps://github.com/58daojia-dba/mysqlbinlog_flashback\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/danfengcao/binlog2sql/\"\u003ehttps://github.com/danfengcao/binlog2sql/\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e上面两种实现方式，都是通过 python-mysql-replication 包，模拟出原库的一个从库，然后 \u003ccode\u003eshow binary logs\u003c/code\u003e 来获取binlog，发起同步binlog的请求，再解析EVENT。但是阿里云 RDS 的binlog在同步给从库之后，** 很快就被 purge 掉了 \u003cstrong\u003e。如果要恢复 ** 昨天\u003c/strong\u003e 的 ** 部分数据 **，两种方案都是拿不到binlog的。也就是闪回的时间有限。\u003c/p\u003e\n\u003cp\u003e还有一些比较简单的实现，就是解析 binlog 物理文件，实现回滚，如 \u003ccode\u003ebinlog-rollback.pl\u003c/code\u003e ，试过，但是速度太慢。\u003c/p\u003e\n\u003cp\u003e为了不影响速度，又想使用比较成熟的闪回方案，我们可以这样做：\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e借助一个自建的 mysqld 实例，将已purge掉的binlog拷贝到该实例的目录下\u003c/li\u003e\n\u003cli\u003e在自建实例里，提前创建好需要恢复的表（结构），因为工具需要连接上来从 \u003ccode\u003einformation_schema.columns\u003c/code\u003e 获取元数据信息\u003c/li\u003e\n\u003cli\u003e拷贝的时候，可以替换掉mysql实例自己的binlog文件名，保持连续\u003c/li\u003e\n\u003cli\u003e可能要修改 \u003ccode\u003emysql-bin.index\u003c/code\u003e，确保文件名还能被mysqld识别到\u003c/li\u003e\n\u003cli\u003e重启mysql实例，\u003ccode\u003eshow binary logs\u003c/code\u003e 看一下是否在列表里面\u003c/li\u003e\n\u003cli\u003e接下来就可以使用上面任何一种工具，模拟从库，指定一个binlog文件，开始时间，结束时间，得到回滚SQL\u003c/li\u003e\n\u003cli\u003e再根据业务逻辑，筛选出需要的sql\u003c/li\u003e\n\u003c/ol\u003e","title":"MySQL根据离线binlog快速“闪回”"},{"content":"AUTO-INC waiting 锁等待 这是生产环境出现的现象，某日下午5点业务高峰期，我们的 慢查询快照抓取程序 报出大量线程阻塞，但是1分钟以后就好了。于是分析了当时的 processlist 和 innodb status 现场记录，发现有大量的 AUTO-INC waiting：\n![auto-inc-lock-wait][1]\n当时想这是得多大的并发量，才会导致 AUTO_INCREMENT 列的自增id分配出现性能问题，不太愿意相信这个事实（后面就再也没出现过）。了解一番之后（见 关于MySQLz自增主键问题（上篇）），发现这个表级别的 AUTO-INC lock 就不应该在业务中存在，因为 innodb_autoinc_lock_mode为1，普通业务都是 simple inserts，获取自增id是靠内存里维护的一个互斥量（mutex counter）。\n问题拿到知数堂优化班上课群里讨论过，也只是猜测是不是慢查询多了导致负载高，或者当时磁盘遇到什么物理故障阿里云那边自动恢复了。再后来怀疑是不是因为插入时带了 auto_increment 列的值（我们有个redis incr实现的自增id服务，虽然这一列有 AAUTO_INCREMENT 定义，但实际已经从发号器取id了），会导致锁的性质会变？\n为了弄清这个疑问，特意去看了下mysql源码，发现如果插入的自增值比表当前AUTOINC值要大，是直接update mutex counter：\n看源码的时候也打消了另一个疑虑：show engine innodb status 看到的 AUTO-INC 有没有可能不区分 表级自增锁和互斥量计数器 两种自增方案，只是告诉你自增id获取忙不过来？ 实际不是的，代码里面有明确的定义是 autoinc_lock还是autoinc_mutex：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 // dict0dict.cc : #ifndef UNIV_HOTBACKUP /********************************************************************//** Acquire the autoinc lock. */ UNIV_INTERN void dict_table_autoinc_lock( /*====================*/ dict_table_t*\ttable)\t/*!\u0026lt; in/out: table */ { mutex_enter(\u0026amp;table-\u0026gt;autoinc_mutex); } /********************************************************************//** Unconditionally set the autoinc counter. */ UNIV_INTERN void dict_table_autoinc_initialize( /*==========================*/ dict_table_t*\ttable,\t/*!\u0026lt; in/out: table */ ib_uint64_t\tvalue)\t/*!\u0026lt; in: next value to assign to a row */ { ut_ad(mutex_own(\u0026amp;table-\u0026gt;autoinc_mutex)); table-\u0026gt;autoinc = value; } 最后在微信上找周彦伟大神问问，在快要放弃的时候，从 innodb_lock_waits 中锁等待之间关系，一层一层挖，终于找到了一条这样的sql:\n1 2 \u0026#34;INSERT INTO mydb1.t_mytable_inc ( f_log_id, f_fff_id, ..., f_from, f_sendmsg ) SELECT 2021712366, 507019984, ..., 10, 0 from dual\u0026#34; 瞬间就明(ma)白(niang)了。典型的 INSERT ... SELECT ...， 但是 select 子句带的全是常量，但是对 innodb 来说它还是认为“这是 bulk inserts，我无法预估插入行数”，所以使用表级锁的自增方式。当时同时有 22 个这样的插入，可能负载也确实比较高导致活跃事务里主键最小的那一条一直处于 query end 状态，后面简单insert也需要等这个 语句 结束，直到释放 AUTO-INC table lock，以致引起雪崩效应。\n之所以一直没发现这条语句，是因为 processlist 太长了，而且格式不友好。快照抓取程序这块还可以优化。\n最后解决其实非常容易：\n既然已经有自增id服务，直接把把主键上的 AUTO_INCREMENT 定义去掉 整改这种 insert \u0026hellip; select \u0026hellip; 的sql。维护时可以，但开发账号要杜绝 周大神说他们用的是 mode 2 模式。也不失为一种方法 load data 为什么没阻塞其它事务 这是一个同行网友请教我的： ![][2]\n上篇讲到，load data infile 由于innodb无法提前知道插入的行数，所以归为 bulk inserts —— 表自增方式升级为表级锁，这样一来其它会话里的 insert岂不应该是会被阻塞，为什么实验结果却没有阻塞。\n当然一开始我也觉得奇怪，但是仔细想一下就知道，这个表级锁是一个特殊的表锁，为了提高并发性，它是在 语句 结束就释放了（而不是事务结束），那么只要验证 LOAD DATA 是把文件里面的行记录，拼装成单个insert就行了，这样其它会话的插入就可以在交错获得表级自增锁，实现不阻塞插入： ![][3]\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 上图 row 模式下 的binlog，看到 BEGIN ... COMMIT 之间包含了 多行 insert。（注：在 statement 模式下，binlog里面记录的是 LOAD DATA 语句，从库会把文件从主库传输过来，再执行） 温馨提示： 1. 如果load data 的文件自带主键值，那么另一个会话获取的自增值很容易产生重复。 2. stackexchange上有个关于 [load data infile 对复制安全性的讨论](http://dba.stackexchange.com/questions/40400/loading-data-in-mysql-using-load-data-infile-replication-safe) ，同意二楼的观点，官方文档里说的 unsafe，并不是说执行这样的语句会导致安全问题，而是 considered unsafe，在 row-based 可用的情况下，优化器会自动把binlog记录为 row ，依然是安全的。 [1]: http://github.com/seanlook/sean-notes-comment/raw/main/static/mysql-autoinc-1.png [2]: http://github.com/seanlook/sean-notes-comment/raw/main/static/mysql-autoinc-loaddata.png [3]: http://github.com/seanlook/sean-notes-comment/raw/main/static/mysql-autoinc-loaddata-binlog.png --- 本文链接地址：http://xgknight.com/2017/02/17/mysql-autoincrement_2/ --- ","permalink":"http://localhost:1313/2017/02/mysql-autoincrement_2/","summary":"\u003ch3 id=\"auto-inc-waiting-锁等待\"\u003eAUTO-INC waiting 锁等待\u003c/h3\u003e\n\u003cp\u003e这是生产环境出现的现象，某日下午5点业务高峰期，我们的 \u003ca href=\"http://xgknight.com/2016/09/27/python-mysql-querykill/\"\u003e慢查询快照抓取程序\u003c/a\u003e 报出大量线程阻塞，但是1分钟以后就好了。于是分析了当时的 processlist 和 innodb status 现场记录，发现有大量的 \u003ccode\u003eAUTO-INC waiting\u003c/code\u003e：\u003c/p\u003e","title":"关于MySQL自增主键的几点问题（下）"},{"content":"前段时间遇到一个InnoDB表自增锁导致的问题，最近刚好有一个同行网友也问到自增锁的疑问，所以抽空系统的总结一下，这两个问题下篇会有阐述。\n1. 划分三种插入类型 这里区分一下几种插入数据行的类型，便于后面描述：（纯逻辑上的划分）\n\u0026ldquo;Simple inserts\u0026rdquo;\n简单插入，就是在处理sql语句的时候，能够提前预估到插入的行数，包括 INSERT / REPLACE 的单行、多行插入，但不含嵌套子查询以及 INSERT ... ON DUPLICATE KEY UPDATE。\n\u0026ldquo;Bulk inserts\u0026rdquo;\n本文暂且叫做 大块插入，不能提前预知语句要插入的行数，也就无法知道分配多少个自增值，包括 INSERT ... SELECT, REPLACE ... SELECT, 以及 LOAD DATA 导入语句。InnoDB会每处理一行记录就为 AUTO_INCREMENT 列分配一个值。\n\u0026ldquo;Mixed-mode inserts\u0026rdquo;\n混合插入，比如在 “简单插入” 多行记录的时候，有的新行有指定自增值，有的没有，所以获得最坏情况下需要插入的数量，然后一次性分配足够的auto_increment id。比如:\n1 2 # c1 是 t1 的 AUTO_INCREMENT 列 INSERT INTO t1 (c1,c2) VALUES (1,\u0026#39;a\u0026#39;), (NULL,\u0026#39;b\u0026#39;), (5,\u0026#39;c\u0026#39;), (NULL,\u0026#39;d\u0026#39;); 又比如 INSERT ... ON DUPLICATE KEY UPDATE，它在 update 阶段有可能分配新的自增id，也可能不会。\n2. 三种自增模式：innodb_autoinc_lock_mode 在以 5.6 版本，自增id累加模式分为：\n** 传统模式**\ntraditional，innodb_autoinc_lock_mode = 0\n在具有 AUTO_INCREMENT 的表上，所有插入语句会获取一个特殊的表级锁 AUTO-INC ，这个表锁是在语句结束之后立即释放（无需等到事务结束），它可以保证在一个insert里面的多行记录连续递增，也能保证多个insert并发情况下自增值是连续的（不会有空洞）。\n** 连续模式 **\nconsecutive，innodb_autoinc_lock_mode = 1\nMySQL 5.1.22开始，InnoDB提供了一种轻量级互斥的自增实现机制，在内存中会有一个互斥量（mutex），每次分配自增长ID时，就通过估算插入的数量（前提是必须能够估算到插入的数量，否则还是使用传统模式），然后更新mutex，下一个线程过来时从新 mutex 开始继续计算，这样就能避免传统模式非要等待每个都插入之后才能获取下一个，把“锁”降级到 只在分配id的时候 锁定互斥量。\n在 innodb_autoinc_lock_mode = 1（默认） 模式下，“简单插入”采用上面的 mutex 方式，“大块插入”（insert/replace \u0026hellip; select \u0026hellip; 、load data\u0026hellip;）依旧采用 AUTO-INC 表级锁方式。当然如果一个事务里已经持有表 AUTO-INC 锁，那么后续的简单插入也需要等待这个 AUTO-INC 锁释放。这能够保证任意insert并发情况下自增值是连续的。\n** 交叉模式 **\ninterleaved，innodb_autoinc_lock_mode = 2\n该模式下所有 INSERT SQL 都不会有表级 AUTO-INC 锁，多个 语句 可以同时执行，所以在高并发插入场景下性能会好一些。但是当 binlog 采用 SBR 格式时，对于从库重放日志或者主库实例恢复时，并不可靠。\n另者，它只能保证自增值在 insert语句级别 （单调）递增，所以多个insert可能会交叉着分配id，最终可能导致多个语句之间的id值不连续，这种情况出现在 混合插入： 1 INSERT INTO t1 (c1,c2) VALUES (1,\u0026#39;a\u0026#39;), (NULL,\u0026#39;b\u0026#39;), (5,\u0026#39;c\u0026#39;), (NULL,\u0026#39;d\u0026#39;); mutex 会按行分配4个id，但实际只用到2个，因此出现空洞。 3. 自增空洞（auto-increment sequence gap） 关于 AUTO_INCREMENT 自增出现空洞的问题，有必要再说明一下。\n在 0, 1, 2 三种任何模式下，如果事务回滚，那么里面获得自增值的sql回滚，但产生的自增值会一起丢失，不可能重新分配给其它insert语句。这也会产生空洞。\n在大块插入情景下\ninnodb_autoinc_lock_mode为 0 或 1 时，因为 AUTO-INC 锁会持续到语句结束，同一时间只有一个 语句 在表上执行，所以自增值是连续的（其它事务需要等待），不会有空洞； innodb_autoinc_lock_mode为 2 时，两个 “大块插入” 之间可能会有空洞，因为每条语句事先无法预知精确的数量而导致分配过多的id，可能有空洞。 4. 混合插入对 AUTO_INCREMENT 的影响 混合插入在 innodb_autoinc_lock_mode 不同模式下会有对 表自增值有不同的表现。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 CREATE TABLE t1 ( c1 INT UNSIGNED NOT NULL AUTO_INCREMENT PRIMARY KEY, c2 CHAR(1) ) ENGINE=INNODB; ALTER TABLE t1 AUTO_INCREMENT 101; mysql\u0026gt; SHOW CREATE TABLE t1\\G *************************** 1. row *************************** Table: t1 Create Table: CREATE TABLE `t1` ( `c1` int(10) unsigned NOT NULL AUTO_INCREMENT, `c2` char(1) DEFAULT NULL, PRIMARY KEY (`c1`) ) ENGINE=InnoDB AUTO_INCREMENT=101 DEFAULT CHARSET=utf8 1. mode 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 mysql\u0026gt; select @@innodb_autoinc_lock_mode; +----------------------------+ | @@innodb_autoinc_lock_mode | +----------------------------+ | 0 | +----------------------------+ mysql\u0026gt; INSERT INTO t1 (c1,c2) VALUES (1,\u0026#39;a\u0026#39;), (NULL,\u0026#39;b\u0026#39;), (5,\u0026#39;c\u0026#39;), (NULL,\u0026#39;d\u0026#39;); mysql\u0026gt; select * from t1; +-----+------+ | c1 | c2 | +-----+------+ | 1 | a | | 5 | c | | 101 | b | | 102 | d | +-----+------+ mysql\u0026gt; show create table t1\\G ... ) ENGINE=InnoDB AUTO_INCREMENT=103 DEFAULT CHARSET=utf8 ... 可以看到下一个自增值是 103 ，因为即使这是 ** 一条 ** insert语句（多行记录），自增值还是每次分配一个，不会在语句开始前一次分配全。\n2. mode 1 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 mysql\u0026gt; truncate table t1; ALTER TABLE t1 AUTO_INCREMENT 101; -- 复原 mysql\u0026gt; select @@innodb_autoinc_lock_mode; +----------------------------+ | @@innodb_autoinc_lock_mode | +----------------------------+ | 1 | +----------------------------+ 1 row in set (0.00 sec) mysql\u0026gt; INSERT INTO t1 (c1,c2) VALUES (1,\u0026#39;a\u0026#39;), (NULL,\u0026#39;b\u0026#39;), (5,\u0026#39;c\u0026#39;), (NULL,\u0026#39;d\u0026#39;); Query OK, 4 rows affected (0.00 sec) Records: 4 Duplicates: 0 Warnings: 0 mysql\u0026gt; select * from t1; +-----+------+ | c1 | c2 | +-----+------+ | 1 | a | | 5 | c | | 101 | b | | 102 | d | +-----+------+ mysql\u0026gt; show create table t1\\G ... ) ENGINE=InnoDB AUTO_INCREMENT=105 DEFAULT CHARSET=utf8 可以看到最终插入的值是一样的，但下一个自增值变成了 105，因为该模式下insert语句处理的时候，提前分配了 4 个自增值，但实际只有了两个。\n注：如果你的insert自增列全都有带值，那么处理的时候是不会分配自增值的，经过下面这个实验，可以知道 ** 分配自增值，是在遇到第一个没有带自增列的行时，一次性分配的 ** ：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 -- Tx1，先运行。 -- 插入第2行的时候 sleep 5s INSERT INTO t1 (c1,c2) VALUES (2,\u0026#39;e\u0026#39;),(sleep(5)+6,\u0026#39;g\u0026#39;),(NULL,\u0026#39;f\u0026#39;), (NULL,\u0026#39;h\u0026#39;); -- Tx2，后运行。 -- 第一行没有给自增列值，马上分配 4 个 INSERT INTO t1 (c1,c2) VALUES (NULL,\u0026#39;b\u0026#39;), (1,\u0026#39;a\u0026#39;), (sleep(5)+5,\u0026#39;c\u0026#39;), (NULL,\u0026#39;d\u0026#39;); -- 得到的结果是 +-----+------+ | c1 | c2 | +-----+------+ | 1 | a | | 2 | e | | 5 | c | | 6 | g | | 101 | b | | 102 | d | | 105 | f | | 106 | h | +-----+------+ 3. mode 2 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 mysql\u0026gt; truncate table t1; ALTER TABLE t1 AUTO_INCREMENT 101; -- 复原 mysql\u0026gt; select @@innodb_autoinc_lock_mode; +----------------------------+ | @@innodb_autoinc_lock_mode | +----------------------------+ | 2 | +----------------------------+ mysql\u0026gt; INSERT INTO t1 (c1,c2) VALUES (1,\u0026#39;a\u0026#39;), (NULL,\u0026#39;b\u0026#39;), (5,\u0026#39;c\u0026#39;), (NULL,\u0026#39;d\u0026#39;); mysql\u0026gt; select * from t1; +-----+------+ | c1 | c2 | +-----+------+ | 1 | a | | 5 | c | | 101 | b | | 102 | d | +-----+------+ mysql\u0026gt; show create table t1\\G ... ) ENGINE=InnoDB AUTO_INCREMENT=105 DEFAULT CHARSET=utf8 结果看起来与 连续模式 一样，其实不然！该模式下，如果另外一个 大块插入 并发执行时，可能会出现以下现象：\n大块插入的的自增值有间断 其它并发执行的事务插入出现 duplicate-key error 1 2 3 4 5 6 7 8 9 10 11 第1点 (create t2 select * from t1) Tx1: insert into t1(c2) select c2 from t2； -- 先执行 Tx2: INSERT INTO t1 (c1,c2) VALUES (1,\u0026#39;a\u0026#39;), (NULL,\u0026#39;b\u0026#39;), (5,\u0026#39;c\u0026#39;), (NULL,\u0026#39;d\u0026#39;); -- 后 并发执行 在交叉模式下，Tx1事务插入的数据行会与 Tx1 交叉出现。 注：如果 Tx1 改成 insert into t1 select * from t2 ，那么 Tx2 执行极有可能会报 duplicate-key error，与下面第2点所说的重复键是不一样的 第2点 mysql\u0026gt; truncate table t1; ALTER TABLE t1 AUTO_INCREMENT 5; -- 复原 mysql\u0026gt; INSERT INTO t1 (c1,c2) VALUES (1,\u0026#39;a\u0026#39;), (NULL,\u0026#39;b\u0026#39;), (5,\u0026#39;c\u0026#39;), (NULL,\u0026#39;d\u0026#39;); ERROR 1062 (23000): Duplicate entry \u0026#39;5\u0026#39; for key \u0026#39;PRIMARY\u0026#39; 总结 上面说了这么多，那么自增模式到底该怎么选择呢？其实很简单，目前数据库默认的 consecutive 即 innodb_autoinc_lock_mode=1 就是最好的模式，一般业务生产库不会有 insert into ... select ...或者 load data infile 这样的维护动作。（提示：即使晚上有数据迁移任务，也不要通过这样的形式进行）\ninnodb_autoinc_lock_mode=2 可以提高获取表自增id的并发能力（性能），但是除非出现上面演示的 duplicate-key 特殊用法情形，不会像网上所说的获取到相同key导致重复的问题。但是如果binlog在 RBR 格式下不建议使用，可能出现主从数据不一致。还有就是能够容忍gap的存在，以及多个语句insert的自增值交叉。\n参考： https://dev.mysql.com/doc/refman/5.6/en/innodb-auto-increment-handling.html\n下篇分析遇到过的 MySQL 自增主键相关的具体问题。\n本文链接地址：http://xgknight.com/2017/02/16/mysql-autoincrement/\n","permalink":"http://localhost:1313/2017/02/mysql-autoincrement/","summary":"\u003cp\u003e前段时间遇到一个InnoDB表自增锁导致的问题，最近刚好有一个同行网友也问到自增锁的疑问，所以抽空系统的总结一下，这两个问题下篇会有阐述。\u003c/p\u003e\n\u003ch2 id=\"1-划分三种插入类型\"\u003e1. 划分三种插入类型\u003c/h2\u003e\n\u003cp\u003e这里区分一下几种插入数据行的类型，便于后面描述：（纯逻辑上的划分）\u003c/p\u003e","title":"关于MySQL自增主键的几点问题（上）"},{"content":"1. Story 也许你经常会被问到，库里某个表最近一年的内每个月的数据量增长情况。当然如果你有按月分表比较好办，挨个 show table status，如果只有一个大表，那估计要在大家都休息的时候，寂寞的夜里去跑sql统计了，因为你只能获取当前的表信息，历史信息追查不到了。\n除此以外，作为DBA本身也要对数据库空间增长情况进行预估，用以规划容量。我们说的表信息主要包括：\n表数据大小（DATA_LENGTH） 索引大小(INDEX_LENGTH) 行数（ROWS） 当前自增值（AUTO_INCREMENT，如果有） 目前是没有看到哪个mysql监控工具上提供这样的指标。这些信息不需要采集的太频繁，而且结果也只是个预估值，不一定准确，所以这是站在一个全局、长远的角度去监控(采集)表的。\n本文要介绍的自己写的采集工具，是基于组内现有的一套监控体系：\nInfluxDB：时间序列数据库，存储监控数据 Grafana：数据展示面板 Telegraf：收集信息的agent 看了下 telegraf 的最新的 mysql 插件，一开始很欣慰：支持收集 Table schema statistics 和 Info schema auto increment columns。试用了一下，有数据，但是如前面所说，除了自增值外其他都是预估值，telegraf收集频率过高没啥意义，也许一天2次就足够了，它提供的 IntervalSlow选项固定写死在代码里，只能是放缓 global status 监控频率。不过倒是可以与其它监控指标分开成两份配置文件，各自定义收集间隔来实现。 最后打算自己用python撸一个，上报到influxdb里 :) 2. Concept 完整代码见 GitHub项目地址：DBschema_gather 实现也特别简单，就是查询 information_schema 库的 COLUMNS、TABLES 两个表：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 SELECT IFNULL(@@hostname, @@server_id) SERVER_NAME, %s as HOST, t.TABLE_SCHEMA, t.TABLE_NAME, t.TABLE_ROWS, t.DATA_LENGTH, t.INDEX_LENGTH, t.AUTO_INCREMENT, c.COLUMN_NAME, c.DATA_TYPE, LOCATE(\u0026#39;unsigned\u0026#39;, c.COLUMN_TYPE) COL_UNSIGNED # CONCAT(c.DATA_TYPE, IF(LOCATE(\u0026#39;unsigned\u0026#39;, c.COLUMN_TYPE)=0, \u0026#39;\u0026#39;, \u0026#39;_unsigned\u0026#39;)) FROM information_schema.`TABLES` t LEFT JOIN information_schema.`COLUMNS` c ON t.TABLE_SCHEMA = c.TABLE_SCHEMA AND t.TABLE_NAME = c.TABLE_NAME AND c.EXTRA = \u0026#39;auto_increment\u0026#39; WHERE t.TABLE_SCHEMA NOT IN ( \u0026#39;mysql\u0026#39;, \u0026#39;information_schema\u0026#39;, \u0026#39;performance_schema\u0026#39;, \u0026#39;sys\u0026#39; ) AND t.TABLE_TYPE = \u0026#39;BASE TABLE\u0026#39; 关于 auto_increment，我们除了关注当前增长到哪了，还会在意相比 int / bigint 的最大值，还有多少可用空间。于是计算了 autoIncrUsage 这一列，用于保存当前已使用的比例。\n然后使用 InfluxDB 的python客户端，批量存入influxdb。如果没有InfluxDB，结果会打印出json —— 这是Zabbix、Open-Falcon这些监控工具普遍支持的格式。\n最后就是使用 Grafana 从 influxdb 数据源画图。\n3. Usage 环境 在 python 2.7 环境下编写的，2.6，3.x没测。 运行需要MySQLdb、influxdb两个库： 1 $ sudo pip install mysql-python influxdb 配置 settings_dbs.py 配置文件 DBLIST_INFO：列表存放需要采集的哪些MySQL实例表信息，元组内分别是连接地址、端口、用户名、密码 用户需要select表的权限，否则看不到对应的信息. InfluxDB_INFO：influxdb的连接信息，注意提前创建好数据库名 mysql_info 设置为 None 可输出结果为json. 创建influxdb上的数据库和存储策略 存放2年，1个复制集：（按需调整） 1 2 CREATE DATABASE \u0026#34;mysql_info\u0026#34; CREATE RETENTION POLICY \u0026#34;mysql_info_schema\u0026#34; ON \u0026#34;mysql_info\u0026#34; DURATION 730d REPLICATION 1 DEFAULT 看大的信息类似于： 放crontab跑 可以单独放在用于监控的服务器上，不过建议在生产环境可以运行在mysql实例所在主机上，安全起见。 一般库在晚上会有数据迁移的动作，可以在迁移前后分别运行 mysql_schema_info.py 来收集一次。不建议太频繁。 1 40 23,5,12,18 * * * /opt/DBschema_info/mysql_schema_info.py \u0026gt;\u0026gt; /tmp/collect_DBschema_info.log 2\u0026gt;\u0026amp;1 生成图表 导入项目下的 grafana_table_stats.json 到 Grafana面板中。效果如下： 表数据大小和行数\n每天行数变化增量,auto_increment使用率\n4. More 分库分表情况下，全局唯一ID在表里无法计算 autoIncrUsage 实现上其实很简单，更主要的是唤醒收集这些信息的意识 可以增加 Graphite 输出格式 原文链接地址：http://xgknight.com/2016/12/04/mysql-schema-gather-statistics/\n","permalink":"http://localhost:1313/2016/12/mysql-schema-gather-statistics/","summary":"\u003ch2 id=\"1-story\"\u003e1. Story\u003c/h2\u003e\n\u003cp\u003e也许你经常会被问到，库里某个表最近一年的内每个月的数据量增长情况。当然如果你有按月分表比较好办，挨个 \u003ccode\u003eshow table status\u003c/code\u003e，如果只有一个大表，那估计要在大家都休息的时候，寂寞的夜里去跑sql统计了，因为你只能获取当前的表信息，历史信息追查不到了。\u003c/p\u003e","title":"监控MySQL你还应该收集表信息"},{"content":"1. Story 在没有形成自己的数据库管理平台以前，数据库实例一多（包括生产和测试环境），许多表要执行DDL会变得异常繁杂。\n说个自己的经历，需要改现网的一个索引来看优化的效果，因为存在风险，不会一次全改，先只改1个库，然后逐步放开。前后验证效果可能花上一两周的时间，除非实现完整的记录了当时的ddl语句和对应的库，否则根本难以记得。这就完全依赖于个人的习惯及能力。\n又比如现网出了个问题，开发追查到一个时间点，想确认那个时候有没有对库表进行过更改操作，如果没有记录表结构变更的历史，也就难以提供需要的信息。\n记录差异，很早就思考过能不能用git来做。终于花了一天时间来实现，并验证、修改达到预期的效果，还算满意。\ngithub项目地址在文后。\n2. Concept 思路很简单，就是利用 mydumper 导出表时会把各表（结构）单独导成一个文件的特性，每天低峰期导出所有对象元数据：表、视图、存储过程、事件、触发器。需要过滤掉 AUTO_INCREMENT 值。\n结构内容存放在一个git仓库下，通过shell脚本提交到 gitlab。所有DDL更改由原来依赖于DBA的主动记录，变成被动采集。\n测试环境和生产环境表结构总会有些差异，为了兼顾同时收集两个环境的数据，设置了 environment 选项，根据当前所在运行的机器，自动判断采集哪些实例信息。\n3. Usage 首先你需要能够存放表结构信息的git仓库，如gitlab，而且建议设置为私有。\n安装 git 和 mydumper mydumper 0.9.1 版本需要编译安装，可以参考这里 file-mydumper-install-ubuntu14-04-sh。当然 yum 或 apt-get 安装其他版本也是一样的。 脚本会尝试自动获取 mydumper 命令的路径。 注意配置git权限的时候，最好不允许其它用户手动提交修改仓库内容。\n配置db实例地址 settings.ini示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 [environment] production=puppetmaster test=puppettestmaster [production] production_auth=your_defaultuser:yourpassword db_name1=192.168.1.100:3306 db_name2=192.168.1.101:3306 db_name3=name3.dbhost.com:3306 db_name4=192.168.1.100:3306:myuser:mypassword [test] test_auth=user1:password1 db_name1=10.0.100.1:3306 db_name2=10.0.100.1:3307 db_name3=10.0.100.2:3306 db_name4=10.0.100.3:3306:myuser1:mypassword1 上面的配置采集 production和test两个环境的表结构，识别两个环境是根据 hostname 来决定的。这样做的好吃就是这个脚本在两个环境下运行不需要做任何修改。 [production]节的名字就是 [environment]节指定的名字 production=xx dbname1=就是配置各个db，地址+端口的形式。用户名和密码可以继续用 : 跟上 production_auth=表示 production 环境下，如 dbname1没有配置用户名时，默认采用这个用户名和密码。这样设计主要是简化配置。\n该数据库用户需要 select,show view,event,trigger,procedure 权限。\nsettings_parser.py 用于解析上面的配置文件，输出collect_tableMeta.sh易处理的格式。 每天运行 可使用 python settings_parser.py 测试解析配置是否正常。 在配置文件里两个环境下（一般网络不互通）分别加上定时任务： 1 2 # Puppet Name: collect_DBschema 5 5 * * * /opt/DBschema/collect_tableMeta.sh \u0026gt;\u0026gt; /tmp/collect_DBschema.log 2\u0026gt;\u0026amp;1 展示效果 A 是新增，M 是修改，D 是删除，一目了然。点开可以前后对比。 4. More 思路和实现都不难，主要是意识，和如何快速找到解决当前需求的办法。一切都是为了效率 :)\n目前所能想到更多的：\n有内容push到git仓库后，使用 web hook 发出邮件。 根据A,B两个表的结构，快速得到A修改成B的样子的DDL。 event 权限问题。event权限没有所谓的读和修改之分，阿里云RDS就把它从 只读 账号里拿除了，导致收集不到事件定义。所以它的高权限账号管理模式还是很有作用的。 密码明文。\n最近公司邀请了一个安全公司给做培训，数据库安全里面，密码明文配置在文件里面是广泛存在的，难搞。 GitHub地址：https://github.com/seanlook/DBschema_gather\n原文链接地址：http://xgknight.com/2016/11/28/mysql-schema-gather-structure/\n","permalink":"http://localhost:1313/2016/11/mysql-schema-gather-structure/","summary":"\u003ch2 id=\"1-story\"\u003e1. Story\u003c/h2\u003e\n\u003cp\u003e在没有形成自己的数据库管理平台以前，数据库实例一多（包括生产和测试环境），许多表要执行DDL会变得异常繁杂。\u003c/p\u003e\n\u003cp\u003e说个自己的经历，需要改现网的一个索引来看优化的效果，因为存在风险，不会一次全改，先只改1个库，然后逐步放开。前后验证效果可能花上一两周的时间，除非实现完整的记录了当时的ddl语句和对应的库，否则根本难以记得。这就完全依赖于个人的习惯及能力。\u003c/p\u003e","title":"一种直观记录表结构变更历史的方法"},{"content":"1. 简介 项目地址：https://github.com/seanlook/px-table-checksum\n主从环境下数据一致性校验经常会用 pt-table-checksum 工具，它的原理及实施过程之前写过一篇文章：生产环境使用 pt-table-checksum 检查MySQL数据一致性。但是DBA工作中还会有些针对两个表检查是否一致，而这两个表之间并没有主从关系，pt工具是基于binlog把在主库进行的检查动作，在从库重放一遍，此时就不适用了。\n总会有这样特殊的需求，比如从阿里云RDS实例迁移到自建mysql实例，它的数据传输服务实现方式是基于表的批量数据提取，加上binlog订阅，但强制row模式会导致pt-table-checksum没有权限把会话临时改成statement。另一种需求是，整库进行字符集转换：库表定义都是utf8，但应用连接使用了默认的 latin1，要将连接字符集和表字符集统一起来，只能以latin1导出数据，再以utf8导入，这种情况数据一致性校验，且不说binlog解析程序不支持statement（如canal），新旧库本身内容不同，pt-table-checksum 算出的校验值也会不一样，失效。\n所以才萌生了参考 pt-table-checksum 自己写了一个：px-table-checksum 。\n2. 实现方法 整体思路是借鉴pt-table-checksum，从源库批量（即chunk）取出一块数据如1000行，计算CRC32值，同样的语句在目标库运行一遍，结果都存入另一个库，最后检查对应编号的chunk crc值是否一致。知道不一致还不行，得能否快速方便的修复差异，所以继续根据那些不一致的chunk，去目标库和源库找到不一致的行，是缺失，还是多余，还是被修改了，然后生成修复sql，根据指示是否自动修复。\n那么问题就在于：\n如何确定批次，也就是下一个chunk该怎么取？ 我还没想做到pt-table-checksum那样，可以根据负载动态调整chunk大小，甚至活跃线程数超过阀值就暂停检查，上来工作量就太大了。目前每次计算的chunk的行数是固定的，可以配置1000或2000等。 所以就要用到分页查询，根据（自增或联合）主键、唯一索引，每次limit 1000后升序取最后一条，作为下一批的起始。所以要分析表上的键情况，组合查询条件。目前仅能检查有主键或唯一所以的表。\n如何保证源库和目标库，运行的sql一样？ 之前一版是目标库和源库，以多线程各自计算chunk，入库，后来才意识到严重的bug：比如同样是取1000行，如果目标库少数据，那么下一个chunk起始就不一样，比较的结果简直一塌糊涂。 所以必须保证相同编号的chunk，起点必须相同，所以想到用队列，存放在源库跑过的所有校验sql，模拟pt工具在目标库重放。考虑到要多线程同时比较多个表，队列可能吃内存过大，于是使用了redis队列。\n直接在数据库中计算crc32，还是取出数据在内存里计算？ 翻了pt-table-checksum的源码，它是在数据库里计算的。但是第一节里说过，如果目标库和源库要使用不同的字符集才能读出正确的数据，只能查询出来之后再比较。所以 px-table-checksum 两种都支持，只需指定一个配置项。\n同时检查多个表，源库sql挤在队列，目标库拿出来执行时过了1s，此时源库那条数据又被修改了一次同步到了目标库，会导致计算结果不一致，实则一致，怎么处理 无法处理，是px-table-checksum相比pt-table-checksum最大的缺陷。 但为了尽可能减少此类问题（比如主从延迟也可能会），特意设计了多个redis队列，目标库多个检查线程，即比如同时指定检查8个表，源库检查会有8个线程对应，但可以根据表的写入情况，配置4个redis队列（目前是随机入列），10个目标库检查线程，来减少不准确因素。 但站在我的角度往往来说，不一致的数据会被记录下来，如果不多，人工核对一下；如果较多，就再跑一遍检查，如果两次都有同一条数据不一致，那就有情况了。\n3. 限制 如果检查期间源表数据，变化频繁，有可能检查的结果不准确 也就是上面第4点的问题。很明显，这个程序每个检查的事务是分开的，不像pt工具能严格保证每条检查sql的事务顺序。但有不一致的数据再排查一下就ok了。实际在我线上使用过程中，99.9%是准确的。 表上必须有主键或唯一索引 程序会检查，如果没有会退出。\nvarbinay,blob等二进制字段不支持修复 其实也不是完全不支持，要看怎么用的。开发如果有把字符先转成字节，再存入mysql，这种就不支持修复。是有办法可以处理，那就是从源库查时用 hex()函数，修复sql里面unhex()写回去。\n4. 使用说明 该python程序基于2.7开发，2.6、3.x上没有测试。使用前需要安装 MySQLdb和hotqueue：\n1 $ sudo pip install MySQL-python hotqueue 要比较的表和选项，使用全配置化，即不通过命令行的方式指定（原谅命令行参数使用方式会额外增加代码量）。\n4.1 px-table-checksum.py 主程序，运行python px-table-checksum.py 执行一致性检查，但一定了解下面的配置文件选项。\n4.2 settings_checksum.py 配置选项\nCHUNK_SIZE: 每次提取的chunk行数\nREDIS_INFO: 指定使用redis队列地址\nREDIS_QUEUE_CNT: redis队列数量，消费者（目标库）有一一对应的线程守着队列\nREDIS_POOL_CNT: 生产者（源库）redis客户端连接池。这个设计是为了缓解GIL带来的问题，把入列端与出列端分开，因为如果表多可能短时间有大量sql入队列，避免hotqueue争用\nCALC_CRC32_DB: True 表示在db里面计算checksum值，False表示取出chunk数据在python里面计算。默认给的值是根据连接字符集定的。\nDO_COMPARE: 运行模式\n0: 只提取数据计算，不比较是否一致。可以在之后在模式2下只比较\n1: 计算，并比较。常用，每次计算之前会删除上一次这个待检查表的结果，比较的结果只告诉哪些chunk号不一致。\n2: 不计算，只从t_checkum结果比较。常用，计算是消耗数据库资源的，可以只对已有的checksum计算结果比较不一致的地方。类似pt工具的--replicate-check-only选项。\nGEN_DATAFIX: 与DO_COMPARE结合使用，为 True 表示对不一致的chunk找到具体不一致行，并生成修复sql；为 False 则什么都不做。\nRUN_DATAFIX: 与GEN_DATAFIX结合使用，为 True 表示对生成的修复sql，在目标库执行。需要谨慎，如果哪一次设置了修复，记得完成后改回False，不然下次检查另一个表就出意外了，所以特意对这个选项再加了一个确认提示。\nDB_CHECKSUM: 一个字典，指定checksum的结果存到哪里 配置文件有示例，必须指定 db_name，表会自动创建。\n4.3 settings_cs_tables.py 上面的配置文件可以认为是用于控制程序的，这个配置文件是指定要校验的源库和目标库信息，以及要检验哪些表。\nTABLES_CHECK: 字典，指定要检查哪些表的一致性，db名为key，多个table名组成列表为value。暂不支持对整个db做检查，同时比较的表数量不建议超过8个 DB_SOURCE: 字典，指定源库的连接信息 DB_SOURCE: 字典，指定目标库的连接信息 5. 示例： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 Starting checksum thread for table: db1.t_test_201308 (192.168.1.122:3306) Before checksum: create table if not exists t_checksum Before checksum: delele old data from t_checksum if exists for table: db1.t_test_201308 Caculate crc32 in program instead of db.(this program need more memory and more db net traffic, but convert charset) Caculating checksums: 192.168.1.122:3306 db1.t_test_201308 TARGET: (\u0026#39;192.168.1.121:3306\u0026#39;, \u0026#39;t_test_201308\u0026#39;, 1, \u0026#39;db1\u0026#39;, \u0026#39;0\u0026#39;, u\u0026#39;1495969\u0026#39;, 451060506) TARGET: (\u0026#39;192.168.1.121:3306\u0026#39;, \u0026#39;t_test_201308\u0026#39;, 2, \u0026#39;db1\u0026#39;, u\u0026#39;1495969\u0026#39;, u\u0026#39;1502593\u0026#39;, -678155635) ... Starting checksum thread for table: db1.t_test_201408 (192.168.1.122:3306) Before checksum: delele old data from t_checksum if exists for table: db1.t_test_201408 Caculate crc32 in program instead of db.(this program need more memory and more db net traffic, but convert charset) Caculating checksums: 192.168.1.122:3306 db1.t_test_201408 TARGET: (\u0026#39;192.168.1.121:3306\u0026#39;, \u0026#39;t_test_201408\u0026#39;TARGET: (\u0026#39;192.168.1.121:3306\u0026#39;, \u0026#39;t_test_201408\u0026#39;, 9, 8, \u0026#39;db1\u0026#39;, u\u0026#39;3836877\u0026#39;, u\u0026#39;3845812\u0026#39;, , \u0026#39;db1\u0026#39;, u\u0026#39;3845812\u0026#39;373759054) ... 源实例 192.168.1.122:3306 db1.t_test_201308 计算checksum结束！ db conection closed. Checksum thread ended for table: db1.t_test_201308 (192.168.1.122:3306) ... 源实例 192.168.1.122:3306 db1.t_test_201408 计算checksum结束！ 消费sql 0 退出！！ 消费sql -1 退出！！ ################################################################################ Start compare chunk\u0026#39;s crc32 for table: [ db1.t_test_201308 ] 表 db1.t_test_201308 数据一致 ################################################################################ ################################################################################ Start compare chunk\u0026#39;s crc32 for table: [ db1.t_test_201408 ] 表 db1.t_test_201408 数据不一致chunk数：10 -------------------------------------------------------------------------------- 该chunk [1] 存在行内容不一致, CRC32: src(828649697) rgt(-1396224393) 去源库和目标库获取chunk[1]不一致行： TO insert or update: [u\u0026#39;3761994\u0026#39;] TO delete: [] 该chunk [5] 存在行内容不一致, CRC32: src(1513453680) rgt(-1614463460) 去源库和目标库获取chunk[5]不一致行： TO insert or update: [u\u0026#39;3806841\u0026#39;] TO delete: [] 原文链接地址：http://xgknight.com/2016/11/20/py-mysql-table-checksum-non-replicas/\n","permalink":"http://localhost:1313/2016/11/py-mysql-table-checksum-non-replicas/","summary":"\u003ch2 id=\"1-简介\"\u003e1. 简介\u003c/h2\u003e\n\u003cp\u003e项目地址：https://github.com/seanlook/px-table-checksum\u003c/p\u003e\n\u003cp\u003e主从环境下数据一致性校验经常会用 pt-table-checksum 工具，它的原理及实施过程之前写过一篇文章：\u003ca href=\"http://xgknight.com/2015/12/29/mysql_replica_pt-table-checksum/\"\u003e生产环境使用 pt-table-checksum 检查MySQL数据一致性\u003c/a\u003e。但是DBA工作中还会有些针对两个表检查是否一致，而这两个表之间并没有主从关系，pt工具是基于binlog把在主库进行的检查动作，在从库重放一遍，此时就不适用了。\u003c/p\u003e","title":"MySQL非主从环境下数据一致性校验及修复程序"},{"content":"1. 简介 取名mypumpkin，是python封装的一个让mysqldump以多线程的方式导出库表，再以mysql命令多线程导入新库，用于成倍加快导出，特别是导入的速度。这一切只需要在 mysqldump 或 mysql 命令前面加上 mypumpkin.py 即可，所以称作魔法。\n项目地址：https://github.com/seanlook/mypumpkin\n该程序源于需要对现网单库几百G的数据进行转移到新库，并对中间进行一些特殊操作（如字符集转换），无法容忍mysqldump导入速度。有人可能会提到为什么不用 mydumper，其实也尝试过它但还是放弃了，原因有：\n不能设置字符集 mydumper强制使用 binary 方式来连接库以达到不关心备份恢复时的字符集问题，然而我的场景下需要特意以不同的字符集导出、再导入。写这个程序的时候正好在公众号看到网易有推送的一篇文章 (解密网易MySQL实例迁移高效完成背后的黑科技)，提到他们对mydumper的改进已支持字符集设置，可是在0.9.1版本的patch里还是没找到。 没有像 mysqldump 那样灵活控制过滤选项（导哪些表、忽略哪些表） 因为数据量之巨大，而且将近70%是不变更的历史表数据，这些表是可以提前导出转换的；又有少量单表大于50G的，最好是分库导出转换。mydumper 不具备 mysqldump 这样的灵活性 对忽略导出gtid信息、触发器等其它支持 阿里云rds 5.6 导出必须要设置 set-gtid-purged=OFF 另外有人还可能提到 mysqlpump —— 它才是我认为mysqldump应该具有的模样，语法兼容，基于表的并发导出。但是只有 mysql服务端 5.7.9 以上才支持，这就是现实和理想的距离。。。\n2. 实现方法 首先说明，mysqldump的导出速度并不慢，经测试能达到50M/s的速度，10G数据花费3分钟的样子，可以看到瓶颈在于网络和磁盘IO，再怎样的导出工具也快不了多少，但是导入却花了60分钟，磁盘和网络大概只用到了20%，瓶颈在目标库写入速度（而一般顺序写入达不到IOPS限制），所以mypumpkin就诞生了 —— 兼顾myloader的导入速度和mysqldump导出的灵活性。\n用python构造1个队列，将需要导出的所有表一次放到队列中，同时启动N个python线程，各自从这个Queue里取出表名，subprocess调用操作系统的mysqldump命令，导出数据到以 dbname.tablename.sql 命名的文件中。load in 与 dump out 类似，根据指定的库名或表名，从dump_dir目录找到所有sql文件，压进队列，N个线程同时调用mysql构造新的命令，模拟 \u0026lt; 操作。\n参数解析从原来自己解析，到改用argparse模块，几乎做了一次重构。 对于没有指定--tables的情况，程序会主动去库里查询一下所有表名，然后过滤进队列。\nload in目标库，选项做到与dump out一样丰富，可以指定导入哪些db、哪些表、忽略哪些表。\n其中的重点是做到与原mysqldump兼容，因为需要对与表有关的选项（-B, -A, --tables, --ignore=），进行分析并组合成新的执行命令，考虑的异常情况非常多。\n3. 限制 重要：导出的数据不保证库级别的一致性 对历史不变表，是不影响的 具体到一个表能保证一致性，这是mysqldump本身采用哪些选项决定的 不同表导出动作在不同的mysqldump命令中，无法保证事务。 在我的案例场景下，是有开发同学辅助使用一套binlog解析程序，等完成后重放所有变更，来保证最终一致性。 另，许多情况下我们导数据，并不需要完整的或者一致的数据，只是用于离线分析或临时导出，重点是快速拿数据给到开发。 不寻常选项识别 程序已经尽力做到与mysqldump命令兼容，只需要加上 mypumpkin.py、指定dump-dir，就完成并发魔法，但有些情况的参数不方便解析，暂不支持格式： 1 2 db1 table1 table2 db2 db3 即以上无法在命令行下判断 db1、table1 是库名还是表面，用的时候只需记住“[-A|-B], [\u0026ndash;tables], [\u0026ndash;ignore-table]”三组，必须出现一个：db1 table1 table2改成db1 --tables table1 table2，db2改成-B db2 db3。 3. 密码暂只能显式输入\n4. 使用说明 安装基于python 2.7 开发，其它版本没测。需要按 MySQLdb 库。\n4.1 help 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 ./mypumpkin.py --help Only mysqldump or mysql allowed after mypumpkin.py usage: mypumpkin.py {mysqldump|mysqls} [--help] This\u0026#39;s a program that wrap mysqldump/mysql to make them dump-out/load-in concurrently. Attention: it can not keep consistent for whole database(s). optional arguments: --help show this help message and exit -B db1 [db1 ...], --databases db1 [db1 ...] Dump one or more databases -A, --all-databases Dump all databases --tables t1 [t1 ...] Specifiy tables to dump. Override --databases (-B) --ignore-table db1.table1 [db1.table1 ...] Do not dump the specified table. (format like --ignore-table=dbname.tablename). Use the directive multiple times for more than one table to ignore. --threads =N Threads to dump out [2], or load in [CPUs*2]. --dump-dir DUMP_DIR Required. Directory to dump out (create if not exist), Or Where to load in sqlfile At least one of these 3 group options given: [-A,-B] [--tables] [--ignore-table] --dump-dir，必选项，原来用的shell标准输入输出 \u0026gt; or \u0026lt; 不允许使用。dump-dir指定目录不存在时会尝试自动创建。 --threads=N，N指定并发导出或导入线程数。dump out 默认线程数2， mypumpkin load in 默认线程数是 cpu个数 * 2。 注：线程数不是越大越好，这里主要的衡量指标是网络带宽、磁盘IO、目标库IOPS，最好用 dstat 观察一下。 -B, --tables，--ignore-table，使用与mysqldump相同，如： 在mysqldump里面，--tables会覆盖--databases/-B选项 在mysqldump里面，--tables与--ignore-table不能同时出现 在mysqldump里面，如果没有指定-B，则--tables或--ignore-table必须紧跟db名之后 其它选项，mypumpkin会原封不动的保留下来，放到shell去执行。所以如果其它选项有错误，检查是交给原生mysqldump去做的，执行过程遇到一个失败则会退出线程。 4.2 example 导出：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 ## 导出源库所有db到visit_dumpdir2目录 （不包括information_schema和performance_schema） $ ./mypumpkin.py mysqldump -h dbhost_name -utest_user -pyourpassword -P3306 \\ --single-transaction --opt -A --dump-dir visit_dumpdir2 ## 导出源库db1,db2，会从原库查询所有表名来过滤 $ ./mypumpkin.py mysqldump -h dbhost_name -utest_user -pyourpassword -P3306 \\ --single-transaction --opt -B db1 db2 --dump-dir visit_dumpdir2 ## 只导出db1库的t1,t2表，如果指定表不存在则有提示 $ ./mypumpkin.py mysqldump -h dbhost_name -utest_user -pyourpassword -P3306 \\ --single-transaction --opt -B db1 --tables t1 t2 --dump-dir visit_dumpdir2 ## 导出db1,db2库，但忽略 db1.t1, db2.t2, db2.t3表 ## mysqldump只支持--ignore-table=db1.t1这种，使用多个重复指令来指定多表。这里做了兼容扩展 $ ./mypumpkin.py mysqldump -h dbhost_name -utest_user -pyourpassword --single-transaction \\ --opt -B db1 db2 --ignore-table=db1.t1 --ignore-table db2.t2 db2.t3 --dump-dir visit_dumpdir2 (如果-A表示全部db) ## 不带 -A/-B $ ./mypumpkin.py mysqldump -h dbhost_name -utest_user -pyourpassword -P3306 \\ --single-transaction --opt db1 --ignore-table=db1.t1 --dump-dir=visit_dumpdir2 ## 其它选项不做处理 $ ./mypumpkin.py mysqldump -h dbhost_name -utest_user -pyourpassword -P3306 \\ --single-transaction --set-gtid-purged=OFF --no-set-names --skip-add-locks -e -q -t -n --skip-triggers \\ --max-allowed-packet=134217728 --net-buffer-length=1638400 --default-character-set=latin1 \\ --insert-ignore --hex-blob --no-autocommit \\ db1 --tables t1 --dump-dir visit_dumpdir2 导入：\n-A, -B, --tables, --ignore-table, --threads, --dump-dir用法与作用与上面完全相同，举部分例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ## 导入dump-dir目录下所有表 $ ./mypumpkin.py mysql -h dbhost_name -utest_user -pyourpassword --port 3307 -A \\ --dump-dir=visit_dumpdir2 ## 导入db1库（所有表） $ ./mypumpkin.py mysql -h dbhost_name -utest_user -pyourpassword --port 3307 -B db1 \\ --dump-dir=visit_dumpdir2 ## 只导入db.t1表 $ ./mypumpkin.py mysql -h dbhost_name -utest_user -pyourpassword --port 3307 \\ --default-character-set=utf8mb4 --max-allowed-packet=134217728 --net-buffer-length=1638400 \\ -B db1 --tables t1 --dump-dir=visit_dumpdir2 ## 导入db1,db2库，但忽略db1.t1表（会到dump-dir目录检查db1,db2有无对应的表存在，不在目标库检查） $ ./mypumpkin.py mysql -h dbhost_name -utest_user -pyourpassword --port 3307 \\ -B db1 db2 --ignore-table=db1.t1 --dump-dir=visit_dumpdir2 5.速度对比 原文链接地址：http://xgknight.com/2016/11/17/python-mysqldump-out-in-concurrency-magic/\n","permalink":"http://localhost:1313/2016/11/python-mysqldump-out-in-concurrency-magic/","summary":"\u003ch2 id=\"1-简介\"\u003e1. 简介\u003c/h2\u003e\n\u003cp\u003e取名mypumpkin，是python封装的一个让mysqldump以多线程的方式导出库表，再以mysql命令多线程导入新库，用于成倍加快导出，特别是导入的速度。这一切只需要在 mysqldump 或 mysql 命令前面加上 \u003ccode\u003emypumpkin.py\u003c/code\u003e 即可，所以称作魔法。\u003c/p\u003e","title":"让mysqldump变成并发导出导入的魔法"},{"content":"1. utf8 与 utf8mb4 异同 先看 官方手册 https://dev.mysql.com/doc/refman/5.6/en/charset-unicode-utf8mb4.html 的说明：\n1 2 3 4 The character set named utf8 uses a maximum of three bytes per character and contains only BMP characters. The utf8mb4 character set uses a maximum of four bytes per character supports supplementary characters: - For a BMP character, utf8 and utf8mb4 have identical storage characteristics: same code values, same encoding, same length. - For a supplementary character, utf8 cannot store the character at all, whereas utf8mb4 requires four bytes to store it. Because utf8 cannot store the character at all, you have no supplementary characters in utf8 columns and need not worry about converting characters or losing data when upgrading utf8 data from older versions of MySQL. MySQL在 5.5.3 之后增加了 utf8mb4 字符编码，mb4即 most bytes 4。简单说 utf8mb4 是 utf8 的超集并完全兼容utf8，能够用四个字节存储更多的字符。\n但抛开数据库，标准的 UTF-8 字符集编码是可以用 1~4 个字节去编码21位字符，这几乎包含了是世界上所有能看见的语言了。然而在MySQL里实现的utf8最长使用3个字节，也就是只支持到了 Unicode 中的 基本多文本平面（U+0000至U+FFFF），包含了控制符、拉丁文，中、日、韩等绝大多数国际字符，但并不是所有，最常见的就算现在手机端常用的表情字符 emoji和一些不常用的汉字，如 “墅” ，这些需要四个字节才能编码出来。\n注：QQ里面的内置的表情不算，它是通过特殊映射到的一个gif图片。一般输入法自带的就是。\n也就是当你的数据库里要求能够存入这些表情或宽字符时，可以把字段定义为 utf8mb4，同时要注意连接字符集也要设置为utf8mb4，否则在 严格模式 下会出现 Incorrect string value: /xF0/xA1/x8B/xBE/xE5/xA2… for column 'name'这样的错误，非严格模式下此后的数据会被截断。\n提示：另外一种能够存储emoji的方式是，不关心数据库表字符集，只要连接字符集使用 latin1，但相信我，你绝对不想这个干，一是这种字符集混用管理极不规范，二是存储空间被放大（读者可以想下为什么）。\n2. utf8mb4_unicode_ci 与 utf8mb4_general_ci 如何选择 字符除了需要存储，还需要排序或比较大小，涉及到与编码字符集对应的 排序字符集（collation）。ut8mb4对应的排序字符集常用的有 utf8mb4_unicode_ci、utf8mb4_general_ci，到底采用哪个在 stackoverflow 上有个讨论，What\u0026rsquo;s the difference between utf8_general_ci and utf8_unicode_ci\n主要从排序准确性和性能两方面看：\n准确性 utf8mb4_unicode_ci 是基于标准的Unicode来排序和比较，能够在各种语言之间精确排序\nutf8mb4_general_ci 没有实现Unicode排序规则，在遇到某些特殊语言或字符是，排序结果可能不是所期望的。\n但是在绝大多数情况下，这种特殊字符的顺序一定要那么精确吗。比如Unicode把ß、Œ当成ss和OE来看；而general会把它们当成s、e，再如ÀÁÅåāă各自都与 A 相等。 性能 utf8mb4_general_ci 在比较和排序的时候更快\nutf8mb4_unicode_ci 在特殊情况下，Unicode排序规则为了能够处理特殊字符的情况，实现了略微复杂的排序算法。\n但是在绝大多数情况下，不会发生此类复杂比较。general理论上比Unicode可能快些，但相比现在的CPU来说，它远远不足以成为考虑性能的因素，索引涉及、SQL设计才是。 我个人推荐是 utf8mb4_unicode_ci，将来 8.0 里也极有可能使用变为默认的规则。相比选择哪一种collation，使用者应该更关心字符集与排序规则在db里要统一就好。\n这也从另一个角度告诉我们，不要可能产生乱码的字段作为主键或唯一索引。我遇到过一例，以 url 来作为唯一索引，但是它记录的有可能是乱码，导致后来想把它们修复就特别麻烦。\n3. 怎么从utf8转换为utf8mb4 3.1 “伪”转换 如果你的表定义和连接字符集都是utf8，那么直接在你的表上执行\n1 ALTER TABLE tbl_name CONVERT TO CHARACTER SET utf8mb4; 则能够该表上所有的列的character类型变成 utf8mb4，表定义的默认字符集也会修改。连接的时候需要使用set names utf8mb4便可以插入四字节字符。（如果依然使用 utf8 连接，只要不出现四字节字符则完全没问题）。\n上面的 convert 有两个问题，一是它不能ONLINE，也就是执行之后全表禁止修改，有关这方面的讨论见 mysql 5.6 原生Online DDL解析；二是，它可能会自动该表字段类型定义，如 VARCHAR 被转成 MEDIUMTEXT，可以通过 MODIFY 指定类型为原类型。\n另外 ALTER TABLE tbl_name DEFAULT CHARACTER SET utf8mb4 这样的语句就不要随便执行了，特别是当表原本不是utf8时，除非表是空的或者你确认表里只有拉丁字符，否则正常和乱的就混在一起了。\n最重要的是，你连接时使用的latin1字符集写入了历史数据，表定义是latin1或utf8，不要期望通过 ALTER ... CONVERT ... 能够让你达到用utf8读取历史中文数据的目的，没卵用，老老实实做逻辑dump。所以我才叫它“伪”转换\n3.2 character-set-server 一旦你决定使用utf8mb4，强烈建议你要修改服务端 character-set-server=utf8mb4，不同的语言对它的处理方法不一样，c++, php, python可以设置character-set，但java驱动依赖于 character-set-server 选项，后面有介绍。\n同时还要谨慎一些特殊选项，如 遇到腾讯云CDB连接字符集设置一个坑。个人不建议设置全局 init_connect。\n4. key 768 long 错误 字符集从utf8转到utf8mb4之后，最容易引起的就是索引键超长的问题。\n对于表行格式是 COMPACT或 REDUNDANT，InnoDB有单个索引最大字节数 768 的限制，而字段定义的是能存储的字符数，比如 VARCHAR(200) 代表能够存200个汉字，索引定义是字符集类型最大长度算的，即 utf8 maxbytes=3, utf8mb4 maxbytes=4，算下来utf8和utf8mb4两种情况的索引长度分别为600 bytes和800bytes，后者超过了768，导致出错：Error 1071: Specified key was too long; max key length is 767 bytes。\nCOMPRESSED和DYNAMIC格式不受限制，但也依然不建议索引太长，太浪费空间和cpu搜索资源。\n如果已有定义超过这个长度的，可加上前缀索引，如果暂不能加上前缀索引（像唯一索引），可把该字段的字符集改回utf8或latin1。 但是，（ ** 敲黑板啦，很重要 ** ），要防止出现 Illegal mix of collations (utf8_general_ci,IMPLICIT) and (utf8mb4_general_ci,COERCIBLE) for operation '=' 错误：连接字符集使用utf8mb4，但 SELECT/UPDATE where条件有utf8类型的列，且条件右边存在不属于utf8字符，就会触发该异常。表示踩过这个坑。\n再多加一个友好提示：EXPLAIN 结果里面的 key_len 指的搜索索引长度，单位是bytes，而且是以字符集支持的单字符最大字节数算的，这也是为什么 INDEX_LENGTH 膨胀厉害的一个原因。\n5. C/C++ 内存空间分配问题 这是我们这边的开发遇到的一个棘手的问题。C或C++连接MySQL使用的是linux系统上的 libmysqlclient 动态库，程序获取到数据之后根据自定义的一个网络协议，按照mysql字段定义的固定字节数来传输数据。从utf8转utf8mb4之后，c++里面针对character单字符内存空间分配，从3个增加到4个，引起异常。\n这个问题其实是想说明，使用utf8mb4之后，官方建议尽量用 varchar 代替 char，这样可以减少固定存储空间浪费（关于char与varchar的选择，可参考 这里）。但开发设计表时 varchar 的大小不能随意加大，它虽然是变长的，但客户端在定义变量来获取数据时，是以定义的为准，而非实际长度。按需分配，避免程序使用过多的内存。\n6. java驱动使用 Java语言里面所实现的UTF-8编码就是支持4字节的，所以不需要配置 mb4 这样的字眼，但如果从MySQL读写emoji，MySQL驱动版本要在 5.1.13 及以上版本，数据库连接依然是 characterEncoding=UTF-8 。\n但还没完，遇到一个大坑。官方手册 里还有这么一段话：\n1 2 3 4 Connector/J did not support utf8mb4 for servers 5.5.2 and newer. Connector/J now auto-detects servers configured with character_set_server=utf8mb4 or treats the Java encoding utf-8 passed using characterEncoding=... as utf8mb4 in the SET NAMES= calls it makes when establishing the connection. (Bug #54175) 意思是，java驱动会自动检测服务端 character_set_server 的配置，如果为utf8mb4，驱动在建立连接的时候设置 SET NAMES utf8mb4。然而其他语言没有依赖于这样的特性。\n7. 主从复制报错 这个问题没有遇到，只是看官方文档有提到，曾经也看到过类似的技术文章。 大概就是从库的版本比主库的版本低，导致有些字符集不支持；或者人工修改了从库上的表或字段的字符集定义，都有可能引起异常。\n8. join 查询问题 这个问题是之前在姜承尧老师公众号看到的一篇文章 MySQL表字段字符集不同导致的索引失效问题，自己也验证了一下，的确会有问题：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 CREATE TABLE t1 ( f_id varchar(20) NOT NULL, f_action char(25) NOT NULL DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;\u0026#39;, PRIMARY KEY (`f_id`), ) ENGINE=InnoDB DEFAULT CHARSET=utf8 ROW_FORMAT=DYNAMIC; CREATE TABLE t1_copy_mb4 ( f_id varchar(20) CHARACTER SET utf8mb4 NOT NULL, f_action char(25) NOT NULL DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;\u0026#39;, PRIMARY KEY (`f_id`), ) ENGINE=InnoDB DEFAULT CHARSET=utf8 ROW_FORMAT=DYNAMIC; 1. EXPLAIN extended select * from t1 INNER JOIN t1_copy_mb4 t2 on t1.f_id=t2.f_id where t1.f_id=\u0026#39;421036\u0026#39;; 2. EXPLAIN extended select * from t1 INNER JOIN t1_copy_mb4 t2 on t1.f_id=t2.f_id where t2.f_id=\u0026#39;421036\u0026#39;; 对应上面1,2 的截图：\n其中 2 的warnings 有convert:\n(convert(t1.f_id using utf8mb4) = \u0026lsquo;421036\u0026rsquo;) 官网能找到这一点解释的还是开头那个地址：\n1 2 3 4 Similarly, the following comparison in the WHERE clause works according to the collation of utf8mb4_col: SELECT * FROM utf8_tbl, utf8mb4_tbl WHERE utf8_tbl.utf8_col = utf8mb4_tbl.utf8mb4_col; 只是索引失效发生在utf8mb4列 在条件左边。（关于MySQL的隐式类型转换，见这里）。\n9. 参考 https://dev.mysql.com/doc/refman/8.0/en/charset-unicode-conversion.html http://forums.mysql.com/read.php?103,187048,188748#msg-188748 Why are we using utf8mb4_general_ci and not utf8mb4_unicode_ci? How to support full Unicode in MySQL databases 10分钟学会理解和解决MySQL乱码问题 原文链接地址：http://xgknight.com/2016/10/23/mysql-utf8mb4/\n","permalink":"http://localhost:1313/2016/10/mysql-utf8mb4/","summary":"\u003ch2 id=\"1-utf8-与-utf8mb4-异同\"\u003e1. utf8 与 utf8mb4 异同\u003c/h2\u003e\n\u003cp\u003e先看 官方手册 \u003ca href=\"https://dev.mysql.com/doc/refman/5.6/en/charset-unicode-utf8mb4.html\"\u003ehttps://dev.mysql.com/doc/refman/5.6/en/charset-unicode-utf8mb4.html\u003c/a\u003e 的说明：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e4\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-fallback\" data-lang=\"fallback\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eThe character set named utf8 uses a maximum of three bytes per character and contains only BMP characters. The utf8mb4 character set uses a maximum of four bytes per character supports supplementary characters:\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e- For a BMP character, utf8 and utf8mb4 have identical storage characteristics: same code values, same encoding, same length.\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e- For a supplementary character, utf8 cannot store the character at all, whereas utf8mb4 requires four bytes to store it. Because utf8 cannot store the character at all, you have no supplementary characters in utf8 columns and need not worry about converting characters or losing data when upgrading utf8 data from older versions of MySQL.\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003eMySQL在 5.5.3 之后增加了 \u003ccode\u003eutf8mb4\u003c/code\u003e 字符编码，mb4即 most bytes 4。简单说 utf8mb4 是 utf8 的超集并完全兼容utf8，能够用四个字节存储更多的字符。\u003c/p\u003e","title":"mysql使用utf8mb4经验吐血总结"},{"content":"最近一个与qq有关的服务迁到腾讯云上，相应的数据库也要从原阿里云RDS迁移到腾讯云CDB上，经过一番摸索，不带任何政治色彩的说，CDB跟RDS相比弱的不止一条街。比如看个错误日志还要提工单，数据库访问没有白名单，数据传输服务竞不支持源库的开启GTID，自带的后台管理是phpMyAdmin，要临时看查询日志也要提工单，当然这些都是可以容忍通过其它方法解决的，但是如果使用上带来了mysql数据库本身的影响，就用的不太爽了。\n最近2个月一直在弄与字符集相关的工作，却还是在cdb踩到一个大坑。情况是这样的，我们旧的RDS上的数据库表定义都是utf8，但由于历史原因，开发一直使用 latin1 去连接的。现在要把这样的一个db迁移到CDB，腾讯云的数据传输服务出了点问题，于是想了办法用阿里云的DTS反向迁。现象是：\n用Navicat客户端latin1连接，旧数据显示都ok 但程序端看到历史数据全是乱码，新数据正常 而且新数据通过navicat去看用 utf8 连接才正常 在mysql命令行下手动 set names latin1 读取旧数据ok，但新数据乱码 这明显是新写入的时候就是以 utf8 连接的，读取的时候新旧数据也以 utf8 连接。但应用端已明确设置使用 latin1 连接来读写。为了验证是否CDB的问题，在相同环境下自建了个mysql实例，一切都ok。\n腾讯云工程师先是怀疑迁移有问题，后来说可能是character_set_server设置的问题，我站在2个月来处理字符集的经验看了虽然不太可能，还是配合截了几个图，在工单、电话了里撕了几个来回：\n因为跟腾讯有合作关系，上头就直接联系到了腾讯云的人，这才找到问题根源：都是--skip-character-set-client-handshake惹的祸。\n1 2 3 --character-set-client-handshake Do not ignore character set information sent by the client. To ignore client information and use the default server character set, use --skip-character-set-client-handshake; this makes MySQL behave like MySQL 4.0 一看到这个选项就恍然大悟了，官方文档FAQ里有专门介绍：A.11.11（个人感觉最后一段贴的结果有问题），大意是说为了兼容 mysql 4.0 的习惯，mysqld启动时加上 --skip-character-set-client-handshake 来忽略客户端字符集的设置，强制使用服务端character-set-server的设置。\n但这个选项默认是没有开启的，当你在web控制台修改了实例字符集时，CDB自作自作主张修改了这个参数并重启 character_set_client_handshake = 0 。而这个参数在 show variables 看不到的，隐藏的比较深。正好我建实例的时候选择了utf8，然后修改为utf8mb4，但应用端要求latin1，便中枪了。\n主要是以前没听过这个参数，后来发现老叶也有篇文章讲到它 MySQL字符集的一个坑，其实是很小的东西，结果排查验证问题前后花了2天。。。\n原文链接地址：http://xgknight.com/2016/10/17/mysql-charset-handshake-cdb/\n","permalink":"http://localhost:1313/2016/10/mysql-charset-handshake-cdb/","summary":"\u003cp\u003e最近一个与qq有关的服务迁到腾讯云上，相应的数据库也要从原阿里云RDS迁移到腾讯云CDB上，经过一番摸索，不带任何政治色彩的说，CDB跟RDS相比弱的不止一条街。比如看个错误日志还要提工单，数据库访问没有白名单，数据传输服务竞不支持源库的开启GTID，自带的后台管理是phpMyAdmin，要临时看查询日志也要提工单，当然这些都是可以容忍通过其它方法解决的，但是如果使用上带来了mysql数据库本身的影响，就用的不太爽了。\u003c/p\u003e","title":"遇到腾讯云CDB连接字符集设置一个坑"},{"content":"Python完成的一个小程序，初衷用于杀掉 MySQL 上的异常线程，如慢查询、处于Sleep状态的，但上线运行以后，以另一种模式运行来实时发现现网的慢查询特别有用，挖掘了许多潜在问题。 项目地址：https://github.com/seanlook/myquerykill\n在使用阿里云RDS的过程中，数据库出现异常，需要快速恢复。网上有许多类似的kill脚本，都是通过 mysqladmin 实现的。然而 Ali-RDS 环境有以下限制：\n不提供 SUPER 权限的用户，也就是用户只能 kill 自己的线程 当连接数暴增时，外部用户无法登陆，包括控制台 为了解决上面两大问题，该 python 脚本通过在db实例上，使用多线程的方式，为每个用户保留一个连接，并实时读取指令配置文件 mysqk.ini，发现有 kill 需求时，利用对应用户已有连接找到 information_schema.processlist 中符合条件的线程，并 kill 。\n说明：该脚本在9月份做过一次重写，7月份的版本（分支 old_0.5.0）是每实例每用户，对应一个线程，db实例一多线程数也太多，看得始终不太优雅，于是改成了一个db实例一个线程，维护同时维护多个用户的会话。同时新版也加入了更多的功能，如按时间窗口检查，包含或排除特定连接，邮件通知，配置项覆盖。\n1. 特性 始终通过 mysql ping 维持一个长连接，并有断开自动重来机制，解决没有连接可用的尴尬 每个db实例有自己的线程，避免需要单独登陆个别用户去kill的繁复操作。 如果你具有 SUPER 权限，也可以简化配置做到兼容 能够分开应对需要杀死线程的场景： 长时间运行超过 N 秒的 Sleep 状态的事务 （一般不建议，但有时候kill它，可以快速释放连接给管理员使用） 排除一些线程不能kill，如 Binlog dump。可配置 包含特定关键字的线程要kill 出现符合条件的线程时，会对当时的processlist, engine status，lock_wait 做一个快照，并邮件发出。妈妈再也不愁没有事故现场了。 有试运行dry_run模式，即执行所有的检查过程但不真正kill 这便是开头所讲的，实时关注生产环境慢查询，而不是等出现问题被动去看slow log，严重的情况连接数可能已经爆了 支持只在时间窗口内运行，考虑到晚上一些长任务不检查 密码加密 2. 快速上手 需要pip安装MySQL-python和pycrypto两个库，只在python 2.7上有测试。\n在 settings.py 里面设置连接的用户名和密码信息。这里假设同一批db的要check的认证信息是一样的，指定的用户既用于登录认证，也用于告知脚本哪些用户需要被检查。 密码要通过 prpcryptec.py 加密，加密的密钥需写入脚本本身的 KEY_DB_AUTH变量。（担心泄露的话，把mysqk.py编译成 pyc 来跑）\n在 mysqk.ini 主配置文件里面\ndb_info 节设置需要被检查的数据库地址，如 db01=10.0.200.100:3306 可分别 db01等指定需要kill thread的选项。[id_db01] 则默认复用 [db_commkill] 的选项 db_comconfig 节设置 db_puser 为能查看到所有processlist的权限用户，且在 settings.py 的DB_AUTH中已指定 只想执行检查，并不想真正kill异常线程，确认 dry_run不等于0 Here we go!\n3. 配置项说明 mysqk.ini：\n3.1 mail_config 邮件通知相关设置，smtp服务地址和认证信息。 mail_receiver= 设置空，表示不发邮件\n3.2 db_info 设置要检查kill哪些数据库实例. 格式：\u0026lt;dbid\u0026gt;=\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt;，dbid是唯一表示db实例的，后面设置各db需要被kill的选项，小节配置名就是 id_\u0026lt;dbid\u0026gt;；端口必需指定。\n在这里出现的db实例都会被执行检查，可用 ; 注释，但需要重启脚本。\n3.3 db_comconfig 检查用公共配置，实时生效。\ndb_puser：指定一个用户名用于 show processlist，需要的权限：PROCESS、information_schema库查看。可以认为是一个代表用户，检查异常thread，把结果提供给有该thread杀掉权限用户。 run_max_count：执行检查的次数，是一个全局控制开关。每次修改这个值都会重新开始检查，即一个 clean start，让刚修改的配置生效。 为 0 表示脚本不进行任何检查，只简单维护与数据库的连接存活。存活检查频率在 settings.py 由 CHECK_CONFIG_INTERVAL × CHECK_PING_MULTI决定 为 999 表示会在后台一致检查连接线程（但不一定有符合kill条件的），检查的频率在 settings.py 里面 CHECK_CONFIG_INTERVAL 指定 为其它值时，表示检查次数满后停止检查 dry_run：是否开启试运行模式，为0表示真实kill，为1或其它值表示试运行。试运行模式可用于监控慢查询并告警。注意同一会话线程ID只告警一次 run_time_window：运行的检查的时间窗口，格式如 08:00-22:00，在这个时间以外不执行检查，留空表示不限制。主要考虑晚上一些统计任务可能出现“异常”线程。 3.4 db_commkill kill用公共配置，实时生效，会被 id_\u0026lt;dbid\u0026gt; 节的选项覆盖。\nk_user：很关键的一个选项，表示你要检查并kill哪些数据库用户，多个用逗号分隔（不要带引号）。\n为 all 时，表示要检查 settings.py 里 DB_AUTH 指定的所有用户\n为 none 时，表示不kill任何异常线程，效果与设置了 dry_run 模式相当\nk_longtime：执行超过设定值的sql则认为异常。一般大于 CHECK_CONFIG_INTERVAL\nk_sleep：Sleep超过设定秒的sql则认为异常，为 0 表示不杀掉sleep状态的线程\nk_exclude：排除掉那些特定关键字的线程，比如复制线程、管理员的连接等\nk_include：包含这些特定关键字的线程，需要被kill。注意，它作用在满足 k_user 和 k_exclude 的前提之下。\nk_exclude与k_include 的值是支持python re模块正则的格式，不要带引号\n3.5 id_dbid 这部分区域的配置项与 db_commconfig 相同，用于针对个别db的kill选项。\n4. 使用建议 两种组合模式：\n设置 dry_run=0，默认 k_user=none，当数据库出现异常时，主动修改对应db的k_user值，动态kill 设置 dry_run=1，默认 k_user=all，相当于运行在daemon模式，有慢查询则邮件通知，并且记录下当时的信息。建议此模式 当然你也可以dry_run=0，k_user=all，让程序一直在后台跑并kill，但生产环境极不推荐。\n有日志和快照文件可以查看。\n5. 配置文件示例 mysqlk.ini :\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 [mail_config] mail_host=smtp.exmail.qq.com mail_user=xxx@ecqun.com mail_pass=xxxxxx mail_receiver= [db_info] crm0=192.168.1.125:3306 crm1=192.168.1.126:3306 crm2=192.168.1.127:3306 crm3=192.168.1.128:3306 base=10.0.200.142:3306 [db_commconfig] db_puser=ecuser ; how many kill times once this config file changed ; 0: DISABLE all kill ; 999: always kill threads that meet kill conditions ; default: 1 ; can not be inherit run_max_count=999 dry_run=1 run_time_window=08:00-22:00 [db_commkill] k_user=all k_longtime=10 k_lock=1 k_sleep=0 k_exclude=Binlog|ecdba|Daemon k_include=select sleep\\(17\\) [id_crm0] ; k_user: who\u0026#39;s threads to be killed. use comma to separate ; none: do not kill anyone\u0026#39;s threads ; all: kill all user\u0026#39;s threads (with other where conditions) ; default: none k_user=all ; k_longtime: filter the threads who\u0026#39;s running time is longer than this ; 0: ignore the time \u0026gt; x condition ; default: 10 k_longtime=10 ; k_sleep: whether kill sleepd threads or not ; 0: do not kill command=\u0026#39;Sleep\u0026#39; threads from processlist ; when it set to 1, usually it\u0026#39;s subset of k_longtime condition ; default: 0 k_sleep=0 [id_crm1] k_user=ecuser k_longtime=10 k_sleep=0 [id_crm2] k_user=all k_longtime=10 k_sleep=0 [id_crm3] 6. 运行示例 原文链接地址：http://xgknight.com/2016/09/27/python-mysql-querykill/\n","permalink":"http://localhost:1313/2016/09/python-mysql-querykill/","summary":"\u003cp\u003ePython完成的一个小程序，初衷用于杀掉 MySQL 上的异常线程，如慢查询、处于Sleep状态的，但上线运行以后，以另一种模式运行来实时发现现网的慢查询特别有用，挖掘了许多潜在问题。\n\u003cstrong\u003e项目地址\u003c/strong\u003e：https://github.com/seanlook/myquerykill\u003c/p\u003e","title":"你可能需要一个实时抓取MySQL慢查询现场的程序"},{"content":"经常会被问到 InnoDB隔离级别中 READ-COMMITED和REPEATABLE-READ 的区别，今天就整理了一下，不再从“脏读”、“幻读”这样的名词解释一样去回答了。\n1. 行锁 InnoDB行锁实际锁的是索引记录，为了防止死锁的产生以及维护所需要的隔离级别，在执行sql语句的全过程中，innodb必须对所需要修改的行每条索引记录上锁。如此一来，如果你执行的 UPDATE 没有很好的索引，那么会导致锁定许多行：\n1 2 3 4 5 update employees set store_id = 0 where store_id = 1; ---TRANSACTION 1EAB04, ACTIVE 7 sec 633 lock struct(s), \u0026lt;strong\u0026gt;heap size 96696\u0026lt;/strong\u0026gt;, 218786 row lock(s), undo log entries 1 MySQL thread id 4, OS thread handle 0x7f8dfc35d700, query id 47 localhost root show engine innodb status 上面的 employees 表 store_id 列没有索引。注意 UPDATE 已经执行完成（没有提交），但依然有 218786 个行锁没有释放，还有一个undo记录。这意味着只有一行被更改，但却持有了额外的锁。堆大小（heap size）代表了分配给锁使用的内存数量。\n在 REPEATABLE-READ 级别，事务持有的 每个锁 在整个事务期间一直被持有。\n在 READ-COMMITED 级别，事务里面特定语句结束之后，不匹配该sql语句扫描条件的锁，会被释放。\n下面是上述相同的 UPDATE 在 READ-COMMITED 级别下的结果：\n1 2 3 4 ---TRANSACTION 1EAB06, ACTIVE 11 sec 631 lock struct(s), \u0026lt;strong\u0026gt;heap size 96696\u0026lt;/strong\u0026gt;, 1 row lock(s), undo log entries 1 MySQL thread id 4, OS thread handle 0x7f8dfc35d700, query id 62 localhost root show engine innodb status 可以看到 heap size 没有变化，但是现在我们只持有一个行锁。无论什么隔离级别下，InnoDB 会为扫描过的每条索引记录创建锁，不同的是在 RC 模式，一旦语句执行完毕（事务未必完成），不符合扫描条件的记录上的锁会被随即释放。释放这些锁后，堆内存并不会马上释放，所以heap size看到与 RR 模式是一样的，但是持有的锁数量明显小了很多。\n这也就意味着在 RC 级别下的事务A，只要A的UPDATE 语句 完成了，其它事务可以修改A中也扫描过的行，但在 RR 级别下不允许。\n2. Read View REPEATABLE-READ 在 REPEATABLE-READ 级别，read view 对象在事务一开启就被创建，这个一致性快照在整个事务期间一直保持打开。在同一个事务里，前后间隔几个小时执行一遍相同的 SELECT，你会得到完全一样的结果，这就是所谓的 MVCC (multiple version concurrency control)，它是通过行版本号和UNDO段来实现的。\n在 REPEATABLE-READ 级别， InnoDB会为范围扫描创建间隙锁（gap locks）：\n1 select * from some_table where id \u0026gt; 100 FOR UPDATE; 上面的update将会创建一个 gap lock，用来防止在 id\u0026gt;100 范围内有新行被插入，锁会持续到事务回滚或提交。比如在同一个事务里，上午5点执行 SELECT \u0026hellip; FOR UPDATE，下午5点执行 UPDATE some_table where id\u0026gt;100，那么这个update只会修改上午5点 SELECT FOR UPDATE所锁定的行，因为大于100的记录的整个 间隙 被加了锁。\nREAD-COMMITED 在 READ-COMMITED 级别，read view 结构在每个语句开始的时候被创建，这意味着即使在同一个事务中，上午5点执行的 SELECT与下午5点执行的SELECT可能会得到不同的结果。因为 read view 在 READ-COMMITED 级别下仅在 语句执行 期间存在。\n这就是所谓的 “幻读”（phantom read）。\nREAD-COMMITED 隔离级别下是没有gap locks，所以执行上面的 SELECT FOR UPDATE where id\u0026gt;100 并不会阻止其它事务插入新行，如果同一个事务里后面执行 UPDATE \u0026hellip; where id\u0026gt;100，就有可能导致实际更新的行数比前面锁定的行数要多。\n补充： 如果了解过 mysqldump 的实现原理，可知它就是充分利用InnoDB的MVCC特性，使用 REPEATABLE-READ 模式获取备份事务的一致性快照，避免锁表和幻读。\n本文主要参考自 percona博客上的一篇文章 https://www.percona.com/blog/2012/08/28/differences-between-read-committed-and-repeatable-read-transaction-isolation-levels/ 。\n本文链接地址：http://xgknight.com/2016/09/03/diffs-between-rr-and-rc-trx_isolation_level/\n","permalink":"http://localhost:1313/2016/09/diffs-between-rr-and-rc-trx_isolation_level/","summary":"\u003cp\u003e经常会被问到 InnoDB隔离级别中 READ-COMMITED和REPEATABLE-READ 的区别，今天就整理了一下，不再从“脏读”、“幻读”这样的名词解释一样去回答了。\u003c/p\u003e","title":"READ-COMMITED 与 REPEATABLE-READ 事务隔离级别之间的异同"},{"content":"这段时间在公司内部准备了一个分享，主题是关于 MySQL事务与锁，准备过程内容很多，也深入弄清楚了一些以前比较迷糊的地方，加上后面的讨论也就一个半小时。\n主要涉及的是乐观锁与悲观锁，InnoDB多版本并发控制的实现，以及隔离级别与各种情况加锁分析，因为涉及的主要还是开发人员，所以不是很深奥。也算花了不少心血，分享一下。\nslideshare: http://www.slideshare.net/ssuser5a0bc0/my-sql-seanlook\n{% pdf http://github.com/seanlook/sean-notes-comment/raw/main/static/mysql-ppt-trx_isolation-lock-seanlook.pdf 900 512 %}\n原文连接地址：http://xgknight.com/2016/08/30/mysql-ppt-trx_isolation-lock/\n","permalink":"http://localhost:1313/2016/08/mysql-ppt-trx_isolation-lock/","summary":"\u003cp\u003e这段时间在公司内部准备了一个分享，主题是关于 MySQL事务与锁，准备过程内容很多，也深入弄清楚了一些以前比较迷糊的地方，加上后面的讨论也就一个半小时。\u003c/p\u003e","title":"浅析MySQL事务隔离级别与锁 分享"},{"content":"端午在家无聊，又不想学习。于是在Youtube随便逛，看到一个很不错的分享，来自 Percona Database Performance。下面是演示稿：\nslideshare: http://www.slideshare.net/ssuser5a0bc0/webinar-2013-advancedquerytuning\n{% pdf https://www.slideshare.net/slideshow/embed_code/key/3HLJJcJmM9KLGT %}\nYoutube: https://www.youtube.com/watch?v=TPFibi2G_oo\n能 条件 的可以看看。\nPercona webinars上有许多类似的分享，传送门： https://www.percona.com/resources/webinars ，不少是他们CEO Peter Zaitsev 亲自上马的。\n原文连接地址：http://xgknight.com/2016/06/11/mysql-advanced-query-tuning-percona/\n","permalink":"http://localhost:1313/2016/06/mysql-advanced-query-tuning-percona/","summary":"\u003cp\u003e端午在家无聊，又不想学习。于是在Youtube随便逛，看到一个很不错的分享，来自 Percona Database Performance。下面是演示稿：\u003c/p\u003e\n\u003cp\u003eslideshare: \u003ca href=\"http://www.slideshare.net/ssuser5a0bc0/webinar-2013-advancedquerytuning\"\u003ehttp://www.slideshare.net/ssuser5a0bc0/webinar-2013-advancedquerytuning\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e{% pdf \u003ca href=\"https://www.slideshare.net/slideshow/embed_code/key/3HLJJcJmM9KLGT\"\u003ehttps://www.slideshare.net/slideshow/embed_code/key/3HLJJcJmM9KLGT\u003c/a\u003e %}\u003c/p\u003e\n\u003cp\u003eYoutube: \u003ca href=\"https://www.youtube.com/watch?v=TPFibi2G_oo\"\u003ehttps://www.youtube.com/watch?v=TPFibi2G_oo\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e能 \u003cem\u003e条件\u003c/em\u003e 的可以看看。\u003c/p\u003e","title":"Advanced MySQL Query Tuning .pdf"},{"content":"如果正在看这篇文章，相信你已经知道自己的需求了。\n在 mysql 5.5 版本以前，修改表结构如添加索引、修改列，需要锁表，期间不能写入，对于大表这简直是灾难。从5.5特别是5.6里，情况有了好转，支持Online DDL，相关介绍见 这篇文章，而我在实际alter table过程中还是会引起 data meta lock 问题。pt-online-schema-change是Percona-toolkit一员，通过改进原生ddl的方式，达到不锁表在线修改表结构。\n1. pt-osc工作过程 创建一个和要执行 alter 操作的表一样的新的空表结构(是alter之前的结构) 在新表执行alter table 语句（速度应该很快） 在原表中创建触发器3个触发器分别对应insert,update,delete操作 以一定块大小从原表拷贝数据到临时表，拷贝过程中通过原表上的触发器在原表进行的写操作都会更新到新建的临时表 Rename 原表到old表中，在把临时表Rename为原表 如果有参考该表的外键，根据alter-foreign-keys-method参数的值，检测外键相关的表，做相应设置的处理 默认最后将旧原表删除 2. 常用选项说明 只介绍部分常用的选项\n--host=xxx --user=xxx --password=xxx 连接实例信息，缩写-h xxx -u xxx -p xxx，密码可以使用参数--ask-pass 手动输入。\n--alter 结构变更语句，不需要 ALTER TABLE关键字。与原始ddl一样可以指定多个更改，用逗号分隔。\n绝大部分情况下表上需要有主键或唯一索引，因为工具在运行当中为了保证新表也是最新的，需要旧表上创建 DELETE和UPDATE 触发器，同步到新表的时候有主键会更快。个别情况是，当alter操作就是在c1列上建立主键时，DELETE触发器将基于c1列。\n子句不支持 rename 去给表重命名。\nalter命令原表就不支持给索引重命名，需要先drop再add，在pt-osc也一样。(mysql 5.7 支持 RENAME INDEX old_index_name TO new_index_name) 但给字段重命名，千万不要drop-add，整列数据会丢失，使用change col1 col1_new type constraint（保持类型和约束一致，否则相当于修改 column type，不能online）\n子句如果是add column并且定义了not null，那么必须指定default值，否则会失败。\n如果要删除外键（名 fk_foo），使用工具的时候外键名要加下划线，比如--alter \u0026quot;DROP FOREIGN KEY _fk_foo\u0026quot;\nD=db_name,t=table_name 指定要ddl的数据库名和表名\n--max-load 默认为Threads_running=25。每个chunk拷贝完后，会检查 SHOW GLOBAL STATUS 的内容，检查指标是否超过了指定的阈值。如果超过，则先暂停。这里可以用逗号分隔，指定多个条件，每个条件格式： status指标=MAX_VALUE或者status指标:MAX_VALUE。如果不指定MAX_VALUE，那么工具会这只其为当前值的120%。 因为拷贝行有可能会给部分行上锁，Threads_running 是判断当前数据库负载的绝佳指标。\n--max-lag 默认1s。每个chunk拷贝完成后，会查看所有复制Slave的延迟情况（Seconds_Behind_Master）。要是延迟大于该值，则暂停复制数据，直到所有从的滞后小于这个值。--check-interval配合使用，指定出现从库滞后超过 max-lag，则该工具将睡眠多长时间，默认1s，再检查。如--max-lag=5 --check-interval=2。 熟悉percona-toolkit的人都知道--recursion-method 可以用来指定从库dsn记录。另外，如果从库被停止，将会永远等待，直到从开始同步，并且延迟小于该值。\n--chunk-time 默认0.5s，即拷贝数据行的时候，为了尽量保证0.5s内拷完一个chunk，动态调整chunk-size的大小，以适应服务器性能的变化。 也可以通过另外一个选项--chunk-size禁止动态调整，即每次固定拷贝 1k 行，如果指定则默认1000行，且比 chunk-time 优先生效\n--set-vars 使用pt-osc进行ddl要开一个session去操作，set-vars可以在执行alter之前设定这些变量，比如默认会设置--set-vars \u0026quot;wait_timeout=10000,innodb_lock_wait_timeout=1,lock_wait_timeout=60\u0026quot;。 因为使用pt-osc之后ddl的速度会变慢，所以预计2.5h只能还不能改完，记得加大wait_timeout。\n--dry-run 创建和修改新表，但不会创建触发器、复制数据、和替换原表。并不真正执行，可以看到生成的执行语句，了解其执行步骤与细节，和--print配合最佳。。\n--execute 确定修改表，则指定该参数。真正执行alter。\u0026ndash;dry-run与\u0026ndash;execute必须指定一个，二者相互排斥\n3. 使用疑惑（限制） 3.1 原表上不能有触发器存在 这个很容易理解，pt-osc会在原表上创建3个触发器，而一个表上不能同时有2个相同类型的触发器，为简单通用起见，只能一棍子打死。 所以如果要让它支持有触发器存在的表也是可以实现的，思路就是：先找到原表触发器定义；重写原表触发器；最后阶段将原表触发器定义应用到新表。\n3.2 通过触发器写数据到临时新表，会不会出现数据不一致或异常 这其实是我的一个顾虑，因为如果update t1，触发update t2，但这条数据还没copy到t2，不就有异常了吗？后台通过打开general_log，看到它创建的触发器：\n1 2 3 4 5 6 7 8 9 10 11 12 6165 Query CREATE TRIGGER `pt_osc_confluence_sbtest3_del` AFTER DELETE ON `confluence`.`sbtest3` FOR EACH ROW DELETE IGNORE FROM `confluence`.`_sbtest3_new` WHERE `confluence`.`_sbtest3_new`.`id` \u0026lt;=\u0026gt; OLD.`id` 6165 Query CREATE TRIGGER `pt_osc_confluence_sbtest3_upd` AFTER UPDATE ON `confluence`.`sbtest3` FOR EACH ROW REPLACE INTO `confluence`.`_sbtest3_new` (`id`, `k`, `c`, `pad`) VALUES (NEW.`id`, NEW.`k`, NEW.`c`, NEW.`pad`) 6165 Query CREATE TRIGGER `pt_osc_confluence_sbtest3_ins` AFTER INSERT ON `confluence`.`sbtest3` FOR EACH ROW REPLACE INTO `confluence`.`_sbtest3_new` (`id`, `k`, `c`, `pad`) VALUES (NEW.`id`, NEW.`k`, NEW.`c`, NEW.`pad`) 并且copy操作是： 6165 Query INSERT LOW_PRIORITY IGNORE INTO `confluence`.`_sbtest3_new` (`id`, `k`, `c`, `pad`) SELECT `id`, `k`, `c`, `pad` FROM `confluence`.`sbtest3` FORCE INDEX(`PRIMARY`) WHERE ((`id` \u0026gt;= \u0026#39;4692805\u0026#39;)) AND ((`id` \u0026lt;= \u0026#39;4718680\u0026#39;)) LOCK IN SHARE MODE /*pt-online-schema-change 46459 copy nibble*/ 在原表上update，新临时表上是replace into整行数据，所以达到有则更新，无则插入。同时配合后面的 insert ignore，保证这条数据不会因为重复而失败。\n3.3 为什么外键那么特殊 假设 t1 是要修改的表，t2 有外键依赖于 t1，_t1_new 是 alter t1 产生的新临时表。 这里的外键不是看t1上是否存在外键，而是作为子表的 t2。主要问题在 rename t1 时，t1“不存在”导致t2的外键认为参考失败，不允许rename。 pt-osc提供--alter-foreign-keys-method选项来决定怎么处理这种情况：\nrebuild_constraints，优先采用这种方式 它先通过 alter table t2 drop fk1,add _fk1 重建外键参考，指向新表 再 rename t1 t1_old, _t1_new t1 ，交换表名，不影响客户端 删除旧表 t1_old 但如果字表t2太大，以致alter操作可能耗时过长，有可能会强制选择 drop_swap。 涉及的主要方法在 pt-online-schema-change 文件的 determine_alter_fk_method, rebuild_constraints, swap_tables三个函数中。 drop_swap， 禁用t2表外键约束检查 FOREIGN_KEY_CHECKS=0 然后 drop t1 原表 再 rename _t1_new t1 这种方式速度更快，也不会阻塞请求。但有风险，第一，drop表的瞬间到rename过程，原表t1是不存在的，遇到请求会报错；第二，如果因为bug或某种原因，旧表已删，新表rename失败，那就太晚了，但这种情况很少见。 我们的开发规范决定，即使表间存在外键参考关系，也不通过表定义强制约束。 3.4 在使用之前需要对磁盘容量进行评估 使用OSC会使增加一倍的空间，包括索引 而且在 Row Based Replication 下，还会写一份binlog。不要想当然使用--set-vars去设置 sql_log_bin=0，因为在这个session级别，alter语句也要在从库上执行，除非你对从库另有打算。\n4. 使用 pt-osc原生 5.6 online ddl相比，如何选择 online ddl在必须copy table时成本较高，不宜采用 pt-osc工具在存在触发器时，不适用 修改索引、外键、列名时，优先采用online ddl，并指定 ALGORITHM=INPLACE 其它情况使用pt-osc，虽然存在copy data pt-osc比online ddl要慢一倍左右，因为它是根据负载调整的 无论哪种方式都选择的业务低峰期执行 特殊情况需要利用主从特性，先alter从库，主备切换，再改原主库 借助percona博客一张图说明一下：\n5. 示例 添加新列 完整输出过程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 [root@ssd-34 sysbench]# pt-online-schema-change --user=user --password=password --host=10.0.201.34 --alter \u0026#34;ADD COLUMN f_id int default 0\u0026#34; D=confluence,t=sbtest3 --print --execute No slaves found. See --recursion-method if host ssd-34 has slaves. Not checking slave lag because no slaves were found and --check-slave-lag was not specified. Operation, tries, wait: analyze_table, 10, 1 copy_rows, 10, 0.25 create_triggers, 10, 1 drop_triggers, 10, 1 swap_tables, 10, 1 update_foreign_keys, 10, 1 Altering `confluence`.`sbtest3`... Creating new table... ==\u0026gt; 创建新表 CREATE TABLE `confluence`.`_sbtest3_new` ( `id` int(10) unsigned NOT NULL AUTO_INCREMENT, `k` int(10) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39;, `c` char(120) COLLATE utf8_bin NOT NULL DEFAULT \u0026#39;\u0026#39;, `pad` char(60) COLLATE utf8_bin NOT NULL DEFAULT \u0026#39;\u0026#39;, PRIMARY KEY (`id`), KEY `k_3` (`k`) ) ENGINE=InnoDB AUTO_INCREMENT=5000001 DEFAULT CHARSET=utf8 COLLATE=utf8_bin MAX_ROWS=1000000 Created new table confluence._sbtest3_new OK. Altering new table... ==\u0026gt; 使用ddl修改新表结构 ALTER TABLE `confluence`.`_sbtest3_new` ADD COLUMN f_id int default 0 Altered `confluence`.`_sbtest3_new` OK. 2016-05-24T20:54:23 Creating triggers... ==\u0026gt; 在旧表上创建3个触发器 CREATE TRIGGER `pt_osc_confluence_sbtest3_del` AFTER DELETE ON `confluence`.`sbtest3` FOR EACH ROW DELETE IGNORE FROM `confluence`.`_sbtest3_new` WHERE `confluence`.`_sbtest3_new`.`id` \u0026lt;=\u0026gt; OLD.`id` CREATE TRIGGER `pt_osc_confluence_sbtest3_upd` AFTER UPDATE ON `confluence`.`sbtest3` FOR EACH ROW REPLACE INTO `confluence`.`_sbtest3_new` (`id`, `k`, `c`, `pad`) VALUES (NEW.`id`, NEW.`k`, NEW.`c`, NEW.`pad`) CREATE TRIGGER `pt_osc_confluence_sbtest3_ins` AFTER INSERT ON `confluence`.`sbtest3` FOR EACH ROW REPLACE INTO `confluence`.`_sbtest3_new` (`id`, `k`, `c`, `pad`) VALUES (NEW.`id`, NEW.`k`, NEW.`c`, NEW.`pad`) 2016-05-24T20:54:23 Created triggers OK. 2016-05-24T20:54:23 Copying approximately 4485573 rows... ==\u0026gt; 分块拷贝数据到新表 INSERT LOW_PRIORITY IGNORE INTO `confluence`.`_sbtest3_new` (`id`, `k`, `c`, `pad`) SELECT `id`, `k`, `c`, `pad` FROM `confluence`.`sbtest3` FORCE INDEX(`PRIMARY`) WHERE ((`id` \u0026gt;= ?)) AND ((`id` \u0026lt;= ?)) LOCK IN SHARE MODE /*pt-online-schema-change 44155 copy nibble*/ SELECT /*!40001 SQL_NO_CACHE */ `id` FROM `confluence`.`sbtest3` FORCE INDEX(`PRIMARY`) WHERE ((`id` \u0026gt;= ?)) ORDER BY `id` LIMIT ?, 2 /*next chunk boundary*/ Copying `confluence`.`sbtest3`: 36% 00:52 remain Copying `confluence`.`sbtest3`: 69% 00:26 remain 2016-05-24T20:56:01 Copied rows OK. 2016-05-24T20:56:01 Analyzing new table... 2016-05-24T20:56:01 Swapping tables... ==\u0026gt; 交换新旧表 RENAME TABLE `confluence`.`sbtest3` TO `confluence`.`_sbtest3_old`, `confluence`.`_sbtest3_new` TO `confluence`.`sbtest3` 2016-05-24T20:56:01 Swapped original and new tables OK. 2016-05-24T20:56:01 Dropping old table... ==\u0026gt; 删除旧表 DROP TABLE IF EXISTS `confluence`.`_sbtest3_old` 2016-05-24T20:56:02 Dropped old table `confluence`.`_sbtest3_old` OK. 2016-05-24T20:56:02 Dropping triggers... DROP TRIGGER IF EXISTS `confluence`.`pt_osc_confluence_sbtest3_del`; DROP TRIGGER IF EXISTS `confluence`.`pt_osc_confluence_sbtest3_upd`; DROP TRIGGER IF EXISTS `confluence`.`pt_osc_confluence_sbtest3_ins`; 2016-05-24T20:56:02 Dropped triggers OK. Successfully altered `confluence`.`sbtest3`. 修改列类型 1 2 3 4 5 6 7 pt-online-schema-change h=10.0.201.34,P=3306,u=jacky,p=xxx,D=confluence,t=sbtest3 \\ --alter \u0026#34;CHANGE pad f_pad varchar(60) NOT NULL DEFAULT \u0026#39;\u0026#39; \u0026#34; \\ --print --dry-run pt-online-schema-change -ujacky -p xxx -h \u0026#34;10.0.201.34\u0026#34; D=confluence,t=sbtest3 \\ --alter \u0026#34;CHANGE pad f_pad varchar(60) NOT NULL DEFAULT \u0026#39;\u0026#39; \u0026#34; \\ --execute 添加删除索引\n放后台执行 1 2 3 pt-online-schema-change --user=user --ask-pass --host=10.0.201.34 \\ --alter \u0026#34;DROP KEY cid, ADD KEY idx_corpid_userid(f_corp_id,f_user_id) \u0026#34; \\ D=confluence,t=sbtest3 --print --execute 修改主键 在我的环境里有不少表设计之初没有自增id，而是采用复合主键，pt-osc 对删除、添加主键会特殊处理，详见 这里 。\n6. 错误处理 **1. 存在trigger **\n1 2 3 [zx@mysql-5 ~]$ pt-online-schema-change -u user -p password -h 10.0.200.195 \\ --alter=\u0026#34;MODIFY COLUMN f_receiver varchar(128) NOT NULL DEFAULT \u0026#39;\u0026#39; AFTER f_user_id\u0026#34; --dry-run D=db_name,t=table_name The table `db_name`.`table_name` has triggers. This tool needs to create its own triggers, so the table cannot already have triggers. 表上存在触发器，不适用。\n**2. no-version-check **\n1 2 3 $ pt-online-schema-change -uuser -ppassword --alter \u0026#34;add key id_provice(f_provice)\u0026#34; \\ D=db_name,t=tb_name -h rdsxxxxxx.mysql.rds.aliyuncs.com Can\u0026#39;t use an undefined value as an ARRAY reference at /usr/bin/pt-online-schema-change line 7335. 这个错误在阿里云RDS上执行时出现的，我以为是我哪里语法写错了，但拿到原生5.6的版本上就没问题了，加上--no-version-check选项就好了，见 https://help.aliyun.com/knowledge_detail/13098164.html ，没深究，应该是pt去验证mysql server版本的时候从rds拿到的信息不对，导致格式出错。\n参考 refman pt-online-schema-change RDS MySQL 如何使用 Percona Toolkit percona-toolkit 之 【pt-online-schema-change】说明 Avoiding MySQL ALTER table downtime MySQL Online DDL和NoSQL Schemaless Design 原文链接地址：http://xgknight.com/2016/05/27/mysql-pt-online-schema-change/\n","permalink":"http://localhost:1313/2016/05/mysql-pt-online-schema-change/","summary":"\u003cp\u003e如果正在看这篇文章，相信你已经知道自己的需求了。\u003c/p\u003e\n\u003cp\u003e在 mysql 5.5 版本以前，修改表结构如添加索引、修改列，需要锁表，期间不能写入，对于大表这简直是灾难。从5.5特别是5.6里，情况有了好转，支持Online DDL，相关介绍见 \u003ca href=\"http://xgknight.com/2016/05/24/mysql-online-ddl-concept\"\u003e这篇文章\u003c/a\u003e，而我在实际alter table过程中还是会引起 data meta lock 问题。pt-online-schema-change是Percona-toolkit一员，通过改进原生ddl的方式，达到不锁表在线修改表结构。\u003c/p\u003e","title":"pt-online-schema-change使用说明、限制与比较"},{"content":"使用 pt-online-schema-change 做在线ddl最添加普通索引、列，修改列类型、添加默认值等使用比较常规，但涉及到要修改的是主键时就有点棘手。在我修改线上实例过程中，有这样的需求，不妨先思考一下怎么做才好：\n1 原表上有个复合主键，现在要添加一个自增id作为主键，如何进行 会涉及到以下修改动作：\n删除复合主键定义 添加新的自增主键 原复合主键字段，修改成唯一索引 如果你够聪明，应该会把这三个操作放在同一个 alter table 命令执行。percona手册里有两个地方对修改主键进行了特殊注解：\n\u0026ndash;alter A notable exception is when a PRIMARY KEY or UNIQUE INDEX is being created from existing columns as part of the ALTER clause; in that case it will use these column(s) for the DELETE trigger.\n\u0026ndash;[no]check-alter\nDROP PRIMARY KEY If \u0026ndash;alter contain DROP PRIMARY KEY (case- and space-insensitive), a warning is printed and the tool exits unless \u0026ndash;dry-run is specified. Altering the primary key can be dangerous, but the tool can handle it. The tool’s triggers, particularly the DELETE trigger, are most affected by altering the primary key because the tool prefers to use the primary key for its triggers. You should first run the tool with \u0026ndash;dry-run and \u0026ndash;print and verify that the triggers are correct. 由上一篇文章 pt-online-schema-change使用说明、限制与比较 可知，pt-osc会在原表t1上创建 AFTER DELETE/UPDATE/INSERT 三个触发器，修改主键影响最大的就是 DELETE 触发器：新表t2上的主键字段在旧表t1上不存在，无法根据主键条件触发删除新表t2数据。but the tool can handle it，原因是pt-osc把触发器改成了下面的形式：\n1 2 3 4 CREATE TRIGGER `pt_osc_confluence_sbtest3_del` AFTER DELETE ON `confluence`.`sbtest3` FOR EACH ROW DELETE IGNORE FROM `confluence`.`_sbtest3_new` WHERE `confluence`.`_sbtest3_new`.`id` \u0026lt;=\u0026gt; OLD.`id` AND `confluence`.`_sbtest3_new`.`k` \u0026lt;=\u0026gt; OLD.`k` 注：sbtest3表上以(id,k)作为复合主键 但是如果id或k列上没有索引，这个删除的代价非常高，所以一定要同时添加复合（唯一）索引 (id,k) .\n而对于INSERT,UPDATE的触发器，依然是 REPLACE INTO语法，因为它采用的是先插入，如果违反主键或唯一约束，则根据主键或意义约束删除这条数据，再执行插入。（但是注意你不能依赖于新表的主键递增，因为如果原表有update，新表就会先插入这一条，导致id与原表记录所在顺序不一样）\n所以如果使用pt-osc去修改删除主键，务必同时添加原主键为 UNIQUE KEY，否则很有可能导致性能问题：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 $ pt-online-schema-change --user=ecuser --password=ecuser --host=10.0.201.34 \\ --alter \u0026#34;DROP PRIMARY KEY,add column pk int auto_increment primary key,add unique key uk_id_k(id,k)\u0026#34; \\ D=confluence,t=sbtest3 --print --dry-run --alter contains \u0026#39;DROP PRIMARY KEY\u0026#39;. Dropping and altering the primary key can be dangerous, especially if the original table does not have other unique indexes. ==\u0026gt;注意 dry-run的输出 ALTER TABLE `confluence`.`_sbtest3_new` DROP PRIMARY KEY,add column pk int auto_increment primary key,add unique key uk_id_k(id,k) Altered `confluence`.`_sbtest3_new` OK. Using original table index PRIMARY for the DELETE trigger instead of new table index PRIMARY because ==\u0026gt; 使用原表主键值判断 the new table index uses column pk which does not exist in the original table. CREATE TRIGGER `pt_osc_confluence_sbtest3_del` AFTER DELETE ON `confluence`.`sbtest3` FOR EACH ROW DELETE IGNORE FROM `confluence`.`_sbtest3_new` WHERE `confluence`.`_sbtest3_new`.`id` \u0026lt;=\u0026gt; OLD.`id` AND `confluence`.`_sbtest3_new`.`k` \u0026lt;=\u0026gt; OLD.`k` 原文链接地址：http://xgknight.com/2016/05/27/mysql-pt-osc-add-primarykey/\n","permalink":"http://localhost:1313/2016/05/mysql-pt-osc-add-primarykey/","summary":"\u003cp\u003e使用 pt-online-schema-change 做在线ddl最添加普通索引、列，修改列类型、添加默认值等使用比较常规，但涉及到要修改的是主键时就有点棘手。在我修改线上实例过程中，有这样的需求，不妨先思考一下怎么做才好：\u003c/p\u003e","title":"使用pt-osc修改主键时注意"},{"content":"做MySQL的都知道，数据库操作里面，DDL操作（比如CREATE,DROP,ALTER等）代价是非常高的，特别是在单表上千万的情况下，加个索引或改个列类型，就有可能堵塞整个表的读写。\n然后 mysql 5.6 开始，大家期待的Online DDL出现了，可以实现修改表结构的同时，依然允许DML操作(select,insert,update,delete)。在这个特性出现以前，用的比较多的工具是pt-online-schema-change，比较请参考pt-online-schema-change使用说明、限制与比较或 ONLINE DDL VS PT-ONLINE-SCHEMA-CHANGE 。\n1. Online DDL 在 MySQL 5.1 （带InnoDB Plugin）和5.5中，有个新特性叫 Fast Index Creation（下称 FIC），就是在添加或者删除二级索引的时候，可以不用复制原表。对于之前的版本对于索引的添加删除这类DDL操作，MySQL数据库的操作过程为如下：\n首先新建Temp table，表结构是 ALTAR TABLE 新定义的结构 然后把原表中数据导入到这个Temp table 删除原表 最后把临时表rename为原来的表名 为了保持数据的一致性，中间复制数据（Copy Table）全程锁表只读，如果有写请求进来将无法提供服务，连接数爆张。\n引入FIC之后，创建二级索引时会对原表加上一个S锁，创建过程不需要重建表（no-rebuild）；删除InnoDB二级索引只需要更新内部视图，并标记这个索引的空间可用，去掉数据库元数据上该索引的定义即可。这个过程也只允许读操作，不能写入，但大大加快了修改索引的速度（不含主键索引，InnoDB IOT的特性决定了修改主键依然需要 Copy Table ）。\nFIC只对索引的创建删除有效，MySQL 5.6 Online DDL把这种特性扩展到了添加列、删除列、修改列类型、列重命名、设置默认值等等，实际效果要看所使用的选项和操作类别来定。\n1.1 Online DDL选项 MySQL 在线DDL分为 INPLACE 和 COPY 两种方式，通过在ALTER语句的ALGORITHM参数指定。\nALGORITHM=INPLACE，可以避免重建表带来的IO和CPU消耗，保证ddl期间依然有良好的性能和并发。 ALGORITHM=COPY，需要拷贝原始表，所以不允许并发DML写操作，可读。这种copy方式的效率还是不如 inplace ，因为前者需要记录undo和redo log，而且因为临时占用buffer pool引起短时间内性能受影响。 上面只是 Online DDL 内部的实现方式，此外还有 LOCK 选项控制是否锁表，根据不同的DDL操作类型有不同的表现：默认mysql尽可能不去锁表，但是像修改主键这样的昂贵操作不得不选择锁表。\nLOCK=NONE，即DDL期间允许并发读写涉及的表，比如为了保证 ALTER TABLE 时不影响用户注册或支付，可以明确指定，好处是如果不幸该 alter语句不支持对该表的继续写入，则会提示失败，而不会直接发到库上执行。ALGORITHM=COPY默认LOCK级别 LOCK=SHARED，即DDL期间表上的写操作会被阻塞，但不影响读取。 LOCK=DEFAULT，让mysql自己去判断lock的模式，原则是mysql尽可能不去锁表 LOCK=EXCLUSIVE，即DDL期间该表不可用，堵塞任何读写请求。如果你想alter操作在最短的时间内完成，或者表短时间内不可用能接受，可以手动指定。 但是有一点需要说明，无论任何模式下，online ddl开始之前都需要一个短时间排它锁(exclusive)来准备环境，所以alter命令发出后，会首先等待该表上的其它操作完成，在alter命令之后的请求会出现等待waiting meta data lock。同样在ddl结束之前，也要等待alter期间所有的事务完成，也会堵塞一小段时间。所以尽量在ALTER TABLE之前确保没有大事务在执行，否则一样出现连环锁表。\n1.2 考虑不同的DDL操作类别 从上面的介绍可以看出，不是5.6支持在线ddl就可以随心所欲的alter table，锁不锁表要看情况：\n提示：下表根据官方 Summary of Online Status for DDL Operations 整理挑选的常用操作。\nIn-Place 为Yes是优选项，说明该操作支持INPLACE Copies Table 为No是优选项，因为为Yes需要重建表。大部分情况与In-Place是相反的 Allows Concurrent DML? 为Yes是优选项，说明ddl期间表依然可读写，可以指定 LOCK=NONE（如果操作允许的话mysql自动就是NONE） Allows Concurrent Query? 默认所有DDL操作期间都允许查询请求，放在这只是便于参考 Notes 会对前面几列Yes/No带 * 号的限制说明 Operation In-Place? Copies Table? Allows Concurrent DML? Allows Concurrent Query? Notes 添加索引 Yes* No* Yes Yes 对全文索引的一些限制 删除索引 Yes No Yes Yes 仅修改表的元数据 OPTIMIZE TABLE Yes Yes Yes Yes 从 5.6.17开始使用ALGORITHM=INPLACE，当然如果指定了old_alter_table=1或mysqld启动带--skip-new则将还是COPY模式。如果表上有全文索引只支持COPY 对一列设置默认值 Yes No Yes Yes 仅修改表的元数据 对一列修改auto-increment 的值 Yes No Yes Yes 仅修改表的元数据 添加 foreign key constraint Yes* No* Yes Yes 为了避免拷贝表，在约束创建时会禁用foreign_key_checks 删除 foreign key constraint Yes No Yes Yes foreign_key_checks 不影响 改变列名 Yes* No* Yes* Yes 为了允许DML并发, 如果保持相同数据类型，仅改变列名 添加列 Yes* Yes* Yes* Yes 尽管允许 ALGORITHM=INPLACE ，但数据大幅重组，所以它仍然是一项昂贵的操作。当添加列是auto-increment，不允许DML并发 删除列 Yes Yes* Yes Yes 尽管允许 ALGORITHM=INPLACE ，但数据大幅重组，所以它仍然是一项昂贵的操作 修改列数据类型 No Yes* No Yes 修改类型或添加长度，都会拷贝表，而且不允许更新操作 更改列顺序 Yes Yes Yes Yes 尽管允许 ALGORITHM=INPLACE ，但数据大幅重组，所以它仍然是一项昂贵的操作 修改ROW_FORMAT 和KEY_BLOCK_SIZE Yes Yes Yes Yes 尽管允许 ALGORITHM=INPLACE ，但数据大幅重组，所以它仍然是一项昂贵的操作 设置列属性NULL或NOT NULL Yes Yes Yes Yes 尽管允许 ALGORITHM=INPLACE ，但数据大幅重组，所以它仍然是一项昂贵的操作 添加主键 Yes* Yes Yes Yes 尽管允许 ALGORITHM=INPLACE ，但数据大幅重组，所以它仍然是一项昂贵的操作。 如果列定义必须转化NOT NULL，则不允许INPLACE 删除并添加主键 Yes Yes Yes Yes 在同一个 ALTER TABLE 语句删除就主键、添加新主键时，才允许inplace；数据大幅重组,所以它仍然是一项昂贵的操作。 删除主键 No Yes No Yes 不允许并发DML，要拷贝表，而且如果没有在同一 ATLER TABLE 语句里同时添加主键则会收到限制 变更表字符集 No Yes No Yes 如果新的字符集编码不同，重建表 从表看出，In-Place为No，DML一定是No，说明 ALGORITHM=COPY 一定会发生拷贝表，只读。但 ALGORITHM=INPLACEE 也要可能发生拷贝表，但可以并发DML:\n添加、删除列，改变列顺序 添加或删除主键 改变行格式ROW_FORMAT和压缩块大小KEY_BLOCK_SIZE 改变列NULL或NOT NULL 优化表OPTIMIZE TABLE 强制 rebuild 该表 不允许并发DML的情况有：修改列数据类型、删除主键、变更表字符集，即这些类型操作ddl是不能online的。\n另外，更改主键索引与普通索引处理方式是不一样的，主键即聚集索引，体现了表数据在物理磁盘上的排列，包含了数据行本身，需要拷贝表；而普通索引通过包含主键列来定位数据，所以普通索引的创建只需要一次扫描主键即可，而且是在已有数据的表上建立二级索引，更紧凑，将来查询效率更高。\n修改主键也就意味着要重建所有的普通索引。删除二级索引更简单，修改InnoDB系统表信息和数据字典，标记该所以不存在，标记所占用的表空间可以被新索引或数据行重新利用。\n1.3 在线DDL的限制 在alter table时，如果涉及到table copy操作，要确保 datadir 目录有足够的磁盘空间，能够放的下整张表，因为拷贝表的的操作是直接在数据目录下进行的。 添加索引无需table copy，但要确保 tmpdir 目录足够存下索引一列的数据（如果是组合索引，当前临时排序文件一合并到原表上就会删除） 在主从环境下，主库执行alter命令在完成之前是不会进入binlog记录事件，如果允许dml操作则不影响记录时间，所以期间不会导致延迟。然而，由于从库是单个SQL Thread按顺序应用relay log，轮到ALTER语句时直到执行完才能下一条，所以从库会在master ddl完成后开始产生延迟。（pt-osc可以控制延迟时间，所以这种场景下它更合适） During each online DDL ALTER TABLE statement, regardless of the LOCK clause, there are brief periods at the beginning and end requiring an exclusive lock on the table (the same kind of lock specified by the LOCK=EXCLUSIVE clause). Thus, an online DDL operation might wait before starting if there is a long-running transaction performing inserts, updates, deletes, or SELECT \u0026hellip; FOR UPDATE on that table; and an online DDL operation might wait before finishing if a similar long-running transaction was started while the ALTER TABLE was in progress. 在执行一个允许并发DML在线 ALTER TABLE时，结束之前这个线程会应用 online log 记录的增量修改，而这些修改是其它thread里产生的，所以有可能会遇到重复键值错误 (ERROR 1062 (23000): Duplicate entry)。 涉及到table copy时，目前还没有机制限制暂停ddl，或者限制IO阀值\n在MySQL 5.7.6开始能够通过 performance_schema 观察alter table的进度 一般来说，建议把多个alter语句合并在一起进行，避免多次table rebuild带来的消耗。但是也要注意分组，比如需要copy table和只需inplace就能完成的，应该分两个alter语句。 如果DDL执行时间很长，期间又产生了大量的dml操作，以至于超过了 innodb_online_alter_log_max_size 变量所指定的大小，会引起 DB_ONLINE_LOG_TOO_BIG 错误。默认为 128M，特别对于需要拷贝大表的alter操作，考虑临时加大该值，以此获得更大的日志缓存空间 执行完 ALTER TABLE 之后，最好 ANALYZE TABLE tb1 去更新索引统计信息 2. 实现过程 online ddl主要包括3个阶段，prepare阶段，ddl执行阶段，commit阶段，rebuild方式比no-rebuild方式实质多了一个ddl执行阶段，prepare阶段和commit阶段类似。下面将主要介绍ddl执行过程中三个阶段的流程。\n** Prepare阶段 ** : 创建新的临时frm文件(与InnoDB无关) 持有EXCLUSIVE-MDL锁，禁止读写 根据alter类型，确定执行方式(copy,online-rebuild,online-norebuild) 假如是Add Index，则选择online-norebuild即INPLACE方式 更新数据字典的内存对象 分配row_log对象记录增量(仅rebuild类型需要) 生成新的临时ibd文件(仅rebuild类型需要) ** ddl执行阶段 ** : 降级EXCLUSIVE-MDL锁，允许读写 扫描old_table的聚集索引每一条记录rec 遍历新表的聚集索引和二级索引，逐一处理 根据rec构造对应的索引项 将构造索引项插入sort_buffer块排序 将sort_buffer块更新到新的索引上 记录ddl执行过程中产生的增量(仅rebuild类型需要) 重放row_log中的操作到新索引上(no-rebuild数据是在原表上更新的) 重放row_log间产生dml操作append到row_log最后一个Block ** commit阶段 ** : 当前Block为row_log最后一个时，禁止读写，升级到EXCLUSIVE-MDL锁 重做row_log中最后一部分增量 更新innodb的数据字典表 提交事务(刷事务的redo日志) 修改统计信息 rename临时idb文件，frm文件 变更完成 这有一直导图挺直观的：http://blog.itpub.net/22664653/viewspace-2056953 。 添加列 时由于需要copy table，row_log会重放到新表上（临时ibd文件），直到最后一个block，锁住原表禁止更新。\nrow_log记录了ddl变更过程中新产生的dml操作，并在ddl执行的最后将其应用到新的表中，保证数据完整性\n3. 对比实验 3.1 添加二级索引 我这里使用sysbench产生的表测试（500w数据）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 mysql\u0026gt; select version(); +------------+ | version() | +------------+ | 5.6.30-log | +------------+ 1 row in set (0.00 sec) mysql\u0026gt; show create table sbtest1; CREATE TABLE `sbtest1` ( `id` int(10) unsigned NOT NULL AUTO_INCREMENT, `k` int(10) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39;, `c` char(120) COLLATE utf8_bin NOT NULL DEFAULT \u0026#39;\u0026#39;, `pad` char(60) COLLATE utf8_bin NOT NULL DEFAULT \u0026#39;\u0026#39;, PRIMARY KEY (`id`), KEY `k_1` (`k`) ) ENGINE=InnoDB AUTO_INCREMENT=5000001 DEFAULT CHARSET=utf8 COLLATE=utf8_bin MAX_ROWS=1000000 mysql\u0026gt; show variables like \u0026#34;old_alter_table\u0026#34;; +-----------------+-------+ | Variable_name | Value | +-----------------+-------+ | old_alter_table | OFF | +-----------------+-------+ 1 row in set (0.00 sec) ** 旧模式 ** 下，创建删除普通索引：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 **SESSION1:** mysql\u0026gt; set old_alter_table=1; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; alter table sbtest1 drop index idx_k_1; Query OK, 5000000 rows affected (44.79 sec) Records: 5000000 Duplicates: 0 Warnings: 0 mysql\u0026gt; alter table sbtest1 add index idx_k_1(k); Query OK, 5000000 rows affected (1 min 11.29 sec) Records: 5000000 Duplicates: 0 Warnings: 0 **SESSION2:** mysql\u0026gt; select * from sbtest1 limit 1; +----+---------+-------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------+ | id | k | c | pad | +----+---------+-------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------+ | 1 | 2481886 | 08566691963-88624...106334-50535565977 | 63188288836-9235114...351-49282961843 | +----+---------+-------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------+ 1 row in set (0.00 sec) mysql\u0026gt; update sbtest1 set k=2481885 where id=1; Query OK, 1 row affected (45.16 sec) Rows matched: 1 Changed: 1 Warnings: 0 **SESSION3:** mysql\u0026gt; show processlist; +--------+-----------------+-----------+------------+---------+--------+---------------------------------+-----------------------------------------+ | Id | User | Host | db | Command | Time | State | Info | +--------+-----------------+-----------+------------+---------+--------+---------------------------------+-----------------------------------------+ | 118652 | root | localhost | confluence | Query | 19 | copy to tmp table | alter table sbtest1 add index k_1(k) | | 118666 | root | localhost | confluence | Query | 3 | Waiting for table metadata lock | update sbtest1 set k=2481885 where id=1 | | 118847 | root | localhost | NULL | Query | 0 | init | show processlist | +--------+-----------------+-----------+------------+---------+--------+---------------------------------+-----------------------------------------+ 4 rows in set (0.00 sec) 同时在datadir目录下可以看到 -rw-rw---- 1 mysql mysql 8.5K May 23 21:24 sbtest1.frm -rw-rw---- 1 mysql mysql 1.2G May 23 21:24 sbtest1.ibd -rw-rw---- 1 mysql mysql 8.5K May 23 20:48 #sql-1c6a_1cf7c.frm -rw-rw---- 1 mysql mysql 638M May 23 20:48 #sql-1c6a_1cf7c.ibd 传统ddl方式有 copy to tmp table 过程，dml更新操作期间被堵住45s：Waiting for table metadata lock。\n下面改成 Online DDL方式\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 **SESSION1** mysql\u0026gt; set old_alter_table=0; mysql\u0026gt; alter table sbtest1 drop index k_1; Query OK, 0 rows affected (0.01 sec) Records: 0 Duplicates: 0 Warnings: 0 索引秒删 mysql\u0026gt; alter table sbtest1 add index k_1(k); Query OK, 0 rows affected (13.99 sec) Records: 0 Duplicates: 0 Warnings: 0 **SESSION2** mysql\u0026gt; update sbtest1 set k=2481887 where id=1; Query OK, 1 row affected (0.00 sec) Rows matched: 1 Changed: 1 Warnings: 0 **SESSION3** mysql\u0026gt; show processlist; +--------+-----------------+-----------+------------+---------+--------+------------------------+--------------------------------------+ | Id | User | Host | db | Command | Time | State | Info | +--------+-----------------+-----------+------------+---------+--------+------------------------+--------------------------------------+ | 118652 | root | localhost | confluence | Query | 10 | altering table | alter table sbtest1 add index k_1(k) | | 118666 | root | localhost | confluence | Sleep | 9 | | NULL | | 118847 | root | localhost | NULL | Query | 0 | init | show processlist | +--------+-----------------+-----------+------------+---------+--------+------------------------+--------------------------------------+ 4 rows in set (0.00 sec) 添加普通索引，并未出现阻塞update操作，而且速度更快。从 rows affected 可以看出有没有copy table。\n但如果在alter之前有大事务在执行，** 会阻塞 ** ddl以及后续的所有请求：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 **SESSION1** mysql\u0026gt; select * from sbtest1 where c=\u0026#39;long select before alter\u0026#39;; Empty set (4.36 sec) **SESSION2** mysql\u0026gt; alter table sbtest1 add index k_1(k); Query OK, 0 rows affected (16.28 sec) Records: 0 Duplicates: 0 Warnings: 0 **SESSION3** mysql\u0026gt; select * from sbtest1 where c=\u0026#39;long select after alter execution but not complete\u0026#39;; Empty set (5.89 sec) **SESSION4** mysql\u0026gt; show processlist; +----+-----------------+-----------+------------+---------+------+---------------------------------+------------------------------------------------------------------------------------+ | Id | User | Host | db | Command | Time | State | Info | +----+-----------------+-----------+------------+---------+------+---------------------------------+------------------------------------------------------------------------------------+ | 5 | root | localhost | confluence | Query | 3 | Sending data | select * from sbtest1 where c=\u0026#39;long select before alter\u0026#39; | | 7 | root | localhost | NULL | Query | 0 | init | show processlist | | 13 | root | localhost | confluence | Query | 2 | Waiting for table metadata lock | alter table sbtest1 add index k_1(k) | | 14 | root | localhost | confluence | Query | 1 | Waiting for table metadata lock | select * from sbtest1 where c=\u0026#39;long select after alter execution but not complete\u0026#39; | +----+-----------------+-----------+------------+---------+------+---------------------------------+------------------------------------------------------------------------------------+ 5 rows in set (0.00 sec) 3.2 添加列示例 添加新列是ddl操作里面相对较多的一类操作。从上文表中可以看到\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 **SESSION1** mysql\u0026gt; ALTER TABLE `sbtest2` \\ ADD COLUMN `f_new_col1` int(11) NULL DEFAULT 0, \\ ADD COLUMN `f_new_col2` varchar(32) NULL DEFAULT \u0026#39;\u0026#39; AFTER `f_new_col1`; Query OK, 0 rows affected (1 min 57.86 sec) Records: 0 Duplicates: 0 Warnings: 0 **SESSION2** mysql\u0026gt; update sbtest2 set c=\u0026#34;update when add colomun ddl start\u0026#34; where c=\u0026#39;33333\u0026#39;; Query OK, 0 rows affected (4.41 sec) Rows matched: 0 Changed: 0 Warnings: 0 **SESSION3** mysql\u0026gt; select * from sbtest2 where c=\u0026#39;select when add colomun ddl start\u0026#39;; Empty set (3.44 sec) **SESSION4** mysql\u0026gt; show processlist; +-----+-----------------+-----------+------------+---------+------+---------------------------+------------------------------------------------------------------------------------------------------+ | Id | User | Host | db | Command | Time | State | Info | +-----+-----------------+-----------+------------+---------+------+---------------------------+------------------------------------------------------------------------------------------------------+ | 5 | root | localhost | confluence | Query | 4 | altering table | ALTER TABLE `sbtest2` ADD COLUMN `f_new_col1` int(11) NULL DEFAULT 0, ADD COLUMN `f_new_col2` varch | | 7 | root | localhost | NULL | Query | 0 | init | show processlist | | 161 | root | localhost | confluence | Query | 2 | Searching rows for update | update sbtest2 set c=\u0026#34;update when add colomun ddl start\u0026#34; where c=\u0026#39;33333\u0026#39; | | 187 | root | localhost | confluence | Query | 1 | Sending data | select * from sbtest2 where c=\u0026#39;select when add colomun ddl start\u0026#39; | +-----+-----------------+-----------+------------+---------+------+---------------------------+------------------------------------------------------------------------------------------------------+ 5 rows in set (0.00 sec) 看到，默认不加 ALGORITHM=INPLACE 就已经允许ddl期间并发DML操作。但是会有一个小临时文件产生：\n1 2 -rw-rw---- 1 mysql mysql 8.6K May 23 21:42 #sql-7055_5.frm -rw-rw---- 1 mysql mysql 112K May 23 21:42 #sql-ib21-16847116.ibd 当指定copy时，就会锁表了（一般你不想这样做）：\n1 2 ALTER TABLE `sbtest2` DROIP COLUMN `f_new_col1`, algorithm=copy; 3.3 修改字段类型 修改列类型与添加新列不一样，修改类型需要rebuild整个表： (select ok, update waiting)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 **SESSION1** mysql\u0026gt; ALTER TABLE sbtest2 CHANGE f_new_col2 f_new_col2 varchar(50) NULL DEFAULT \u0026#39;\u0026#39;, algorithm=inplace ; ERROR 1846 (0A000): ALGORITHM=INPLACE is not supported. Reason: Cannot change column type INPLACE. Try ALGORITHM=COPY. 不支持INPLACE mysql\u0026gt; ALTER TABLE sbtest2 CHANGE f_new_col2 f_new_col2 varchar(50) NULL DEFAULT \u0026#39;\u0026#39;; **SESSION2** mysql\u0026gt; update sbtest2 set c=\u0026#34;update when add colomun ddl start\u0026#34; where c=\u0026#39;33333\u0026#39;; mysql\u0026gt; select * from sbtest2 where c=\u0026#39;select when add colomun ddl start\u0026#39;; Empty set (3.79 sec) mysql\u0026gt; show processlist; +-----+-----------------+-----------+------------+---------+------+---------------------------------+----------------------------------------------------------------------------------+ | Id | User | Host | db | Command | Time | State | Info | +-----+-----------------+-----------+------------+---------+------+---------------------------------+----------------------------------------------------------------------------------+ | 5 | root | localhost | confluence | Query | 5 | copy to tmp table | ALTER TABLE sbtest2 CHANGE f_new_col2 f_new_col2 varchar(50) NULL DEFAULT \u0026#39;\u0026#39; | | 7 | root | localhost | NULL | Query | 0 | init | show processlist | | 161 | root | localhost | confluence | Query | 4 | Waiting for table metadata lock | update sbtest2 set c=\u0026#34;update when add colomun ddl start\u0026#34; where c=\u0026#39;33333\u0026#39; | | 187 | root | localhost | confluence | Query | 3 | Sending data | select * from sbtest2 where c=\u0026#39;select when add colomun ddl start\u0026#39; | +-----+-----------------+-----------+------------+---------+------+---------------------------------+----------------------------------------------------------------------------------+ 5 rows in set (0.00 sec) 3.4 Waiting for table metadata lock Online DDL看起来很美好，实验测试也正如预期，但几次在生产环境修改索引时（5000w的表），还是无法避免出现大量 Waiting for table metadata lock 锁等待，线程数持续增加并告警，导致长达十多分钟不可写。后来发现原来是 5.6.16 版本开始mysql对日期、时间类型的存储格式进行了改动，会导致日期类型的表在升级前后，第一次alter必须rebuild：（地址）\n1 2 3 4 5 6 7 As of MySQL 5.6.16, ALTER TABLE upgrades old temporal columns to 5.6 format for ADD COLUMN, CHANGE COLUMN, MODIFY COLUMN, ADD INDEX, and FORCE operations. Hence, the following statement upgrades a table containing columns in the old format: ALTER TABLE tbl_name FORCE; This conversion cannot be done using the INPLACE algorithm because the table must be rebuilt, so specifying ALGORITHM=INPLACE in these cases results in an error. Specify ALGORITHM=COPY if necessary. 关于 metadata lock 介绍参考云栖 这系列文章。\n4. 参考 MySQL online ddl原理 MySQL 5.6 Online DDL [MySQL 5.6] MySQL 5.6 online ddl 使用、测试及关键函数栈 MySQL Manual Overview of Online DDL MySQL InnoDB Add Index实现调研(一：Inplace Add Index) tencentDBA 实现的在线加字段 原文链接地址：http://xgknight.com/2016/05/24/mysql-online-ddl-concept/\n","permalink":"http://localhost:1313/2016/05/mysql-online-ddl-concept/","summary":"\u003cp\u003e做MySQL的都知道，数据库操作里面，DDL操作（比如CREATE,DROP,ALTER等）代价是非常高的，特别是在单表上千万的情况下，加个索引或改个列类型，就有可能堵塞整个表的读写。\u003c/p\u003e","title":"mysql 5.6 原生Online DDL解析"},{"content":"最近在排查现网Text与Blob类型，发现有不少，在《高性能MySQL(第3版)》看到对这两种变长数据类型的处理会涉及到在磁盘上创建临时表，性能开销比较大。于是把影响blob型数据存储方式了解了一下：row_format。\n1. InnoDB的Antelop与Barracuda文件格式 Innodb存储引擎保存记录，是以行的形式存放的（与之对应的是像Google BigTable这种列数据库）。在InnoDB 1.0.x版本之前，InnoDB 存储引擎提供了 Compact 和 Redundant 两种格式来存放行记录数据，这也是目前使用最多的一种格式。Redundant 格式是为兼容之前版本而保留的。\nMySQL 5.1 中的 innodb_plugin 引入了新的文件格式：Barracuda（将以前的行格式 compact 和 redundant 合称为Antelope），该文件格式拥有新的两种行格式：compressed和dynamic。\n在 MySQL 5.6 版本中，默认还是 Compact 行格式，也是目前使用最多的一种 ROW FORMAT。用户可以通过命令 SHOW TABLE STATUS LIKE'table_name' 来查看当前表使用的行格式，其中 row_format 列表示当前所使用的行记录结构类型。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 mysql\u0026gt; show variables like \u0026#34;innodb_file_format\u0026#34;; +--------------------+-----------+ | Variable_name | Value | +--------------------+-----------+ | innodb_file_format | Barracuda | +--------------------+-----------+ 1 row in set mysql\u0026gt; show table status like \u0026#34;tablename%\u0026#34;\\G *************************** 1. row *************************** Name: t_rf_compact Engine: InnoDB Version: 10 Row_format: Compact Rows: 4 Avg_row_length: 36864 Data_length: 147456 Max_data_length: 0 Index_length: 0 Data_free: 0 Auto_increment: 7 Create_time: 2016-05-14 20:52:58 Update_time: NULL Check_time: NULL Collation: utf8_general_ci Checksum: NULL Create_options: Comment: 1 row in set (0.00 sec) 在 msyql 5.7.9 及以后版本，默认行格式由innodb_default_row_format变量决定，它的默认值是DYNAMIC，也可以在 create table 的时候指定ROW_FORMAT=DYNAMIC。\n注意，如果要修改现有表的行模式为compressed或dynamic，必须先将文件格式设置成Barracuda：set global innodb_file_format=Barracuda;，再用ALTER TABLE tablename ROW_FORMAT=COMPRESSED;去修改才能生效，否则修改无效却无提示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 mysql\u0026gt; ALTER TABLE tablename ROW_FORMAT=COMPRESSED; Query OK, 0 rows affected Records: 0 Duplicates: 0 Warnings: 2 修改失败 mysql\u0026gt; show warnings; +---------+------+-----------------------------------------------------------------------+ | Level | Code | Message | +---------+------+-----------------------------------------------------------------------+ | Warning | 1478 | InnoDB: ROW_FORMAT=COMPRESSED requires innodb_file_format \u0026gt; Antelope. | | Warning | 1478 | InnoDB: assuming ROW_FORMAT=COMPACT. | +---------+------+-----------------------------------------------------------------------+ 2 rows in set 2. 对TEXT/BLOB这类大字段类型的影响 2.1 compact 在 Antelope 两种行格式下，如果blob列值长度 \u0026lt;= 768 bytes，就不会发生行溢出(page overflow)，内容都在数据页(B-tree Node)；如果列值长度 \u0026gt; 768字节，那么前768字节依然在数据页，而剩余的则放在溢出页(off-page)，如下图：\n上面所讲的讲的blob或变长大字段类型包括blob,text,varchar，其中varchar列值长度大于某数N时也会存溢出页，在latin1字符集下N值可以这样计算：innodb的块大小默认为16kb，由于innodb存储引擎表为索引组织表，树底层的叶子节点为一双向链表，因此每个页中至少应该有两行记录，这就决定了innodb在存储一行数据的时候不能够超过8k，减去其它列值所占字节数，约等于N。\n我们知道对于InnoDB来说，内存是极为珍贵的，如果把768字节长度的blob都放在数据页，虽然可以节省部分IO，但相对来说能缓存行数就变少，也就是能缓存的索引值变少了，降低了索引效率。\n2.2 dynamic Barracuda 的两种行格式对blob采用完全行溢出，即聚集索引记录（数据页）只保留20字节的指针，指向真实存放它的溢出段地址： dynamic行格式，列存储是否放到off-page页，主要取决于行大小，它会把行中最长的那一列放到off-page，直到数据页能存放下两行。TEXT/BLOB列 \u0026lt;=40 bytes 时总是存放于数据页。这种方式可以避免compact那样把太多的大列值放到 B-tree Node，因为dynamic格式认为，只要大列值有部分数据放在off-page，那把整个值放入都放入off-page更有效。\ncompressed 物理结构上与dynamic类似，但是对表的数据行使用zlib算法进行了压缩存储。在long blob列类型比较多的情况下用，可以降低off-page的使用，减少存储空间（一般40%左右），但要求更高的CPU，buffer pool里面可能会同时存储数据的压缩版和非压缩版，所以也多占用部分内存。这里 MySQL 5.6 Manual innodb-compression-internals 讲的十分清楚。\n另外，由于ROW_FORMAT=DYNAMIC 和 ROW_FORMAT=COMPRESSED 是从 ROW_FORMAT=COMPACT 变化来的，所以他们处理 CHAR类型存储的方式和 COMPACT 一样。\n3. 对blob型字段存取优化 如果一个查询涉及BLOB值，又需要使用临时表——不管它多小——它都会立即在磁盘上创建临时表。这样效率很低，尤其是对小而快的查询，临时表可能是查询中最大的开销。\n比如：创建一个带Text字段的compact表：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 mysql\u0026gt; CREATE TABLE `t_rf_compact` ( `f_id` int(11) NOT NULL AUTO_INCREMENT, `f_char` char(30) DEFAULT NULL, `f_varchar` varchar(30) NOT NULL DEFAULT \u0026#39;\u0026#39;, `f_text` text NOT NULL, PRIMARY KEY (`f_id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 ROW_FORMAT=COMPACT; mysql\u0026gt; insert into t_rf_compact(f_char,f_varchar,f_text) values(\u0026#39;aa\u0026#39;,\u0026#39;中中\u0026#39;,repeat(\u0026#39;b\u0026#39;,700)); mysql\u0026gt; insert into t_rf_compact(f_char,f_varchar,f_text) values(\u0026#39;aa\u0026#39;,\u0026#39;文\u0026#39;,repeat(\u0026#39;c\u0026#39;,60000)); 第二条数据会行溢出，前768字节放在Clustered Index数据页，剩余的放扩展存储空间 mysql\u0026gt; explain select t1.f_id from t_rf_compact t1,t_rf_compact t2 where t1.f_id=t2.f_id order by t1.f_id limit 1; +----+-------------+-------+--------+---------------+---------+---------+-------------------+------+-------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+-------------+-------+--------+---------------+---------+---------+-------------------+------+-------------+ | 1 | SIMPLE | t1 | index | PRIMARY | PRIMARY | 4 | NULL | 6 | Using index | | 1 | SIMPLE | t2 | eq_ref | PRIMARY | PRIMARY | 4 | d_ec_crm2.t1.f_id | 1 | Using index | +----+-------------+-------+--------+---------------+---------+---------+-------------------+------+-------------+ 2 rows in set (0.00 sec) mysql\u0026gt; show status like \u0026#34;%tmp%tables\u0026#34;; +-------------------------+-------+ | Variable_name | Value | +-------------------------+-------+ | Created_tmp_disk_tables | 7 | | Created_tmp_tables | 36 | +-------------------------+-------+ 2 rows in set (0.00 sec) mysql\u0026gt; select t1.f_id from t_rf_compact t1,t_rf_compact t2 where t1.f_id=t2.f_id order by t1.f_id limit 1; +------+ | f_id | +------+ | 1 | +------+ 1 row in set (0.00 sec) mysql\u0026gt; show status like \u0026#34;%tmp%tables\u0026#34;; +-------------------------+-------+ | Variable_name | Value | +-------------------------+-------+ | Created_tmp_disk_tables | 7 | | Created_tmp_tables | 36 | +-------------------------+-------+ 2 rows in set (0.00 sec) 没有临时表产生，所以磁盘临时表无变化。让它产生临时表：（但不涉及text列）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 mysql\u0026gt; explain select t1.f_id from t_rf_compact t1,t_rf_compact t2 where t1.f_id=t2.f_id order by t2.f_id; +----+-------------+-------+--------+---------------+---------+---------+-------------------+------+----------------------------------------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+-------------+-------+--------+---------------+---------+---------+-------------------+------+----------------------------------------------+ | 1 | SIMPLE | t1 | index | PRIMARY | PRIMARY | 4 | NULL | 6 | Using index; Using temporary; Using filesort | | 1 | SIMPLE | t2 | eq_ref | PRIMARY | PRIMARY | 4 | d_ec_crm2.t1.f_id | 1 | Using index | +----+-------------+-------+--------+---------------+---------+---------+-------------------+------+----------------------------------------------+ 2 rows in set (0.00 sec) mysql\u0026gt; select t1.f_id from t_rf_compact t1,t_rf_compact t2 where t1.f_id=t2.f_id order by t2.f_id; mysql\u0026gt; show status like \u0026#34;%tmp%tables\u0026#34;; +-------------------------+-------+ | Variable_name | Value | +-------------------------+-------+ | Created_tmp_disk_tables | 7 | | Created_tmp_tables | 37 | +-------------------------+-------+ 2 rows in set (0.00 sec) 虽然有Using temporary，但内存临时表还是够用，磁盘临时表还是无变化。返回TEXT列（也会使用临时表排序）：\n1 2 3 4 5 6 7 8 9 mysql\u0026gt; select t1.f_text from t_rf_compact t1,t_rf_compact t2 where t1.f_id=t2.f_id order by t2.f_id; mysql\u0026gt; show status like \u0026#34;%tmp%tables\u0026#34;; +-------------------------+-------+ | Variable_name | Value | +-------------------------+-------+ | Created_tmp_disk_tables | 8 | | Created_tmp_tables | 38 | +-------------------------+-------+ 2 rows in set (0.00 sec) Created_tmp_disk_tables磁盘临时表有增加，与上面结论相符：只有有TEXT/BLOB列参与，如果用到临时表，不管它多小，都会创建在磁盘上，从而带来性能消耗。\n注：磁盘临时表存储引擎一定是 MyISAM，与select @@default_tmp_storage_engine;（5.6.3开始）看到的InnoDB无关，它是控制CREATE TEMPORARY TABLE时的默认引擎。在 5.7.5 开始internal_tmp_disk_storage_engine选项可以定义磁盘临时表的引擎类型。关于临时表与内存表可以参考 [MySQL FAQ]系列 — 什么情况下会用到临时表 -老叶 。\n有两种办法来减轻这种不利的情况：通过 SUBSTRING() 函数把值转换为 VARCHAR，或者让磁盘临时表更快一些。\n让磁盘临时表运行更快的方式是，把它们放在基于内存的文件系统tmpfs，tmpfs文件系统为了降低开销不会刷新内存数据到磁盘，读写速度也很快，而临时表也不需要持久存放。mysql的 tmpdir 参数控制临时文件存放位置，建议如果使用的话要监控空间使用率。另外如果BLOB列非常大或多，可以考虑调大InnoDB日志缓存大小innodb_log_buffer_size。\n如果使用BLOB这类变长大字段类型，需要以下后果考虑：\n大字段在InnoDB里可能浪费大量空间。例如，若存储字段值只是比行的要求多了一个字节，也会使用整个页面来存储剩下的字节，浪费了页面的大部分空间。同样的，如果有一个值只是稍微超过了32个页的大小，实际上就需要使用96个页面。 扩展存储禁用了自适应哈希，因为需要完整的比较列的整个长度，才能发现是不是正确的数据（哈希帮助InnoDB非常快速的找到“猜测的位置”，但是必须检查“猜测的位置”是不是正确）。因为自适应哈希是完全的内存结构，并且直接指向Buffer Pool中访问“最”频繁的页面，但对于扩展存储空间却无法使用Adaptive Hash。 太长的值可能使得在查询中作为WHERE条件不能使用索引，因而执行很慢。在应用WHERE条件之前，MySQL需要把所有的列读出来，所以可能导致MySQL要求InnoDB读取很多扩展存储，然后检查WHERE条件，丢弃所有不需要的数据。查询不需要的列绝对不是好主意，在这种特殊的场景下尤其需要避免这样做。如果发现查询正遇到这个限制带来的问题，可以尝试通过覆盖索引来解决部分问题。 如果一张表里有很多大字段，最好是把它们组合起来单独存到一个列里面，比如说用XML文档格式存储。这让所有的大字段共享一个扩展存储空间，这比每个字段用自己的页要好。 有时候可以把大字段用COMPRESS()压缩后再存为BLOB，或者在发送到MySQL前在应用程序中进行压缩，这可以获得显著的空间优势和性能收益。 —— 《高性能MySQL(第3版)》 P368 对上面的解读就是：\n如果预期长度范围varchar就满足，就避免使用TEXT 对于字段非常大的列可以在应用程序里压缩后再存到mysql，如果列值很长请考虑用单独的表存放 一张表有多个类blob字段，把它们组合起来如\u0026lt;TEXT\u0026gt;\u0026lt;f_big_col1\u0026gt;long..\u0026lt;/f_big_col1\u0026gt; \u0026lt;f_content\u0026gt;long..\u0026lt;/f_content\u0026gt;\u0026lt;/TEXT\u0026gt;，再压缩存储。但要考虑是否使用全文索引，是否需要前缀索引。 参考 MySQL 大字段溢出导致数据回写失败\ninnodb使用大字段text，blob的一些优化建议 -玄惭\n[MySQL优化案例]系列 — 优化InnoDB表BLOB列的存储效率 -老叶\nInnoDB 数据表压缩原理与限制 MySQL Manual DYNAMIC and COMPRESSED Row Formats 《MySQL技术内幕·InnoDB存储引擎》 P\n原文链接地址：http://xgknight.com/2016/05/18/mysql-blob-row_format/\n","permalink":"http://localhost:1313/2016/05/mysql-blob-row_format/","summary":"\u003cp\u003e最近在排查现网Text与Blob类型，发现有不少，在《高性能MySQL(第3版)》看到对这两种变长数据类型的处理会涉及到在磁盘上创建临时表，性能开销比较大。于是把影响blob型数据存储方式了解了一下：row_format。\u003c/p\u003e","title":"InnoDB行格式对text/blob大变长字段的影响"},{"content":"关于MySQL InnoDB表的主键设计，有必要从开发规范 http://xgknight.com/2016/05/11/mysql-dev-principle-ec/ 里拿出来，单独展开说一下。 InnoDB是一个聚集索引组织表，即行数据是按照聚集索引在物理磁盘上存储的，并且是块状结构，默认一个block是16kB。\n图片来《高性能MySQL》\n首先在设计表结构时，表一定要显式定义主键，自增主键，或者联合主键，或全局ID。 （所有与主键，包括其它索引，相关的字段，都要定义为NOT NULL，这是因为如果允许NULL，那么在索引的每条记录上，都要多用一个标记去记录这个列是否是NULL，占用多余的存储空间）\n1. 自增主键特性 对于高并发的插入速度较快，因为每次插入新记录，都是在之前记录的右边顺序插入，不需要频繁的分裂。 表上要建立多个二级索引时，索引记录都会带上主键，根据主键去定位行数据。自增主键一般是int或bigint型，多个二级索引上面占用的空间较小。\n2. 联合主键特性 每次新记录插入，都要寻找到合适的“缝隙”，插入，当插入位置空间不够时，需要做页分裂，这个需要维护成本。 二级索引带上的主键值，是联合主键的总长度，所以一个单列索引占用的空间里面，主键部分占了大部分，空间利用率不高，而且这种是 optimize table 解决不了的。 （提示：聚集索引叶子节点，就是行数据本身，所以，不需要另外的空间存储主键）\n但是联合主键有一个好处：逻辑上一批数据，在物理上很有可能相邻存储，有可能检索的数据，在一个block里面，减少了读取并缓存磁盘块的数量，一个是速度的提升，一个是减小内存的消耗。 比如 (f_c_id,f_m_id,f_type) 作为联合主键，f_c_id=22299有20w条记录，每条记录平均160bytes，一个页能存16kB，即100条记录（不考虑预留），那么f_c_id=22299需要2000个page，而且是相邻的page。\n举例，应用检索数据 f_c_id=22299, f_m_id IN(12345,23456) ，假设数据在块1和块10，缓存到内存。不多久检索f_c_id=22299, f_m_id=12399，刚好在块1。\n如果是自增id，那么就没有这个顺序， 而是根据插入数据时间来的，那么这两条记录可能在物理上很远的地方，要多读取磁盘。\n3. 全局ID 全局ID跟自增ID特性基本相同，但是它的值是从另外的服务获取的数字增长类型，不要UUID。\n只在有分库（一般有全局统计需求），或其它可能需要全局唯一性的情况下，才使用，否则没必要引入多余的服务依赖。\n另外，定义全局ID时，注意字段范围要满足要求，小心溢出；不要加上多余的 AUTO_INCREMENT 定义。\n使用全局id还有一个好处：在做数据迁移或拆库时，可以无缝切换，因为新旧数据id不用担心重复。\n4. 设计原则：自增主键 VS 联合主键 所有索引字段，特别主键，无论自增或联合主键，一定定义为 not null 表没有特殊情况下，都使用自增主键，尽量不用联合主键 特别是“可能作为联合主键”里面有的字段，会频繁update的情况，更不能做联合主键 在业务层具有唯一性的属性，如果不依赖于数据库的唯一索引来编码，也不用使用Unique Key。如果需要数据库维护唯一性，可使用Unique Key，比如将上面的联合主键定义为联合索引，再另外定义一个自增主键 如果表上有一个单列字段，已具有唯一性，可直接定义成主键，不必设置自增id 尽量用int或bigint型，如果不能，也要控制主键varchar列的长度在30以内。不要用带汉字或url类似的字段作为主键 根据上面的顺序走完，还是想用联合主键的，以下任意条件满足，可用： 表上的插入数据并发量不高 有明显的上文【联合主键】部分说到的，热点数据相邻存储的场景 出了联合主键外，其它索引的只有1-2个 与DBA协商后同意 参考： http://imysql.com/2015/10/29/mysql-faq-clustered-index.shtml\n原文连接地址：http://xgknight.com/2016/05/13/mysql-innodb-primary_key/\n","permalink":"http://localhost:1313/2016/05/mysql-innodb-primary_key/","summary":"\u003cp\u003e关于MySQL InnoDB表的主键设计，有必要从开发规范 \u003ca href=\"http://xgknight.com/2016/05/11/mysql-dev-principle-ec/\"\u003ehttp://xgknight.com/2016/05/11/mysql-dev-principle-ec/\u003c/a\u003e 里拿出来，单独展开说一下。\nInnoDB是一个聚集索引组织表，即行数据是按照聚集索引在物理磁盘上存储的，并且是块状结构，默认一个block是16kB。\u003c/p\u003e","title":"InnoDB表主键设计方案"},{"content":"updated: 2017-11-12 本文所提规范，在我博客上可以找到多篇案例。\n最近一段时间一边在线上抓取SQL来优化，一边在整理这个开发规范，尽量减少新的问题SQL进入生产库。今天也是对公司的开发做了一次培训，PPT就不放上来了，里面有十来个生产SQL的案例。因为规范大部分还是具有通用性，所以也借鉴了像去哪儿和赶集的规范，但实际在撰写本文的过程中，每一条规范的背后无不是在工作中有参照的反面例子的。如果时间可以的话，会抽出一部分或分析其原理，或用案例证明。\n1. 命名规范 库名、表名、字段名必须使用小写字母，并采用下划线分割 MySQL有配置参数lower_case_table_names=1，即库表名以小写存储，大小写不敏感。如果是0，则库表名以实际情况存储，大小写敏感；如果是2，以实际情况存储，但以小写比较。 如果大小写混合使用，可能存在abc，Abc，ABC等多个表共存，容易导致混乱。 字段名显示区分大小写，但实际使⽤时不区分，即不可以建立两个名字一样但大小写不一样的字段。 为了统一规范， 库名、表名、字段名使用小写字母，不允许 - 号。 库名以 d_ 开头，表名以 t_ 开头，字段名以 f_ 开头 比如表 t_crm_relation，中间的 crm 代表业务模块名 库名，如果不是分库，两个不同db实例里面的db名，不能相同，以免混淆 视图以view_开头，事件以event_开头，触发器以trig_开头，存储过程以proc_开头，函数以func_开头 普通索引以idx_col1_col2命名，唯一索引以uk_col1_col2命名（可去掉f_公共部分）。如 idx_companyid_corpid_contacttime(f_company_id,f_corp_id,f_contact_time) 如果某些特殊情况需要在sql里面指定索引，select * from t_test using index(idx_i_abc)，这种所以如果可以，命名的时候加上 i 分隔，如idx_i_corpid, uk_i_user，方便DBA在修改索引的时候会注意到这个 i 标识，不能随意修改这个索引(名称)，否则查询会出错。当然这种情况尽量不要出现。 库名、表名、字段名禁止超过32个字符，需见名知意 库名、表名、字段名支持最多64个字符，但为了统一规范、易于辨识以及减少传输量，禁止超过32个字符\n临时用的库、表名须以tmp位前缀，日期为后缀 如 tmp_t_crm_relation_0425。备份表也类似，形如 bak_t_xxxx_20160425 ，这样便于查找和知道有效期。 正常业务里用的临时表、中间表，后缀尽量不要包含 tmp 命名，以免造成歧义。\n按日期时间分表须符合_YYYY[MM][DD]格式 这也是为将来有可能分表做准备的，比如t_crm_ec_record_201403，但像 t_crm_contact_at201506就打破了这种规范。 不具有时间特性的，直接以 t_tbname_001 这样的方式命名。\n2. 库表基础规范 使用Innodb存储引擎 5.5版本开始mysql默认存储引擎就是InnoDB，5.7版本开始，系统表都放弃MyISAM了。\n表字符集统一使用UTF8MB4 UTF8字符集存储汉字占用3个字节，存储英文字符占用一个字节 校对字符集使用默认的 utf8mb4_general_ci。特别对于使用GUI设计表结构时，要检查它生成的sql定义 连接的客户端也使用utf8，建立连接时指定charset或SET NAMES UTF8;。（对于已经在项目中长期使用latin1的，救不了了） 如果遇到EMOJ等表情符号的存储需求，可申请使用UTF8MB4字符集 所有表都要添加注释 尽量给字段也添加注释 类status型需指明主要值的含义，如\u0026quot;0-离线，1-在线\u0026quot; 控制单表字段数量 单表字段数上限30左右，再多的话考虑垂直分表，一是冷热数据分离，二是大字段分离，三是常在一起做条件和返回列的不分离。 表字段控制少而精，可以提高IO效率，内存缓存更多有效数据，从而提高响应速度和并发能力，后续 alter table 也更快。 所有表都必须要显式指定主键 主键尽量采用自增方式，InnoDB表实际是一棵索引组织表，顺序存储可以提高存取效率，充分利用磁盘空间。还有对一些复杂查询可能需要自连接来优化时需要用到。 只有需要全局唯一主键时，使用外部自增id服务 如果没有主键或唯一索引，update/delete是通过所有字段来定位操作的行，相当于每行就是一次全表扫描 少数情况可以使用联合唯一主键，需与DBA协商 对于主键字段值是从其它地方插入（非自己使用AUTO_INCREMENT生产），去掉auto_increment定义。比如一些31天表、历史月份表上，不要auto_increment属性；再必须全局id服务获取的主键。 不强制使用外键参考 即使2个表的字段有明确的外键参考关系，也不使用 FOREIGN KEY ，因为新纪录会去主键表做校验，影响性能。\n适度使用存储过程、视图，禁止使用触发器、事件 存储过程（procedure）虽然可以简化业务端代码，在传统企业写复杂逻辑时可能会用到，而在互联网企业变更是很频繁的，在分库分表的情况下要升级一个存储过程相当麻烦。又因为它是不记录log的，所以也不方便debug性能问题。如果使用过程，一定考虑如果执行失败的情况。 使用视图一定程度上也是为了降低代码里SQL的复杂度，但有时候为了视图的通用性会损失性能（比如返回不必要的字段）。 触发器（trigger）也是同样，但也不应该通过它去约束数据的强一致性，mysql只支持“基于行的触发”，也就是说，触发器始终是针对一条记录的，而不是针对整个sql语句的，如果变更的数据集非常大的话，效率会很低。掩盖一条sql背后的工作，一旦出现问题将是灾难性的，但又很难快速分析和定位。再者需要ddl时无法使用pt-osc工具。放在transaction执行。 事件（event）也是一种偷懒的表现，目前已经遇到数次由于定时任务执行失败影响业务的情况，而且mysql无法对它做失败预警。建立专门的 job scheduler 平台。 单表数据量控制在5000w以内 表字段数量不要超过20个，如果有需要建立主副表，主键一一关联，避免单行数据过多以及修改记录binlog ROW模式导致文件过大。 特别对于有一个text/blob或很大长度的varchar字段时，更应考虑单独存储。但也要注意查询条件尽量放在一个表上。 9. ### 数据库中不允许存储明文密码 ###\n3. 字段规范 char、varchar、text等字符串类型定义 对于长度基本固定的列，如果该列恰好更新又特别频繁，适合char。 utf8mb4字符集下，尽量使用varchar varchar虽然存储变长字符串，但不可太小也不可太大。UTF8最多能存21844个汉字，或65532个英文 varbinary(M)保存的是二进制字符串，它保存的是字节而不是字符，所以没有字符集的概念，M长度0-255（字节）。只用于排序或比较时大小写敏感的类型，不包括密码存储 TEXT类型与VARCHAR都类似，存储可变长度，最大限制也是2^16，但是它20bytes以后的内容是在数据页以外的空间存储（row_format=dynamic），对它的使用需要多一次寻址，没有默认值。 一般用于存放容量平均都很大、操作没有其它字段那样频繁的值。 网上部分文章说要避免使用text和blob，要知道如果纯用varchar可能会导致行溢出，效果差不多，但因为每行占用字节数过多，会导致buffer_pool能缓存的数据行、页下降。另外text和blob上面一般不会去建索引，而是利用sphinx之类的第三方全文搜索引擎，如果确实要创建（前缀）索引，那就会影响性能。凡事看具体场景。 另外尽可能把text/blob拆到另一个表中 BLOB可以看出varbinary的扩展版本，内容以二进制字符串存储，无字符集，区分大小写，有一种经常提但不用的场景：不要在数据库里存储图片。 int、tinyint、decimal等数字类型定义 使用tinyint来代替 enum和boolean ENUM类型在需要修改或增加枚举值时，需要在线DDL，成本较高；ENUM列值如果含有数字类型，可能会引起默认值混淆 tinyint使用1个字节，一般用于status,type,flag的列 建议使用 UNSIGNED 存储非负数值 相比不使用 unsigned，可以扩大一倍使用数值范围 int使用固定4个字节存储，int(11)与int(4)只是显示宽度的区别。但是定义是bigint(20), int(11)，不要随便改动这个显示宽度，c++里面需要这个长度去截取字段 使用Decimal 代替float/double存储精确浮点数 对于货币、金额这样的类型，使用decimal，如 decimal(9,2)。float默认只能能精确到6位有效数字 timestamp与datetime选择 datetime 和 timestamp类型所占的存储空间不同，前者5个字节(5.5是8字节)，后者4个字节，这样造成的后果是两者能表示的时间范围不同。前者范围为1000-01-01 00:00:00 ~ 9999-12-31 23:59:59，后者范围为 1970-01-01 08:00:01 到 2038-01-19 11:14:07 。所以 TIMESTAMP 支持的范围比 DATATIME 要小。 timestamp可以在insert/update行时，自动更新时间字段（如 f_set_time timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP），但一个表只能有一个这样的定义。 timestamp显示与时区有关，内部总是以 UTC 毫秒 来存的。还受到严格模式的限制 优先使用timestamp，datetime也没问题 默认时间，要么current_timestamp，要么'1970-01-02 01:01:01\u0026rsquo;，不要设置为\u0026rsquo;\u0026lsquo;或0 where条件里不要对时间列上使用时间函数 如果使用int的型存储时间戳，约定统一使用 int unsigned default 0 建议字段都定义为NOT NULL 如果是索引字段，一定要定义为not null 。因为null值会影响cordinate统计，影响优化器对索引的选择 如果不能保证insert时一定有值过来，定义时使用default \u0026rsquo;\u0026rsquo; ，或 0 同一意义的字段定义必须相同 比如不同表中都有 f_user_id 字段，那么它的类型、字段长度要设计成一样\n4. 索引规范 任何新的select,update,delete上线，都要先explain，看索引使用情况 尽量避免extra列出现：Using File Sort，Using Temporary，rows超过1000的要谨慎上线。 explain解读\ntype：ALL, index, range, ref, eq_ref, const, system, NULL（从左到右，性能从差到好） possible_keys：指出MySQL能使用哪个索引在表中找到记录，查询涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询使用 key：表示MySQL实际决定使用的键（索引） 如果没有选择索引，键是NULL。要想强制MySQL使用或忽视possible_keys列中的索引，在查询中使用FORCE INDEX、USE INDEX或者IGNORE INDEX ref：表示选择 key 列上的索引，哪些列或常量被用于查找索引列上的值 rows：根据表统计信息及索引选用情况，估算的找到所需的记录所需要读取的行数 Extra Using temporary：表示MySQL需要使用临时表来存储结果集，常见于排序和分组查询 Using filesort：MySQL中无法利用索引完成的排序操作称为“文件排序” 索引个数限制 索引是双刃剑，会增加维护负担，增大IO压力，索引占用空间是成倍增加的 单张表的索引数量控制在5个以内，或不超过表字段个数的20%。若单张表多个字段在查询需求上都要单独用到索引，需要经过DBA评估。 避免冗余索引 InnoDB表是一棵索引组织表，主键是和数据放在一起的聚集索引，普通索引最终指向的是主键地址，所以把主键做最后一列是多余的。如f_crm_id作为主键，联合索引(f_user_id,f_crm_id)上的f_crm_id就完全多余 (a,b,c)、(a,b)，后者为冗余索引。可以利用前缀索引来达到加速目的，减轻维护负担 没有特殊要求，使用自增id作为主键 主键是一种聚集索引，顺序写入。组合唯一索引作为主键的话，是随机写入，适合写少读多的表 主键不允许更新 索引尽量建在选择性高的列上 不在低基数列上建立索引，例如性别、类型。但有一种情况，idx_feedbackid_type (f_feedback_id,f_type)，如果经常用 f_type=1 比较，而且能过滤掉90%行，那这个组合索引就值得创建。有时候同样的查询语句，由于条件取值不同导致使用不同的索引，也是这个道理。 索引选择性计算方法（基数 ÷ 数据行数） Selectivity = Cardinality / Total Rows = select count(distinct col1)/count(*) from tbname，越接近1说明col1上使用索引的过滤效果越好 走索引扫描行数超过30%时，改全表扫描 最左前缀原则 mysql使用联合索引时，从左向右匹配，遇到断开或者范围查询时，无法用到后续的索引列 比如索引idx_c1_c2_c3 (c1,c2,c3)，相当于创建了(c1)、(c1,c2)、(c1,c2,c3)三个索引，where条件包含上面三种情况的字段比较则可以用到索引，但像 where c1=a and c3=c 只能用到c1列的索引，像 c2=b and c3=c等情况就完全用不到这个索引 遇到范围查询(\u0026gt;、\u0026lt;、between、like)也会停止索引匹配，比如 c1=a and c2 \u0026gt; 2 and c3=c，只有c1,c2列上的比较能用到索引，(c1,c2,c3)排列的索引才可能会都用上 where条件里面字段的顺序与索引顺序无关，mysql优化器会自动调整顺序 前缀索引 对超过30个字符长度的列创建索引时，考虑使用前缀索引，如 idx_cs_guid2 (f_cs_guid(26))表示截取前26个字符做索引，既可以提高查找效率，也可以节省空间 前缀索引也有它的缺点是，如果在该列上 ORDER BY 或 GROUP BY 时无法使用索引，也不能把它们用作覆盖索引(Covering Index) 如果在varbinary或blob这种以二进制存储的列上建立前缀索引，要考虑字符集，括号里表示的是字节数 合理使用覆盖索引减少IO INNODB存储引擎中，secondary index(非主键索引，又称为辅助索引、二级索引)没有直接存储行地址，而是存储主键值。 如果用户需要查询secondary index中所不包含的数据列，则需要先通过secondary index查找到主键值，然后再通过主键查询到其他数据列，因此需要查询两次。覆盖索引则可以在一个索引中获取所有需要的数据列，从而避免回表进行二次查找，节省IO因此效率较高。 例如SELECT email，uid FROM user_email WHERE uid=xx，如果uid不是主键，适当时候可以将索引添加为index(uid，email)，以获得性能提升。\n尽量不要在频繁更新的列上创建索引 如不在定义了 ON UPDATE CURRENT_STAMP 的列上创建索引，维护成本太高（好在mysql有insert buffer，会合并索引的插入）\n修改表结构时 drop colum 时要注意，与这个字段相关的索引都会改变，变化是从原索引抽掉该字段定义。这种情况有可能导致部分索引重复或失效。 5. SQL设计 杜绝直接 SELECT * 读取全部字段 即使需要所有字段，减少网络带宽消耗，能有效利用覆盖索引，表结构变更对程序基本无影响\n能确定返回结果只有一条时，使用 limit 1 在保证数据不会有误的前提下，能确定结果集数量时，多使用limit，尽快的返回结果。\n小心隐式类型转换 转换规则 a. 两个参数至少有一个是 NULL 时，比较的结果也是 NULL，例外是使用 \u0026lt;=\u0026gt; 对两个 NULL 做比较时会返回 1，这两种情况都不需要做类型转换 b. 两个参数都是字符串，会按照字符串来比较，不做类型转换 c. 两个参数都是整数，按照整数来比较，不做类型转换 d. 十六进制的值和非数字做比较时，会被当做二进制串 e. 有一个参数是 TIMESTAMP 或 DATETIME，并且另外一个参数是常量，常量会被转换为 timestamp f. 有一个参数是 decimal 类型，如果另外一个参数是 decimal 或者整数，会将整数转换为 decimal 后进行比较，如果另外一个参数是浮点数，则会把 decimal 转换为浮点数进行比较 g. 所有其他情况下，两个参数都会被转换为浮点数再进行比较。\n如果一个索引建立在string类型上，如果这个字段和一个int类型的值比较，符合第 g 条。如f_phone定义的类型是varchar，但where使用f_phone in (098890)，两个参数都会被当成成浮点型。发生这个隐式转换并不是最糟的，最糟的是string转换后的float，mysql无法使用索引，这才导致了性能问题。如果是 f_user_id = \u0026lsquo;1234567\u0026rsquo; 的情况，符合第 b 条,直接把数字当字符串比较。 禁止在where条件列上使用函数 会导致索引失效，如lower(email)，f_qq % 4。可放到右边的常量上计算 返回小结果集不是很大的情况下，可以对返回列使用函数，简化程序开发 使用like模糊匹配，%不要放首位 会导致索引失效，有这种搜索需求是，考虑其它方案，如sphinx全文搜索\n涉及到复杂sql时，务必先参考已有索引设计，先explain 简单SQL拆分，不以代码处理复杂为由。 比如 OR 条件： f_phone=\u0026lsquo;10000\u0026rsquo; or f_mobile=\u0026lsquo;10000\u0026rsquo;，两个字段各自有索引，但只能用到其中一个。可以拆分成2个sql，或者union all。 先explain的好处是可以为了利用索引，增加更多查询限制条件 使用join时，where条件尽量使用充分利用同一表上的索引 如 select t1.a,t2.b * from t1,t2 and t1.a=t2.a and t1.b=123 and t2.c= 4 ，如果t1.c与t2.c字段相同，那么t1上的索引(b,c)就只用到b了。此时如果把where条件中的t2.c=4改成t1.c=4，那么可以用到完整的索引 这种情况可能会在字段冗余设计（反范式）时出现 正确选取inner join和left join。不允许滥用left join 少用子查询，改用join 小于5.6版本时，子查询效率很低，不像Oracle那样先计算子查询后外层查询。5.6版本开始得到优化\n考虑使用union all，少使用union，注意考虑去重 union all不去重，而少了排序操作，速度相对比union要快，如果没有去重的需求，优先使用union all 如果UNION结果中有使用limit，在2个子SQL可能有许多返回值的情况下，各自加上limit。如果还有order by，请找DBA。 IN的内容尽量不超过200个 超过500个值使用批量的方式，否则一次执行会影响数据库的并发能力，因为单SQL只能且一直占用单CPU，而且可能导致主从复制延迟。\n拒绝大事务 比如在一个事务里进行多个select，多个update，如果是高频事务，会严重影响MySQL并发能力，因为事务持有的锁等资源只在事务rollback/commit时才能释放。但同时也要权衡数据写入的一致性。 不要再事务里面做除数据库以外的操作。\n避免使用is null, is not null这样的比较 order by .. limit 这种查询更多的是通过索引去优化，但order by的字段有讲究，比如主键id与f_time都是顺序递增，那就可以考虑order by id而非 f_time 。\nc1 \u0026lt; a order by c2 与上面不同的是，order by之前有个范围查询，由前面的内容可知，用不到类似(c1,c2)的索引，但是可以利用(c2,c1)索引。另外还可以改写成join的方式实现。\n分页优化 建议使用合理的分页方式以提高分页效率，大页情况下不使用跳跃式分页 假如有类似下面分页语句: SELECT * FROM table1 ORDER BY ftime DESC LIMIT 10000,10; 这种分页方式会导致大量的io，因为MySQL使用的是提前读取策略。 推荐分页方式： SELECT * FROM table1 WHERE ftime \u0026lt; last_time ORDER BY ftime DESC LIMIT 10 即传入上一次分页的界值\nSELECT * FROM table as t1 inner JOIN (SELECT id FROM table ORDER BY time LIMIT 10000，10) as t2 ON t1.id=t2.id\ncount计数 首先count()、count(1)、count(col1)是有区别的，count()表示整个结果集有多少条记录，count(1)表示结果集里以primary key统计数量，绝大多数情况下count()与count(1)效果一样的，但count(col1)表示的是结果集里 col1 列 NOT null 的记录数。优先采用count() 大数据量count是消耗资源的操作，甚至会拖慢整个库，查询性能问题无法解决的，应从产品设计上进行重构。例如当频繁需要count的查询，考虑使用汇总表 遇到distinct的情况，group by方式可能效率更高。 delete,update语句改成select再explain select最多导致数据库慢，写操作才是锁表的罪魁祸首\n减少与数据库交互的次数，尽量采用批量SQL语句 INSERT ... ON DUPLICATE KEY UPDATE ...，插入行后会导致在一个UNIQUE索引或PRIMARY KEY中出现重复值，则执行旧行UPDATE，如果不重复则直接插入，影响1行。 REPLACE INTO类似，但它是冲突时删除旧行。INSERT IGNORE相反，保留旧行，丢弃要插入的新行。 INSERT INTO VALUES(),(),()，合并插入。 杜绝危险SQL 去掉where 1=1 这样无意义或恒真的条件，如果遇到update/delete或遭到sql注入就恐怖了 SQL中不允许出现DDL语句。一般也不给予create/alter这类权限，但阿里云RDS只区分读写用户 是否应该 order by 主键 许多排序的场景，如果主键id是增长的，如果 order by f_create_time 查询慢，有可能使用了filesort，此时最简单的办法是看能否换成 order by id，因为id作为主键是递增的，并且附带在了每个二级索引后面。 但是也要谨慎使用 order by id，特别是在explain结果看到filesort的情况下，优化器极有可能放弃这个filesort，而选择了它所认为更高效的扫描方式，实则更慢。\n使用正确的表 比如要统计昨天的数据这类业务较多，是否可以设计一个昨天表，不在31天表上统计，在月份表上统计也行。 或者其它组已经有“半统计”的数据，从他们那抽取数据，而不是在原始数据上统计\n6. 行为规范 不允许在DBA不知情的情况下导现网数据 大批量更新，如修复数据，避开高峰期，并通知DBA。直接执行sql的由运维或DBA同事操作 及时处理已下线业务的SQL 复杂sql上线审核 因为目前还没有SQL审查机制，复杂sql如多表join,count,group by，主动上报DBA评估。 重要项目的数据库方案选型和设计必须提前通知DBA参与 7. DBA运维规范 这部分可另起一篇规范了，这里先开个头。\n安装初始化MySQL，严格安装约定的目录、配置文件、权限、参数来初始化 第一时间添加监控、备份 定期巡检 对先上过期废弃的表，及时与开发确认归档清除，同时也要注意与它相关的视图、过程、事件等。 本文参考 互联网MySQL开发规范 这个基本也是《去哪儿MySQL开发规范.pdf》版本 MySQL数据库开发的三十六条军规_石展_完整.pdf 老叶观点：MySQL开发规范之我见 MySQL开发规范与使用技巧总结 http://highdb.com/mysql%E5%BC%80%E5%8F%91%E8%A7%84%E8%8C%83/ 本文链接地址：http://xgknight.com/2016/05/11/mysql-dev-principle-ec/\n","permalink":"http://localhost:1313/2016/05/mysql-dev-principle-ec/","summary":"\u003cp\u003eupdated: 2017-11-12\n本文所提规范，在我博客上可以找到多篇案例。\u003c/p\u003e\n\u003cp\u003e最近一段时间一边在线上抓取SQL来优化，一边在整理这个开发规范，尽量减少新的问题SQL进入生产库。今天也是对公司的开发做了一次培训，PPT就不放上来了，里面有十来个生产SQL的案例。因为规范大部分还是具有通用性，所以也借鉴了像去哪儿和赶集的规范，但实际在撰写本文的过程中，每一条规范的背后无不是在工作中有参照的反面例子的。如果时间可以的话，会抽出一部分或分析其原理，或用案例证明。\u003c/p\u003e","title":"MySQL数据库开发规范-EC"},{"content":"1. 隐式类型转换实例 今天生产库上突然出现MySQL线程数告警，IOPS很高，实例会话里面出现许多类似下面的sql：(修改了相关字段和值)\n1 2 SELECT f_col3_id,f_qq1_id FROM d_dbname.t_tb1 WHERE f_col1_id=1226391 and f_col2_id=1244378 and f_qq1_id in (12345,23456,34567,45678,56789,67890,78901,89012,90123,901231,901232,901233) 用 explain 看了下扫描行数和索引选择情况：\n1 2 3 4 5 6 7 8 mysql\u0026gt;explain SELECT f_col3_id,f_qq1_id FROM d_dbname.t_tb1 WHERE f_col1_id=1226391 and f_col2_id=1244378 and f_qq1_id in (12345,23456,34567,45678,56789,67890,78901,89012,90123,901231,901232,901233); +------+---------------+---------+--------+--------------------------------+---------------+------------+--------+--------+------------------------------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +------+---------------+---------+--------+--------------------------------+---------------+------------+--------+--------+------------------------------------+ | 1 | SIMPLE | t_tb1 | ref | uid_type_frid,idx_corpid_qq1id | uid_type_frid | 8 | const | 1386 | Using index condition; Using where | +------+---------------+---------+--------+--------------------------------+---------------+------------+--------+--------+------------------------------------+ 共返回 1 行记录,花费 11.52 ms. t_tb1 表上有个索引uid_type_frid(f_col2_id,f_type)、idx_corp_id_qq1id(f_col1_id,f_qq1_id)，而且如果选择后者时，f_qq1_id的过滤效果应该很佳，但却选择了前者。当使用 hint use index(idx_corp_id_qq1id)时：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 mysql\u0026gt;explain extended SELECT f_col3_id,f_qq1_id FROM d_dbname.t_tb1 use index(idx_corpid_qq1id) WHERE f_col1_id=1226391 and f_col2_id=1244378 and f_qq1_id in (12345,23456,34567,45678,56789,67890,78901,89012,90123,901231,901232,901233); +------+---------------+--------+--------+---------------------+------------------+------------+----------+-------------+------------------------------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +------+---------------+--------+--------+---------------------+------------------+------------+----------+-------------+------------------------------------+ | 1 | SIMPLE | t_tb1 | ref | idx_corpid_qq1id | idx_corpid_qq1id | 8 | const | 2375752 | Using index condition; Using where | +---- -+---------------+--------+--------+---------------------+------------------+------------+----------+-------------+------------------------------------+ 共返回 1 行记录,花费 17.48 ms. mysql\u0026gt;show warnings; +-----------------+----------------+-----------------------------------------------------------------------------------------------------------------------+ | Level | Code | Message | +-----------------+----------------+-----------------------------------------------------------------------------------------------------------------------+ | Warning | 1739 | Cannot use range access on index \u0026#39;idx_corpid_qq1id\u0026#39; due to type or collation conversion on field \u0026#39;f_qq1_id\u0026#39; | | Note | 1003 | /* select#1 */ select `d_dbname`.`t_tb1`.`f_col3_id` AS `f_col3_id`,`d_dbname`.`t_tb1`.`f_qq1_id` AS `f_qq1_id` from `d_dbname`.`t_tb1` USE INDEX (`idx_corpid_qq1id`) where | | | | ((`d_dbname`.`t_tb1`.`f_col2_id` = 1244378) and (`d_dbname`.`t_tb1`.`f_col1_id` = 1226391) and (`d_dbname`.`t_tb1`.`f_qq1_id` in | | | | (12345,23456,34567,45678,56789,67890,78901,89012,90123,901231,901232,901233))) | +-----------------+----------------+-----------------------------------------------------------------------------------------------------------------------+ 共返回 2 行记录,花费 10.81 ms. rows列达到200w行，但问题也发现了：select_type应该是 range 才对，key_len看出来只用到了idx_corpid_qq1id索引的第一列。上面explain使用了 extended，所以show warnings;可以很明确的看到 f_qq1_id 出现了隐式类型转换：f_qq1_id是varchar，而后面的比较值是整型。\n解决该问题就是避免出现隐式类型转换(implicit type conversion)带来的不可控：把f_qq1_id in的内容写成字符串：\n1 2 3 4 5 6 7 8 mysql\u0026gt;explain SELECT f_col3_id,f_qq1_id FROM d_dbname.t_tb1 WHERE f_col1_id=1226391 and f_col2_id=1244378 and f_qq1_id in (\u0026#39;12345\u0026#39;,\u0026#39;23456\u0026#39;,\u0026#39;34567\u0026#39;,\u0026#39;45678\u0026#39;,\u0026#39;56789\u0026#39;,\u0026#39;67890\u0026#39;,\u0026#39;78901\u0026#39;,\u0026#39;89012\u0026#39;,\u0026#39;90123\u0026#39;,\u0026#39;901231\u0026#39;); +-------+---------------+--------+---------+--------------------------------+------------------+-------------+---------+---------+------------------------------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +-------+---------------+--------+---------+--------------------------------+------------------+-------------+---------+---------+------------------------------------+ | 1 | SIMPLE | t_tb1 | range | uid_type_frid,idx_corpid_qq1id | idx_corpid_qq1id | 70 | | 40 | Using index condition; Using where | +-------+---------------+--------+---------+--------------------------------+------------------+-------------+---------+---------+------------------------------------+ 共返回 1 行记录,花费 12.41 ms. 扫描行数从1386减少为40。\n类似的还出现过一例：\n1 2 3 SELECT count(0) FROM d_dbname.t_tb2 where f_col1_id= \u0026#39;1931231\u0026#39; AND f_phone in(098890); | Warning | 1292 | Truncated incorrect DOUBLE value: \u0026#39;1512-98464356\u0026#39; 优化后直接从扫描rows 100w行降为1。\n借这个机会，系统的来看一下mysql中的隐式类型转换。\n2. mysql隐式转换规则 2.1 规则 下面来分析一下隐式转换的规则：\na. 两个参数至少有一个是 NULL 时，比较的结果也是 NULL，例外是使用 \u0026lt;=\u0026gt; 对两个 NULL 做比较时会返回 1，这两种情况都不需要做类型转换 b. 两个参数都是字符串，会按照字符串来比较，不做类型转换 c. 两个参数都是整数，按照整数来比较，不做类型转换 d. 十六进制的值和非数字做比较时，会被当做二进制串 e. 有一个参数是 TIMESTAMP 或 DATETIME，并且另外一个参数是常量，常量会被转换为 timestamp f. 有一个参数是 decimal 类型，如果另外一个参数是 decimal 或者整数，会将整数转换为 decimal 后进行比较，如果另外一个参数是浮点数，则会把 decimal 转换为浮点数进行比较 g. 所有其他情况下，两个参数都会被转换为浮点数再进行比较\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 mysql\u0026gt; select 11 + \u0026#39;11\u0026#39;, 11 + \u0026#39;aa\u0026#39;, \u0026#39;a1\u0026#39; + \u0026#39;bb\u0026#39;, 11 + \u0026#39;0.01a\u0026#39;; +-----------+-----------+-------------+--------------+ | 11 + \u0026#39;11\u0026#39; | 11 + \u0026#39;aa\u0026#39; | \u0026#39;a1\u0026#39; + \u0026#39;bb\u0026#39; | 11 + \u0026#39;0.01a\u0026#39; | +-----------+-----------+-------------+--------------+ | 22 | 11 | 0 | 11.01 | +-----------+-----------+-------------+--------------+ 1 row in set, 4 warnings (0.00 sec) mysql\u0026gt; show warnings; +---------+------+-------------------------------------------+ | Level | Code | Message | +---------+------+-------------------------------------------+ | Warning | 1292 | Truncated incorrect DOUBLE value: \u0026#39;aa\u0026#39; | | Warning | 1292 | Truncated incorrect DOUBLE value: \u0026#39;a1\u0026#39; | | Warning | 1292 | Truncated incorrect DOUBLE value: \u0026#39;bb\u0026#39; | | Warning | 1292 | Truncated incorrect DOUBLE value: \u0026#39;0.01a\u0026#39; | +---------+------+-------------------------------------------+ 4 rows in set (0.00 sec) mysql\u0026gt; select \u0026#39;11a\u0026#39; = 11, \u0026#39;11.0\u0026#39; = 11, \u0026#39;11.0\u0026#39; = \u0026#39;11\u0026#39;, NULL = 1; +------------+-------------+---------------+----------+ | \u0026#39;11a\u0026#39; = 11 | \u0026#39;11.0\u0026#39; = 11 | \u0026#39;11.0\u0026#39; = \u0026#39;11\u0026#39; | NULL = 1 | +------------+-------------+---------------+----------+ | 1 | 1 | 0 | NULL | +------------+-------------+---------------+----------+ 1 row in set, 1 warning (0.01 sec) 上面可以看出11 + 'aa'，由于操作符两边的类型不一样且符合第g条，aa要被转换成浮点型小数，然而转换失败（字母被截断），可以认为转成了 0，整数11被转成浮点型还是它自己，所以11 + 'aa' = 11。\n0.01a转成double型也是被截断成0.01，所以11 + '0.01a' = 11.01。\n等式比较也说明了这一点，'11a'和'11.0'转换后都等于 11，这也正是文章开头实例为什么没走索引的原因： varchar型的f_qq1_id，转换成浮点型比较时，等于 12345 的情况有无数种如12345a、12345.b等待，MySQL优化器无法确定索引是否更有效，所以选择了其它方案。\n但并不是只要出现隐式类型转换，就会引起上面类似的性能问题，最终是要看转换后能否有效选择索引。像f_id = '654321'、f_mtime between '2016-05-01 00:00:00' and '2016-05-04 23:59:59'就不会影响索引选择，因为前者f_id是整型，即使与后面的字符串型数字转换成double比较，依然能根据double确定f_id的值，索引依然有效。后者是因为符合第e条，只是右边的常量做了转换。\n开发人员可能都只要存在这么一个隐式类型转换的坑，但却又经常不注意，所以干脆无需记住那么多规则，该什么类型就与什么类型比较。\n2.2 隐式类型转换的安全问题 implicit type conversion 不仅可能引起性能问题，还有可能产生安全问题。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 mysql\u0026gt; desc t_account; +-----------+-------------+------+-----+---------+----------------+ | Field | Type | Null | Key | Default | Extra | +-----------+-------------+------+-----+---------+----------------+ | fid | int(11) | NO | PRI | NULL | auto_increment | | fname | varchar(20) | YES | | NULL | | | fpassword | varchar(50) | YES | | NULL | | +-----------+-------------+------+-----+---------+----------------+ mysql\u0026gt; select * from t_account; +-----+-----------+-------------+ | fid | fname | fpassword | +-----+-----------+-------------+ | 1 | xiaoming | p_xiaoming | | 2 | xiaoming1 | p_xiaoming1 | +-----+-----------+-------------+ 假如应用前端没有WAF防护，那么下面的sql很容易注入： mysql\u0026gt; select * from t_account where fname=\u0026#39;A\u0026#39; ; fname传入 A\u0026#39; OR 1=\u0026#39;1 mysql\u0026gt; select * from t_account where fname=\u0026#39;A\u0026#39; OR 1=\u0026#39;1\u0026#39;; 攻击者更聪明一点： fname传入 A'+'B ，fpassword传入 ccc'+0 ：\n1 2 3 4 5 6 7 8 mysql\u0026gt; select * from t_account where fname=\u0026#39;A\u0026#39;+\u0026#39;B\u0026#39; and fpassword=\u0026#39;ccc\u0026#39;+0; +-----+-----------+-------------+ | fid | fname | fpassword | +-----+-----------+-------------+ | 1 | xiaoming | p_xiaoming | | 2 | xiaoming1 | p_xiaoming1 | +-----+-----------+-------------+ 2 rows in set, 7 warnings (0.00 sec) 参考 MySQL隐式转化整理 WHRER条件里的数据类型必须和字段数据类型一致 Implicit type conversion in MySQL 原文链接地址：http://xgknight.com/2016/05/05/mysql-type-conversion/\n","permalink":"http://localhost:1313/2016/05/mysql-type-conversion/","summary":"\u003ch2 id=\"1-隐式类型转换实例\"\u003e1. 隐式类型转换实例\u003c/h2\u003e\n\u003cp\u003e今天生产库上突然出现MySQL线程数告警，IOPS很高，实例会话里面出现许多类似下面的sql：(修改了相关字段和值)\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e2\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-fallback\" data-lang=\"fallback\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eSELECT f_col3_id,f_qq1_id FROM d_dbname.t_tb1 WHERE f_col1_id=1226391 and f_col2_id=1244378 and \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003ef_qq1_id in (12345,23456,34567,45678,56789,67890,78901,89012,90123,901231,901232,901233)\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e用 explain 看了下扫描行数和索引选择情况：\u003c/p\u003e","title":"小心MySQL的隐式类型转换陷阱"},{"content":"最近在准备给开发做一个mysql数据库开发规范方面培训，一步一步来，结合在生产环境发现的数据库方面的问题，从几个常用的数据类型说起。\nint、tinyint与bigint 它们都是（精确）整型数据类型，但是占用字节数和表达的范围不同。首先没有这个表就说不过去了：\nType Storage Minimum Value Maximum Value (Bytes) (Signed/Unsigned) (Signed/Unsigned) TINYINT 1 -128 127 0 255 SMALLINT 2 -32768 32767 0 65535 MEDIUMINT 3 -8388608 8388607 0 16777215 INT 4 -2147483648 2147483647 0 4294967295 BIGINT 8 -9223372036854775808 9223372036854775807 0 18446744073709551615 只需要知道对应类型占多少字节就能推算出范围了，比如int占 4 bytes,即4*8=32bits，大约10位数字，也能理解为什么int默认显示位数是11。\n遇到比较多的是tinyint和bigint，tinyint一般用于存放status,type这种数值小的数据，不够用时可能会用smallint。bigint一般用于自增主键。\n为了避免数据库被过度设计，布尔、枚举类型也采用tinyint。\n还有一点也是经常被提到的关于 int(M) 中M的理解，int型数据无论是int(4)还是int(11)，都已经占用了 4 bytes 存储空间，M表示的只是显示宽度(display width, max value 255)，并不是定义int的长度。\n例如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 mysql\u0026gt; CREATE TABLE `tc_integer` ( `f_id` bigint(20) PRIMARY KEY AUTO_INCREMENT, `f_type` tinyint, `f_flag` tinyint(1), `f_num` smallint(5) unsigned ZEROFILL ) ENGINE=InnoDB DEFAULT CHARSET=utf8; mysql\u0026gt; desc tc_integer; +----------------+-------------------------------+------+-----+---------+----------------+ | Field | Type | Null | Key | Default | Extra | +----------------+-------------------------------+------+-----+---------+----------------+ | f_id | bigint(20) | NO | PRI | NULL | auto_increment | | f_type | tinyint(4) | YES | | NULL | | | f_flag | tinyint(1) | YES | | NULL | | | f_num | smallint(5) unsigned zerofill | YES | | NULL | | +----------------+-------------------------------+------+-----+---------+----------------+ 4 rows in set (0.01 sec) 插入几条数据看一下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 mysql\u0026gt; insert into tc_integer values(1, 1, 1, 1); Query OK, 1 row affected (0.02 sec) mysql\u0026gt; insert into tc_integer values(9223372036854775808, 127, 127, 65535); Query OK, 1 row affected, 1 warning (0.01 sec) mysql\u0026gt; show warnings; +---------+------+-----------------------------------------------+ | Level | Code | Message | +---------+------+-----------------------------------------------+ | Warning | 1264 | Out of range value for column \u0026#39;f_id\u0026#39; at row 1 | +---------+------+-----------------------------------------------+ 1 row in set (0.00 sec) mysql\u0026gt; select i.*, length(i.f_flag) as len_flag from tc_integer i; +---------------------+--------------+---------------+----------------+----------+ | f_id | f_type | f_flag | f_num | len_flag | +---------------------+--------------+---------------+----------------+----------+ | 1 | 1 | 1 | 00001 | 1 | | 9223372036854775807 | 127 | 127 | 65535 | 3 | +---------------------+--------------+---------------+----------------+----------+ 2 rows in set (0.00 sec) mysql\u0026gt; select * from tc_integer where f_num=\u0026#39; 01\u0026#39; and f_num=1 and f_num=f_flag; +------+--------------+---------------+----------------+ | f_id | f_type | f_flag | f_num | +------+--------------+---------------+----------------+ | 1 | 1 | 1 | 00001 | +------+--------------+---------------+----------------+ 1 row in set (0.00 sec) 上面的实验说明了几个问题：\nf_id列插入比最大值还大的数，出现warnings，并且最终的值自动变成 9223372036854775807 。这个坑曾经在迁移到阿里RDS时遇到过，他们的迁移工具是java写的，结果我们的主键值大于java INTEGER里面的最大限制，导致 duplicate key问题。 f_flag的显示宽度为1，但并不影响更多位数的显示。也证实了tinyint(1)并不像char(1)那样限制存储长度 f_num定义成无符号的zerofill类型，能存储的最大数值是65535，而signed才是32767。（当列上使用zerofill时，unsigned会自动加上） zerofill的作用是在显示检索结果的时候，左边用0补齐到display width，实际存储时不补0的，仅作为返回结果meta data的一部分。查询的条件值忽略0和空格 length()在numeric类型中作用于char_length()一样，因为字节数已经固定了。 zerofill的使用可能会在复杂join时因为了解不够深入而带来问题，所以最终的结论也很简单：除非极端的特殊需要，尽量不用zerofill，建表时这类int无需指定 (11) 这样的显示宽度。\nfloat与decimal MySQL使用DECIMAL类型去存储对精度要求比较高的数值，比如金额，也叫定点数，decimal在mysql内存是以字符串二进制存储的。声明语法是DECIMAL(M,D)，占用字节 M+2 bytes。M是数字最大位数（精度precision），范围1-65；D是小数点右侧数字个数（标度scale），范围0-30，但不得超过M。\n占用字节数计算方法 —— 小数和整数分别计算，每9位数占4字节，剩余部分如下表换算：\nLeftover Digits Number of Bytes 0 0 1–2 1 3–4 2 5–6 3 7–9 4 比如DECIMAL(18,9)，整数部分和小数部分各9位，所以各占4字节，共8bytes 再比如DECIMAL(20,6)，整数14位，需要4字节存9位，还需3字节存5位；小数6位，需3字节。共10bytes （感谢 consatan 在评论区提出文中错误）\n比如定义DECIMAL(7,3)：\n能存的数值范围是 -9999.999 ~ 9999.999，占用4个字节 123.12 -\u0026gt; 123.120，因为小数点后未满3位，补0 123.1245 -\u0026gt; 123.125，小数点只留3位，多余的自动四舍五入截断 12345.12 -\u0026gt; 保存失败，因为小数点未满3位，补0变成12345.120，超过了7位。严格模式下报错，非严格模式存成9999.999 MySQL使用FLOAT和DOUBLE来表示近似数值类型，这是因为十进制0.1在电脑里用二进制是无法精确表示的，只能尽可能的接近。\n单精度浮点数float占4字节，float标准语法允许通过FLOAT(M)的形式指定精度，但是这个精度值M只是决定存储大小： 0-23与默认不指定效果相同，24-53就变成双精度的DOUBLE了。\nfloat还有非MySQL自己实现的非标准语法FLOAT(M,D)，代表最多存储M个数字长度，其中小数点后数字个数为D。效果与 DECIMAL(M,D)很相似。\ndouble 和 float 的区别是double精度高，有效数字16位（float精度7位）。但double消耗内存是float的两倍，占8字节，double的运算速度比float慢得多。\n1 2 3 4 5 6 7 8 9 10 11 msyql\u0026gt; create table tc_float(fid int primary key auto_increment,f_float float, f_float10 float(10), f_float25 float(25), f_float7_3 float(7,3), f_float9_2 float(9,2), f_float30_3 float(30,3), f_decimal9_2 decimal(9,2)); mysql\u0026gt; insert into tc_float(f_float,f_float10,f_float25) values(123456,123456,123456); mysql\u0026gt; insert into tc_float(f_float,f_float10,f_float25) values(1234567.89,12345.67,1234567.89); mysql\u0026gt; select * from tc_float; +-----+----------+-----------+------------+------------+------------+-------------+--------------+ | fid | f_float | f_float10 | f_float25 | f_float7_3 | f_float9_2 | f_float30_3 | f_decimal9_2 | +-----+----------+-----------+------------+------------+------------+-------------+--------------+ | 1 | 123456 | 123456 | 123456 | NULL | NULL | NULL | NULL | | 2 | 1234570 | 12345.7 | 1234567.89 | NULL | NULL | NULL | NULL | +-----+----------+-----------+------------+------------+------------+-------------+--------------+ 可以看到float与float(10)是没区别的，float默认能精确到6位有效数字 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 mysql\u0026gt; insert into tc_float(f_float9_2,f_decimal9_2) values(123456.78,123456.78); mysql\u0026gt; insert into tc_float(f_float9_2,f_decimal9_2) values(1234567.1,1234567.125); Query OK, 1 row affected, 1 warning (0.00 sec) mysql\u0026gt; show warnings; +-------+------+---------------------------------------------------+ | Level | Code | Message | +-------+------+---------------------------------------------------+ | Note | 1265 | Data truncated for column \u0026#39;f_decimal9_2\u0026#39; at row 1 | +-------+------+---------------------------------------------------+ 1 row in set (0.00 sec) mysql\u0026gt; select * from tc_float; +-----+----------+-----------+------------+------------+------------+-------------+--------------+ | fid | f_float | f_float10 | f_float25 | f_float7_3 | f_float9_2 | f_float30_3 | f_decimal9_2 | +-----+----------+-----------+------------+------------+------------+-------------+--------------+ | 6 | NULL | NULL | NULL | NULL | 123456.78 | NULL | 123456.78 | | 9 | NULL | NULL | NULL | NULL | 1234567.12 | NULL | 1234567.13 | +-----+----------+-----------+------------+------------+------------+-------------+--------------+ mysql\u0026gt; insert into tc_float(f_float7_3) values(12345.1); ERROR 1264 (22003): Out of range value for column \u0026#39;f_float7_3\u0026#39; at row 1 float(9,2)与decimal(9,2)是很像的，并没有前面提到24位一下6位有效数字的限制 他们俩之间的差别就在精度上，f_float9_2本应该是 1234567.10，结果小数点变成 .12 。f_decimal9_2因为标度为2，所以 .125 四舍五入成 .13 将 12345.1 插入f_float7_3列，因为转成标度3时 12345.100，整个位数大于7，所以 out of range 了 另外在编程中应尽量避免做浮点数的比较，否则可能会导致一些潜在的问题。\n坚决不允许使用float去存money，使用decimal更加稳妥，但使用decimal做除法依旧会产生浮点型，所以特殊情况请考虑使用整型，货币单位使用 分 ，或者除法在最后进行。\n参考 MySQL各数据类型的区别 MySQL manual Out-of-Range and Overflow Handling MySQL FLOAT vs DEC: working with fraction and decimal Never use floats for money 本文链接地址：http://xgknight.com/2016/04/29/mysql-numeric-int-float/\n","permalink":"http://localhost:1313/2016/04/mysql-numeric-int-float/","summary":"\u003cp\u003e最近在准备给开发做一个mysql数据库开发规范方面培训，一步一步来，结合在生产环境发现的数据库方面的问题，从几个常用的数据类型说起。\u003c/p\u003e\n\u003ch2 id=\"inttinyint与bigint\"\u003eint、tinyint与bigint\u003c/h2\u003e\n\u003cp\u003e它们都是（精确）整型数据类型，但是占用字节数和表达的范围不同。首先没有这个表就说不过去了：\u003c/p\u003e","title":"MySQL数字类型int与tinyint、float与decimal如何选择"},{"content":"数据类型差不多是接触mysql一开始就了解的内容，最近遇到几个现象如varchar自动转mediumtext，blob存储性能的问题，不得不回头明确一下关于MySQL常用数据类型的选择。\nmysql手册这里 已经讲的很清楚了。它们都是定义字符串型字段时常用的类型，但它们存储和检索的方式有不同，最大长度和尾部的空格是否保留也有差别。\nchar类型是使用固定长度空间进行存储，范围0-255。比如CHAR(30)能放30个字符，存放abcd时，尾部会以空格补齐，实际占用空间 30 * 3bytes (utf8)。检索它的时候尾部空格会被去除。\nchar善于存储经常改变的值，或者长度相对固定的值，比如type、ip地址或md5之类的数据，不容易产生碎片。关于它的效率可以参考这里。\nvarchar类型保存可变长度字符串，范围0-65535（但受到单行最大64kb的限制）。比如用 varchar(30) 去存放abcd，实际使用5个字节，因为还需要使用额外1个字节来标识字串长度（0-255使用1个字节，超过255需要2个字节）。\nvarchar善于存储值的长短不一的列，也是用的最多的一种类型，节省磁盘空间。update时varchar列时，如果新数据比原数据大，数据库需要重新开辟空间，这一点会有性能略有损耗，但innodb引擎下查询效率比char高一点。这也是innodb官方推荐的类型。\n如果存储时真实长度超过了char或者varchar定义的最大长度呢？\n在SQL严格模式下，无论char还是varchar，如果尾部要被截断的是非空格，会提示错误，即插入失败 在SQL非严格模式下，无论char还是varchar，如果尾部要被截断的是非空格，会提示warning，但可以成功 如果尾部要被截断的是空格，无论SQL所处模式，varchar都可以插入成功但提示warning；char也可以插入成功，并且无任何提示 这里特意提到SQL的严格模式，是因为在工作中也遇到过一些坑，参考MySQL的sql_mode严格模式注意点。\n贴上官方的一个表格：\nValue CHAR(4) Storage Required VARCHAR(4) Storage Required '' \u0026rsquo; ' 4 bytes '' 1 byte \u0026lsquo;ab\u0026rsquo; \u0026lsquo;ab ' 4 bytes \u0026lsquo;ab\u0026rsquo; 3 bytes \u0026lsquo;abcd\u0026rsquo; \u0026lsquo;abcd\u0026rsquo; 4 bytes \u0026lsquo;abcd\u0026rsquo; 5 bytes \u0026lsquo;abcdefgh\u0026rsquo; \u0026lsquo;abcd\u0026rsquo; 4 bytes \u0026lsquo;abcd\u0026rsquo; 5 bytes 另外，mysql字段值比较时默认是不区分大小写的，这是由于他们的校对规则（一般是 utf8_general_ci）决定的，按字符比较，所以查询时 值尾部 的空格也是被忽略的，除非建表时对列指定 BINARY （校对字符集变成utf8_bin）或者select * from vc where binary v='ab ';，就会按字节比较，即比较时区分大小写和尾部空格。\n需要注意的是，使用varchar不能因为长度可变就随意分大空间，比如90个字节能放够的列定义成varchar(200)，因为开辟内存时是以200字节进行的，遇到需要filesort或tmp table作业可能会带来不利影响。\n最后研究一下字符集对存储长度影响，以 create table tc_utf8(c1 int primary key auto_increment, c2 char(30), c3 varchar(N)) charset=utf8; 为例：\n字符集为utf8，于是中文每个字符占3个字节，英文还是1个字节，所以N最大为 (65535-1-2-4-30*3)/3 = 21812，即最多能存放21812个英文、数字、汉字。其中65535是单行最大限制，减1是NULL标识位，减2的是头部的2个字节标识长度，减30*3的原因是char(30)占用90个字节，最后除以3还是因为utf8最长用3个字节表示一个字符。\n但有人会说，utf8的英文字符只需要1个字节表示，并不占用3个字节，在存ASCII字符的情况下N是不是可以更大呢。答案是否定的，因为定义表的时候mysql事先并不知道c3要存的是英文还在中文，只能以最大来计。mysql也是以这种方式来确保行最大 65535 bytes 限制：数据行只要出现一个ascii字符（如英文字母、数字），就永远达不到65535，数据行全中文则刚好满。\n还有一种特殊情况：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 mysql\u0026gt; show variables like \u0026#34;char%\u0026#34;; +--------------------------+----------------------------+ | Variable_name | Value | +--------------------------+----------------------------+ | character_set_client | utf8 | | character_set_connection | utf8 | | character_set_database | utf8 | | character_set_filesystem | binary | | character_set_results | utf8 | | character_set_server | latin1 | | character_set_system | utf8 | | character_sets_dir | /usr/share/mysql/charsets/ | +--------------------------+----------------------------+ 8 rows in set (0.12 sec) mysql\u0026gt; select @@sql_mode; +------------------------+ | @@sql_mode | +------------------------+ | NO_ENGINE_SUBSTITUTION | +------------------------+ 1 rows in set (0.13 sec) mysql\u0026gt; create table tc_utf8_21812(c1 int primary key auto_increment, c2 char(30), c3 varchar(21812)) charset=utf8; Query OK, 0 rows affected (0.10 sec) mysql\u0026gt; create table tc_utf8_21813(c1 int primary key auto_increment, c2 char(30), c3 varchar(21845)) charset=utf8; Row size too large. The maximum row size for the used table type, not counting BLOBs, is 65535. This includes storage overhead, check the manual. You have to change some columns to TEXT or BLOBs mysql\u0026gt; create table tc_utf8_21846(c1 int primary key auto_increment, c2 char(30), c3 varchar(21846)) charset=utf8; Query OK, 0 rows affected, 1 warnings (0.10 sec) mysql\u0026gt; show warnings; +-------+------+---------------------------------------------+ | Level | Code | Message | +-------+------+---------------------------------------------+ | Note | 1246 | Converting column \u0026#39;c3\u0026#39; from VARCHAR to TEXT | +-------+------+---------------------------------------------+ 1 rows in set (0.14 sec) 即在非严格模式下，因为N=21813 \u0026gt; 21812，所以报 Row size too large 错误。但N=21846 \u0026gt; (65535/3)时，只是出现warnings，varchar自动变成了mediumtext 类型。\n细心的朋友可能注意到上面开始我看了一下字符集 show variabels like \u0026quot;char%\u0026quot;;，因为接下来要说明另外一个问题：客户端字符集与database不一样的情况。\n我们回到 N\u0026lt;=21812 的正常情况：\n1 2 3 4 5 6 CREATE TABLE `tc_utf8` ( `c1` int(11) NOT NULL AUTO_INCREMENT, `c2` char(30) DEFAULT NULL, `c3` varchar(30) DEFAULT NULL, PRIMARY KEY (`c1`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; 插入一些数据：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 mysql\u0026gt; set names utf8; mysql\u0026gt; insert into tc_utf8(c2,c3) values(\u0026#39;en_30\u0026#39;,repeat(\u0026#39;a\u0026#39;,30)); Query OK, 1 rows affected (17.87 sec) mysql\u0026gt; insert into tc_utf8(c2,c3) values(\u0026#39;en_31\u0026#39;,repeat(\u0026#39;b\u0026#39;,31)); Query OK, 1 rows affected, 1 warnings (0.10 sec) mysql\u0026gt; show warnings; +---------+------+-----------------------------------------+ | Level | Code | Message | +---------+------+-----------------------------------------+ | Warning | 1265 | Data truncated for column \u0026#39;c3\u0026#39; at row 1 | +---------+------+-----------------------------------------+ 1 rows in set (0.14 sec) mysql\u0026gt; insert into tc_utf8(c2,c3) values(\u0026#39;zh_30\u0026#39;,repeat(\u0026#39;中\u0026#39;,30)); Query OK, 1 rows affected (0.18 sec) mysql\u0026gt; insert into tc_utf8(c2,c3) values(\u0026#39;zh_31\u0026#39;,repeat(\u0026#39;文\u0026#39;,31)); Query OK, 1 rows affected, 1 warnings (0.09 sec) 意料之中，汉字同样被截断 ysql\u0026gt; select c2,c3,length(c3),char_length(c3) from tc_utf8; +-------+------------+-----------------+------------------------------------------------------------------------+ | c2 | length(c3) | char_length(c3) | c3 | +-------+------------+-----------------+------------------------------------------------------------------------+ | en_30 | 30 | 30 | aaaaaaaaaaaaaaaaaaaaaaaaaaaaaa | | en_31 | 30 | 30 | bbbbbbbbbbbbbbbbbbbbbbbbbbbbbb | | zh_30 | 90 | 30 | 中中中中中中中中中中中中中中中中中中中中中中中中中中中中中中 | | zh_31 | 90 | 30 | 文文文文文文文文文文文文文文文文文文文文文文文文文文文文文文 | +-------+------------+-----------------+------------------------------------------------------------------------+ 4 rows in set (0.00 sec) 上面的en_30代表insert的时候存入30个英文字符。可以看到30个a占用30个字节，30个汉字占用90个字节，大于30的会被截断，证实了文章一开头的说法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 mysql\u0026gt; set names latin1; mysql\u0026gt; insert into tc_utf8(c2,c3) values(\u0026#39;zh_30_latin1\u0026#39;,repeat(\u0026#39;中\u0026#39;,30)); Query OK, 1 rows affected, 1 warnings (0.10 sec) mysql\u0026gt; show warnings; +---------+------+-----------------------------------------+ | Level | Code | Message | +---------+------+-----------------------------------------+ | Warning | 1265 | Data truncated for column \u0026#39;c3\u0026#39; at row 1 | +---------+------+-----------------------------------------+ 1 rows in set (0.14 sec) mysql\u0026gt; insert into tc_utf8(c2,c3) values(\u0026#39;zh_10_latin1\u0026#39;,repeat(\u0026#39;中\u0026#39;,10)); Query OK, 1 rows affected (0.10 sec) mysql\u0026gt; insert into tc_utf8(c2,c3) values(\u0026#39;zh_10_latin1\u0026#39;,repeat(\u0026#39;文\u0026#39;,10)); Query OK, 1 rows affected (0.11 sec) mysql\u0026gt; insert into tc_utf8(c2,c3) values(\u0026#39;zh_11_latin1\u0026#39;,repeat(\u0026#39;文\u0026#39;,11)); Query OK, 1 rows affected, 1 warnings (0.12 sec) 截断 上面的实验显示，db table是utf8，但客户端连接时使用latin1，在非严格模式下 varchar(30) 只能存10个汉字，多余的尾部被截断了\n我们来看一下占用字节的情况：（2,3行的乱码是意料之中的）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 mysql\u0026gt; select c1,c2,c3,length(c3),char_length(c3) from tc_utf8; +----+--------------+--------------------------------+------------+-----------------+ | c1 | c2 | c3 | length(c3) | char_length(c3) | +----+--------------+--------------------------------+------------+-----------------+ | 1 | en_30 | aaaaaaaaaaaaaaaaaaaaaaaaaaaaaa | 30 | 30 | | 2 | en_31 | bbbbbbbbbbbbbbbbbbbbbbbbbbbbbb | 30 | 30 | | 3 | zh_30 | ?????????????????????????????? | 90 | 30 | | 4 | zh_31 | ?????????????????????????????? | 90 | 30 | | 5 | zh_30_latin1 | 中中中中中中中中中中 | 60 | 30 | | 6 | zh_10_latin1 | 中中中中中中中中中中 | 60 | 30 | | 7 | zh_10_latin1 | 文文文文文文文文文文 | 80 | 30 | | 9 | zh_11_latin1 | 文文文文文文文文文文 | 80 | 30 | +----+--------------+--------------------------------+------------+-----------------+ 8 rows in set (0.14 sec) 看到char_length函数算出的中、英文字符个数都是30，但一个“中”占6字节，一个“文”占8字节，是不是很诧异，这中间有数次的编码转换过程，有兴趣 可以参考 http://mysql.rjweb.org/doc.php/charcoll ，是可以模拟出来的。\n在严格模式下就没这么复杂了，所以尽量使用 STRICT_TRANS_TABLES ，避免意外的情况带入生产环境。早期设计的时候就要保持客户端与数据库字符集一致。\n参考 MySQL manual:The CHAR and VARCHAR Types MySQL字符集指南\u0026ndash;进阶篇V0.7 MySQL字符集与校对规则 MySQL String Length http://sunny90.com/a/database/2014/0819/24.html 本文链接地址：http://xgknight.com/2016/04/28/mysql-char-varchar-set/\n","permalink":"http://localhost:1313/2016/04/mysql-char-varchar-set/","summary":"\u003cp\u003e数据类型差不多是接触mysql一开始就了解的内容，最近遇到几个现象如varchar自动转mediumtext，blob存储性能的问题，不得不回头明确一下关于MySQL常用数据类型的选择。\u003c/p\u003e","title":"MySQL字符数据类型char与varchar的区别"},{"content":"1. MySQL莫名变成了 Strict SQL Mode 最近测试组那边反应数据库部分写入失败，app层提示是插入成功，但表里面里面没有产生数据，而两个写入操作的另外一个表有数据。因为 insert 失败在数据库层面是看不出来的，于是找php的同事看下错误信息：\n1 [Err] 1364 - Field `f_company_id` doesn\u0026#39;t have a default value 很明显2个 insert 操作，第一条成功，第二条失败了，但因为没有控制在一个事务当中，导致app里面依然提示成功，这是客户入库操作，心想如果线上也有这个问题得是多大的代价。\n不说开发的问题，好端端的mysql怎么突然就部分表写入失败呢？根据上面的问题很快能猜到是 sql_mode 问题： NOT NULL 列没有默认值但代码里也没给值，在非严格模式下，int列默认为0，string列默认为\u0026rsquo;\u0026lsquo;了，所以不成问题；但在严格模式下，是直接返回失败的。\n一看，果然：\n1 2 3 4 5 6 mysql\u0026gt; show variables like \u0026#34;sql_mode\u0026#34;; +---------------+--------------------------------------------+ | Variable_name | Value | +---------------+--------------------------------------------+ | sql_mode | STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION | +---------------+--------------------------------------------+ 但是一直是没问题的的，就突然出现了，有谁会去改 sql_mode 呢，生产环境产生这个问题的风险有多大？所以必须揪出来。\n先 set global sql_mode='' ，让他们用着先（文后会给解决问题根本的办法），同时打开general_log看是哪一个用户有类似设置 sql_mode 命令：\n1 2 3 4 1134456 Query SET autocommit=1 1134456 Query Set sql_mode=\u0026#39;NO_ENGINE_SUBSITUTION,STRICT_TRANS_TABLES\u0026#39; 1134457 Connect ecuser@10.0.200.173 on 1134457 Query /* mysql-connector-java-5.1.35 ... 看出是java组那边哪个框架建立连接的时候使用设置了sql_mode，但这是session级别的，不影响php那边用户的连接。\n那会是什么原因在 set global 之后又变回strict模式呢，于是想到 mysqld_safe 启动实际是一个保护进程，在mysqld异常停止之后会拉起来，会不会中间有异常导致 mysqld 重启，致使 global 失效？看了mysql错误日志，才想到前些天断过电，所以决定直接改 /etc/my.cnf配置：\n1 2 [mysqld] sql_mode=NO_ENGINE_SUBSTITUTION 重启myqld之后，还是STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION，很少遇到my.cnf里面配置不生效的情况。无独有偶，在 stackoverflow上找到同样的问题 how-to-make-sql-mode-no-engine-substitution-permanent-in-mysql-my-cnf ，原因很简单，sql_mode这个选项被其它地方的配置覆盖了。\n了解一下mysql配置文件的加载顺序：\n1 2 3 $ mysqld --help --verbose|grep -A1 -B1 cnf Default options are read from the following files in the given order: /etc/my.cnf /etc/mysql/my.cnf /usr/etc/my.cnf ~/.my.cnf mysql按照上面的顺序加载配置文件，后面的配置项会覆盖前面的。最后终于在 /usr/my.cnf 找到有一条sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES，把这个文件删掉，/etc/my.cnf 里面的就生效了。\n但是目前没能整明白的是，mysql运行这么长时间怎么突然在/usr （MYSQL_BASE）下多个my.cnf，也不像人为创建的。其它实例也没这样的问题。\n类似还出现过一例：存储过程里把 \u0026rsquo;\u0026rsquo; 传给int型的，严格模式是不允许，而非严格模式只是一个warning。（命令行执行完语句后，show warnings 可看见）\n那么解决这类问题的终极（推荐）办法其实是，考虑到数据的兼容性和准确性，MySQL就应该运行在严格模式下！无论开发环境还是生产环境，否则代码移植到线上可能产生隐藏的问题。\nsql_mode 问题可以很简单，也可以很复杂。曾经在一个交流群里看到有人提到，主从sql_mode设置不一致导致复制异常，这里自己正好全面了解一下几个常用的值，方便以后排除问题多个方向。\n2. sql_mode 常用值说明 官方手册专门有一节介绍 https://dev.mysql.com/doc/refman/5.6/en/sql-mode.html 。 SQL Mode 定义了两个方面：MySQL应支持的SQL语法，以及应该在数据上执行何种确认检查。\nSQL语法支持类 ONLY_FULL_GROUP_BY\n对于GROUP BY聚合操作，如果在SELECT中的列、HAVING或者ORDER BY子句的列，没有在GROUP BY中出现，那么这个SQL是不合法的。是可以理解的，因为不在 group by 的列查出来展示会有矛盾。\n在5.7中默认启用，所以在实施5.6升级到5.7的过程需要注意： 1 2 3 4 5 Expression #1 of SELECT list is not in GROUP BY clause and contains nonaggregated column \u0026#39;1066export.ebay_order_items.TransactionID\u0026#39; which is not functionally dependent on columns in GROUP BY clause; this is incompatible with sql_mode=only_full_group_by ANSI_QUOTES\n启用 ANSI_QUOTES 后，不能用双引号来引用字符串，因为它被解释为识别符，作用与 ` 一样。\n设置它以后，update t set f1=\u0026quot;\u0026quot; ...，会报 Unknown column \u0026rsquo;\u0026rsquo; in \u0026lsquo;field list 这样的语法错误。\nPIPES_AS_CONCAT\n将 || 视为字符串的连接操作符而非 或 运算符，这和Oracle数据库是一样的，也和字符串的拼接函数 CONCAT() 相类似\nNO_TABLE_OPTIONS\n使用 SHOW CREATE TABLE 时不会输出MySQL特有的语法部分，如 ENGINE ，这个在使用 mysqldump 跨DB种类迁移的时候需要考虑。\nNO_AUTO_CREATE_USER\n字面意思不自动创建用户。在给MySQL用户授权时，我们习惯使用 GRANT ... ON ... TO dbuser 顺道一起创建用户。设置该选项后就与oracle操作类似，授权之前必须先建立用户。5.7.7开始也默认了。\n数据检查类\nNO_ZERO_DATE\n认为日期 \u0026lsquo;0000-00-00\u0026rsquo; 非法，与是否设置后面的严格模式有关。\n1.如果设置了严格模式，则 NO_ZERO_DATE 自然满足。但如果是 INSERT IGNORE 或 UPDATE IGNORE，\u0026lsquo;0000-00-00\u0026rsquo;依然允许且只显示warning\n2.如果在非严格模式下，设置了NO_ZERO_DATE，效果与上面一样，\u0026lsquo;0000-00-00\u0026rsquo;允许但显示warning；如果没有设置NO_ZERO_DATE，no warning，当做完全合法的值。 3.NO_ZERO_IN_DATE情况与上面类似，不同的是控制日期和天，是否可为 0 ，即 2010-01-00 是否合法。\nNO_ENGINE_SUBSTITUTION\n使用 ALTER TABLE或CREATE TABLE 指定 ENGINE 时， 需要的存储引擎被禁用或未编译，该如何处理。启用NO_ENGINE_SUBSTITUTION时，那么直接抛出错误；不设置此值时，CREATE用默认的存储引擎替代，ATLER不进行更改，并抛出一个 warning .\nSTRICT_TRANS_TABLES 设置它，表示启用严格模式。\n注意 STRICT_TRANS_TABLES 不是几种策略的组合，单独指 INSERT、UPDATE出现少值或无效值该如何处理: 1.前面提到的把 \u0026rsquo;\u0026rsquo; 传给int，严格模式下非法，若启用非严格模式则变成0，产生一个warning 2.Out Of Range，变成插入最大边界值 3.A value is missing when a new row to be inserted does not contain a value for a non-NULL column that has no explicit DEFAULT clause in its definition\n上面并没有囊括所有的 SQL Mode，选了几个代表性的，详细还是 看手册。\nsql_mode一般来说很少去关注它，没有遇到实际问题之前不会去启停上面的条目。我们常设置的 sql_mode 是 ANSI、STRICT_TRANS_TABLES、TRADITIONAL，ansi和traditional是上面的几种组合。\nANSI：更改语法和行为，使其更符合标准SQL 相当于REAL_AS_FLOAT, PIPES_AS_CONCAT, ANSI_QUOTES, IGNORE_SPACE TRADITIONAL：更像传统SQL数据库系统，该模式的简单描述是当在列中插入不正确的值时“给出错误而不是警告”。 相当于 STRICT_TRANS_TABLES, STRICT_ALL_TABLES, NO_ZERO_IN_DATE, NO_ZERO_DATE, ERROR_FOR_DIVISION_BY_ZERO, NO_AUTO_CREATE_USER, NO_ENGINE_SUBSTITUTION ORACLE：相当于 PIPES_AS_CONCAT, ANSI_QUOTES, IGNORE_SPACE, NO_KEY_OPTIONS, NO_TABLE_OPTIONS, NO_FIELD_OPTIONS, NO_AUTO_CREATE_USER 无论何种mode，产生error之后就意味着单条sql执行失败，对于支持事务的表，则导致当前事务回滚；但如果没有放在事务中执行，或者不支持事务的存储引擎表，则可能导致数据不一致。MySQL认为，相比直接报错终止，数据不一致问题更严重。于是 STRICT_TRANS_TABLES 对非事务表依然尽可能的让写入继续，比如给个\u0026quot;最合理\u0026quot;的默认值或截断。而对于 STRICT_ALL_TABLES，如果是单条更新，则不影响，但如果更新的是多条，第一条成功，后面失败则会出现部分更新。\n5.6.6 以后版本默认就是NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES，5.5默认为 \u0026rsquo;\u0026rsquo; 。\n3. 设置 sql_mode 查看\n1 2 3 4 5 6 7 8 9 10 11 查看当前连接会话的sql模式： mysql\u0026gt; select @@session.sql_mode; 或者从环境变量里取 mysql\u0026gt; show variables like \u0026#34;sql_mode\u0026#34;; 查看全局sql_mode设置： mysql\u0026gt; select @@global.sql_mode; 只设置global，需要重新连接进来才会生效 设置\n1 2 3 4 5 6 7 8 9 10 11 12 形式如 mysql\u0026gt; set sql_mode=\u0026#39;\u0026#39;; mysql\u0026gt; set global sql_mode=\u0026#39;NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES\u0026#39;; 如果是自定义的模式组合，可以像下面这样 Adding only one mode to sql_mode without removing existing ones: mysql\u0026gt; SET sql_mode=(SELECT CONCAT(@@sql_mode,\u0026#39;,\u0026lt;mode_to_add\u0026gt;\u0026#39;)); Removing only a specific mode from sql_mode without removing others: mysql\u0026gt; SET sql_mode=(SELECT REPLACE(@@sql_mode,\u0026#39;\u0026lt;mode_to_remove\u0026gt;\u0026#39;,\u0026#39;\u0026#39;)); 配置文件里面设置sql-mode=\u0026quot;\u0026quot; 。\n一个有趣的试验 updated: 2017-12-10\n现网做数据迁移测试时报另一个错误，原由是这样的：一个1.8亿的表里面，因为某种原因需要把字段定义null改为not null，避免下游服务（如ES）处理特殊数据时异常情况。但这是一个并发dml非常高又达到100多G的大表，online ddl针对这种修改字段类型简直束手无策，pt-osc也慢的很。\n刚好有一个做数据迁移的契机，原本打算在新库上把字段改好，再通过dts或类似的数据迁移工具，同步过去。在非严格模式下，原本是null的值也会变成0或\u0026rsquo;\u0026rsquo;，但还是报错了：\n1 2 3 4 5 6 7 set sql_mode=\u0026#39;\u0026#39;; -- 置为非严格模式 insert into t(id, a) values(1, null); [Err] 1048 - Column \u0026#39;a\u0026#39; cannot be null 然而 insert into t(id, a) values(1, null),(2, null),; Affected rows: 2 找到官方文档上的原话，可以解释：\nIf you are not using strict mode, then whenever you insert an “incorrect” value into a column, such as a NULL into a NOT NULL column or a too-large numeric value into a numeric column, MySQL sets the column to the “best possible value” instead of producing an error\nIf you try to store NULL into a column that doesn\u0026rsquo;t take NULL values, an error occurs for single-row INSERT statements. For multiple-row INSERT statements or for INSERT INTO \u0026hellip; SELECT statements, MySQL Server stores the implicit default value for the column data type\n非严格模式下，单行插入 null 到 not null 列，会失败；多行插入则只是warning。规则是这样，也就无需解释。\n参考 MySQL manual sql-mode mysql的sql_mode合理设置 set-sql-mode-blank-after-upgrading-to-mysql-5-6 MySQL SQL_MODE详解 原文链接地址：http://xgknight.com/2016/04/22/mysql-sql-mode-troubleshooting/\n","permalink":"http://localhost:1313/2016/04/mysql-sql-mode-troubleshooting/","summary":"\u003ch2 id=\"1-mysql莫名变成了-strict-sql-mode\"\u003e1. MySQL莫名变成了 Strict SQL Mode\u003c/h2\u003e\n\u003cp\u003e最近测试组那边反应数据库部分写入失败，app层提示是插入成功，但表里面里面没有产生数据，而两个写入操作的另外一个表有数据。因为 insert 失败在数据库层面是看不出来的，于是找php的同事看下错误信息：\u003c/p\u003e","title":"MySQL sql_mode 说明（及处理一起 sql_mode 引发的问题）"},{"content":"这个亏已经吃过很多次了，在开发以前的sql代码里面，许多以 or 作为where条件的查询，甚至更新。这里举例来说明使用 or 的弊端，以及改进办法。\n1 2 select f_crm_id from d_dbname1.t_tbname1 where f_xxx_id = 926067 and (f_mobile =\u0026#39;1234567891\u0026#39; or f_phone =\u0026#39;1234567891\u0026#39; ) limit 1 从查询语句很容易看出，f_mobile和f_phone两个字段都有可能存电话号码，一般思路都是用 or 去一条sql解决，但表数据量一大简直是灾难： t_tbanme1上有索引idx_id_mobile(f_xxx_id,f_mobile), idx_phone(f_phone),idx_id_email(f_id,f_email)，explain 的结果却使用了 idx_id_email 索引，有时候运气好可能走 idx_id_mobile f_xxx_id\n因为mysql的每条查询，每个表上只能选择一个索引。如果使用了 idx_id_mobile 索引，恰好有一条数据，因为有 limit 1 ，那么恭喜很快得到结果；但如果 f_mobile 没有数据，那 f_phone 字段只能在f_id条件下挨个查找，扫描12w行。 or 跟 and 不一样，甚至有开发认为添加 (f_xxx_id,f_mobile,f_phone)不就完美了吗，要吐血了~\n那么优化sql呢，很简单（注意f_mobile,f_phone上都要有相应的索引），方法一：\n1 2 3 (select f_crm_id from d_dbname1.t_tbname1 where f_xxx_id = 900000 and f_mobile =\u0026#39;1234567891\u0026#39; limit 1 ) UNION ALL (select f_crm_id from d_dbname1.t_tbname1 where f_xxx_id = 900000 and f_phone =\u0026#39;1234567891\u0026#39; limit 1 ) 两条独立的sql都能用上索引，分查询各自limit，如果都有结果集返回，随便取一条就行。\n还有一种优化办法，如果这种查询特别频繁（又无缓存），改成单独的sql执行，比如大部分号码值都在f_mobile上，那就先执行分sql1，有结果则结束，判断没有结果再执行分sql2 ，能减少数据库查询速度，让代码去处理更多的事情，方法二伪代码：\n1 2 3 4 5 sql1 = select f_crm_id from d_dbname1.t_tbname1 where f_xxx_id = 900000 and f_mobile =\u0026#39;1234567891\u0026#39; limit 1; sq1.execute(); if no result sql1: sql1 = select f_crm_id from d_dbname1.t_tbname1 where f_xxx_id = 900000 and f_phone =\u0026#39;1234567891\u0026#39; limit 1; sql1.execute(); 复杂一点的场景是止返回一条记录那么简单，limit 2：\n1 2 3 select a.f_crm_id from d_dbname1.t_tbname1 as a where (a.f_create_time \u0026gt; from_unixtime(\u0026#39;1464107527\u0026#39;) or a.f_modify_time \u0026gt; from_unixtime(\u0026#39;1464107527\u0026#39;) ) limit 0,200 这种情况方法一、二都需要改造，因为 f_create_time，f_modify_time 都可能均满足判断条件，这样就会返回重复的数据。\n方法一需要改造：\n1 2 3 4 5 6 7 (select a.f_crm_id from d_dbname1.t_tbname1 as a where a.f_create_time \u0026gt; from_unixtime(\u0026#39;1464397527\u0026#39;) limit 0,200 ) UNION ALL (select a.f_crm_id from d_dbname1.t_tbname1 as a where a.f_modify_time \u0026gt; from_unixtime(\u0026#39;1464397527\u0026#39;) and a.f_create_time \u0026lt;= from_unixtime(\u0026#39;1464397527\u0026#39;) limit 0,200 ) 有人说 把 UNION ALL 改成 UNION 不就去重了吗？如果说查询比较频繁，或者limit比较大，数据库还是会有压力，所以需要做trade off。\n这种情况更多还是适合方法二，包括有可能需要 order by limit 情况。改造伪代码：\n1 2 3 4 5 6 7 8 sql1 = (select a.f_crm_id from d_dbname1.t_tbname1 as a where a.f_create_time \u0026gt; from_unixtime(\u0026#39;1464397527\u0026#39;) limit 0,200 ); sql1.execute(); sql1_count = sql1.result.count if sql1_count \u0026lt; 200 : sql2 = (select a.f_crm_id from d_dbname1.t_tbname1 as a where a.f_modify_time \u0026gt; from_unixtime(\u0026#39;1464397527\u0026#39;) and a.f_create_time \u0026lt;= from_unixtime(\u0026#39;1464397527\u0026#39;) limit 0, (200 - sql1_count) ); sql2.execute(); final_result = paste(sql1,sql2); or条件在数据库上很难优化，能在代码里优化逻辑，不至于拖垮数据库。只有在 or 条件下无需索引时（且需要比较的数据量小），才考虑。\n相同字段 or 可改成 in，如 f_id=1 or f_id=100 -\u0026gt; f_id in (1,100)。 效率问题见文章 mysql中or和in的效率问题 。\n上述优化情景都是存储引擎在 InnoDB 情况下，在MyISAM有不同，见mysql or条件可以使用索引而避免全表 。\n原文链接地址：http://xgknight.com/2016/04/05/mysql-avoid-or-query/\n","permalink":"http://localhost:1313/2016/04/mysql-avoid-or-query/","summary":"\u003cp\u003e这个亏已经吃过很多次了，在开发以前的sql代码里面，许多以 or 作为where条件的查询，甚至更新。这里举例来说明使用 or 的弊端，以及改进办法。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e2\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-fallback\" data-lang=\"fallback\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eselect f_crm_id from d_dbname1.t_tbname1 where  f_xxx_id = 926067  \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eand (f_mobile =\u0026#39;1234567891\u0026#39; or f_phone =\u0026#39;1234567891\u0026#39; ) limit 1\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e从查询语句很容易看出，f_mobile和f_phone两个字段都有可能存电话号码，一般思路都是用 or 去一条sql解决，但表数据量一大简直是灾难：\n\u003cimg loading=\"lazy\" src=\"http://github.com/seanlook/sean-notes-comment/raw/main/static/mysql-avoid-or-1.png\"\u003e\u003c/p\u003e","title":"MySQL避免索引列使用 OR 条件"},{"content":"sysbench是一个模块化的、跨平台、多线程基准测试工具，主要用于评估测试各种不同系统参数下的数据库负载情况。关于这个项目的详细介绍请看：https://github.com/akopytov/sysbench 。 它主要包括以下几种方式的测试：\ncpu性能 磁盘io性能 调度程序性能 内存分配及传输速度 POSIX线程性能 数据库性能(OLTP基准测试) sysbench的数据库OLTP测试支持MySQL、PostgreSQL、Oracle，目前主要用于Linux操作系统，开源社区已经将sysbench移植到了Windows，并支持SQL Server的基准测试。\n废话不多说，开始。\n1. sysbench安装 mysql版本: mysql-community-server-5.6.29 OS: CentOS 6.7 X86_64 sysbench 0.5相比0.4版本有一些变化，包括oltp测试结合了lua脚本，还多了一些隐藏选项，本文会涉及得到一部分。 目前许多仓库里已编译好的二进制sysbench还是0.4.x版本，不过现在主流也还是github上的0.5，可以从 这里下载0.5版本的rpm包直接安装，不过我选择自己编译，因为只有这个办法是通用的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // 先安装编译依赖环境 $ sudo yum install gcc gcc-c++ automake make libtool mysql-community-devel $ cd /tmp \u0026amp;\u0026amp; git clone https://github.com/akopytov/sysbench.git $ cd /tmp/sysbench \u0026amp;\u0026amp; ./autogen.sh $ ./configure --prefix=/usr/local/sysbench-0.5 $ ./make \u0026amp;\u0026amp; sudo make install // 0.5版本需要oltp.lua测试脚本 // 如果是rpm包方式安装的，在 /usr/share/doc/sysbench/tests/db/ 下可找到 $ cd /usr/local/sysbench \u0026amp;\u0026amp; sudo mkdir -p share/tests/db $ cp /tmp/sysbench/sysbench/tests/db/*.lua share/tests/db/ $ ./bin/sysbench --version sysbench 0.5 如果需要测试PostgreSQL、Oracle，则在configure时需要加上 \u0026ndash;with-oracle 或者 –with-pgsql 参数\n2. 使用sysbench对mysql压测 2.1 只读示例 1 2 3 4 5 6 7 8 ./bin/sysbench --test=./share/tests/db/oltp.lua \\ --mysql-host=10.0.201.36 --mysql-port=8066 --mysql-user=ecuser --mysql-password=ecuser \\ --mysql-db=dbtest1a --oltp-tables-count=10 --oltp-table-size=500000 \\ --report-interval=10 --oltp-dist-type=uniform --rand-init=on --max-requests=0 \\ --oltp-test-mode=nontrx --oltp-nontrx-mode=select \\ --oltp-read-only=on --oltp-skip-trx=on \\ --max-time=120 --num-threads=12 \\ [prepare|run|cleanup] 注意最后一行，一项测试开始前需要用prepare来准备好表和数据，run执行真正的压测，cleanup用来清除数据和表。实际prepare的表结构：\n1 2 3 4 5 6 7 8 9 10 mysql\u0026gt; desc dbtest1a.sbtest1; +-------+------------------+------+-----+---------+----------------+ | Field | Type | Null | Key | Default | Extra | +-------+------------------+------+-----+---------+----------------+ | id | int(10) unsigned | NO | PRI | NULL | auto_increment | | k | int(10) unsigned | NO | MUL | 0 | | | c | char(120) | NO | | | | | pad | char(60) | NO | | | | +-------+------------------+------+-----+---------+----------------+ 4 rows in set (0.00 sec) 上面的测试命令代表的是：对mysql进行oltp基准测试，表数量10，每表行数约50w（几乎delete多少就会insert的多少），并且是非事务的只读测试，持续60s，并发线程数12。\n需要说明的选项：\nmysql-db=dbtest1a：测试使用的目标数据库，这个库名要事先创建\n--oltp-tables-count=10：产生表的数量\n--oltp-table-size=500000：每个表产生的记录行数\n--oltp-dist-type=uniform：指定随机取样类型，可选值有 uniform(均匀分布), Gaussian(高斯分布), special(空间分布)。默认是special\n--oltp-read-only=off：表示不止产生只读SQL，也就是使用oltp.lua时会采用读写混合模式。默认 off，如果设置为on，则不会产生update,delete,insert的sql。\n--oltp-test-mode=nontrx ：执行模式，这里是非事务式的。可选值有simple,complex,nontrx。默认是complex\nsimple：简单查询，SELECT c FROM sbtest WHERE id=N complex (advanced transactional)：事务模式在开始和结束事务之前加上begin和commit， 一个事务里可以有多个语句，如点查询、范围查询、排序查询、更新、删除、插入等，并且为了不破坏测试表的数据，该模式下一条记录删除后会在同一个事务里添加一条相同的记录。 nontrx (non-transactional)：与simple相似，但是可以进行update/insert等操作，所以如果做连续的对比压测，你可能需要重新cleanup,prepare。 --oltp-skip-trx=[on|off]：省略begin/commit语句。默认是off\n--rand-init=on：是否随机初始化数据，如果不随机化那么初始好的数据每行内容除了主键不同外其他完全相同\n--num-threads=12： 并发线程数，可以理解为模拟的客户端并发连接数\n--report-interval=10：表示每10s输出一次测试进度报告\n--max-requests=0：压力测试产生请求的总数，如果以下面的max-time来记，这个值设为0\n--max-time=120：压力测试的持续时间，这里是2分钟。\n注意，针对不同的选项取值就会有不同的子选项。比如oltp-dist-type=special，就有比如oltp-dist-pct=1、oltp-dist-res=50两个子选项，代表有50%的查询落在1%的行（即热点数据）上，另外50%均匀的(sample uniformly)落在另外99%的记录行上。\n再比如oltp-test-mode=nontrx时, 就可以有oltp-nontrx-mode，可选值有select（默认）, update_key, update_nokey, insert, delete，代表非事务式模式下使用的测试sql类型。\n以上代表的是一个只读的例子，可以把num-threads依次递增（16,36,72,128,256,512），或者调整my.cnf参数，比较效果。另外需要注意的是，大部分mysql中间件对事务的处理，默认都是把sql发到主库执行，所以只读测试需要加上oltp-skip-trx=on来跳过测试中的显式事务。\nps1: 只读测试也可以使用share/tests/db/select.lua进行，但只是简单的point select。 ps2: 我在用sysbench压的时候，在mysql后端会话里有时看到大量的query cache lock，如果使用的是uniform取样，最好把查询缓存关掉。当然如果是做两组性能对比压测，因为都受这个因素影响，关心也不大。\n2.2 混合读写 读写测试还是用oltp.lua，只需把--oltp-read-only等于off。\n1 2 3 4 5 ./bin/sysbench --test=./share/tests/db/oltp.lua --mysql-host=10.0.201.36 --mysql-port=8066 --mysql-user=ecuser --mysql-password=ecuser --mysql-db=dbtest1a --oltp-tables-count=10 --oltp-table-size=500000 --report-interval=10 --rand-init=on --max-requests=0 --oltp-test-mode=nontrx --oltp-nontrx-mode=select --oltp-read-only=off --max-time=120 --num-threads=128 prepare ./bin/sysbench --test=./share/tests/db/oltp.lua --mysql-host=10.0.201.36 --mysql-port=8066 --mysql-user=ecuser --mysql-password=ecuser --mysql-db=dbtest1a --oltp-tables-count=10 --oltp-table-size=500000 --report-interval=10 --rand-init=on --max-requests=0 --oltp-test-mode=nontrx --oltp-nontrx-mode=select --oltp-read-only=off --max-time=120 --num-threads=128 run ./bin/sysbench --test=./share/tests/db/oltp.lua --mysql-host=10.0.201.36 --mysql-port=8066 --mysql-user=ecuser --mysql-password=ecuser --mysql-db=dbtest1a --oltp-tables-count=10 --oltp-table-size=500000 --report-interval=10 --rand-init=on --max-requests=0 --oltp-test-mode=nontrx --oltp-nontrx-mode=select --oltp-read-only=off --max-time=120 --num-threads=128 cleanup 然而oltp-test-mode=nontrx一直没有跟着我预期的去走，在mysql general log里面看到的sql记录与complex模式相同。所以上面示例中的--oltp-test-mode=nontrx --oltp-nontrx-mode=select可以删掉。\n**update: ** sysbench作者 akopytov 对我这个疑问有了回复：https://github.com/akopytov/sysbench/issues/34 ，原来sysbench 0.5版本去掉了这个选项，因为作者正在准备1.0版本，所以也就没有更新0.5版本的doc。网上的博客漫天飞，就没有一个提出来的，也是没谁了。\n分析一下oltp.lua脚本内容，可以清楚单个事务各操作的默认比例：select:update_key:update_non_key:delete:insert = 14:1:1:1:1，可通过oltp-point-selects、oltp-simple-ranges、oltp-sum-ranges、oltp-order-ranges、oltp-distinct-ranges，oltp-index-updates、oltp-non-index-updates这些选项去调整读写权重。\n同只读测试一样，在atlas,mycat这类中间件测试中如果不加oltp-skip-trx=on，那么所有查询都会发往主库，但如果在有写入的情况下使用--oltp-skip-trx=on跳过BEGIN和COMMIT，会出现问题：\nALERT: failed to execute MySQL query: INSERT INTO sbtest4 (id, k, c, pad) VALUES (48228, 47329, '82773802508-44916890724-85859319254-67627358653-96425730419-64102446666-75789993135-91202056934-68463872307-28147315305', '13146850449-23153169696-47584324044-14749610547-34267941374'): ALERT: Error 1062 Duplicate entry \u0026lsquo;48228\u0026rsquo; for key \u0026lsquo;PRIMARY\u0026rsquo; FATAL: failed to execute function `event\u0026rsquo;: (null)\n原因也很容易理解，每个线程将选择一个随机的表，不加事务的情况下高并发更新（插入）出现重复key的概率很大，但我们压测不在乎这些数据，所以需要跳过这个错误--mysql-ignore-errors=1062，这个问题老外有出过打补丁的方案允许--mysql-ignore-duplicates=on，但作者新加入的忽略错误码这个功能已经取代了它。mysql-ignore-errors选项是0.5版本加入的，但目前没有文档标明，也是我在github上提的 issue 作者回复的。\n这里不得不佩服老外的办事效率和责任心，提个疑惑能立马得到回复，反观国内，比如在atlas,mycat项目里提到问题到现在都没人搭理。。。\n2.3 只更新 如果基准测试的时候，你只想比较两个项目的update（或insert）效率，那可以不使用oltp脚本，而直接改用update_index.lua：\n1 2 3 4 5 6 ./bin/sysbench --test=./share/tests/db/update_index.lua \\ --mysql-host=10.0.201.36 --mysql-port=8066 --mysql-user=ecuser --mysql-password=ecuser \\ --mysql-db=dbtest1a --oltp-tables-count=10 --oltp-table-size=500000 \\ --report-interval=10 --rand-init=on --max-requests=0 \\ --oltp-read-only=off --max-time=120 --num-threads=128 \\ [ prepare | run | cleanup ] 此时像oltp-read-only=off许多参数都失效了。需要说明的是这里 (非)索引更新，不是where条件根据索引去查找更新，而是更新索引列上的值。\n3. 结果解读 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 sysbench 0.5: multi-threaded system evaluation benchmark Running the test with following options: Number of threads: 128 Report intermediate results every 20 second(s) Initializing random number generator from timer. Random number generator seed is 0 and will be ignored Initializing worker threads... Threads started! [ 20s] threads: 128, tps: 2354.54, reads: 33035.89, writes: 9423.39, response time: 66.80ms (95%), errors: 0.00, reconnects: 0.00 [ 40s] threads: 128, tps: 2377.75, reads: 33274.26, writes: 9507.55, response time: 66.88ms (95%), errors: 0.00, reconnects: 0.00 [ 60s] threads: 128, tps: 2401.35, reads: 33615.30, writes: 9607.40, response time: 66.40ms (95%), errors: 0.00, reconnects: 0.00 [ 80s] threads: 128, tps: 2381.20, reads: 33331.50, writes: 9522.55, response time: 67.30ms (95%), errors: 0.00, reconnects: 0.00 [ 100s] threads: 128, tps: 2388.85, reads: 33446.10, writes: 9556.35, response time: 67.00ms (95%), errors: 0.00, reconnects: 0.00 [ 120s] threads: 128, tps: 2386.40, reads: 33421.35, writes: 9545.35, response time: 66.94ms (95%), errors: 0.00, reconnects: 0.00 OLTP test statistics: queries performed: read: 4003048 //总select数量 write: 1143728 //总update、insert、delete语句数量 other: 571864 //commit、unlock tables以及其他mutex的数量 total: 5718640 transactions: 285932 (2382.10 per sec.) //通常需要关注的数字(TPS) read/write requests: 5146776 (42877.85 per sec.) other operations: 571864 (4764.21 per sec.) ignored errors: 0 (0.00 per sec.) //忽略的错误数 reconnects: 0 (0.00 per sec.) General statistics: total time: 120.0334s //即max-time指定的压测实际 total number of events: 285932 //总的事件数，一般与transactions相同 total time taken by event execution: 15362.6623s response time: min: 17.60ms avg: 53.73ms //95%的语句的平均响应时间 max: 252.90ms approx. 95 percentile: 66.88ms Threads fairness: events (avg/stddev): 2233.8438/9.04 execution time (avg/stddev): 120.0208/0.01 我们一般关注的用于绘图的指标主要有：\nresponse time avg: 平均响应时间。（后面的95%的大小可以通过--percentile=98的方式去更改） transactions: 精确的说是这一项后面的TPS 。但如果使用了-oltp-skip-trx=on，这项事务数恒为0，需要用total number of events 去除以总时间，得到tps（其实还可以分为读tps和写tps） read/write requests: 用它除以总时间，得到吞吐量QPS 当然还有一些系统层面的cpu,io,mem相关指标 sysbench还可以对文件系统IO测试，CPU性能测试，以及内存分配与传输速度测试，这里就不介绍了。\n总结起来sysbench的缺点就是，模拟的表结构太简单，不像tpcc-mysql那样完整的事务系统。但对于性能压测对比还是很有用的，因为sysbench使用的环境参数限制是一样的。\n4. 参考 Percona sysbench oltp.lua sysbench manual 0.4 sysbench介绍与使用 sysbench测试mysql性能 sysbench 0.5使用手册 本文链接地址：http://xgknight.com/2016/03/28/mysql-sysbench\n","permalink":"http://localhost:1313/2016/03/mysql-sysbench/","summary":"\u003cp\u003esysbench是一个模块化的、跨平台、多线程基准测试工具，主要用于评估测试各种不同系统参数下的数据库负载情况。关于这个项目的详细介绍请看：https://github.com/akopytov/sysbench 。\n它主要包括以下几种方式的测试：\u003c/p\u003e","title":"使用sysbench对mysql压力测试"},{"content":"从公司网管那捣鼓来一个“遗弃” Mac mini，说其它人觉得用起来太卡，正好我的工作PC( CPU 4×i3，MEM 8G, HDD 500G)软件开多了也觉得有些卡，特别是我使用浏览器的习惯不太好，每次搜索统一结果都要打开好多标签页对比，文章性质的觉得有用想将来记录下来就没关闭页面，一两个星期下来只Chrome使用的内存就达到4G多。不用也浪费，于是就拿Mac mini分摊一下压力。\n刚拿到手时心想得有多不堪配置才使得的Mac mini卡到嫌弃的地步，看了下底面的型号，A1347——这是2014年底出的新款，没有我想象的那么旧，还好。于是找来显示器、鼠键准备开用了（在某宝上买根八字电源线）。\n但是开机密码没有啊！虽然简单重装是个办法，但我还是想看看里面现在是什么样的，杀鸡焉用牛刀。直接Crack root\u0026hellip;\n1. 破解Mac root密码 找到这篇文章 http://wowking.blog.51cto.com/1638252/753774 。我们平头百姓手头哪会有刻录的Mac OS光盘，而且也没移动光驱，所以方法一就不考虑了。方法二是单用户模式，毕竟 OS X 也是*nix血统，命令行几个命令倒难不到我。\n可是众所周知，Mac的键盘跟普通键盘是不一样的，开机启动的时候command + S在一般美式键盘下到底能不能进入单用户模式呢？嗯，行的，按下mini的开机按钮之后不断 win + S。进入Single user model之后提示符#root\u0026gt;，逐步输入以下命令：\n1 2 3 4 5 6 7 8 9 10 11 # 执行硬盘检测（只读）, 这一步可以省略 /sbin/fsck -y # 加载文件系统（读/写） /sbin/mount -uaw # 删除初始化设置时的OSX生成的隐藏文件”.applesetupdone” rm /var/db/.AppleSetupDone # 重启 reboot 重启后开机画面会指导你创建一个新的管理员账号，然后这个新的账号密码登陆。就是这么简单，接下来删用户抹除一切使用痕迹😄。\n进去之后着实令我窃喜：OS X Yosemite, 2.6 GHZ Intel Core i5, 8G DDR3, Intel Iris 1536 MB, 1TB HDD，就这配置比得上我当前的Win PC了，高兴得捡了块宝似的。优胜美地系统与我自己的Mac Book Pro一样，无缝立马开始用。\n然而面临的一个问题来了，现在2台工作电脑，配有2套鼠标键盘，切换太不方便了。于是我用大腿想了想，嗯，应该有专门的多台电脑间共享鼠键的软件。啪啪啪几下锁定两款Sharemouse、Synergy。\n2. 跨平台共享鼠标键盘-synergy 先来简单说一下Sharemouse，收费，但你懂的，但这东西毕竟用的人少，要分别在在windows和Mac两个平台上找到相同版本的破解版是多么不容易。中间折腾就不说了，成功使用 V2.0.53 版本。但号称的拖拽文件我始终没看到，我猜还是不同系统的缘故。sharemouse是有阉割了拖拽和加密功能的免费版的，而且配置超级简单，基本上只要在同一局域网，各自把软件装上，就可以用其中随便哪一电脑的鼠键来回在两个显示器之间滑动，而且还有dimmy效果。（抱歉，因为文章是后写的，没截图）\nSynergy也是鼎鼎大名的一款，而且开源、跨平台，也能复制剪切版和拖拽文件，据说它是谷歌工程师标配，因为他们也有在多台主机间控制电脑困扰。\n但synergy公司也很奇葩，工具开源，但最新版的下载不免费，你要支付之后才能看到新版下载页面（旧版本免费开放，但你明知道有bug而且已解决，纠结吧少年）。我想原因大概是synergy既要遵守开源协议，但又要维持收入吧。奇怪的是网上竟然很少有人把它共享下载。当然，如果你不嫌麻烦，可以去 https://github.com/symless/synergy 下载源码，自己编译，synergy还很友好的提供了编译指南\u0026hellip;点到为止，我也不想再浪费无谓的折腾时间。\n这里分享v1.7.4版本下载，链接: http://pan.baidu.com/s/1mhbaLza 密码: m4d7\n我现在一直使用的是synergy，鼠键接在Windows主机，但有一个问题没解决：synergy即使加入了Mac mini（用户）开机启动，但用户没输密码登陆之前，是不会启动synergy的，所以还是要另外接一套鼠键来输密码，随后synergy接管，衰，不知谁有更好的办法？\n下面简单介绍配置过程。\nwindows作服务端 synergy跟sharemouse很大不同在于，sharemouse是不分Server和Client的，鼠键可以插在任意一台电脑上，而synergy要求鼠键在Server，需要鼠键的其它电脑可以没有。\n勾选 【Server】，可以看到当前ip 点击 【设置服务端】，默认最中间显示器代表当前电脑 从右上角拖一个到你想要展示的相对位置，双击编辑 【屏幕名】（即其它电脑的主机名）\nmac做客户端 在mac【设置】里选择【安全与隐私】，点击【隐私】选项卡，【辅助功能】，勾选右边的 Synergy。 勾选【Client】，输入上一节看到的服务端ip。 同时注意 screen name 就是上一节要填入的屏幕名，也是主机名啦。 不要忘了 start，看到 starting cocoa loop 就正常了，享受 “一键” 的快感吧。\n偷偷的往后瞥了一眼，那个同事还说2套鼠键来回用。。。\n多说一句，synergy或sharemouse跟kvm切换器不同，不能实现kvm switch的屏幕扩展、录像等功能，kvm switch显示器也是共用的。\n一切似乎都完美了，开开心心的typing, browsing了2个星期，卡！一直盯着那个圈转啊转啊。Mac mini上任务也不算多，活动监视器也没看到CPU消耗大户。\n这就是这台Mac mini被抛弃的原因吗？难道我也要放弃它吗？我陷入了深深的沉思。\n网上查了查“Mac mini 换固态硬盘”，有大批的文章。一不做二不休，给Mac mini拆机换SSD ！\n3. Mac mini换SSD 跟小吴关系好，要来一个SATA接口的128G三星固态硬盘850 EVO，查了3篇文章对着看，精确每一步，这么mini的mini，拆坏一个零件或者掉个螺丝，赔不起\u0026hellip;\n就是这几篇了：\n教程：2014款低配Mac mini换SSD固态硬盘 (主要看这个，作者好有耐心) 2014款mac mini 拆机 更换ssd 升级硬盘 固态硬盘 记录教程 这还有个不是2014款的拆解视频 (没看过，写文章的时候才搜到) 但是有个问题，旧的HDD换下来，新的SSD装上去，系统资料什么的可都没了。\n解决这个问题方法可多了：\n有硬盘盒的话最方便。用Superduper或者Carbon Copy Cloner工具直接把源OSX系统+数据整盘镜像到你的SSD中，换好之后开机直接可以用了。 先手动备份（拷贝）文件到其它系统/硬盘，换上SSD后用U盘全新安装OSX，恢复数据。 好吧，好像也没有那么多方法。虽然第一种比较通用而且技术含量高，但因为这台Mac并没用多久，文稿和软件不多，备份恢复容易，于是我选择了第2种。\n另外又多说一句，Mac mini因为零部件排版紧密，没有台式机或笔记本那么多插拔的口子，CPU和内存是焊死在主板上的，所以是换不了滴。\n接下来就是心灵手巧的我，漫长的两个小时的肢解和还原过程了，此处略去一万字。\n拆的时候螺丝按顺序分开放，脑子记好零件位置，不确定之前先拍个照好还原，其它也没什么了。附图：\n几点说明：\n第一步打开黑色后盖，用刀口起子或者硬薄片轻轻在下方撬动。早前一直想转开它（老版） 用到两种螺丝刀 T6H和T9，JK 6089-A 第3步取下wifi天线，有3根线各自连接的圆圈比较难取，我是用镊子夹住网上提的。取天线的时候往后小幅度摇摆拉拽。 第4步说的取风扇排线，我是用手一边向上空提排线，一边镊子的小尖尖在下面翘。它的排线是从上空往下“按”的，跟平常印象里的“插”不一样。这个地方堵了好久 第六步把主板撬出来很关键了。千万注意啊，是水平的往出口方向使劲，“推”出来，文中说“撬”有点误导。我是以下面做支点撬，那两个孔让我给弄坏了😓，还好不太要紧。 装回去文章倒着往前看就是了 不得不说换完之后，很有成就感。下面就是装系统，感受一下要上天的ssd了。\n4. U盘安装OS X 跟用U盘安装windows还是有点不同的，要先在一台Mac电脑上格式化U盘。参考这里U盘全新安装OS X\n下载苹果官方 OS X Yosemite 正式版，解压得到 “Install OS X Yosemite.app”，拷贝到【应用程序】目录中\n使用Mac的【磁盘工具】，将U盘分区划成“Mac OS扩展(日志式)”、“GUID分区表”\n在终端里执行下面的命令\nsudo /Applications/Install\\ OS\\ X\\ Yosemite.app/Contents/Resources/createinstallmedia --volume \\ /Volumes/Untitled --applicationpath /Applications/Install\\ OS\\ X\\ Yosemite.app --nointeraction 上面/Volumes/Untitled是U盘的名字。回车后，系统会提示你输入管理员密码，接下来就是等待系统开始制作启动盘了。\n从U盘启动安装 OS X 在Mac mini上插上U盘，启动Mac，然后一直按住【option】键（即Alt键，不行就重启多试几次）。 在进入刚进入安装过程后，要先对ssd盘格式化才能看到它。接下来就按照 向导 就可以完成安装了。建议appleID完成后再添加。\n本文链接地址：http://xgknight.com/2016/01/18/mac-mini-zturn/\n","permalink":"http://localhost:1313/2016/01/mac-mini-zturn/","summary":"\u003cp\u003e从公司网管那捣鼓来一个“遗弃” Mac mini，说其它人觉得用起来太卡，正好我的工作PC( CPU 4×i3，MEM 8G, HDD 500G)软件开多了也觉得有些卡，特别是我使用浏览器的习惯不太好，每次搜索统一结果都要打开好多标签页对比，文章性质的觉得有用想将来记录下来就没关闭页面，一两个星期下来只Chrome使用的内存就达到4G多。不用也浪费，于是就拿Mac mini分摊一下压力。\u003c/p\u003e","title":"记一次Mac mini折腾过程（鼠键共享，更换SSD）"},{"content":"公司数据中心从托管机房迁移到阿里云，需要对mysql迁移（Replication）后的数据一致性进行校验，但又不能对生产环境使用造成影响，pt-table-checksum 成为了绝佳也是唯一的检查工具。\npt-table-checksum 是 Percona-Toolkit 的组件之一，用于检测MySQL主、从库的数据是否一致。其原理是在主库执行基于statement的sql语句来生成主库数据块的checksum，把相同的sql语句传递到从库执行，并在从库上计算相同数据块的checksum，最后，比较主从库上相同数据块的checksum值，由此判断主从数据是否一致。检测过程根据唯一索引将表按row切分为块（chunk），以为单位计算，可以避免锁表。检测时会自动判断复制延迟、 master的负载， 超过阀值后会自动将检测暂停，减小对线上服务的影响。\npt-table-checksum 默认情况下可以应对绝大部分场景，官方说，即使上千个库、上万亿的行，它依然可以很好的工作，这源自于设计很简单，一次检查一个表，不需要太多的内存和多余的操作；必要时，pt-table-checksum 会根据服务器负载动态改变 chunk 大小，减少从库的延迟。\n为了减少对数据库的干预，pt-table-checksum还会自动侦测并连接到从库，当然如果失败，可以指定--recursion-method选项来告诉从库在哪里。它的易用性还体现在，复制若有延迟，在从库 checksum 会暂停直到赶上主库的计算时间点（也通过选项--设定一个可容忍的延迟最大值，超过这个值也认为不一致）。\n为了保证主数据库服务的安全，该工具实现了许多保护措施：\n自动设置 innodb_lock_wait_timeout 为1s，避免引起 默认当数据库有25个以上的并发查询时，pt-table-checksum会暂停。可以设置 --max-load 选项来设置这个阀值 当用 Ctrl+C 停止任务后，工具会正常的完成当前 chunk 检测，下次使用 --resume 选项启动可以恢复继续下一个 chunk 工作过程 直接看 nettedfish 的说明：\n1. 连接到主库：pt工具连接到主库，然后自动发现主库的所有从库。默认采用show full processlist来查找从库，但是这只有在主从实例端口相同的情况下才有效。 3. 查找主库或者从库是否有复制过滤规则：这是为了安全而默认检查的选项。你可以关闭这个检查，但是这可能导致checksum的sql语句要么不会同步到从库，要么到了从库发现从库没有要被checksum的表，这都会导致从库同步卡库。 5. 开始获取表，一个个的计算。 6. 如果是表的第一个chunk，那么chunk-size一般为1000；如果不是表的第一个chunk，那么采用19步中分析出的结果。 7. 检查表结构，进行数据类型转换等，生成checksum的sql语句。 8. 根据表上的索引和数据的分布，选择最合适的split表的方法。 9. 开始checksum表。 10. 默认在chunk一个表之前，先删除上次这个表相关的计算结果。除非–resume。 14. 根据explain的结果，判断chunk的size是否超过了你定义的chunk-size的上限。如果超过了，为了不影响线上性能，这个chunk将被忽略。 15. 把要checksum的行加上for update锁，并计算。 17-18. 把计算结果存储到master_crc master_count列中。 19. 调整下一个chunk的大小。 20. 等待从库追上主库。如果没有延迟备份的从库在运行，最好检查所有的从库，如果发现延迟最大的从库延迟超过max-lag秒，pt工具在这里将暂停。 21. 如果发现主库的max-load超过某个阈值，pt工具在这里将暂停。 22. 继续下一个chunk，直到这个table被chunk完毕。 23-24. 等待从库执行完checksum，便于生成汇总的统计结果。每个表汇总并统计一次。 25-26. 循环每个表，直到结束。 校验结束后，在每个从库上，执行如下的sql语句即可看到是否有主从不一致发生：\n1 2 select * from percona.checksums where master_cnt \u0026lt;\u0026gt; this_cnt OR master_crc \u0026lt;\u0026gt; this_crc OR ISNULL(master_crc) \u0026lt;\u0026gt; ISNULL(this_crc) \\G 你需要知道的选项 --replicate-check：执行完 checksum 查询在percona.checksums表中，不一定马上查看结果呀 —— yes则马上比较chunk的crc32值并输出DIFFS列，否则不输出。默认yes，如果指定为--noreplicate-check，一般后续使用下面的--replicate-check-only去输出DIFF结果。\n--replicate-check-only：不在主从库做 checksum 查询，只在原有 percona.checksums 表中查询结果，并输出数据不一致的信息。周期性的检测一致性时可能用到。\n--nocheck-binlog-format：不检测日志格式。这个选项对于 ROW 模式的复制很重要，因为pt-table-checksum会在 Master和Slave 上设置binlog_format=STATEMENT（确保从库也会执行 checksum SQL），MySQL限制从库是无法设置的，所以假如行复制从库，再作为主库复制出新从库时（A-\u0026gt;B-\u0026gt;C），B的checksums数据将无法传输。（没验证）\n--replicate= 指定 checksum 计算结果存到哪个库表里，如果没有指定，默认是 percona.checksums 。 但是我们检查使用的mysql用户一般是没有 create table 权限的，所以你可能需要先手动创建：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 CREATE DATABASE IF NOT EXISTS percona; CREATE TABLE IF NOT EXISTS percona.checksums ( db CHAR(64) NOT NULL, tbl CHAR(64) NOT NULL, chunk INT NOT NULL, chunk_time FLOAT NULL, chunk_index VARCHAR(200) NULL, lower_boundary TEXT NULL, upper_boundary TEXT NULL, this_crc CHAR(40) NOT NULL, this_cnt INT NOT NULL, master_crc CHAR(40) NULL, master_cnt INT NULL, ts TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, PRIMARY KEY (db,tbl,chunk), INDEX ts_db_tbl(ts,db,tbl) ) ENGINE=InnoDB; 生产环境中数据库用户权限一般都是有严格管理的，假如连接用户是repl_user（即直接用复制用户来检查），它应该额外赋予对其它库的 SELECT ，LOCK TABLES 权限，如果后续要用 pt-table-sync 就就需要写权限了。对percona库有写权限：\nGRANT ALL PRIVILEGEES on percona.* to repl_user@'%' IDENTIFIED BY 'repl_pass'; GRANT SELECT,LOCK TABLES,PROCESS,SUPER on *.* to repl_user@'%'; 注：\n为了减少不必要的麻烦，确保你的 repl_user@\u0026lsquo;xxx\u0026rsquo; 用户能同时登陆主库和从库 --create-replicate-table 选项会自动创建 percona.checksums 表，但也意味着赋予额外的 CREATE TABLE权限给 percona_tk@\u0026lsquo;xxx\u0026rsquo; 用户。默认yes PROCESS用于自动发现从库信息，SUPER权限用于set binlog_format。 --no-check-replication-filters 表示不需要检查 Master 配置里是否指定了 Filter。 默认会检查，如果配置了 Filter，如 replicate_do_db,replicate-wild-ignore-table,binlog_ignore_db 等，在从库checksum就与遇到表不存在而报错退出，所以官方默认是yes（--check-replication-filters）但我们实际在检测中时指定--databases=，所以就不存在这个问题，干脆不检测\n--empty-replicate-table：每个表checksum开始前，清空它之前的检测数据（不影响其它表的checksum数据），默认yes。当然如果使用--resume启动检测数据不会清空。 当启用--noempty-replicate-table即不清空时，不计算计算chunk,只计算。\n--databases=，-d：要检查的数据库，逗号分隔。用脚趾头想也知道 --databases-regex 正则匹配要检测的数据库，--ignore-databases[-regex]忽略检查的库。Filter选项。\n--tables=，-t：要检查的表，逗号分隔。如果要检查的表分布在不同的db中，可以用--tables=dbname1.table1,dbnamd2.table2的形式。同理有--tables-regex，--ignore-tables，--ignore-tables-regex。--replicate指定的checksum表始终会被过滤。\n--recursion-method：发现从库的方式。pt-table-checksum 默认可以在主库的 processlist 中找到从库复制进程，从而识别出有哪些从库，但如果使用是非标准3306端口，会导致找不到从库信息。此时就会自动采用host方式，但需要提前在从库 my.cnf 里面配置report_host、report_port信息，如：\n1 2 report_host = MASTER_HOST report_port = 13306 最终极的办法是dsn，dsn指定的是某个表（如 percona.dsns ），表行记录是改主库的（多个）从库的连接信息。适用以下任一情形：\n主库不能自动发现从库 不想在从库添加额外配置（因为要重启） 主从检测连接用户信息不一样 多个从库时只想验证指定从库的一致 我比较倾向使用DSN的方式。这个dsns表只需要在执行 pt-table-checksum 命令的服务器上能够访问到就行。这里纠正一个认识，网上很多人说 pt-table-checksum 要在主库上执行，其实不是的，我的mysql实例比较多，只需在某一台服务器上安装percona-toolkit，这台服务能够同时访问主库和从库就行了。具体用法见后面实例。\n检测实例 同网段间主从一致检查 场景：\n标准端口3306，只检查某一个库的关键表 一主一从，binlog不是ROW模式 同网段复制，percona_tk@\u0026lsquo;192.168.5.%\u0026rsquo; 具备该有的权限： 1 2 GRANT ALL PRIVILEGEES on repl_user.* to repl_user@\u0026#39;192.168.5.%\u0026#39; IDENTIFIED BY \u0026#39;repl_pass\u0026#39;; GRANT SELECT,LOCK TABLES,PROCESS,SUPER on *.* to repl_user@\u0026#39;192.168.5.%\u0026#39;; 这是最简单的方式，把要连接和检查的信息交代就行了：\n1 2 # pt-table-checksum h=MASTER_HOST,u=repl_user,p=\u0026#39;repl_pass\u0026#39;,P=3306 \\ --databases=d_ts_profile --tables=t_user,t_user_detail,t_user_group --nocheck-replication-filters 如果是首次运行，会在主库自动创建 percona.checksums 表。\n输出结果：\n1 2 3 4 5 6 Replica lag is 2307 seconds on mysql-5. Waiting. Checksumming d_ts_profile.t_user_account: 3% 54:48 remain TS ERRORS DIFFS ROWS CHUNKS SKIPPED TIME TABLE 12-18T16:07:48 0 0 313641 9 0 146.417 d_ts_profile.t_user 12-18T16:08:00 0 0 397734 12 0 11.747 d_ts_profile.t_user_detail 12-18T16:08:24 0 0 1668327 20 0 23.941 d_ts_profile.t_user_group TS ：完成检查的时间戳。 ERRORS ：检查时候发生错误和警告的数量。 DIFFS ：不一致的chunk数量。当指定 --no-replicate-check 即检查完但不立即输出结果时，会一直为0；当指定 --replicate-check-only 即不检查只从checksums表中计算crc32，且只显示不一致的信息（毕竟输出的大部分应该是一致的，容易造成干扰）。 ROWS ：比对的表行数。 CHUNKS ：被划分到表中的块的数目。 SKIPPED ：由于错误或警告或过大，则跳过块的数目。 TIME ：执行的时间。 TABLE ：被检查的表名 使用dsn跨数据中心检测 场景：\n非标准端口13306，只检查以 d_ts 开头的所有库 一主二从，binlog是ROW模式，其中一从在阿里云ECS上，主库是无法直接访问该从库的 检测用的账号因为不是%，所以不一样 以下是我环境的情况 MASTER_HOST:13306 主库 REPLICA_HOST:3306 从库 PTCHECK_HOST pt-table-checksum所在服务器 DSN_DBHOST，记录从库（连接）dsns的数据库 最优的方式就是dsn指定从库了。在从库或从库同网段主机里装上 percona-toolkit。\n在DSN_DBHOST 数据库实例上创建DSNs表：\n1 2 3 4 5 6 7 8 9 create database percona; CREATE TABLE `percona`.`dsns` ( `id` int(11) NOT NULL AUTO_INCREMENT, `parent_id` int(11) DEFAULT NULL, `dsn` varchar(255) NOT NULL, PRIMARY KEY (`id`) ); GRANT ALL PRIVILEGEES on percona.* to percona_tk@\u0026#39;PTCHECK_HOST\u0026#39; IDENTIFIED BY \u0026#39;percona_pass\u0026#39;; 如果有多个实例要检查，可以创建多个类似的dsns表。上面的percona_tk用户只是用来访问dsn库。插入从库信息：\n1 2 use percona; insert into dsns(dsn) values(\u0026#39;h=REPLICA_HOST,P=3306,u=repl_user,p=repl_pass\u0026#39;); DSNs记录 dsn 列格式如 h=REPLICA_HOST,u=repl_user,p=repl_pass\n在 PTCHECK_HOST 上执行检查命令：\n1 2 3 # pt-table-checksum --replicate=percona.checksums --nocheck-replication-filters --no-check-binlog-format \\ h=MASTER_HOST,u=repl_user,p=\u0026#39;repl_pass\u0026#39;,P=13306 --databases-regex=d_ts.* \\ --recursion-method dsn=h=DSN_DBHOST,u=percona_tk,p=\u0026#39;percona_pass\u0026#39;,P=3306,D=percona,t=dsn 选项的意思就不多说了。\n检测完如果一致，其实是求个心安，特别是在做数据迁移的时候。如果不一致，那就需要借助 pt-table-sync 工具了，不作介绍。\n常见错误 Diffs cannot be detected because no slaves were found 不能自动找到从库，确认processlist或host或dsns方式用对了。\nCannot connect to h=slave1.***.com,p=\u0026hellip;,u=percona_user 可以在pt-table-checksum命令前加PTDEBUG=1来看详细的执行过程，如端口、用户名、权限错误。\nWaiting for the \u0026ndash;replicate table to replicate to XXX 问题出在 percona.checksums 表在从库不存在，根本原因是没有从主库同步过来，所以看一下从库是否延迟严重。\nPausing because Threads_running=25 反复打印出类似上面停止检查的信息。这是因为当前数据库正在运行的线程数大于默认25，pt-table-checksum 为了减少对库的压力暂停检查了。等数据库压力过了就好了，或者也可以直接 Ctrl+C 终端，下一次加上--resume继续执行，或者加大--max-load=值。\n字符集问题\n1 2 3 4 5 Error checksumming table Error executing checksum query: DBD::mysql::st execute failed: Illegal mix of collations 12-17T14:48:04 Error checksumming table d_ec_cs.t_online_cs: Error executing checksum query: DBD::mysql::st execute failed: Illegal mix of collations for operation \u0026#39;concat_ws\u0026#39; [for Statement \u0026#34;REPLACE INTO `percona`.`ali_checksum` (db, tbl, chunk, chunk_index, lower_boundary, upper_boundary, this_cnt, this_crc) SELECT ?, ?, ?, ?, ?, ?, COUNT(*) AS cnt, COALESCE(LOWER(CONV(BIT_XOR(CAST(CRC32(CONCAT_WS(\u0026#39;#\u0026#39;, `f_cs_id`, `f_corp_id`, `f_valid`, `f_show_name`, `f_online_msg`, `f_offline_msg`, `f_show_mobile`, `f_group_id`, `f_qq`, `f_show_qq`, `f_msn`, `f_show_msn`, `f_sms_online`, `f_scheme`, `f_tel`, `f_telno`, `f_show_tel`, `f_contact`, `f_mobile`, `f_position`, `f_other1`, `f_other2`, `f_other_text1`, `f_other_text2`, `f_email`, `f_qq_first`, `f_qq_first_type`, `f_aids_open`, `f_aids_qq`, `f_aids_crmqq`, `f_aids_yahoo`, `f_aids_skype`, `f_aids_aliww`, `f_aids_msn`, `f_aids_alibaba`, `f_aids_alitrade`, CONCAT(ISNULL(`f_show_name`), ISNULL(`f_group_id`), ISNULL(`f_qq`), ISNULL(`f_show_qq`), ISNULL(`f_sms_online`), ISNULL(`f_other_text1`), ISNULL(`f_other_text2`), ISNULL(`f_email`)) )) AS UNSIGNED)), 10, 16)), 0) AS crc FROM `d_ec_cs`.`t_online_cs` /*checksum table*/\u0026#34; with ParamValues: 0=\u0026#39;d_ts_profile\u0026#39;, 1=\u0026#39;t_user_account\u0026#39;, 2=1, 3=undef, 4=undef, 5=undef] at /usr/bin/pt-table-checksum line 10520. 是个bug，暂时无法解决，Illegal mix of collations for operation \u0026lsquo;concat_ws\u0026rsquo;。\n参考 pt-table-checksum 用pt-table-checksum校验数据一致性 使用pt-table-checksum及pt-table-sync校验复制一致性详细介绍 Pausing because Threads_running=0 本文链接地址：http://xgknight.com/2015/12/29/mysql_replica_pt-table-checksum/\n","permalink":"http://localhost:1313/2015/12/mysql_replica_pt-table-checksum/","summary":"\u003cp\u003e公司数据中心从托管机房迁移到阿里云，需要对mysql迁移（Replication）后的数据一致性进行校验，但又不能对生产环境使用造成影响，pt-table-checksum 成为了绝佳也是唯一的检查工具。\u003c/p\u003e","title":"生产环境使用 pt-table-checksum 检查MySQL数据一致性"},{"content":"1. 说明 1.1 xtrabackup mysqldump对于导出10G以下的数据库或几个表，还是适用的，而且更快捷。一旦数据量达到100-500G，无论是对原库的压力还是导出的性能，mysqldump就力不从心了。Percona-Xtrabackup备份工具，是实现MySQL在线热备工作的不二选择，可进行全量、增量、单表备份和还原。（但当数据量更大时，可能需要考虑分库分表，或使用 LVM 快照来加快备份速度了）\n2.2版本 xtrabackup 能对InnoDB和XtraDB存储引擎的数据库非阻塞地备份，innobackupex通过perl封装了一层xtrabackup，对MyISAM的备份通过加表读锁的方式实现。2.3版本 xtrabackup 命令直接支持MyISAM引擎。\nXtraBackup优势 ：\n无需停止数据库进行InnoDB热备 增量备份MySQL 流压缩到传输到其它服务器 能比较容易地创建主从同步 备份MySQL时不会增大服务器负载 1.2 replication 为什么要做主从复制？ 我想这是要在实施以前要想清楚的问题。是为了实现读写分离，减轻主库负载或数据分析？ 为了数据安全，做备份恢复？主从切换做高可用？ 大部分场景下，以上三个问号一主一从都能够解决，而且任何生产环境都建议你至少要有一个从库，假如你的读操作压力特别大，甚至要做一主多从，还可以不同的slave扮演不同的角色，例如使用不同的索引，或者不同的存储引擎，或使用一个小内存server做slave只用于备份。（当然slave太多也会对master的负载和网络带宽造成压力，此时可以考虑级联复制，即 A-\u0026gt;B-\u0026gt;C ）\n还有需要考虑的是，一主一从，一旦做了主从切换，不通过其它HA手段干预的话，业务访问的还是原IP，而且原主库很容易就作废了。于是 主-主 复制就产生了，凭借各自不同的 server-id ，可以避免 “A的变化同步到B，B应用变化又同步到A” 这样循环复制的问题。但建议是，主主复制，其中一个主库强制设置为只读，主从切换后架构依然是可用的。\n复制过程是slave主动向master拉取，而不是master去推的，所以理想情况下做搭建主从时不需要master做出任何改变甚至停服，slave失败也不影响主库。\n复制类型\n基于语句的复制：STATEMENT，在主服务器上执行的SQL语句，在从服务器上执行同样的语句，有可能会由于SQL执行上下文环境不同而是数据不一致，例如调用NOW()函数。MySQL在5.7.7以前默认采用基于语句的复制，在 5.7.7 及以后版本默认改用 row-based。 基于行的复制：ROW，把改变的内容复制过去，而不是把命令在从服务器上执行一遍。从mysql5.0开始支持，能够严格保证数据完全一致，但此时用mysqlbinlog去分析日志就没啥意义。因为任何一条update语句，都会把涉及到的行数据全部set值，所以binlog文件会比较大。 （遇到的一个坑是，迁移时，从库改正了字段默认值定义，但数据在主库更改后，即使产生的新数据默认值是正确的，但基于行的复制依然用不正确的值字段全部更新了） 混合类型的复制: MIXED，默认采用基于语句的复制，一旦发现基于语句的无法精确的复制时，就会采用基于行的复制。 mysql系统库mysql库里面表的日志记录格式需要说明：在通过如INSERT、UPDATE、DELETE、TRUNCATE等方式直接修改数据的语句，使用 binlog_format指定的方式记录，但使用GRANT、ALTER、CREATE、RENAME等改动的mysql库里数据的，会强制使用statement-based方式记录binlog。\n可以在线修改二进制日志类型，如SET SESSION binlog_format=MIXED;，需要SUPER权限。\n复制类型还可以分为 异步复制和半同步复制。 通常没说明指的都是异步，即主库执行完Commit后，在主库写入Binlog日志后即可成功返回客户端，无需等等Binlog日志传送给从库，一旦主库宕机，有可能会丢失日志。而半同步复制，是等待其中一个从库也接收到Binlog事务并成功写入Relay Log之后，才返回Commit操作成功给客户端；如此半同步就保证了事务成功提交后至少有两份日志记录，一份在主库Binlog上，另一份在从库的Relay Log上，从而进一步保证数据完整性；半同步复制很大程度取决于主从网络RTT（往返时延），以插件 semisync_master/semisync_slave 形式存在。 原理 (1) master将改变记录到二进制日志(binary log)中（这些记录叫做二进制日志事件，binary log events）； (2) slave将master的binary log events拷贝到它的中继日志(relay log)； (3) slave重做中继日志中的事件，将改变反映它自己的数据。 该过程的第一部分就是master记录二进制日志。在每个事务更新数据完成之前，master在二进制日志记录这些改变。MySQL将事务串行的写入二进制日志，即使事务中的语句都是交叉执行的。在事件写入二进制日志完成后，master通知存储引擎提交事务。 下一步将master的binary log拷贝到它自己的中继日志。首先，slave开始一个工作线程——I/O线程。I/O线程在master上打开一个普通的连接，请求从指定日志文件的指定位置之后的日志内容，然后开始binlog dump process。Binlog dump process从master的二进制日志中读取事件，如果已经跟上master，它会睡眠并等待master产生新的事件。I/O线程将这些事件写入中继日志。 SQL slave thread（SQL从线程）处理该过程的最后一步。SQL线程从中继日志读取事件，并重放其中的事件而更新slave的数据，使其与master中的数据一致。只要该线程与I/O线程保持一致，中继日志通常会位于OS的缓存中，所以中继日志的开销很小。 此外，在master中也有一个工作线程：和其它MySQL的连接一样，slave在master中打开一个连接也会使得master开始一个线程。复制过程有一个很重要的限制——复制在slave上是串行化的，也就是说master上的并行更新操作不能在slave上并行操作。\n补充:\nmysql 5.7开始加入了多源复制，这个特性对同时有很多个mysql实例是很有用的，阿里云RDS（迁移）实现了类似的方式。 从MySQL 5.6.2开始，mysql binlog支持checksum校验，并且5.6.6默认启用（CRC32），这对自己模拟实现mysql复制的场景有影响。 下面开始配置主从：\n主从版本一致—\u0026gt;主库授权复制帐号—\u0026gt;确保开启binlog及主从server_id唯一—\u0026gt;xtrabackup恢复到从库—\u0026gt;记录xtrabackup_binlog_info中binlog名称及偏移量—\u0026gt;从库change master to —\u0026gt;slave start—\u0026gt;检查两个yes\n2. 创建复制账号 在主库上\nmysql\u0026gt; GRANT REPLICATION SLAVE ON *.* TO 'slave_ali'@'192.168.5.%' IDENTIFIED BY 'slave_ali_pass'; mysql\u0026gt; FLUSH PRIVILEGES; 3. 使用Percona-Xtrabackup恢复数据 这里假设比较简单的情况：全量备份，全量恢复，不涉及增量。\n安装和具体使用，见文章。\n赋予备份用户权限：\n1 2 3 mysql\u0026gt; CREATE USER \u0026#39;bkpuser\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;bkppass\u0026#39;; mysql\u0026gt; GRANT RELOAD, LOCK TABLES, REPLICATION CLIENT,PROCESS,SUPER ON *.* TO \u0026#39;bkpuser\u0026#39;@\u0026#39;localhost\u0026#39;; mysql\u0026gt; FLUSH PRIVILEGES; 完整的选项使用请执行innobackupex –-help，这里只介绍使用常用的选项进行完整备份及增量备份和还原。\n这一节是把数据恢复到从库，借此记录一下xtrabackup的使用（用了云之后，备份技能都丢了~）。生产环境你应该是早就有了xtrabackup的备份，做从库时只需要把备份拷过来，解压恢复。\n假设 MySQL 安装目录在/opt/mysql，my.cnf配置文件/opt/mysql/my.cnf，端口3306，数据目录/opt/mysql_data，sock位于/opt/mysql_data/mysql.sock。备份数据放在/data/backup/mysql/。\n3.1 全量备份 1 2 $ export BKP_PASS=\u0026#34;bkppass\u0026#34; $ innobackupex --defaults-file=/opt/mysql/my.cnf --host=localhost --port=3306 --user=bkpuser --password=${BKP_PASS} /data/backup/mysql 默认会以当天 日期+时间 戳命名备份目录，如 2015-09-16_00-00-02。一般会对它进行tar压缩，由于tar只能单进程，所以往往这个压缩过程会比备份过程耗时2倍还多。拷贝到需要恢复（做从库）的目录。\n如果手头有一份未压缩的全备数据，要在另一台恢复，其实还不如直接 rsync 过来，将近400G的数据压缩与解压缩过程特别漫长。 3.2 全量恢复 在恢复的数据库服务器（从库）上：\n``` 恢复准备 $ innobackupex --use-memory=16G --apply-log 2015-09-16_00-00-02 确认数据库是关闭的，并且datadir，目录下为空 $ innobackupex --defaults-file=/opt/mysql/my.cnf --use-memory=16G --copy-back 2015-09-16_00-00-02 ``` 第一步是恢复准备，apply-log应用全备时 log sequence number 之后的数据，完了后会输出类似 InnoDB: Last MySQL binlog file position 0 262484673, file name ./mysql-bin.000135 的信息，告诉我们了后面的从库应该从哪个地方开始复制。时间不会很长，但最好用screen之类的软件放到后台执行，以免终端断开，功亏一篑。 第二步使用新的my.cnf文件，将完整的mysql数据文件拷贝到datadir下。 4. 做从库 上面恢复过程最后一步apply-log完成之后，会得到一个lsn position 和binlog文件名：262484673、mysql-bin.000135。下面开始从库制作。\n一般在copy-back之后需要修改数据文件目录的属性：\n1 # chown -R mysql.mysql /opt/mysql_data 4.1 my.cnf 从库的配置文件简单一点可以从主库拷贝过来，但根据需要，要注意以下几处\nserver-id一定不能与主库相同 否则，会出现如下错误： Slave: received end packet FROM server, apparent master shutdown\n从库一般作为只读库使用，所以为安全起见，设置只读 set global read_only=1; 可以在从服务器的 my.cnf 里加入read-only参数来实现这一点，唯一需要注意的一点事read-only仅对没有super权限的用户有效。所以最好核对一下连接从服务器的用户，确保其没有super权限。\n关于从库的事件 MYSQL Replication 可以很好的达到你的预期：从库的事件不会自己去执行，主库会把event执行的结果直接同步。在statement模式下，复制的是 event BODY 里的SQL，在row模式下是主库事件执行完成后影响的行精确复制。\n从库 event_scheduler 参数是被忽略的，并且每个event 状态会是 SLAVESIDE_DISABLED ，但CREATE/ALTER EVENT等操作语句是会复制。主从切换后，从库事件状态会变成ENABLE。\n参数调整 从库是不允许写入的，否则数据就不一致了。从库实例的配置可以不要主库那么高，比如原16G的buffer pool，根据用途，从库可以设到4-8G（当时前提是将来你也不打算把它切换为主库用）。 相应的，read_buffer_size，sort_buffer_size, query_cache_size 这些读相关参数可以略微增大。当然我一般都懒得去改。\nskip-slave-start 主从创建完成后，默认情况下次启动从库，会自动启动复制进程，一般这也正是我们需要的，但在维护阶段时你可能不想从库启动后立即开始复制，--skip-slave-start选项可以帮到你。\nlog-slave-updates 正常情况从库是不需要写回放日志产生的binlog，无形中增加服务器压力。但如果你想要实现级联复制即 A -\u0026gt; B -\u0026gt; C ，B同时是A的从库，也是C的主库，就需要开启 log-bin 和 log-slave-updates 。\n另外，建议显示设置 log-bin=mysql-bin 确保主从正常切换。 show variables like 'log%' 查看当前值。\n关于过滤表见mysql-replica-filter\nsync_binlog For the greatest possible durability and consistency in a replication setup using InnoDB with transactions, you should use innodb_flush_log_at_trx_commit=1 and sync_binlog=1 in the master my.cnf file.\n上面的话同时也意味着性能最低。可以在这埋点，假如出现慢的情况，把两参数调成2。\n4.2 启动从库 启动数据库，注意看日志\n1 # /opt/mysql/bin/mysqld_safe --defaults-file=/opt/mysql/my.cnf \u0026amp; 提示：如果你不确定这个库是谁的从库，保守起见加上--skip-slave-start启动，兴许能防止数据不一致。\n4.3 change master 在从库上\n$ mysql -uslave_ali -p'slave_ali_pass' -S /opt/mysql_data/mysql.sock mysql\u0026gt; change master to master_host=MASTER_HOST, master_port=3306, master_user='slave_ali',master_password='slave_ali_pass', master_log_file='mysql-bin.000135', master_log_pos=262484673; 上面的 master_log_file 和 master_log_pos 即是输出的值，也可以在新的数据目录下xtrabackup_binlog_info找到信息。\nmysql\u0026gt; show slave status\\G mysql\u0026gt; start slave; mysql\u0026gt; show slave status\\G 4.4 验证同步延迟 从库执行 show slave status\\G 节选：\n1 2 3 4 5 6 7 8 9 10 11 Slave_IO_State: Waiting for master to send event Master_Log_File: mysql-bin.000004 Read_Master_Log_Pos: 931 Relay_Log_File: slave1-relay-bin.000056 Relay_Log_Pos: 950 Relay_Master_Log_File: mysql-bin.000004 Slave_IO_Running: Yes Slave_SQL_Running: Yes Exec_Master_Log_Pos: 931 Relay_Log_Space: 408 Seconds_Behind_Master: 0 Master_Log_File： I/O线程当前正在读取的主服务器二进制日志文件的名称\nRead_Master_Log_Pos：本机I/O线程读取主服务器二进制日志位置 上面2各值，与在主库执行show master status;看到的值如果基本接近，说明从库IO线程已经赶上了主库的binlog。\nRelay_Master_Log_File: 由SQL线程执行的包含多数近期事件的主服务器二进制日志文件的名称\nExec_Master_Log_Pos: SQL线程执行来自master的二进制日志最后一个事件位置 与上面的Relay_Master_Log_File一起，同Master_Log_File、Read_Master_Log_Pos比较，能看到SQL线程是否已经赶上从库本地的IO线程。\nSlave_IO_Running：I/O线程是否启动并成功连接到主服务器上 一般和下面的Slave_IO_Running和Seconds_Behind_Master一起监控主从健康状态\nSlave_SQL_Running：SQL线程是否启动\nSeconds_Behind_Master: 从属服务器“落后”多少秒 官网的解释是：The number of seconds that the slave SQL thread is behind processing the master binary log。但是当 SBM 为 0 时也不代表一定没有延迟，因为可能因为网络慢的缘故，从库的IO线程传输binlog太慢，它的SQL线程应用日志很容易就赶上relay log，但实际主库产生的binlog比传输的快，就会造成为0的假象。 有时你反复status会发现 Seconds_Behind_Master 的值在0与一个很大的数之间波动，有可能是主库上执行了一个非常大的event，没执行完毕的时候从库SBM显示为0，event执行完成并传输完binlog后，就会显示SBM非常巨大。（我在从机房迁移mysql到阿里云上部分库老出现这种情况，应该跟网络和大event都有关系）。 另外，relay log 中event记录的时间戳是主库上的时间戳，而SQL thread的时间戳是从库上的，如果主库和从库的时间偏差较大，那么这个SBM的意义就基本不存在了。\n5. 参考 高性能Mysql主从架构的复制原理及配置详解\nHow does MySQL Replication really work?\nXtraBackup不停机不锁表搭建MySQL主从同步实践\nMySQL复制原理与配置\n许多模糊的内容还是看官网的\n本文链接地址：http://xgknight.com/2015/12/14/mysql-replicas/\n","permalink":"http://localhost:1313/2015/12/mysql-replicas/","summary":"\u003ch2 id=\"1-说明\"\u003e1. 说明\u003c/h2\u003e\n\u003ch3 id=\"11-xtrabackup\"\u003e1.1 xtrabackup\u003c/h3\u003e\n\u003cp\u003emysqldump对于导出10G以下的数据库或几个表，还是适用的，而且更快捷。一旦数据量达到100-500G，无论是对原库的压力还是导出的性能，mysqldump就力不从心了。Percona-Xtrabackup备份工具，是实现MySQL在线热备工作的不二选择，可进行全量、增量、单表备份和还原。（但当数据量更大时，可能需要考虑分库分表，或使用 LVM 快照来加快备份速度了）\u003c/p\u003e","title":"使用 Xtrabackup 在线对MySQL做主从复制"},{"content":"今天11月1号，深圳的天气正好从这一天凉了起来，傍晚回住处的公交车上给家里打了个电话，是爸爸接的，说家里已经有点冷了。\n现在对冷没什么概念了，深圳是一个没有冬天的城市，一件外套就能过冬。也就是今天起风了出门才稍稍感觉到凉，昨天还热的不行呢——那是因为去爬山了。\n南山，2年前来这里的第一个月就听说过，但两次上过梧桐山，上半年爬过凤凰山，就偏偏离自己最近的南山未曾到访。山虽然不高，但一直放着不去还能再找到人陪我去不成，于是就响应党组织号召，登山去。\n周六下午，小明从公司过去，而我从家里坐公交过去，照计划的时间应该2点半可以集合，无奈在深大转车多等了20分钟，结果是小明跟其他人一起先从海关登山口上山，先到山顶者有奖，我晚十分钟到出发点，去追他们。出乎意料，迈进登山口就一直上台阶，上啊上啊上，T恤已经全湿了，我竟然还穿着紧身牛仔裤！（其实主要考虑到晚上吃饭方便）。由于平时也打打球，体力不算太差，20分钟上到了全程海拔一半的样子，还没追上，双腿力量也下降了，正好碰到没跟上大部队的两个人，就一起走了。后半程坡也小了很多，吹来一丝微风能感觉到背上一阵凉意。此时群里已经有人到观景台发图了，但奇怪的是那么一大波上去怎么才有2个人发图，原来拼的不仅仅是体力，还有手机信号……\n三点半时基本上都到顶了，风景还不错，能看到深圳湾大桥（据说晚上很美），和对面的香港。\n团体里大部分我是认识的，有我以前的同事，和球场上认识的伙伴。虽然我已离职近4个月，但我党组织关系还在TP，也交了党费，这才有机会和他们一起出来。还有经费，号召大家买书，于是买了《摄影的艺术》《皮囊》等，小明也为他单反买了本，我看中的是他那本室内装饰和川菜食谱，嘿嘿。\n爬完山当然还有活动，自助餐——不是平时想象的哪种自助餐。蛇口是富人区，自助的当然是海鲜之类的，与大饱口福和四海一家有点像，除了种类没有后面两家多，味道和环境都还不错，感受一下。\n原本以为5点半开吃，顶多2小时回去了（因为人多而且还有些不熟的），结果听说海上世界就在附近，反正刚刚为了吃回本，肚子都撑了，就走着去了。哦，想起原来当天是万圣节，可不热闹了。\n常去的南山腐败地，一个海岸城，一个欢乐海岸，怎么能漏了海上世界，也是早有听说却没来过。一路望去，好多歪果仁，而且装扮忒吓人。海上世界最中心有一艘“船”叫明华号，当然甲板上开着各种餐厅。无意听到人说8点整有水秀表演，几个大男人在一顿狂拍后，终于等来了 water show 。短短的三分钟！\n周六算是疯了一天，周日计划还是学点东西，上午9点起来看了看puppet视频，下午去公司简单加了个班。上周经理不在，杂事一大堆，也是身不由己，也是欠了很多技术债。\n最后，晚上做了顿饭，忙活2个小时——可是三个人的两顿饭菜啊，不过挺有成就感的，因为吃完了……\n11月，你好！\n本文链接地址： http://xgknight.com/2015/11/01/nan-shan-hike/\n","permalink":"http://localhost:1313/2015/11/nan-shan-hike/","summary":"\u003cp\u003e今天11月1号，深圳的天气正好从这一天凉了起来，傍晚回住处的公交车上给家里打了个电话，是爸爸接的，说家里已经有点冷了。\u003c/p\u003e\n\u003cp\u003e现在对冷没什么概念了，深圳是一个没有冬天的城市，一件外套就能过冬。也就是今天起风了出门才稍稍感觉到凉，昨天还热的不行呢——那是因为去爬山了。\u003c/p\u003e","title":"南山南"},{"content":"下午一点钟才起来，今天本来也没什么安排，算不上睡懒觉，毕竟昨晚四点钟才睡。\n昨天（周六）公司写字楼的物业举办了一届羽毛球赛，七点钟就起来坐地铁来到侨城东，看来公司包的场地是华侨城锦绣花园的一个社区羽毛球馆，果然住着一群有钱人。我八点35到场，热个身，大概9点钟开始抽签，抽了个7号，也就是其他谁也抽到7号那就与我对打。运气太背了，一个估计有170斤的对手笑呵呵的站在我面前。人家力气大，专打我后场球，我手臂疼痛感还没恢复，被秒了。\n剩下没事只给我司的人拍照了。哎，虽然我手机拍照效果一般，但也不差，pp拍出来噪点严重，不清晰。然后觉得反正现在也没事，物业方也没找到合适的裁判，我就顺口应了句“我来吧”，裁女单。额，场面有多和谐我就不讲了，双方是挽着手上场的。本以为完事了，结果，又要裁男单，裁复赛，最后决赛。当时我想现在空下这么多场地，好好练几个球，可大家都不愿意顶替我去裁。最后前三甲决赛，就我一个喊着，“13比11，这一局比赛结束”——决赛果然精彩，双方咬着分不放。因为是循环赛，按最后每人赢的局数定名次，三人打了七局。这还是我第一次当裁判呢。\n回来时都12点多了，又困又累，一同事顺路就开车送我到了西乡。本以为可以冲个澡，睡四五个小时，结果，公司客户在投诉网站使用很慢，远程到公司找了一个小时原因没结果，还趴在桌上睡着了。（程序员节还出事情呢？）\n等我醒来，室友几个约好了去民治聚餐，公司催命电话又打过来了，好在运维现在不止我一个，就让星星（我领导）去解决了。\n真的很庆幸能有这么一群玩耍的朋友，我们七个是13年一同进TP的，离职只剩2个了，每次好久没约，就在群里吼一句，大家都不约而同的来了。乔帮主说的对，平时工作压力大，到了这，咱们就吹牛逼，自黑，互相调侃。好家伙，一顿饭能从下午五点半吃到十点，然后转战楼上KTV。我向来不喜欢唱歌这样的场所，但去也就去了，大家都自己人，不会唱歌瞎吼也没事（雷军的Are you OK都有人点，我还怕什么），玩玩骰子也可以。\n玩的真的很疯，但也很开心。几个人里面，有一对已经领证了，我们都看过他们的分分合合，在桌上听他吹自己的理想规划，心想结婚了就是不一样；另一个也是我理工同届了，经常一起开玩笑，他刚从TP离职去了一加；还有威哥，互相说对方做的饭不好吃；还有勤快的小明，善于自黑强哥，花痴文，正在创业的韦爷。\n到凌晨1点半实在是困了，一晚上嗓子哑了，芥末也吃了，圆满了。打个优步回到家，看似还清醒，贫民窟的百万富翁，没5分钟我就睡着了，醒来就一点了。\n晚上又去蹭原公司场地打球，不想宅家，提前把晚上的汤煲好——这样的周末过得才有意义。\n本文链接地址： http://xgknight.com/2015/10/25/weekends-badminton-ktv/\n","permalink":"http://localhost:1313/2015/10/weekends-badminton-ktv/","summary":"\u003cp\u003e下午一点钟才起来，今天本来也没什么安排，算不上睡懒觉，毕竟昨晚四点钟才睡。\u003c/p\u003e\n\u003cp\u003e昨天（周六）公司写字楼的物业举办了一届羽毛球赛，七点钟就起来坐地铁来到侨城东，看来公司包的场地是华侨城锦绣花园的一个社区羽毛球馆，果然住着一群有钱人。我八点35到场，热个身，大概9点钟开始抽签，抽了个7号，也就是其他谁也抽到7号那就与我对打。运气太背了，一个估计有170斤的对手笑呵呵的站在我面前。人家力气大，专打我后场球，我手臂疼痛感还没恢复，被秒了。\u003c/p\u003e","title":"周末腐败地"},{"content":"原文地址：https://www.quora.com/What-do-women-think-of-men-who-can-cook 作者：Shambhavi Tripathi 翻译：Seanlook\nWhat do women think of men who can cook? 这个问题很有意思，我想我可以很好的回答这个问题，因为我有幸认识这些人。\n我的弟弟和我的两个好朋友都很擅长做饭，所以我将以他们为原型来回答。\n在我回答之前呢，我想提一下我自己算得上是一个极度偏执的人，因为我很爱吃。我就是个吃货（素食），我的味蕾从未被满足过，并且7×24小时不间断的寻找美食。然而，我自己对下厨一无所知，甚至麦琪面都下不好。好了，接下来让我来开始回答，在我看来男人会做饭是怎样的。 (Image Credits: Fathers day Archives | Kitchen Remodeling)\n他们对很小的细节感兴趣 大部分人去餐厅时会怎样做？好吧，我来告诉你我一般怎么做。要么根据我自己喜好点几种特定成分的菜（例如奶酪），要么心情好的时候，根据菜单上的图片来点一些新菜式。是的，这就是我点菜的水平。现在当我和我弟或者喜欢做饭的朋友一起出去时，他们会这样做：大声念出菜名，同时也会念出它包含些什么（无论菜名后面的括号里写的是什么）。他们会尝试想象一下如果自己做出来会是什么味道。如果他们还不满足于念出菜名，有可能还会叫来服务员，询问各种细节，比如制作的过程，那道菜通常要提前准备什么。他们对这个太感兴趣了！与此同时，我只好不耐烦的看这看那，心想，为什么他就不能随便点任何想吃的东西呢？\n他们极度追求完美 当他们为你刚做好一道鲜汁四溢佳肴，你如狼似虎的吃着，“天呐，不能更好吃了，太美味了，简直了！”。但当他们尝了一下，脸上摆出的奇怪的表情，我至今都没理解什么意思，他们会然后点评了一下小的不足并记在脑子里避免将来还犯同样的错误。\n他们很性感 我们很爱看一个男人在做饭，真的很难不爱上一个厨房里的男人。看着他用双手创造出精美的一道菜，如此动人。它超过了其它赏赐，他们做饭的姿态透着某种性感。看着他们为你准备一顿早餐或者一杯咖啡，绝对可以大幅度拉高性感指数。 (Image Credits: istock_000018935400large - Howard Falco)\n他们经常给你的生活带来新体验 他们总乐意去发明新的菜式，也会学习各种你可能从没听过的烹饪方法。他们给你的生活带来新花样，这是可遇不可求的品质。\n他们觉得“做饭是女人的工作”这种想法很荒谬 这些人理解的下厨，是没有那么多局限的，这件事不仅仅限制只有女性才能做，他们完全打破这个令人愤怒的事实（印度除外），他们乐意并且为做出爱心饭菜的行为感到高兴。\n他们可以时刻为你做吃的 无论是中午还是半夜，只要你在他们面前表达意愿，想要他做东西给你吃，放心吧，他绝对不会拒绝你。甚至半夜在家里，我的胃由于饿在咕咕叫的时候，我请求正在忙其它事情的弟弟做点吃的，他从未说一个不字。相反，他总能带来你怎么也想不通他是如何利用以前一样的食材，做出完全超乎意料的东西来。谢谢老弟：P\n他们身体比我们健康 拥有大量关于各式食物的知识，他们知道哪种食物是健康的，哪种可能对身体不好甚至是有害的。所以他们通过推荐相对均衡、健康的饮食习惯，让自己和身边的人也安全健康起来。\n他们很擅长打开一个话题，特别是在陌生场合 全世界到处遍布食物，当你以一名游客或者其它身份出现在一个陌生地点时，这些会做饭的人会很轻易的跟当地人搭上话，和他们一起旅游会感到很轻松，因为他们总知道怎样不会冷场，不感到尴尬，跟陌生人可以很友好的交流。\n他们是天底下所有妈妈的“菜” 把他们介绍给你妈妈认识，并告诉说他会做饭，恐怕她听不进其它事情了。你妈妈将会对他印象深刻，甚至开始讨论关于菜式做法之类的事情。几乎每位母亲都爱这一点，你妈妈可能还会对你吼道：“向他学习！你甚至连杯茶都泡不好。”。\n他们绝不会要求我进厨房（最后但我喜欢） 由于他们知道我对做饭没有一点概念，所以我可以很舒适的待在任意地方。他们从不会指指点点，也不会让你上前帮忙，依然总是会做出美味佳肴来满足我和身边的人。\nMEN WHO CAN COOK ARE AMAZING AND A BLESSING. THEY ARE INTERNATIONALLY IN DEMAND AND TOTALLY RESPECTE.\n本文链接地址：http://xgknight.com/2015/10/21/what-do-women-think-of-men-who-can-cook/\n","permalink":"http://localhost:1313/2015/10/what-do-women-think-of-men-who-can-cook/","summary":"\u003cp\u003e原文地址：https://www.quora.com/What-do-women-think-of-men-who-can-cook\n作者：\u003ca href=\"https://www.quora.com/Shambhavi-Tripathi\"\u003eShambhavi Tripathi\u003c/a\u003e\n翻译：\u003ca href=\"http://xgknight.com\"\u003eSeanlook\u003c/a\u003e\u003c/p\u003e","title":"在女性眼里，男人会做饭是种什么体验？"},{"content":"汽车在公路上一路奔驰，车厢内很安静，大部分人闭目休息，能确定的是司机是清醒的，而我在后面靠窗的位置，取掉眼镜，不太清晰的望着窗外。一片片无人问津小树林，一片片因下雨而污浊的池塘水，一片片村庄、农田……﻿\n是的，老毛病又犯了，又要发感慨了。﻿﻿\n昨天这个时候还在深圳地铁上，忙忙碌碌，人挤人。每天朝七晚九，周末睡不醒，完全没有7月份换工作那会儿打了鸡血一样，与自己的约定也始终没坚持。早在一个月前，实在想不到国庆去哪，也是因为种种压力，澳门的计划，四川的计划，没法任性的说走就走，于是就选择了回家，去见见老同学们，去参加婚礼，去看看父母，去看看自己。﻿﻿\n昨天在列车上，看完了『侣行1』，作者带我们去探寻索马里的恐怖之都摩加迪沙，体验被枪抵住胸膛的心跳；带我们去北极的奥伊米亚康，在地冻天寒的雪地上露营；还深入乌克兰切尔诺贝利核电站，挑战核辐射恐惧；最后去感受毁灭与美学兼具的马鲁姆火山，看岩浆翻滚，体验生死，把命交给爱人。当然，不必羡慕，不必自悔，但哪怕我们生活做出他们百分之一的改变，至少深藏一颗不羁的内心，不要再一成不变，不要再泥潭深陷，就会变得不再慵懒，变得有趣。﻿﻿\n能折腾，有信仰，这是我对他们四人团队的极简总结。而这正是我还没走出的迷途，Yes和No用错地方。﻿﻿\n人一生会遇到形形色色的人，相信每个人背后都有故事。这些人会对你产生重大影响的人，一双手都可以数的过来，而时常能陪在身边的更是屈指可数。与他们去经历欢笑与泪水，去经历生死与难忘，这样才懂得珍惜，不会恶语相向。很喜欢道士下山范伟讲的那段话，“人生七十古来稀，十年少小，十年老弱，还有五十年，五十年再分成日夜，只有二十五年的光景了，再加上 刮风下雨，三灾六病，人这一辈子 还能剩下多少好日子。”。工作，努力尽心就好，对自己做的事情负责；生活，本应多样。(写完这段，良辰都想吐了)﻿﻿\n火车上还看电影『遗弃』，差一点陷入平常悬疑片的路子，特别是女主开始怀疑自己的时候，好了，不剧透了，小电影里值得一看。﻿﻿\n凌晨1点到的九江，以亲友马上过来接我为由，逃离出站口过分“热烈”的拉客仪式，不下十个说有小妹儿的，“我们这都这么叫”，终于在一公里开外的地方找到一个宾馆，尼玛，还是双标。抓紧时间睡了四个小时就滚了。\n本文链接地址： http://xgknight.com/2015/09/30/the-way-home-20151001/\n","permalink":"http://localhost:1313/2015/09/the-way-home-20151001/","summary":"\u003cp\u003e汽车在公路上一路奔驰，车厢内很安静，大部分人闭目休息，能确定的是司机是清醒的，而我在后面靠窗的位置，取掉眼镜，不太清晰的望着窗外。一片片无人问津小树林，一片片因下雨而污浊的池塘水，一片片村庄、农田……﻿\u003c/p\u003e","title":"回家看看（国庆）"},{"content":"看到身边朋友在玩一个叫 nice 的应用，也试用了一把。\n从下载量来说它是LOFTER的2倍，它们都可以划分为图片社交。这样说对于网易乐乎来说是不公平的，lofter定位是轻博客，类似于国外的tumblr，生产高质量的内容，尤其是图片。（jianshu倾向于文字，类似国外的medium）\n而nice呢，注重图片几乎到放弃文字的地步，简单的通过打标签来注解图片，炫耀的意思不言而喻，而恰好它打的是陌生人社交的牌，大家都互相不认识，不会引起熟人间拉仇恨的嫌疑。陌生人之间也丝毫不吝啬自己的赞，这种低成本却又能给对方带来好感的点赞行为，实际都是虚伪在作怪。我因为应用要求上传了一个阿狸的头像，几分钟内也能收到十多个赞，我当时都蒙了。但是确实喜欢听到被点赞的通知，这大概能解释为什么女生偏爱这个app——全nice内容无非就是自拍照、吃的什么、逛街——无特效，不发图。\n在nice里，你会发现所有人都过着小资生活。它不是一个发泄的场地，也不适合记录生活，因为它是短暂的，一个人可能接触nice一到两个月基本就淡出了。有时候想想用nice的人其实是自私的，因为你的图（背后）往往不止你一人，但因为几乎全来自陌生人点赞，满足的是个人的虚荣心，而图中那一刻的其他人无非是个陪衬。不然为何不发惹朋友圈呢……\n可能有人出来批判我了，女生爱美怎么啦，注孤生。也许我喜欢的只是对生活一种简简单单的表达。你为何不愿在朋友圈发同样的，难道是因为缺少标签的功能吗，no！ 难道是文艺青年号称要逃离朋友圈，也不对！一万个哈姆雷特！\n在nice久了，刷够了别人的美图，忍不住自己也要上图。要有上图的资本，就要打破原来的计划去寻找“素材”，会不会对身边平凡的生活感到厌倦——我YY的。\n人人都有爱美之心，无可厚非，但吸取更有营养的内容，增加自己的涵养，戒除浮躁，懂心交流，才是高情商的选择。\n\u0026ndash; 玛德，在dropbox上下个插图搞了一个小时\n本文链接地址： http://xgknight.com/2015/07/14/nice-is-not-nice/\n","permalink":"http://localhost:1313/2015/07/nice-is-not-nice/","summary":"\u003cp\u003e看到身边朋友在玩一个叫 nice 的应用，也试用了一把。\u003c/p\u003e\n\u003cp\u003e从下载量来说它是LOFTER的2倍，它们都可以划分为图片社交。这样说对于网易乐乎来说是不公平的，lofter定位是轻博客，类似于国外的tumblr，生产高质量的内容，尤其是图片。（jianshu倾向于文字，类似国外的medium）\u003c/p\u003e","title":"nice is not nice"},{"content":"第一天入职 EC，总体感觉还不错，就是不知道日后的工作怎样。eva给我们五个介绍了公司的制度和福利，公共免费wifi，下午四点下午茶有水果，办公电脑不限网（中午休息时间竟然有人直接打dota，还有看动漫的）。sunny跟我们签的2年合同。好了夸完说说其他的感受。\n公司产品——EC营客通。主要这一个产品，有web、PC、android、IOS平台，而且主要卖点是与腾讯qq无缝连接，同时也能连接手机通讯录、邮箱、excel，号称“连接一切”，不然怎么叫 Easy Connection 。试用了移动端，其实功能很简单:支持各种数据来源的导入，加比较全的手机通讯录功能，，再加定时提醒功能（这不是最近我在试用的 『滴答清单』的功能吗），最后是外勤签到和统计的功能。并没有多少先进的科学方法，或令人眼前一亮的新功能。\nPC端的功能稍微复杂一点，但界面简直就是qq的副本，没了qq秀和游戏广告。这不禁让我想到了企业qq RTX，四像四不像。我想ec存在的价值在于，让员工有意识的通过工具去区分工作和生活。至于要做中国的Salesforce，路途还非常非常遥远，因为它“不止连接”。\n至于我很早就了解到的纷享销客，内部培训的时候除了说方向不一样外，还有贬低对手的意思，什么操作性crm与分析型crm。试用了一把，纷享销客也有分析统计预测的功能，走的路线确实完全不一样，似乎fxiaoke更注重于流程审批、知识共享、外勤签到等功能。究竟哪一个是以后的方向，还是各自结合，还很难说。salesforce估值400多亿肯定是有它的道理，如果2年之内没达到sf现在的原型，就很难有更大发展了。\n晕，怎么上班第一天胡乱评价自家产品。\n以后上下班要挤地铁高峰期了，告别了班车福利，似乎以前坐班车从窗户旁看到了公车上的自己。\n现在在想，第二份工作要给自己角色上一个怎样的转变呢，我隐约的感觉到不在甘于这个小弟的角色，而是需要主动在运维团队里推进工作、提出建设性意见的人。听桂哥和超哥的意思，以后工作的关键词大概是kvm, docker, zabbix, saltstack，还是希望能够接触到数据库、开发和架构方面的内容。加油↖(^ω^)↗！\n本文链接地址： http://xgknight.com/2015/07/07/ec-the-first-day/\n","permalink":"http://localhost:1313/2015/07/ec-the-first-day/","summary":"\u003cp\u003e第一天入职 \u003ca href=\"www.scrm.com\"\u003eEC\u003c/a\u003e，总体感觉还不错，就是不知道日后的工作怎样。eva给我们五个介绍了公司的制度和福利，公共免费wifi，下午四点下午茶有水果，办公电脑不限网（中午休息时间竟然有人直接打dota，还有看动漫的）。sunny跟我们签的2年合同。好了夸完说说其他的感受。\u003c/p\u003e\n\u003cp\u003e公司产品——EC营客通。主要这一个产品，有web、PC、android、IOS平台，而且主要卖点是与腾讯qq无缝连接，同时也能连接手机通讯录、邮箱、excel，号称“连接一切”，不然怎么叫 Easy Connection 。试用了移动端，其实功能很简单:支持各种数据来源的导入，加比较全的手机通讯录功能，，再加定时提醒功能（这不是最近我在试用的 『滴答清单』的功能吗），最后是外勤签到和统计的功能。并没有多少先进的科学方法，或令人眼前一亮的新功能。\u003c/p\u003e","title":"EC的第一天"},{"content":"在一个群里看到一个面试题，试着去解答一下，毕竟正好花时间了解过日志这方面的内容。\n希望能达到的使用场景：\n在写业务逻辑时也能进行结构化的log, 并且log被转移到一个数据库， 一个UI前端以这个log数据库为支持， 可以可视化各种指标， 并且保留未来可以对指标进行alarm的可能性\n希望从两个方面考虑这个问题：\n技术通路实现。 在每一步会用些什么技术? 一些核心组件比如log采集和log数据库有哪些已有方案， 是否有优劣？ 从运维角度看， 这套系统可能在哪些方面有需要考量的地方。 比如log采集是否会影响业务进程？ log数据库的运维可能遇到哪些问题？ 可以看出问题提出者比较在意解决这些问题过程中的思维方式和学习能力，弱化实践经验的要求。\n首先根据要求确认一下要达到效果：\nlog日志采集 log存储 log展示 alarm报警(附加) 1 确定日志流向/架构 因为一开始脑海里也不知道原型是怎样的，就是以前用过linux自带的rsyslog功能感觉很类似：在日志服务器上通过配置rsyslog存入mysql的插件，而其它的各个服务器上默认rsyslog都是开启的，修改conf的系统日志、mail、cron等不输出到本地，而是指向mysql数据库。前端通过loganalyzer从数据库获取数据，图形化显示（简陋到不想说了。。。），但是显示的柱形图/饼图没有什么意义，默认对系统messages处理比较方便，要记录nginx或业务逻辑的log还需做其它额外操作。\n但rsyslog并不是一无是处，它的整个架构特别是消息队列的设计，跟后面要讲的许多分布式日志系统是很像的。所以脑海里日记采集的原型出来了：\n业务逻辑的日志输出到文件file，服务上的日志采集客户端agent实时监控这个logfile，作为输入；日志中心服务器server接受来自agent的消息，存入后端数据库。另有一个UI从这个数据库取得数据显示，并提供搜索、统计图表。 然而有以下几个问题需要考虑，这也就是为什么出现各种开源解决方案： 日志产生数量过大，不能及时发送到server怎么办 可以使用队列或redis来缓冲 日志中心服务器server故障怎么办，肯定不能丢失日志，即可靠性 有的解决办法是对 log server 做集群，通过zookeeper来同步配置；有的是在agent上本地暂时存放，等恢复后重新传输，redis就可以承担这个角色 考虑到这个日志平台的可扩展性，新的日志来源input不一定是file，比如rsyslog 至少需要支持常用的input 是否支持过滤功能 filter可以在日志发送之前就把不匹配的日志内容排除掉 log结构化 收集的日志初始是一长字符串，为了后面使用方便，需要将日志结构化存储（后面会有说明） 存储采用关系型数据库对海量日志存储，性能肯定很大问题 log日志存储没有一致性的要求，甚至可以说一条日志根本就没意义，而是需要通过大量的日志，通过分析、比较趋势具备用处。于是日志的存储各显大招，主流有两种：hadoop分布式文件系统HDFS，elasticsearch（后面简称es）全文搜索引擎，它们都具备很强的可伸缩性和多节点高可用性 由于存储方式的不同，数据分析与展示也就有各自的阵营 HDFS一般采用MapReduce处理数据，es既可以通过其丰富的插件显示或搜索数据，也可以通过推荐使用的kibana来展示数据 总结下来大致流程图如下：\n2 log结构化 当然可能你一直存在这样一个疑问：log的结构化问题处理\n代码里logger的内容大概是timestamp,log_level,module,message\u0026hellip; ，一下是nginx的access示例：\n1 2 172.16.30.88 - [08/Jun/2015:00:08:38 +0800] \u0026#34;POST /notice/statement_findStatementVByPage.htm?1433637553824 HTTP/1.1\u0026#34; 200 114 \u0026#34;http://service.tp-link.net/\u0026#34; \u0026#34;Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; Trident/6.0)\u0026#34; 处理这条非结构话的字符串或消息，无非就是在它发送到日志中心之前格式化，像最简单的rsyslog处理方法是通过数据库表字段Mapping来存放，而es则是通过编写Grok规则来结构化，如将IP、日期、请求方式、响应状态码、响应时间等组合成json字符串。（然而Grok写起来是非常痛苦的，以至于官方github上专门维护了一份通用规则表）\n可以说上面提到的各项内容从采集、存储、分析、展示，几乎在所有大型分布式日志系统中都可以找到各自的实现。而具体开源项目的选型，主要根据侧重功能、数据量级、管理复杂度、社区或文档的完善程度等来决定。\n3 对运维带来的影响 是否选用这一套日志管理系统，从运维角度看，需要考虑以下因素\n日志采集是否影响原有进程 应该这样说，业务代码的log是记录到文件的，日志采集进程也是是直接从文件读取，所以外部是不会影响（不包括占用系统资源）。但，记录日志势必会损耗一定的性能，建议做法是通过配置文件设定是否打开日志，优化做法是日志缓存、异步记录、仅记录有价值的日志。\nlog数据库的运维可能会遇到的问题 比较容易出现问题的就是log数据存储出现单点故障、性能不达标，这两方面顾虑都可以通过多节点集群来解决，而且要能够实现添加或去除节点对外透明（即可扩展性）。HDFS和es都可以满足这个要求。 具体到es，还可能遇到索引分区的问题，定义以timestamp或module或日志类型等索引，这个需要具体深入了解业务需求了。\n运维成本\n维护复杂程度，包括学习成本，文档是否完善，能否自定义插件，社区是否成熟涉及到出异常能否快速解决 部署是否方便，通过salt或docker能否方便的完成部署 资源，即引入这一套系统，所需要投入的基础设施 与docker结合的使用 日志默认是写到docker自己的文件系统上，记录或收集方式需要考虑 在host映射volume，日志写到host，日志收集方法不变 docker自身提供日志写入host的系统日志messages功能，日志改收集message 或者, 写插件，agent直接从docker stdout输入 将日志收集agent端封装在docker images里，统一从registry拉取运行，达到自动化部署 可靠性与伸缩性 上面也已经提到，agent日志传输失败需要能够暂时存在本地，等待重传；存储查询遇到性能问题有叫成熟的优化方案，如添加节点或优化es索引\n对日志系统进行监控 日志收集（进程）出现异常，能通过系统本身或其它监控平台报警。还要考虑恢复所用的时间。\n日志系统里定义阈值，能否及时告警 系统自带当然更好，如果没有实现指标告警的难易程度。（不幸的是，logstash有告警插件。。）\n实时性分析要求 即提交一个查询log请求，能够在秒级响应请求结果，图示化显示趋势。\n日志保留周期 对日志存储端来说这是个小问题，但是在agent服务器上日志文件是持续增大的，是否需要定期echo一下。\n认证访问 我们不会把日志数据公布给任何人，架设在内网还要，如果在公网，一是最好能ssl加密，而是有登录验证。这个在logstash没有看到相关的内容，可能需要自己实现\n后话 因为曾经在一次技术沙龙上听到有人分享过logstash，所以一提日志管理时就想到了它，从而比较方便了知道了一个日志采集、存储、分析、展示系统的一个大致技术和架构。然后问google \u0026ldquo;logstash alternative\u0026quot;发现类似的开源/商业的技术可谓是百花齐放，flume，kafka，chukwa，fluent等（上面几个都有了解比较过，架构与上面的图片相似，有的是采用消息订阅的方式，有的结合hadoop使用分析TB级数据的）。\n一开始也是为了避免过早的陷入细节，就把上面几个框架记录了下各自的偏重的适用场景、优缺点、管理复杂度，然后自己搭了一套LEK（Logstash、Elasticsearch、Kibana）环境体验了一把，比起枯燥的看架构原理，更有成就感。从功能上来LEK说刚好可以达到所提要求，而且在github上的logstash的star有4000多个，大有一统江湖之势，新浪有结合docker在使用logstash，在一个交流群里问到也有人在用。（因为各版本兼容性问题，官网原文文档是最完善的。但logstash也有诸如内存占用偏高等问题，都有积极维护的插件来解决）\n最后结合自己以前的经验，思考了一下日后运维工作中可能会涉及到的问题，包括监控和自动化、高可用等方面。\n补充 后来知道还有使用OpenTSDB这种时间序列数据库去存放日志的方案，有机会研究一下。\n本文链接地址：http://xgknight.com/2015/06/09/gongshi-logsystem-elk-preview/\n","permalink":"http://localhost:1313/2015/06/gongshi-logsystem-elk-preview/","summary":"\u003cp\u003e在一个群里看到一个面试题，试着去解答一下，毕竟正好花时间了解过日志这方面的内容。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e希望能达到的使用场景：\u003c/p\u003e\n\u003cp\u003e在写业务逻辑时也能进行结构化的log, 并且log被转移到一个数据库， 一个UI前端以这个log数据库为支持， 可以可视化各种指标， 并且保留未来可以对指标进行alarm的可能性\u003c/p\u003e","title":"解答一个关于日志系统的思路"},{"content":"关于nginx的安装和基本配置请参考nginx，本文在原基础上完成以下几个功能：\n结合proxy和upstream模块实现nginx负载均衡 结合nginx_upstream_check_module模块实现后端服务器的健康检查 使用nginx-sticky-module扩展模块实现Cookie会话黏贴（session-sticky效果） 使用proxy模块实现静态文件缓存 使用ngx_cache_purge实现更强大的缓存清除功能 1. 安装及模块说明 上面提到的3个模块都属于第三方扩展模块，需要提前下好源码，然后编译时通过--add-moudle=src_path一起安装。\n注意：\n使用 nginx_upstream_check_module(简记为m1) 时要先为nginx打上相应版本的patch，我的nginx版本为 1.6.3，所以patch对应 m1 解压后目录下的check_1.5.12+.patch，所以进入nginx源码目录，执行 patch -p1 \u0026hellip;（见下方示例） nginx-sticky-module-ng(简记为m2) 模块可以单独使用，但是因为m1监控检查的方式是依赖于m2的，所以要使用m2，还要对m1打上patch，进入m2源码目录，执行 patch -p0\u0026hellip; 编译示例：（CentOS 6.5 x86_64, nginx 1.6.3）\n# yum -y install gcc gcc-c++ make libtool zlib zlib-devel openssl openssl--devel pcre pcre-devel # cd nginx-1.6.3 # patch -p1 \u0026lt; ../nginx_upstream_check_module-0.3.0/check_1.5.12+.patch # cd ../nginx-sticky-module-ng-1.2.5 # patch -p0 \u0026lt; ../nginx_upstream_check_module-0.3.0/nginx-sticky-module.patch # ./configure --prefix=/usr/local/nginx-1.6 --with-pcre --with-http_stub_status_module --with-http_ssl_module --with-http_gzip_static_module --with-http_realip_module --add-module=../nginx_upstream_check_module-0.3.0 --add-module=../nginx-sticky-module-ng-1.2.5 --add-module=../ngx_cache_purge-2.3 # make \u0026amp;\u0026amp; make install 如果你想在已安装好的nginx上添加第三方模块，依然需要重新编译，但为了不覆盖你原有的配置，请不要make install，而是直接拷贝可执行文件：\n1 2 3 4 # nginx -V //可以看到原来的编译选项，下面用到 # ./configure ... --add-module=.. //你的第三方模块 # make //make后不要install，改用手动拷贝。先备份 # cp objs/nginx /usr/local/nginx-1.6/sbin/nginx 2. nginx-sticky-module 项目地址：https://bitbucket.org/nginx-goodies/nginx-sticky-module-ng\n这个模块的作用是通过cookie黏贴的方式将来自同一个客户端（浏览器）的请求发送到同一个后端服务器上处理，这样一定程度上可以解决多个backend servers的session同步的问题 —— 因为不再需要同步，而RR轮询模式必须要运维人员自己考虑session同步的实现。\n另外内置的 ip_hash 也可以实现根据客户端IP来分发请求，但它很容易造成负载不均衡的情况，而如果nginx前面有CDN网络或者来自同一局域网的访问，它接收的客户端IP是一样的，容易造成负载不均衡现象。淘宝Tengine的 ngx_http_upstream_session_sticky_module 也是类似的功能。nginx-sticky-module的cookie过期时间，默认浏览器关闭就过期，也就是会话方式。\n这个模块并不合适不支持 Cookie 或手动禁用了cookie的浏览器，此时默认sticky就会切换成RR。它不能与ip_hash同时使用。\n2.1 sticky配置 1 2 3 4 5 upstream backend { server 172.29.88.226:8080 weight=1; server 172.29.88.227:8080 weight=1; sticky; } 配置起来超级简单，一般来说一个sticky指令就够了。\nsticky [name=route] [domain=.foo.bar] [path=/] [expires=1h] [hash=index|md5|sha1] [no_fallback];：\nname: 可以为任何的 string 字符,默认是 route domain：哪些域名下可以使用这个 cookie path：哪些路径对启用 sticky，例如 path/test，那么只有 test 这个目录才会使用 sticky 做负载均衡 expires：cookie 过期时间，默认浏览器关闭就过期，也就是会话方式。 no_fallbackup：如果设置了这个，cookie 对应的服务器宕机了，那么将会返回502（bad gateway 或者 proxy error），建议不启用 你在查看官方文档可能会注意到里面也有个 sticky 指令，要说它们的作用几乎是一样的，但是你可能注意到This directive is available as part of our commercial subscription.的说明 —— 这是nginx商业版本里才有的特性。包括后面的check指令，在nginx的商业版本里也有对应的health_check（配在 location ）实现几乎一样的监控检查功能。\n2.2 load-balance其它调度方案 这里顺带介绍一下nginx的负载均衡模块支持的其它调度算法：\n轮询（默认） ： 每个请求按时间顺序逐一分配到不同的后端服务器，如果后端某台服务器宕机，故障系统被自动剔除，使用户访问不受影响。Weight 指定轮询权值，Weight值越大，分配到的访问机率越高，主要用于后端每个服务器性能不均的情况下。 ip_hash ： 每个请求按访问IP的hash结果分配，这样来自同一个IP的访客固定访问一个后端服务器，有效解决了动态网页存在的session共享问题。当然如果这个节点不可用了，会发到下个节点，而此时没有session同步的话就注销掉了。 least_conn ： 请求被发送到当前活跃连接最少的realserver上。会考虑weight的值。 url_hash ： 此方法按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，可以进一步提高后端缓存服务器的效率。Nginx本身是不支持url_hash的，如果需要使用这种调度算法，必须安装Nginx 的hash软件包 nginx_upstream_hash 。 fair ： 这是比上面两个更加智能的负载均衡算法。此种算法可以依据页面大小和加载时间长短智能地进行负载均衡，也就是根据后端服务器的响应时间来分配请求，响应时间短的优先分配。Nginx本身是不支持fair的，如果需要使用这种调度算法，必须下载Nginx的 upstream_fair 模块。 3. 负载均衡与健康检查 严格来说，nginx自带是没有针对负载均衡后端节点的健康检查的，但是可以通过默认自带的 ngx_http_proxy_module 模块和 ngx_http_upstream_module 模块中的相关指令来完成当后端节点出现故障时，自动切换到下一个节点来提供访问。\n3.1 load-balance示例 1 2 3 4 5 6 7 8 9 10 11 upstream backend { ip_hash; server 172.29.88.226:8080 weight 2; server 172.29.88.226:8080 weight=1 max_fails=2 fail_timeout=30s ; server 172.29.88.227:8080 backup; } server { location / { proxy_pass http://backend; proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504; } weight ： 轮询权值也是可以用在ip_hash的，默认值为1\nmax_fails ： 允许请求失败的次数，默认为1。当超过最大次数时，返回proxy_next_upstream 模块定义的错误。\nfail_timeout ： 有两层含义，一是在 30s 时间内最多容许 2 次失败；二是在经历了 2 次失败以后，30s时间内不分配请求到这台服务器。\nbackup ： 预留的备份机器。当其他所有的非backup机器出现故障的时候，才会请求backup机器，因此这台机器的压力最轻。（为什么我的1.6.3版本里配置backup启动nginx时说invalid parameter \u0026quot;backup\u0026quot;？）\nmax_conns： 限制同时连接到某台后端服务器的连接数，默认为0即无限制。因为queue指令是commercial，所以还是保持默认吧。\nproxy_next_upstream ： 这个指令属于 http_proxy 模块的，指定后端返回什么样的异常响应时，使用另一个realserver\n3.2 nginx_upstream_check_module nginx_upstream_check_module 是专门提供负载均衡器内节点的健康检查的外部模块，由淘宝的姚伟斌大神开发，通过它可以用来检测后端 realserver 的健康状态。如果后端 realserver 不可用，则后面的请求就不会转发到该节点上，并持续检查几点的状态。在淘宝自己的 tengine 上是自带了该模块。项目地址：https://github.com/yaoweibin/nginx_upstream_check_module 。\n下面的是一个带后端监控检查的 nginx.conf 配置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 upstream backend { sticky; # or simple round-robin server 172.29.88.226:8080 weight=2; server 172.29.88.226:8081 weight=1 max_fails=2 fail_timeout=30s ; server 172.29.88.227:8080 weight=1 max_fails=2 fail_timeout=30s ; server 172.29.88.227:8081; check interval=5000 rise=2 fall=3 timeout=1000 type=http; check_http_send \u0026#34;HEAD / HTTP/1.0\\r\\n\\r\\n\u0026#34;; check_http_expect_alive http_2xx http_3xx; } server { location / { proxy_pass http://backend; } location /status { check_status; access_log off; allow 172.29.73.23; deny all; } 上面配置的意思是，对name这个负载均衡条目中的所有节点，每个5秒检测一次，请求2次正常则标记 realserver状态为up，如果检测 3 次都失败，则标记 realserver的状态为down，超时时间为1秒。\ncheck指令只能出现在upstream中：\ninterval ： 向后端发送的健康检查包的间隔。 fall ： 如果连续失败次数达到fall_count，服务器就被认为是down。 rise ： 如果连续成功次数达到rise_count，服务器就被认为是up。 timeout ： 后端健康请求的超时时间。 default_down ： 设定初始时服务器的状态，如果是true，就说明默认是down的，如果是false，就是up的。默认值是true，也就是一开始服务器认为是不可用，要等健康检查包达到一定成功次数以后才会被认为是健康的。 type：健康检查包的类型，现在支持以下多种类型 tcp：简单的tcp连接，如果连接成功，就说明后端正常。 http：发送HTTP请求，通过后端的回复包的状态来判断后端是否存活。 ajp：向后端发送AJP协议的Cping包，通过接收Cpong包来判断后端是否存活。 ssl_hello：发送一个初始的SSL hello包并接受服务器的SSL hello包。 mysql: 向mysql服务器连接，通过接收服务器的greeting包来判断后端是否存活。 fastcgi：发送一个fastcgi请求，通过接受解析fastcgi响应来判断后端是否存活 port: 指定后端服务器的检查端口。你可以指定不同于真实服务的后端服务器的端口，比如后端提供的是443端口的应用，你可以去检查80端口的状态来判断后端健康状况。默认是0，表示跟后端server提供真实服务的端口一样。该选项出现于Tengine-1.4.0。 如果 type 为 http ，你还可以使用check_http_send来配置http监控检查包发送的请求内容，为了减少传输数据量，推荐采用 HEAD 方法。当采用长连接进行健康检查时，需在该指令中添加keep-alive请求头，如： HEAD / HTTP/1.1\\r\\nConnection: keep-alive\\r\\n\\r\\n 。当采用 GET 方法的情况下，请求uri的size不宜过大，确保可以在1个interval内传输完成，否则会被健康检查模块视为后端服务器或网络异常。\ncheck_http_expect_alive指定HTTP回复的成功状态，默认认为 2XX 和 3XX 的状态是健康的。\n4. nginx的proxy缓存使用 nginx的页面缓存功能与上面的负载均衡和健康检查是没有关系的，放在这里一是因为懒得再起一篇文章，二是再有load-balance的地方一般都会启用缓存的。\n缓存也就是将js、css、image等静态文件从tomcat缓存到nginx指定的缓存目录下，既可以减轻tomcat负担，也可以加快访问速度，但这样缓存及时清理成为了一个问题，所以需要 ngx_cache_purge 这个模块来在过期时间未到之前，手动清理缓存。（这里有篇 文章，对比使用缓存、不使用缓存、使用动静分离三种情况下，高并发性能比较。使用代理缓存功能性能会高出很多倍）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 http { ... // $upstream_cache_status记录缓存命中率 log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39; \u0026#39;\u0026#34;$upstream_cache_status\u0026#34;\u0026#39;; proxy_temp_path /usr/local/nginx-1.6/proxy_temp; proxy_cache_path /usr/local/nginx-1.6/proxy_cache levels=1:2 keys_zone=cache_one:100m inactive=2d max_size=2g; server { listen 80; server_name ittest.example.com; root html; index index.html index.htm index.jsp; location ~ .*\\.(gif|jpg|png|html|css|js|ico|swf|pdf)(.*) { proxy_pass http://backend; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_cache cache_one; add_header Nginx-Cache $upstream_cache_status; proxy_cache_valid 200 304 301 302 8h; proxy_cache_valid 404 1m; proxy_cache_valid any 2d; proxy_cache_key $host$uri$is_args$args; expires 30d; } location ~ /purge(/.*) { #设置只允许指定的IP或IP段才可以清除URL缓存。 allow 127.0.0.1; allow 172.29.73.0/24; deny all; proxy_cache_purge cache_one $host$1$is_args$args; error_page 405 =200 /purge$1; } } } 说明\nproxy_temp_path ： 缓存临时目录。后端的响应并不直接返回客户端，而是先写到一个临时文件中，然后被rename一下当做缓存放在 proxy_cache_path 。0.8.9版本以后允许temp和cache两个目录在不同文件系统上（分区），然而为了减少性能损失还是建议把它们设成一个文件系统上。\nproxy_cache_path ... ： 设置缓存目录，目录里的文件名是 cache_key 的MD5值。 levels=1:2 keys_zone=cache_one:50m表示采用2级目录结构，Web缓存区名称为cache_one，内存缓存空间大小为100MB，这个缓冲zone可以被多次使用。文件系统上看到的缓存文件名类似于 /usr/local/nginx-1.6/proxy_cache/c/29/b7f54b2df7773722d382f4809d65029c 。 inactive=2d max_size=2g表示2天没有被访问的内容自动清除，硬盘最大缓存空间为2GB，超过这个大学将清除最近最少使用的数据。\nproxy_cache ： 引用前面定义的缓存区 cache_one\nproxy_cache_key ： 定义cache_key\nproxy_cache_valid ： 为不同的响应状态码设置不同的缓存时间，比如200、302等正常结果可以缓存的时间长点，而404、500等缓存时间设置短一些，这个时间到了文件就会过期，而不论是否刚被访问过。\nexpires ： 在响应头里设置Expires:或Cache-Control:max-age，返回给客户端的浏览器缓存失效时间。\n关于缓存的失效期限上面有三个选项：X-Accel-Expires、inactive、proxy_cache_valid、expires，它们之间是有优先级的，按上面的顺序如果在header里设置 X-Accel-Expires 则它的优先级最高，否则inactive优先级最高。更多资料请参考 nginx缓存优先级 或这里。 清除缓存 上述配置的proxy_cache_purge指令用于方便的清除缓存，但必须按照第三方的 ngx_cache_purge 模块才能使用，项目地址：https://github.com/FRiCKLE/ngx_cache_purge/ 。\n使用 ngx_cache_purge 模块清除缓存有2种办法（直接删除缓存目录下的文件也算一种办法）：\necho发送PURGE指令 proxy_cache_purge PURGE from 127.0.0.1表示只允许在来自本地的清除指令 1 # echo -e \u0026#39;PURGE / HTTP/1.0\\r\\n\u0026#39; | nc 127.0.0.1 80 GET方式请求URL 即使用配置文件中的location ~ /purge(/.*)，浏览器访问http://ittest.example.com/purge/your/may/path来清除缓存，或者echo -e 'GET /purge/ HTTP/1.0\\r\\n' | nc ittest.example.com 80 参考\nofficial documentation\nNginx实战系列之功能篇\u0026mdash;-后端节点健康检查\nTengine nginx_upstream_check_module\nnginx反向代理tomcat集群做负载均衡缓存\nweb内容缓存 nginx高性能缓存详解\n使用nginx sticky实现基于cookie的负载均衡\n原文链接地址：http://xgknight.com/2015/05/22/nginx-cache-check/\n","permalink":"http://localhost:1313/2015/06/nginx-cache-check/","summary":"\u003cp\u003e关于nginx的安装和基本配置请参考\u003ca href=\"http://xgknight.com/2015/05/17/nginx-install-and-config\"\u003enginx\u003c/a\u003e，本文在原基础上完成以下几个功能：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e结合proxy和upstream模块实现nginx负载均衡\u003c/li\u003e\n\u003cli\u003e结合\u003ccode\u003enginx_upstream_check_module\u003c/code\u003e模块实现后端服务器的健康检查\u003c/li\u003e\n\u003cli\u003e使用\u003ccode\u003enginx-sticky-module\u003c/code\u003e扩展模块实现Cookie会话黏贴（session-sticky效果）\u003c/li\u003e\n\u003cli\u003e使用proxy模块实现静态文件缓存\u003c/li\u003e\n\u003cli\u003e使用\u003ccode\u003engx_cache_purge\u003c/code\u003e实现更强大的缓存清除功能\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"1-安装及模块说明\"\u003e1. 安装及模块说明\u003c/h1\u003e\n\u003cp\u003e上面提到的3个模块都属于第三方扩展模块，需要提前下好源码，然后编译时通过\u003ccode\u003e--add-moudle=src_path\u003c/code\u003e一起安装。\u003c/p\u003e","title":"nginx做负载均衡器以及proxy缓存配置"},{"content":"nginx下配置ssl本来是很简单的，无论是去认证中心买SSL安全证书还是自签署证书，但最近公司OA的一个需求，得以有个机会实际折腾一番。一开始采用的是全站加密，所有访问http:80的请求强制转换（rewrite）到https，后来自动化测试结果说响应速度太慢，https比http慢慢30倍，心想怎么可能，鬼知道他们怎么测的。所以就试了一下部分页面https（不能只针对某类动态请求才加密）和双向认证。下面分节介绍。\n默认nginx是没有安装ssl模块的，需要编译安装nginx时加入--with-http_ssl_module选项。\n关于SSL/TLS原理请参考 这里，如果你只是想测试或者自签发ssl证书，参考 这里 。\n提示：nignx到后端服务器由于一般是内网，所以不加密。\n1. 全站ssl 全站做ssl是最常见的一个使用场景，默认端口443，而且一般是单向认证。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 server { listen 443; server_name example.com; root /apps/www; index index.html index.htm; ssl on; ssl_certificate ../SSL/ittest.pem; ssl_certificate_key ../SSL/ittest.key; # ssl_protocols SSLv3 TLSv1 TLSv1.1 TLSv1.2; # ssl_ciphers ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP; # ssl_prefer_server_ciphers on; } 如果想把http的请求强制转到https的话：\n1 2 3 4 5 6 7 8 server { listen 80; server_name example.me; rewrite ^ https://$server_name$request_uri? permanent; ### 使用return的效率会更高 # return 301 https://$server_name$request_uri; } ssl_certificate证书其实是个公钥，它会被发送到连接服务器的每个客户端，ssl_certificate_key私钥是用来解密的，所以它的权限要得到保护但nginx的主进程能够读取。当然私钥和证书可以放在一个证书文件中，这种方式也只有公钥证书才发送到client。\nssl_protocols指令用于启动特定的加密协议，nginx在1.1.13和1.0.12版本后默认是ssl_protocols SSLv3 TLSv1 TLSv1.1 TLSv1.2，TLSv1.1与TLSv1.2要确保OpenSSL \u0026gt;= 1.0.1 ，SSLv3 现在还有很多地方在用但有不少被攻击的漏洞。\nssl_ciphers选择加密套件，不同的浏览器所支持的套件（和顺序）可能会不同。这里指定的是OpenSSL库能够识别的写法，你可以通过 openssl -v cipher 'RC4:HIGH:!aNULL:!MD5'（后面是你所指定的套件加密算法） 来看所支持算法。\nssl_prefer_server_ciphers on设置协商加密算法时，优先使用我们服务端的加密套件，而不是客户端浏览器的加密套件。\nhttps优化参数 ssl_session_cache shared:SSL:10m; : 设置ssl/tls会话缓存的类型和大小。如果设置了这个参数一般是shared，buildin可能会参数内存碎片，默认是none，和off差不多，停用缓存。如shared:SSL:10m表示我所有的nginx工作进程共享ssl会话缓存，官网介绍说1M可以存放约4000个sessions。 详细参考serverfault上的问答ssl_session_cache。 ssl_session_timeout ： 客户端可以重用会话缓存中ssl参数的过期时间，内网系统默认5分钟太短了，可以设成30m即30分钟甚至4h。 设置较长的keepalive_timeout也可以减少请求ssl会话协商的开销，但同时得考虑线程的并发数了。\n提示：在生成证书请求csr文件时，如果输入了密码，nginx每次启动时都会提示输入这个密码，可以使用私钥来生成解密后的key来代替，效果是一样的，达到免密码重启的效果：\n1 openssl rsa -in ittest.key -out ittest_unsecure.key 导入证书 如果你是找一个知名的ssl证书颁发机构如VeriSign、Wosign、StartSSL签发的证书，浏览器已经内置并信任了这些根证书，如果你是自建C或获得二级CA授权，都需要将CA证书添加到浏览器，这样在访问站点时才不会显示不安全连接。各个浏览的添加方法不在本文探讨范围内。\n2. 部分页面ssl 一个站点并不是所有信息都是非常机密的，如网上商城，一般的商品浏览可以不通过https，而用户登录以及支付的时候就强制经过https传输，这样用户访问速度和安全性都得到兼顾。\n但是请注意不要理解错了，是对页面加密而不能针对某个请求加密，一个页面或地址栏的URL一般会发起许多请求的，包括css/png/js等静态文件和动态的java或php请求，所以要加密的内容包含页面内的其它资源文件，否则就会出现http与https内容混合的问题。在http页面混有https内容时，页面排版不会发生乱排现象；在https页面中包含以http方式引入的图片、js等资源时，浏览器为了安全起见会阻止加载。\n下面是只对example.com/account/login登录页面进行加密的栗子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 root /apps/www; index index.html index.htm; server { listen 80; server_name example.com; location ^~ /account/login { rewrite ^ https://$server_name:443$request_uri? permanent; } location / { proxy_pass http://localhost:8080; ### Set headers #### proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_redirect off; } } server { listen 443 ssl; server_name example.com; ssl on; ssl_certificate ../SSL/ittest.pem; ssl_certificate_key ../SSL/ittest.key; ssl_protocols SSLv3 TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP; ssl_prefer_server_ciphers on; location ^~ /account/login { proxy_pass http://localhost:8080; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_redirect off; ### Most PHP, Python, Rails, Java App can use this header -\u0026gt; https ### proxy_set_header X-Forwarded-Proto $scheme; } location / { rewrite ^ http://$server_name$request_uri? permanent; } } 关于rewrite与location的写法参考这里。当浏览器访问http://example.com/account/login.xx时，被301到https://example.com/account/login.xx，在这个ssl加密的虚拟主机里也匹配到/account/login，反向代理到后端服务器，后面的传输过程是没有https的。这个login.xx页面下的其它资源也是经过https请求nginx的，登录成功后跳转到首页时的链接使用http，这个可能需要开发代码里面控制。\n上面配置中使用了proxy_set_header X-Forwarded-Proto $scheme，在jsp页面使用request.getScheme()得到的是https 。如果不把请求的$scheme协议设置在header里，后端jsp页面会一直认为是http，将导致响应异常。 ssl配置块还有个与不加密的80端口类似的location /，它的作用是当用户直接通过https访问首页时，自动跳转到不加密端口，你可以去掉它允许用户这样做。 3. 实现双向ssl认证 上面的两种配置都是去认证被访问的站点域名是否真实可信，并对传输过程加密，但服务器端并没有认证客户端是否可信。（实际上除非特别重要的场景，也没必要去认证访问者，除非像银行U盾这样的情况）\n要实现双向认证HTTPS，nginx服务器上必须导入CA证书（根证书/中间级证书），因为现在是由服务器端通过CA去验证客户端的信息。还有必须在申请服务器证书的同时，用同样的方法生成客户证书。取得客户证书后，还要将它转换成浏览器识别的格式（大部分浏览器都认识PKCS12格式）：\n1 openssl pkcs12 -export -clcerts -in client.crt -inkey client.key -out client.p12 然后把这个client.p12发给你相信的人，让它导入到浏览器中，访问站点建立连接的时候nginx会要求客户端把这个证书发给自己验证，如果没有这个证书就拒绝访问。\n同时别忘了在 nginx.conf 里配置信任的CA：（如果是二级CA，请把根CA放在后面，形成CA证书链）\n1 2 3 4 5 6 7 8 9 10 proxy_ignore_client_abort on； ssl on; ... ssl_verify_client on; ssl_verify_depth 2; ssl_client_certificate ../SSL/ca-chain.pem; # 在双向location下加入： proxy_set_header X-SSL-Client-Cert $ssl_client_cert; 拓展：使用geo模块 nginx默认安装了一个ngx_http_geo_module，这个geo模块可以根据客户端IP来创建变量的值，用在如来自172.29.73.0/24段的IP访问login时使用双向认证，其它段使用一般的单向认证。\n1 2 3 4 geo $duplexing_user { default 1; include geo.conf; # 注意在0.6.7版本以后，include是相对于nginx.conf所在目录而言的 } 语法 geo [$address] $variable { … }，位于http段，默认地址是$reoute_addr，假设 conf/geo.conf 内容：\n1 2 3 127.0.0.1/32 LOCAL; # 本地 172.29.73.23/32 SEAN; # 某个IP 172.29.73.0/24 1; # IP段，可以按国家或地域定义后面的不同的值 需要配置另外一个虚拟主机server{ssl 445}，里面使用上面双向认证的写法，然后在80或443里使用变量$duplexing_user去判断，如果为1就rewrite到445，否则rewrite到443。具体用法可以参考nginx geo使用方法。\n参考\nNginx部署部分https与部分http Linux+Nginx/Apache/Tomcat新增SSL证书，开启https访问教程 SSL \u0026amp; SPDY 已全面部署 SSL证书与Https应用部署小结 ngx_http_ssl_module docs Optimizing HTTPS on Nginx http://zhangge.net/4861.html http://blog.chinaunix.net/uid-192074-id-3135733.html ","permalink":"http://localhost:1313/2015/05/nginx-ssl/","summary":"\u003cp\u003enginx下配置ssl本来是很简单的，无论是去认证中心买SSL安全证书还是自签署证书，但最近公司OA的一个需求，得以有个机会实际折腾一番。一开始采用的是全站加密，所有访问http:80的请求强制转换（rewrite）到https，后来自动化测试结果说响应速度太慢，https比http慢慢30倍，心想怎么可能，鬼知道他们怎么测的。所以就试了一下部分页面https（不能只针对某类动态请求才加密）和双向认证。下面分节介绍。\u003c/p\u003e","title":"nginx配置ssl加密（单双向认证、部分https）"},{"content":"公司内部 OA 系统要做线上高可用，避免单点故障，所以计划使用2台虚拟机通过 Keepalived 工具来实现 nginx 的高可用（High Avaiability），达到一台nginx入口服务器宕机，另一台备机自动接管服务的效果。（nginx做反向代理，实现后端应用服务器的负载均衡）快速搭建请直接跳至 第2节。\n1. Keepalived介绍 Keepalived是一个基于VRRP协议来实现的服务高可用方案，可以利用其来避免IP单点故障，类似的工具还有heartbeat、corosync、pacemaker。但是它一般不会单独出现，而是与其它负载均衡技术（如lvs、haproxy、nginx）一起工作来达到集群的高可用。\n1.1 VRRP协议 VRRP全称 Virtual Router Redundancy Protocol，即 虚拟路由冗余协议。可以认为它是实现路由器高可用的容错协议，即将N台提供相同功能的路由器组成一个路由器组(Router Group)，这个组里面有一个master和多个backup，但在外界看来就像一台一样，构成虚拟路由器，拥有一个虚拟IP（vip，也就是路由器所在局域网内其他机器的默认路由），占有这个IP的master实际负责ARP相应和转发IP数据包，组中的其它路由器作为备份的角色处于待命状态。master会发组播消息，当backup在超时时间内收不到vrrp包时就认为master宕掉了，这时就需要根据VRRP的优先级来选举一个backup当master，保证路由器的高可用。\n在VRRP协议实现里，虚拟路由器使用 00-00-5E-00-01-XX 作为虚拟MAC地址，XX就是唯一的 VRID （Virtual Router IDentifier），这个地址同一时间只有一个物理路由器占用。在虚拟路由器里面的物理路由器组里面通过多播IP地址 224.0.0.18 来定时发送通告消息。每个Router都有一个 1-255 之间的优先级别，级别最高的（highest priority）将成为主控（master）路由器。通过降低master的优先权可以让处于backup状态的路由器抢占（pro-empt）主路由器的状态，两个backup优先级相同的IP地址较大者为master，接管虚拟IP。\n与heartbeat/corosync等比较 直接摘抄自 http://www.linuxidc.com/Linux/2013-08/89227.htm ：\nHeartbeat、Corosync、Keepalived这三个集群组件我们到底选哪个好，首先我想说明的是，Heartbeat、Corosync是属于同一类型，Keepalived与Heartbeat、Corosync，根本不是同一类型的。Keepalived使用的vrrp协议方式，虚拟路由冗余协议 (Virtual Router Redundancy Protocol，简称VRRP)；Heartbeat或Corosync是基于主机或网络服务的高可用方式；简单的说就是，Keepalived的目的是模拟路由器的高可用，Heartbeat或Corosync的目的是实现Service的高可用。\n所以一般Keepalived是实现前端高可用，常用的前端高可用的组合有，就是我们常见的LVS+Keepalived、Nginx+Keepalived、HAproxy+Keepalived。而Heartbeat或Corosync是实现服务的高可用，常见的组合有Heartbeat v3(Corosync)+Pacemaker+NFS+Httpd 实现Web服务器的高可用、Heartbeat v3(Corosync)+Pacemaker+NFS+MySQL 实现MySQL服务器的高可用。总结一下，Keepalived中实现轻量级的高可用，一般用于前端高可用，且不需要共享存储，一般常用于两个节点的高可用。而Heartbeat(或Corosync)一般用于服务的高可用，且需要共享存储，一般用于多节点的高可用。这个问题我们说明白了。\n又有博友会问了，那heartbaet与corosync我们又应该选择哪个好啊，我想说我们一般用corosync，因为corosync的运行机制更优于heartbeat，就连从heartbeat分离出来的pacemaker都说在以后的开发当中更倾向于corosync，所以现在corosync+pacemaker是最佳组合。\n1.2 Keepalived + nginx keepalived可以认为是VRRP协议在Linux上的实现，主要有三个模块，分别是core、check和vrrp。core模块为keepalived的核心，负责主进程的启动、维护以及全局配置文件的加载和解析。check负责健康检查，包括常见的各种检查方式。vrrp模块是来实现VRRP协议的。本文基于如下的拓扑图：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 +-------------+ | uplink | +-------------+ | + MASTER keep|alived BACKUP 172.29.88.224 172.29.88.222 172.29.88.225 +-------------+ +-------------+ +-------------+ | nginx01 |----| virtualIP |----| nginx02 | +-------------+ +-------------+ +-------------+ | +------------------+------------------+ | | | +-------------+ +-------------+ +-------------+ | web01 | | web02 | | web03 | +-------------+ +-------------+ +-------------+ 2. keepalived实现nginx高可用 2.1安装 我的环境是CentOS 6.2 X86_64，直接通过yum方式安装最简单：\n1 2 3 # yum install -y keepalived # keepalived -v Keepalived v1.2.13 (03/19,2015) 2.2 nginx监控脚本 该脚本检测ngnix的运行状态，并在nginx进程不存在时尝试重新启动ngnix，如果启动失败则停止keepalived，准备让其它机器接管。\n/etc/keepalived/check_nginx.sh ：\n1 2 3 4 5 6 7 8 9 10 #!/bin/bash counter=$(ps -C nginx --no-heading|wc -l) if [ \u0026#34;${counter}\u0026#34; = \u0026#34;0\u0026#34; ]; then /usr/local/bin/nginx sleep 2 counter=$(ps -C nginx --no-heading|wc -l) if [ \u0026#34;${counter}\u0026#34; = \u0026#34;0\u0026#34; ]; then /etc/init.d/keepalived stop fi fi 你也可以根据自己的业务需求，总结出在什么情形下关闭keepalived，如 curl 主页连续2个3s没有响应则切换： (感谢网友对这个脚本提出的几处语法错误，已修正)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 #!/bin/bash # curl -IL http://localhost/member/login.htm # curl --data \u0026#34;memberName=fengkan\u0026amp;password=22\u0026#34; http://localhost/member/login.htm count=0 for (( k=0; k\u0026lt;2; k++ )) do check_code=$( curl --connect-timeout 3 -sL -w \u0026#34;%{http_code}\\\\n\u0026#34; http://localhost/login.html -o /dev/null ) if [ \u0026#34;$check_code\u0026#34; != \u0026#34;200\u0026#34; ]; then count=$(expr $count + 1) sleep 3 continue else count=0 break fi done if [ \u0026#34;$count\u0026#34; != \u0026#34;0\u0026#34; ]; then # /etc/init.d/keepalived stop exit 1 else exit 0 fi 2.3 keepalived.conf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 ! Configuration File for keepalived global_defs { notification_email { zhouxiao@example.com itsection@example.com } notification_email_from itsection@example.com smtp_server mail.example.com smtp_connect_timeout 30 router_id LVS_DEVEL } vrrp_script chk_nginx { # script \u0026#34;killall -0 nginx\u0026#34; script \u0026#34;/etc/keepalived/check_nginx.sh\u0026#34; interval 2 weight -5 fall 3 rise 2 } vrrp_instance VI_1 { state MASTER interface eth0 mcast_src_ip 172.29.88.224 virtual_router_id 51 priority 101 advert_int 2 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 172.29.88.222 } track_script { chk_nginx } } 在其它备机BACKUP上，只需要改变 state MASTER -\u0026gt; state BACKUP，priority 101 -\u0026gt; priority 100，mcast_src_ip 172.29.88.224 -\u0026gt; mcast_src_ip 172.29.88.225即可。\nservice keepalived restart 2.4 配置选项说明 global_defs\nnotification_email ： keepalived在发生诸如切换操作时需要发送email通知地址，后面的 smtp_server 相比也都知道是邮件服务器地址。也可以通过其它方式报警，毕竟邮件不是实时通知的。 router_id ： 机器标识，通常可设为hostname。故障发生时，邮件通知会用到 vrrp_instance\nstate ： 指定instance(Initial)的初始状态，就是说在配置好后，这台服务器的初始状态就是这里指定的，但这里指定的不算，还是得要通过竞选通过优先级来确定。如果这里设置为MASTER，但如若他的优先级不及另外一台，那么这台在发送通告时，会发送自己的优先级，另外一台发现优先级不如自己的高，那么他会就回抢占为MASTER interface ： 实例绑定的网卡，因为在配置虚拟IP的时候必须是在已有的网卡上添加的 mcast_src_ip ： 发送多播数据包时的源IP地址，这里注意了，这里实际上就是在那个地址上发送VRRP通告，这个非常重要，一定要选择稳定的网卡端口来发送，这里相当于heartbeat的心跳端口，如果没有设置那么就用默认的绑定的网卡的IP，也就是interface指定的IP地址 virtual_router_id ： 这里设置VRID，这里非常重要，相同的VRID为一个组，他将决定多播的MAC地址 priority ： 设置本节点的优先级，优先级高的为master advert_int ： 检查间隔，默认为1秒。这就是VRRP的定时器，MASTER每隔这样一个时间间隔，就会发送一个advertisement报文以通知组内其他路由器自己工作正常 authentication ： 定义认证方式和密码，主从必须一样 virtual_ipaddress ： 这里设置的就是VIP，也就是虚拟IP地址，他随着state的变化而增加删除，当state为master的时候就添加，当state为backup的时候删除，这里主要是有优先级来决定的，和state设置的值没有多大关系，这里可以设置多个IP地址 track_script ： 引用VRRP脚本，即在 vrrp_script 部分指定的名字。定期运行它们来改变优先级，并最终引发主备切换。 vrrp_script 告诉 keepalived 在什么情况下切换，所以尤为重要。可以有多个 vrrp_script\nscript ： 自己写的检测脚本。也可以是一行命令如killall -0 nginx interval 2 ： 每2s检测一次 weight -5 ： 检测失败（脚本返回非0）则优先级 -5 fall 2 ： 检测连续 2 次失败才算确定是真失败。会用weight减少优先级（1-255之间） rise 1 ： 检测 1 次成功就算成功。但不修改优先级 这里要提示一下script一般有2种写法：\n通过脚本执行的返回结果，改变优先级，keepalived继续发送通告消息，backup比较优先级再决定 脚本里面检测到异常，直接关闭keepalived进程，backup机器接收不到advertisement会抢占IP 上文 vrrp_script 配置部分，killall -0 nginx属于第1种情况，/etc/keepalived/check_nginx.sh属于第2种情况（脚本中关闭keepalived）。个人更倾向于通过shell脚本判断，但有异常时exit 1，正常退出exit 0，然后keepalived根据动态调整的 vrrp_instance 优先级选举决定是否抢占VIP：\n如果脚本执行结果为0，并且weight配置的值大于0，则优先级相应的增加 如果脚本执行结果非0，并且weight配置的值小于0，则优先级相应的减少 其他情况，原本配置的优先级不变，即配置文件中priority对应的值。\n提示：\n优先级不会不断的提高或者降低 可以编写多个检测脚本并为每个检测脚本设置不同的weight（在配置中列出就行） 不管提高优先级还是降低优先级，最终优先级的范围是在[1,254]，不会出现优先级小于等于0或者优先级大于等于255的情况 在MASTER节点的 vrrp_instance 中 配置 nopreempt ，当它异常恢复后，即使它 prio 更高也不会抢占，这样可以避免正常情况下做无谓的切换 以上可以做到利用脚本检测业务进程的状态，并动态调整优先级从而实现主备切换。\n配置结束\n在默认的keepalive.conf里面还有 virtual_server,real_server 这样的配置，我们这用不到，它是为lvs准备的。 notify 可以定义在切换成MASTER或BACKUP时执行的脚本，如有需求请自行google。\nnotify\n2.5 nginx配置 当然nginx没有什么可配置的，因为它与keepalived并没有联系。但记住，2台nginx服务器上的配置应该是完全一样的（rsync同步），这样才能做到对用户透明，nginx.conf 里面的 server_name 尽量使用域名来代替，然后dns解析这个域名到虚拟IP 172.29.88.222。\n更多关于nginx内容配置请参考 这里 。\n3. 测试 根据上面的配置，初始化状态：172.29.88.224 (itoatest1,MASTER,101)，172.29.88.222（itoatest2,BACKUP,100），nginx和keepalived都启动，虚拟IP 172.29.88.222 在 itoatest1 上：\n1 2 3 4 5 # 使用ip命令配置的地址，ifconfig查看不了 [root@itoatest1 nginx-1.6]# ip a|grep eth0 2: eth0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000 inet 172.29.88.224/24 brd 172.29.88.255 scope global eth0 inet 172.29.88.222/32 scope global eth0 浏览器访问 172.29.88.222 或域名，OK。\n直接关闭 itoatest1 上的nginx：/usr/local/nginx-1.6/sbin/nginx -s stop：\n1 2 3 [root@localhost keepalived]# ip a|grep eth0 2: eth0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000 inet 172.29.88.224/24 brd 172.29.88.255 scope global eth0 vip消失，漂移到 itoatest2：\n同时可以看到两台服务器上 /var/log/messages：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 ## itoatest1 Jun 5 16:44:01 itoatest1 Keepalived_vrrp[44875]: VRRP_Instance(VI_1) Sending gratuitous ARPs on eth0 for 172.29.88.222 Jun 5 16:44:06 itoatest1 Keepalived_vrrp[44875]: VRRP_Instance(VI_1) Sending gratuitous ARPs on eth0 for 172.29.88.222 Jun 5 16:44:46 itoatest1 Keepalived_vrrp[44875]: VRRP_Script(chk_nginx) failed Jun 5 16:44:48 itoatest1 Keepalived_vrrp[44875]: VRRP_Instance(VI_1) Received higher prio advert Jun 5 16:44:48 itoatest1 Keepalived_vrrp[44875]: VRRP_Instance(VI_1) Entering BACKUP STATE Jun 5 16:44:48 itoatest1 Keepalived_vrrp[44875]: VRRP_Instance(VI_1) removing protocol VIPs. Jun 5 16:44:48 itoatest1 Keepalived_healthcheckers[44874]: Netlink reflector reports IP 172.29.88.222 removed ## itoatest2 Jun 5 16:44:00 itoatest2 Keepalived_vrrp[35555]: VRRP_Instance(VI_1) Transition to MASTER STATE Jun 5 16:44:00 itoatest2 Keepalived_vrrp[35555]: VRRP_Instance(VI_1) Received higher prio advert Jun 5 16:44:00 itoatest2 Keepalived_vrrp[35555]: VRRP_Instance(VI_1) Entering BACKUP STATE Jun 5 16:44:48 itoatest2 Keepalived_vrrp[35555]: VRRP_Instance(VI_1) forcing a new MASTER election Jun 5 16:44:48 itoatest2 Keepalived_vrrp[35555]: VRRP_Instance(VI_1) forcing a new MASTER election Jun 5 16:44:49 itoatest2 Keepalived_vrrp[35555]: VRRP_Instance(VI_1) Transition to MASTER STATE Jun 5 16:44:50 itoatest2 Keepalived_vrrp[35555]: VRRP_Instance(VI_1) Entering MASTER STATE Jun 5 16:44:50 itoatest2 Keepalived_vrrp[35555]: VRRP_Instance(VI_1) setting protocol VIPs. Jun 5 16:44:50 itoatest2 Keepalived_vrrp[35555]: VRRP_Instance(VI_1) Sending gratuitous ARPs on eth0 for 172.29.88.222 Jun 5 16:44:50 itoatest2 Keepalived_healthcheckers[35554]: Netlink reflector reports IP 172.29.88.222 added Jun 5 16:44:55 itoatest2 Keepalived_vrrp[35555]: VRRP_Instance(VI_1) Sending gratuitous ARPs on eth0 for 172.29.88.222 你也可以通过在两台服务器上抓包来查看 优先级priority 的变化：\n1 2 3 ## itoatest1 上 ## 直接输出，或后加 -w itoatest-kl.cap存入文件用wireshark查看 # tcpdump -vvv -n -i eth0 dst 224.0.0.18 and src 172.29.88.224 参考\n使用Keepalived实现Nginx高可用性\nHigh Availability Support Based on keepalived\nnginx+keepalived实现双机热备的高可用\nLVS原理详解及部署之五：LVS+keepalived实现负载均衡\u0026amp;高可用\nKeepalived双主模型中vrrp_script中权重改变故障排查\n虚拟路由器冗余协议【原理篇】VRRP详解\nKeepalived原理与实战精讲\n","permalink":"http://localhost:1313/2015/05/nginx-keepalived-ha/","summary":"\u003cp\u003e公司内部 OA 系统要做线上高可用，避免单点故障，所以计划使用2台虚拟机通过 Keepalived 工具来实现 nginx 的高可用（High Avaiability），达到一台nginx入口服务器宕机，另一台备机自动接管服务的效果。（nginx做反向代理，实现后端应用服务器的负载均衡）快速搭建请直接跳至 第2节。\u003c/p\u003e","title":"Nginx+Keepalived实现站点高可用"},{"content":"1. location正则写法 一个示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 location = / { # 精确匹配 / ，主机名后面不能带任何字符串 [ configuration A ] } location / { # 因为所有的地址都以 / 开头，所以这条规则将匹配到所有请求 # 但是正则和最长字符串会优先匹配 [ configuration B ] } location /documents/ { # 匹配任何以 /documents/ 开头的地址，匹配符合以后，还要继续往下搜索 # 只有后面的正则表达式没有匹配到时，这一条才会采用这一条 [ configuration C ] } location ~ /documents/Abc { # 匹配任何以 /documents/Abc 开头的地址，匹配符合以后，还要继续往下搜索 # 只有后面的正则表达式没有匹配到时，这一条才会采用这一条 [ configuration CC ] } location ^~ /images/ { # 匹配任何以 /images/ 开头的地址，匹配符合以后，停止往下搜索正则，采用这一条。 [ configuration D ] } location ~* \\.(gif|jpg|jpeg)$ { # 匹配所有以 gif,jpg或jpeg 结尾的请求 # 然而，所有请求 /images/ 下的图片会被 config D 处理，因为 ^~ 到达不了这一条正则 [ configuration E ] } location /images/ { # 字符匹配到 /images/，继续往下，会发现 ^~ 存在 [ configuration F ] } location /images/abc { # 最长字符匹配到 /images/abc，继续往下，会发现 ^~ 存在 # F与G的放置顺序是没有关系的 [ configuration G ] } location ~ /images/abc/ { # 只有去掉 config D 才有效：先最长匹配 config G 开头的地址，继续往下搜索，匹配到这一条正则，采用 [ configuration H ] } location ~* /js/.*/\\.js 已=开头表示精确匹配 如 A 中只匹配根目录结尾的请求，后面不能带任何字符串。 ^~ 开头表示uri以某个常规字符串开头，不是正则匹配 ~ 开头表示区分大小写的正则匹配; ~* 开头表示不区分大小写的正则匹配 / 通用匹配, 如果没有其它匹配,任何请求都会匹配到 顺序 no优先级： (location =) \u0026gt; (location 完整路径) \u0026gt; (location ^~ 路径) \u0026gt; (location ,* 正则顺序) \u0026gt; (location 部分起始路径) \u0026gt; (/)\n上面的匹配结果 按照上面的location写法，以下的匹配示例成立：\n/ -\u0026gt; config A\n精确完全匹配，即使/index.html也匹配不了 /downloads/download.html -\u0026gt; config B\n匹配B以后，往下没有任何匹配，采用B /images/1.gif -\u0026gt; configuration D\n匹配到F，往下匹配到D，停止往下 /images/abc/def -\u0026gt; config D 最长匹配到G，往下匹配D，停止往下\n你可以看到 任何以/images/开头的都会匹配到D并停止，FG写在这里是没有任何意义的，H是永远轮不到的，这里只是为了说明匹配顺序 /documents/document.html -\u0026gt; config C\n匹配到C，往下没有任何匹配，采用C /documents/1.jpg -\u0026gt; configuration E\n匹配到C，往下正则匹配到E /documents/Abc.jpg -\u0026gt; config CC 最长匹配到C，往下正则顺序匹配到CC，不会往下到E 实际使用建议 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 所以实际使用中，个人觉得至少有三个匹配规则定义，如下： #直接匹配网站根，通过域名访问网站首页比较频繁，使用这个会加速处理，官网如是说。 #这里是直接转发给后端应用服务器了，也可以是一个静态首页 # 第一个必选规则 location = / { proxy_pass http://tomcat:8080/index } # 第二个必选规则是处理静态文件请求，这是nginx作为http服务器的强项 # 有两种配置模式，目录匹配或后缀匹配,任选其一或搭配使用 location ^~ /static/ { root /webroot/static/; } location ~* \\.(gif|jpg|jpeg|png|css|js|ico)$ { root /webroot/res/; } #第三个规则就是通用规则，用来转发动态请求到后端应用服务器 #非静态文件请求就默认是动态请求，自己根据实际把握 #毕竟目前的一些框架的流行，带.php,.jsp后缀的情况很少了 location / { proxy_pass http://tomcat:8080/ } http://tengine.taobao.org/book/chapter_02.html http://nginx.org/en/docs/http/ngx_http_rewrite_module.html\n2. Rewrite规则 rewrite功能就是，使用nginx提供的全局变量或自己设置的变量，结合正则表达式和标志位实现url重写以及重定向。rewrite只能放在server{},location{},if{}中，并且只能对域名后边的除去传递的参数外的字符串起作用，例如 http://xgknight.com/a/we/index.php?id=1\u0026amp;u=str 只对/a/we/index.php重写。语法rewrite regex replacement [flag];\n如果相对域名或参数字符串起作用，可以使用全局变量匹配，也可以使用proxy_pass反向代理。\n表明看rewrite和location功能有点像，都能实现跳转，主要区别在于rewrite是在同一域名内更改获取资源的路径，而location是对一类路径做控制访问或反向代理，可以proxy_pass到其他机器。很多情况下rewrite也会写在location里，它们的执行顺序是：\n执行server块的rewrite指令 执行location匹配 执行选定的location中的rewrite指令 如果其中某步URI被重写，则重新循环执行1-3，直到找到真实存在的文件；循环超过10次，则返回500 Internal Server Error错误。\n2.1 flag标志位 last : 相当于Apache的[L]标记，表示完成rewrite break : 停止执行当前虚拟主机的后续rewrite指令集 redirect : 返回302临时重定向，地址栏会显示跳转后的地址 permanent : 返回301永久重定向，地址栏会显示跳转后的地址 因为301和302不能简单的只返回状态码，还必须有重定向的URL，这就是return指令无法返回301,302的原因了。这里 last 和 break 区别有点难以理解：\nlast一般写在server和if中，而break一般使用在location中 last不终止重写后的url匹配，即新的url会再从server走一遍匹配流程，而break终止重写后的匹配 break和last都能组织继续执行后面的rewrite指令 2.2 if指令与全局变量 if判断指令 语法为if(condition){...}，对给定的条件condition进行判断。如果为真，大括号内的rewrite指令将被执行，if条件(conditon)可以是如下任何内容：\n当表达式只是一个变量时，如果值为空或任何以0开头的字符串都会当做false 直接比较变量和内容时，使用=或!= ~正则表达式匹配，~*不区分大小写的匹配，!~区分大小写的不匹配 -f和!-f用来判断是否存在文件 -d和!-d用来判断是否存在目录 -e和!-e用来判断是否存在文件或目录 -x和!-x用来判断文件是否可执行\n例如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 if ($http_user_agent ~ MSIE) { rewrite ^(.*)$ /msie/$1 break; } //如果UA包含\u0026#34;MSIE\u0026#34;，rewrite请求到/msid/目录下 if ($http_cookie ~* \u0026#34;id=([^;]+)(?:;|$)\u0026#34;) { set $id $1; } //如果cookie匹配正则，设置变量$id等于正则引用部分 if ($request_method = POST) { return 405; } //如果提交方法为POST，则返回状态405（Method not allowed）。return不能返回301,302 if ($slow) { limit_rate 10k; } //限速，$slow可以通过 set 指令设置 if (!-f $request_filename){ break; proxy_pass http://127.0.0.1; } //如果请求的文件名不存在，则反向代理到localhost 。这里的break也是停止rewrite检查 if ($args ~ post=140){ rewrite ^ http://example.com/ permanent; } //如果query string中包含\u0026#34;post=140\u0026#34;，永久重定向到example.com location ~* \\.(gif|jpg|png|swf|flv)$ { valid_referers none blocked www.jefflei.com www.leizhenfang.com; if ($invalid_referer) { return 404; } //防盗链 } 全局变量 下面是可以用作if判断的全局变量\n$args ： #这个变量等于请求行中的参数，同$query_string $content_length ： 请求头中的Content-length字段。 $content_type ： 请求头中的Content-Type字段。 $document_root ： 当前请求在root指令中指定的值。 $host ： 请求主机头字段，否则为服务器名称。 $http_user_agent ： 客户端agent信息 $http_cookie ： 客户端cookie信息 $limit_rate ： 这个变量可以限制连接速率。 $request_method ： 客户端请求的动作，通常为GET或POST。 $remote_addr ： 客户端的IP地址。 $remote_port ： 客户端的端口。 $remote_user ： 已经经过Auth Basic Module验证的用户名。 $request_filename ： 当前请求的文件路径，由root或alias指令与URI请求生成。 $scheme ： HTTP方法（如http，https）。 $server_protocol ： 请求使用的协议，通常是HTTP/1.0或HTTP/1.1。 $server_addr ： 服务器地址，在完成一次系统调用后可以确定这个值。 $server_name ： 服务器名称。 $server_port ： 请求到达服务器的端口号。 $request_uri ： 包含请求参数的原始URI，不包含主机名，如：”/foo/bar.php?arg=baz”。 $uri ： 不带请求参数的当前URI，$uri不包含主机名，如”/foo/bar.html”。 $document_uri ： 与$uri相同。 例：http://localhost:88/test1/test2/test.php $host：localhost $server_port：88 $request_uri：http://localhost:88/test1/test2/test.php $document_uri：/test1/test2/test.php $document_root：/var/www/html $request_filename：/var/www/html/test1/test2/test.php\n2.3 常用正则 . ： 匹配除换行符以外的任意字符 ? ： 重复0次或1次 + ： 重复1次或更多次 * ： 重复0次或更多次 \\d ：匹配数字 ^ ： 匹配字符串的开始 $ ： 匹配字符串的介绍 {n} ： 重复n次 {n,} ： 重复n次或更多次 [c] ： 匹配单个字符c [a-z] ： 匹配a-z小写字母的任意一个 小括号()之间匹配的内容，可以在后面通过$1来引用，$2表示的是前面第二个()里的内容。正则里面容易让人困惑的是\\转义特殊字符。\n2.4 rewrite实例 例1：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 http { # 定义image日志格式 log_format imagelog \u0026#39;[$time_local] \u0026#39; $image_file \u0026#39; \u0026#39; $image_type \u0026#39; \u0026#39; $body_bytes_sent \u0026#39; \u0026#39; $status; # 开启重写日志 rewrite_log on; server { root /home/www; location / { # 重写规则信息 error_log logs/rewrite.log notice; # 注意这里要用‘’单引号引起来，避免{} rewrite \u0026#39;^/images/([a-z]{2})/([a-z0-9]{5})/(.*)\\.(png|jpg|gif)$\u0026#39; /data?file=$3.$4; # 注意不能在上面这条规则后面加上“last”参数，否则下面的set指令不会执行 set $image_file $3; set $image_type $4; } location /data { # 指定针对图片的日志格式，来分析图片类型和大小 access_log logs/images.log mian; root /data/images; # 应用前面定义的变量。判断首先文件在不在，不在再判断目录在不在，如果还不在就跳转到最后一个url里 try_files /$arg_file /image404.html; } location = /image404.html { # 图片不存在返回特定的信息 return 404 \u0026#34;image not found\\n\u0026#34;; } } 对形如/images/ef/uh7b3/test.png的请求，重写到/data?file=test.png，于是匹配到location /data，先看/data/images/test.png文件存不存在，如果存在则正常响应，如果不存在则重写tryfiles到新的image404 location，直接返回404状态码。\n例2：\n1 rewrite ^/images/(.*)_(\\d+)x(\\d+)\\.(png|jpg|gif)$ /resizer/$1.$4?width=$2\u0026amp;height=$3? last; 对形如/images/bla_500x400.jpg的文件请求，重写到/resizer/bla.jpg?width=500\u0026amp;height=400地址，并会继续尝试匹配location。\n例3： 见 ssl部分页面加密 。\n参考\nhttp://www.nginx.cn/216.html http://www.ttlsa.com/nginx/nginx-rewriting-rules-guide/ 老僧系列nginx之rewrite规则快速上手 http://fantefei.blog.51cto.com/2229719/919431 ","permalink":"http://localhost:1313/2015/05/nginx-location-rewrite/","summary":"\u003ch1 id=\"1-location正则写法\"\u003e1. location正则写法\u003c/h1\u003e\n\u003cp\u003e一个示例：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e 1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 7\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 8\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 9\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e10\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e11\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e12\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e13\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e14\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e15\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e16\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e17\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e18\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e19\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e20\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e21\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e22\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e23\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e24\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e25\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e26\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e27\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e28\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e29\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e30\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e31\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e32\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e33\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e34\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e35\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e36\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e37\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e38\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e39\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e40\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e41\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e42\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e43\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e44\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e45\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e46\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e47\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e48\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e49\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e50\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e51\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-fallback\" data-lang=\"fallback\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003elocation  = / {\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  # 精确匹配 / ，主机名后面不能带任何字符串\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  [ configuration A ]\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003elocation  / {\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  # 因为所有的地址都以 / 开头，所以这条规则将匹配到所有请求\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  # 但是正则和最长字符串会优先匹配\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  [ configuration B ]\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003elocation /documents/ {\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  # 匹配任何以 /documents/ 开头的地址，匹配符合以后，还要继续往下搜索\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  # 只有后面的正则表达式没有匹配到时，这一条才会采用这一条\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  [ configuration C ]\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003elocation ~ /documents/Abc {\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  # 匹配任何以 /documents/Abc 开头的地址，匹配符合以后，还要继续往下搜索\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  # 只有后面的正则表达式没有匹配到时，这一条才会采用这一条\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  [ configuration CC ]\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003elocation ^~ /images/ {\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  # 匹配任何以 /images/ 开头的地址，匹配符合以后，停止往下搜索正则，采用这一条。\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  [ configuration D ]\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003elocation ~* \\.(gif|jpg|jpeg)$ {\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  # 匹配所有以 gif,jpg或jpeg 结尾的请求\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  # 然而，所有请求 /images/ 下的图片会被 config D 处理，因为 ^~ 到达不了这一条正则\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  [ configuration E ]\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003elocation /images/ {\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  # 字符匹配到 /images/，继续往下，会发现 ^~ 存在\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  [ configuration F ]\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003elocation /images/abc {\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  # 最长字符匹配到 /images/abc，继续往下，会发现 ^~ 存在\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  # F与G的放置顺序是没有关系的\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  [ configuration G ]\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003elocation ~ /images/abc/ {\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e  # 只有去掉 config D 才有效：先最长匹配 config G 开头的地址，继续往下搜索，匹配到这一条正则，采用\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e    [ configuration H ]\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003elocation ~* /js/.*/\\.js\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cul\u003e\n\u003cli\u003e已\u003ccode\u003e=\u003c/code\u003e开头表示精确匹配\n如 A 中只匹配根目录结尾的请求，后面不能带任何字符串。\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e^~\u003c/code\u003e 开头表示uri以某个常规字符串开头，不是正则匹配\u003c/li\u003e\n\u003cli\u003e~ 开头表示区分大小写的正则匹配;\u003c/li\u003e\n\u003cli\u003e~* 开头表示不区分大小写的正则匹配\u003c/li\u003e\n\u003cli\u003e/ 通用匹配, 如果没有其它匹配,任何请求都会匹配到\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e顺序 no优先级：\n(location =) \u0026gt; (location 完整路径) \u0026gt; (location ^~ 路径) \u0026gt; (location \u003cdel\u003e,\u003c/del\u003e* 正则顺序) \u0026gt; (location 部分起始路径) \u0026gt; (/)\u003c/p\u003e","title":"nginx配置location总结及rewrite规则写法"},{"content":"nginx在工作中已经有好几个环境在使用了，每次都是重新去网上扒博客，各种编译配置，今天自己也整理一份安装文档和nginx.conf配置选项的说明，留作以后参考。像负载均衡配置（包括健康检查）、缓存（包括清空缓存）配置实例，请参考 http://xgknight.com/2015/05/17/nginx-install-and-config ，ssl加密请参考 http://xgknight.com/2015/05/28/nginx-ssl/ 。\n1. 安装nginx 1.1 选择稳定版本 我们编译安装nginx来定制自己的模块，机器CentOS 6.2 x86_64。首先安装缺少的依赖包：\n1 # yum -y install gcc gcc-c++ make libtool zlib zlib-devel openssl openssl-devel pcre pcre-devel 这些软件包如果yum上没有的话可以下载源码来编译安装，只是要注意编译时默认安装的目录，确保下面在安装nginx时能够找到这些动态库文件（ldconfig）。\n从 http://nginx.org/en/download.html 下载稳定版nginx-1.6.3.tar.gz到/usr/local/src下解压。\n为了后续准备我们另外下载2个插件模块：nginx_upstream_check_module-0.3.0.tar.gz —— 检查后端服务器的状态，nginx-goodies-nginx-sticky-module-ng-bd312d586752.tar.gz（建议在/usr/local/src下解压后将目录重命名为nginx-sticky-module-ng-1.2.5） —— 后端做负载均衡解决session sticky问题（与upstream_check模块结合使用需要另外打补丁，请参考nginx负载均衡配置实战）。\n请注意插件与nginx的版本兼容问题，一般插件越新越好，nginx不用追新，稳定第一。nginx-1.4.7，nginx-sticky-module-1.1，nginx_upstream_check_module-0.2.0，这个搭配也没问题。sticky-1.1与nginx-1.6版本由于更新没跟上编译出错。（可以直接使用Tengine，默认就包括了这些模块）\n1 2 3 4 5 6 7 8 [root@cachets nginx-1.6.3]# pwd /usr/local/src/nginx-1.6.3 [root@cachets nginx-1.6.3]# ./configure --prefix=/usr/local/nginx-1.6 --with-pcre \\ \u0026gt; --with-http_stub_status_module --with-http_ssl_module \\ \u0026gt; --with-http_gzip_static_module --with-http_realip_module \\ \u0026gt; --add-module=../nginx_upstream_check_module-0.3.0 [root@cachets nginx-1.6.3]# make \u0026amp;\u0026amp; make install 1.2 常用编译选项说明 nginx大部分常用模块，编译时./configure --help以--without开头的都默认安装。\n--prefix=PATH ： 指定nginx的安装目录。默认 /usr/local/nginx --conf-path=PATH ： 设置nginx.conf配置文件的路径。nginx允许使用不同的配置文件启动，通过命令行中的-c选项。默认为prefix/conf/nginx.conf --user=name： 设置nginx工作进程的用户。安装完成后，可以随时在nginx.conf配置文件更改user指令。默认的用户名是nobody。--group=name类似 --with-pcre ： 设置PCRE库的源码路径，如果已通过yum方式安装，使用--with-pcre自动找到库文件。使用--with-pcre=PATH时，需要从PCRE网站下载pcre库的源码（版本4.4 - 8.30）并解压，剩下的就交给Nginx的./configure和make来完成。perl正则表达式使用在location指令和 ngx_http_rewrite_module模块中。 --with-zlib=PATH ： 指定 zlib（版本1.1.3 - 1.2.5）的源码解压目录。在默认就启用的网络传输压缩模块ngx_http_gzip_module时需要使用zlib 。 --with-http_ssl_module ： 使用https协议模块。默认情况下，该模块没有被构建。前提是openssl与openssl-devel已安装 --with-http_stub_status_module ： 用来监控 Nginx 的当前状态 --with-http_realip_module ： 通过这个模块允许我们改变客户端请求头中客户端IP地址值(例如X-Real-IP 或 X-Forwarded-For)，意义在于能够使得后台服务器记录原始客户端的IP地址 --add-module=PATH ： 添加第三方外部模块，如nginx-sticky-module-ng或缓存模块。每次添加新的模块都要重新编译（Tengine可以在新加入module时无需重新编译） 再提供一种编译方案：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ./configure \\ \u0026gt; --prefix=/usr \\ \u0026gt; --sbin-path=/usr/sbin/nginx \\ \u0026gt; --conf-path=/etc/nginx/nginx.conf \\ \u0026gt; --error-log-path=/var/log/nginx/error.log \\ \u0026gt; --http-log-path=/var/log/nginx/access.log \\ \u0026gt; --pid-path=/var/run/nginx/nginx.pid \\ \u0026gt; --lock-path=/var/lock/nginx.lock \\ \u0026gt; --user=nginx \\ \u0026gt; --group=nginx \\ \u0026gt; --with-http_ssl_module \\ \u0026gt; --with-http_stub_status_module \\ \u0026gt; --with-http_gzip_static_module \\ \u0026gt; --http-client-body-temp-path=/var/tmp/nginx/client/ \\ \u0026gt; --http-proxy-temp-path=/var/tmp/nginx/proxy/ \\ \u0026gt; --http-fastcgi-temp-path=/var/tmp/nginx/fcgi/ \\ \u0026gt; --http-uwsgi-temp-path=/var/tmp/nginx/uwsgi \\ \u0026gt; --with-pcre=../pcre-7.8 \u0026gt; --with-zlib=../zlib-1.2.3 1.3 启动关闭nginx 1 2 3 4 5 6 7 8 9 10 11 12 ## 检查配置文件是否正确 # /usr/local/nginx-1.6/sbin/nginx -t # ./sbin/nginx -V # 可以看到编译选项 ## 启动、关闭 # ./sbin/nginx # 默认配置文件 conf/nginx.conf，-c 指定 # ./sbin/nginx -s stop 或 pkill nginx ## 重启，不会改变启动时指定的配置文件 # ./sbin/nginx -s reload 或 kill -HUP `cat /usr/local/nginx-1.6/logs/nginx.pid` 当然也可以将 nginx 作为系统服务管理，下载 nginx 到/etc/init.d/，修改里面的路径然后赋予可执行权限。\n1 # service nginx {start|stop|status|restart|reload|configtest} 1.4 yum安装 \u0026mdash;- 2015-05-22更新 yum安装rpm包会比编译安装简单很多，默认会安装许多模块，但缺点是如果你想以后安装第三方模块那就没办法了。\n1 2 3 4 5 6 # vi /etc/yum.repo.d/nginx.repo [nginx] name=nginx repo baseurl=http://nginx.org/packages/centos/$releasever/$basearch/ gpgcheck=0 enabled=1 剩下的就yum install nginx搞定，也可以yum install nginx-1.6.3安装指定版本（前提是你去packages里看到有对应的版本，默认是最新版稳定版）。\n2. nginx.conf配置文件 Nginx配置文件主要分成四部分：main（全局设置）、server（主机设置）、upstream（上游服务器设置，主要为反向代理、负载均衡相关配置）和 location（URL匹配特定位置后的设置），每部分包含若干个指令。main部分设置的指令将影响其它所有部分的设置；server部分的指令主要用于指定虚拟主机域名、IP和端口；upstream的指令用于设置一系列的后端服务器，设置反向代理及后端服务器的负载均衡；location部分用于匹配网页位置（比如，根目录“/”,“/images”,等等）。他们之间的关系式：server继承main，location继承server；upstream既不会继承指令也不会被继承。它有自己的特殊指令，不需要在其他地方的应用。\n当前nginx支持的几个指令上下文：\n2.1 通用 下面的nginx.conf简单的实现nginx在前端做反向代理服务器的例子，处理js、png等静态文件，jsp等动态请求转发到其它服务器tomcat：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 user www www; worker_processes 2; error_log logs/error.log; #error_log logs/error.log notice; #error_log logs/error.log info; pid logs/nginx.pid; events { use epoll; worker_connections 2048; } http { include mime.types; default_type application/octet-stream; #log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; # \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; # \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; #access_log logs/access.log main; sendfile on; # tcp_nopush on; keepalive_timeout 65; # gzip压缩功能设置 gzip on; gzip_min_length 1k; gzip_buffers 4 16k; gzip_http_version 1.0; gzip_comp_level 6; gzip_types text/html text/plain text/css text/javascript application/json application/javascript application/x-javascript application/xml; gzip_vary on; # http_proxy 设置 client_max_body_size 10m; client_body_buffer_size 128k; proxy_connect_timeout 75; proxy_send_timeout 75; proxy_read_timeout 75; proxy_buffer_size 4k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; proxy_temp_file_write_size 64k; proxy_temp_path /usr/local/nginx/proxy_temp 1 2; # 设定负载均衡后台服务器列表 upstream backend { #ip_hash; server 192.168.10.100:8080 max_fails=2 fail_timeout=30s ; server 192.168.10.101:8080 max_fails=2 fail_timeout=30s ; } # 很重要的虚拟主机配置 server { listen 80; server_name itoatest.example.com; root /apps/oaapp; charset utf-8; access_log logs/host.access.log main; #对 / 所有做负载均衡+反向代理 location / { root /apps/oaapp; index index.jsp index.html index.htm; proxy_pass http://backend; proxy_redirect off; # 后端的Web服务器可以通过X-Forwarded-For获取用户真实IP proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504; } #静态文件，nginx自己处理，不去backend请求tomcat location ~* /download/ { root /apps/oa/fs; } location ~ .*\\.(gif|jpg|jpeg|bmp|png|ico|txt|js|css)$ { root /apps/oaapp; expires 7d; } location /nginx_status { stub_status on; access_log off; allow 192.168.10.0/24; deny all; } location ~ ^/(WEB-INF)/ { deny all; } #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } ## 其它虚拟主机，server 指令开始 } 2.2 常用指令说明 2.2.1 main全局配置 nginx在运行时与具体业务功能（比如http服务或者email服务代理）无关的一些参数，比如工作进程数，运行的身份等。\nwoker_processes 2 在配置文件的顶级main部分，worker角色的工作进程的个数，master进程是接收并分配请求给worker处理。这个数值简单一点可以设置为cpu的核数grep ^processor /proc/cpuinfo | wc -l，也是 auto 值，如果开启了ssl和gzip更应该设置成与逻辑CPU数量一样甚至为2倍，可以减少I/O操作。如果nginx服务器还有其它服务，可以考虑适当减少。\nworker_cpu_affinity 也是写在main部分。在高并发情况下，通过设置cpu粘性来降低由于多CPU核切换造成的寄存器等现场重建带来的性能损耗。如worker_cpu_affinity 0001 0010 0100 1000; （四核）。\nworker_connections 2048 写在events部分。每一个worker进程能并发处理（发起）的最大连接数（包含与客户端或后端被代理服务器间等所有连接数）。nginx作为反向代理服务器，计算公式 最大连接数 = worker_processes * worker_connections/4，所以这里客户端最大连接数是1024，这个可以增到到8192都没关系，看情况而定，但不能超过后面的worker_rlimit_nofile。当nginx作为http服务器时，计算公式里面是除以2。\nworker_rlimit_nofile 10240 写在main部分。默认是没有设置，可以限制为操作系统最大的限制65535。\nuse epoll 写在events部分。在Linux操作系统下，nginx默认使用epoll事件模型，得益于此，nginx在Linux操作系统下效率相当高。同时Nginx在OpenBSD或FreeBSD操作系统上采用类似于epoll的高效事件模型kqueue。在操作系统不支持这些高效模型时才使用select。\n2.2.2 http服务器 与提供http服务相关的一些配置参数。例如：是否使用keepalive啊，是否使用gzip进行压缩等。\nsendfile on 开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，减少用户空间到内核空间的上下文切换。对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。\nkeepalive_timeout 65 : 长连接超时时间，单位是秒，这个参数很敏感，涉及浏览器的种类、后端服务器的超时设置、操作系统的设置，可以另外起一片文章了。长连接请求大量小文件的时候，可以减少重建连接的开销，但假如有大文件上传，65s内没上传完成会导致失败。如果设置时间过长，用户又多，长时间保持连接会占用大量资源。\nsend_timeout : 用于指定响应客户端的超时时间。这个超时仅限于两个连接活动之间的时间，如果超过这个时间，客户端没有任何活动，Nginx将会关闭连接。\nclient_max_body_size 10m 允许客户端请求的最大单文件字节数。如果有上传较大文件，请设置它的限制值\nclient_body_buffer_size 128k 缓冲区代理缓冲用户端请求的最大字节数\n模块http_proxy： 这个模块实现的是nginx作为反向代理服务器的功能，包括缓存功能（另见文章）\nproxy_connect_timeout 60 nginx跟后端服务器连接超时时间(代理连接超时)\nproxy_read_timeout 60 连接成功后，与后端服务器两个成功的响应操作之间超时时间(代理接收超时)\nproxy_buffer_size 4k 设置代理服务器（nginx）从后端realserver读取并保存用户头信息的缓冲区大小，默认与proxy_buffers大小相同，其实可以将这个指令值设的小一点\nproxy_buffers 4 32k proxy_buffers缓冲区，nginx针对单个连接缓存来自后端realserver的响应，网页平均在32k以下的话，这样设置\nproxy_busy_buffers_size 64k 高负荷下缓冲大小（proxy_buffers*2）\nproxy_max_temp_file_size 当 proxy_buffers 放不下后端服务器的响应内容时，会将一部分保存到硬盘的临时文件中，这个值用来设置最大临时文件大小，默认1024M，它与 proxy_cache 没有关系。大于这个值，将从upstream服务器传回。设置为0禁用。\nproxy_temp_file_write_size 64k 当缓存被代理的服务器响应到临时文件时，这个选项限制每次写临时文件的大小。proxy_temp_path （可以在编译的时候）指定写到哪那个目录。\nproxy_pass，proxy_redirect见 location 部分。\n模块http_gzip：\ngzip on : 开启gzip压缩输出，减少网络传输。 gzip_min_length 1k ： 设置允许压缩的页面最小字节数，页面字节数从header头得content-length中进行获取。默认值是20。建议设置成大于1k的字节数，小于1k可能会越压越大。 gzip_buffers 4 16k ： 设置系统获取几个单位的缓存用于存储gzip的压缩结果数据流。4 16k代表以16k为单位，安装原始数据大小以16k为单位的4倍申请内存。 gzip_http_version 1.0 ： 用于识别 http 协议的版本，早期的浏览器不支持 Gzip 压缩，用户就会看到乱码，所以为了支持前期版本加上了这个选项，如果你用了 Nginx 的反向代理并期望也启用 Gzip 压缩的话，由于末端通信是 http/1.0，故请设置为 1.0。 gzip_comp_level 6 ： gzip压缩比，1压缩比最小处理速度最快，9压缩比最大但处理速度最慢(传输快但比较消耗cpu) gzip_types ：匹配mime类型进行压缩，无论是否指定,”text/html”类型总是会被压缩的。 gzip_proxied any ： Nginx作为反向代理的时候启用，决定开启或者关闭后端服务器返回的结果是否压缩，匹配的前提是后端服务器必须要返回包含”Via”的 header头。 gzip_vary on ： 和http头有关系，会在响应头加个 Vary: Accept-Encoding ，可以让前端的缓存服务器缓存经过gzip压缩的页面，例如，用Squid缓存经过Nginx压缩的数据。。 2.2.3 server虚拟主机 http服务上支持若干虚拟主机。每个虚拟主机一个对应的server配置项，配置项里面包含该虚拟主机相关的配置。在提供mail服务的代理时，也可以建立若干server。每个server通过监听地址或端口来区分。\nlisten 监听端口，默认80，小于1024的要以root启动。可以为listen *:80、listen 127.0.0.1:80等形式。\nserver_name 服务器名，如localhost、www.example.com，可以通过正则匹配。\n模块http_stream 这个模块通过一个简单的调度算法来实现客户端IP到后端服务器的负载均衡，upstream后接负载均衡器的名字，后端realserver以 host:port options; 方式组织在 {} 中。如果后端被代理的只有一台，也可以直接写在 proxy_pass 。\n2.2.4 location http服务中，某些特定的URL对应的一系列配置项。\nroot /var/www/html 定义服务器的默认网站根目录位置。如果locationURL匹配的是子目录或文件，root没什么作用，一般放在server指令里面或/下。\nindex index.jsp index.html index.htm 定义路径下默认访问的文件名，一般跟着root放\nproxy_pass http:/backend 请求转向backend定义的服务器列表，即反向代理，对应upstream负载均衡器。也可以proxy_pass http://ip:port。\nproxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 这四个暂且这样设，如果深究的话，每一个都涉及到很复杂的内容，也将通过另一篇文章来解读。\n关于location匹配规则的写法，可以说尤为关键且基础的，参考文章 nginx配置location总结及rewrite规则写法;\n2.3 其它 2.3.1 访问控制 allow/deny Nginx 的访问控制模块默认就会安装，而且写法也非常简单，可以分别有多个allow,deny，允许或禁止某个ip或ip段访问，依次满足任何一个规则就停止往下匹配。如：\n1 2 3 4 5 6 7 8 9 10 location /nginx-status { stub_status on; access_log off; # auth_basic \u0026#34;NginxStatus\u0026#34;; # auth_basic_user_file /usr/local/nginx-1.6/htpasswd; allow 192.168.10.100; allow 172.29.73.0/24; deny all; } 我们也常用 httpd-devel 工具的 htpasswd 来为访问的路径设置登录密码：\n1 2 3 4 5 6 7 # htpasswd -c htpasswd admin New passwd: Re-type new password: Adding password for user admin # htpasswd htpasswd admin //修改admin密码 # htpasswd htpasswd sean //多添加一个认证用户 这样就生成了默认使用CRYPT加密的密码文件。打开上面nginx-status的两行注释，重启nginx生效。\n2.3.2 列出目录 autoindex Nginx默认是不允许列出整个目录的。如需此功能，打开nginx.conf文件，在location，server 或 http段中加入autoindex on;，另外两个参数最好也加上去:\nautoindex_exact_size off; 默认为on，显示出文件的确切大小，单位是bytes。改为off后，显示出文件的大概大小，单位是kB或者MB或者GB autoindex_localtime on; 默认为off，显示的文件时间为GMT时间。改为on后，显示的文件时间为文件的服务器时间 1 2 3 4 5 6 location /images { root /var/www/nginx-default/images; autoindex on; autoindex_exact_size off; autoindex_localtime on; } 参考\nhttp://liuqunying.blog.51cto.com/3984207/1420556 http://nginx.org/en/docs/ngx_core_module.html#worker_cpu_affinity http://wiki.nginx.org/HttpCoreModule#sendfile ","permalink":"http://localhost:1313/2015/05/nginx-install-and-config/","summary":"\u003cp\u003enginx在工作中已经有好几个环境在使用了，每次都是重新去网上扒博客，各种编译配置，今天自己也整理一份安装文档和nginx.conf配置选项的说明，留作以后参考。像负载均衡配置（包括健康检查）、缓存（包括清空缓存）配置实例，请参考 \u003ca href=\"http://xgknight.com/2015/05/17/nginx-install-and-config\"\u003ehttp://xgknight.com/2015/05/17/nginx-install-and-config\u003c/a\u003e ，ssl加密请参考 \u003ca href=\"http://xgknight.com/2015/05/28/nginx-ssl/\"\u003ehttp://xgknight.com/2015/05/28/nginx-ssl/\u003c/a\u003e 。\u003c/p\u003e","title":"nginx服务器安装及配置文件详解"},{"content":"在公司OA和CRM系统遇到要实现在线查看word/jpg等文件的功能，按照开发小组的要求搭建了一套解决方案：OpenOffice + JodConvertor + SWFTool+ FlexPaper，其中OpenOffice + JodConvertor用于将文档转化为PDF格式文档，SwfTool用于将PDF转化为SWF文档，FlexPaper用于展示。使用这个解决方案的最大好处就是跨平台且较为简单。\n1.1 安装openoffice openoffice需要jdk的支持，而且默认已经安装，如果没有，手动下载Apache_OpenOffice_4.0.1_Linux_x86-64_install-rpm_zh-CN.tar.gz到/usr/local/src（CentOS 6.4 x86_64）：\n1 2 3 # tar -zxf Apache_OpenOffice_4.0.1_Linux_x86-64_install-rpm_zh-CN.tar.gz # cd zh-CN/RPMS # rpm –ivh *.rpm 拷贝字体 安装完成后把windows（c:\\windows\\fonts）下的一些常用字体拷贝到 /opt/openoffice4/share/fonts/truetype 目录下，如Arial, Calibri, Courier New, Consolas等，如果你想正确的保留原doc的中文字体，还需要把 黑体、微软雅黑、宋体 常规、新宋体 常规、幼圆、隶书、楷体 等中文字体拷贝进去（重启进程后生效）。\n启动后台进程 切换至普通用户，如wxcrm启动转换进程：\n1 2 3 $ /opt/openoffice4/program/soffice -headless -accept=\u0026#34;socket,host=127.0.0.1,port=8100;urp;\u0026#34; -nofirststartwizard \u0026amp; # ps –ef | grep soffice 1.2 解压jodconverter JODConverter是一个java的OpenDucument文件转换器，可以进行许多文件格式的转换工具，它利用OpenOffice来进行转换工作，它能完成以下转换：\nMicrosoft Office格式转换为OpenDucument，以及OpenDucument转换为Microsoft Office OpenDucument转换为PDF，Word、Excel、PowerPoint转换为PDF，RTF转换为PDF等。 从 http://sourceforge.net/projects/jodconverter/files/JODConverter/2.2.2/ 下载jodconverter-2.2.2.zip解压到 /opt 目录下/opt/jodconverter-2.2.2/。手动转换测试，使用到的文件是安装包内的lib/jodconverter-cli-2.2.2.jar：\n1 java -jar /opt/jodconverter-2.2.2/lib/jodconverter-cli-2.2.2.jar /home/oa/docker.docx /home/oa/docker.pdf 至此doc等文件格式可以成功转换成pdf。\n2.1 swftool swftool可以将pdf/jpg等转换成swf格式。搜索下载swftools-0.9.1.tar.gz（0.9.2在安装时可能需要错误处理）：\n1 2 3 4 5 6 # yum install gcc* automake zlib-devel libjpeg-devel giflib-devel freetype-devel # tar vxzf swftools-0.9.1.tar.gz # cd swftools-0.9.1 # ./configure --prefix=/usr/local/swftools # make \u0026amp;\u0026amp; make install 至此已安装完预览功能，可以通过：\n1 /usr/local/bin/pdf2swf -t docker4.pdf -o docker4.swf -T 9 -f -z 测试转换。-t 后接待转换的pdf文件路径，-o接输出文件路径和名称，-T 9 设置使用flash版本9，这个设置主要是为了跟FlexPaper的版本对应； -f 保留字体，-z使用zlib进行压缩，这是最常用的几个命令，其他命令可以从SWF官网了解。\n2.2 安装xpdf语言包 在转换包含中文的PDF文档成swf时，常常会因为缺少所需的字体而出现乱码，或者干脆就没有文字，就需要使用到xpdf的字体库。 到 http://www.foolabs.com/xpdf/download.html 下载xpdf-chinese-simplified.tar.gz，解压到/usr/local下，编辑add-to-xpdfrc文件，如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 # vi /usr/local/xpdf-chinese-simplified/add-to-xpdfrc #----- begin Chinese Simplified support package (2011-sep-02) cidToUnicode Adobe-GB1 /usr/local/xpdf-chinese-simplified/Adobe-GB1.cidToUnicode unicodeMap ISO-2022-CN /usr/local/xpdf-chinese-simplified/ISO-2022-CN.unicodeMap unicodeMap EUC-CN /usr/local/xpdf-chinese-simplified/EUC-CN.unicodeMap unicodeMap GBK /usr/local/xpdf-chinese-simplified/GBK.unicodeMap cMapDir Adobe-GB1 /usr/local/xpdf-chinese-simplified/CMap toUnicodeDir /usr/local/xpdf-chinese-simplified/CMap fontDir /usr/share/fonts/win displayCIDFontTT Adobe-GB1 /usr/share/fonts/win/SIMHEI.ttf displayCIDFontTT Adobe-GB1 /usr/local/xpdf-chinese-simplified/CMap/gbsn00lp.ttf displayCIDFontTT Adobe-GB1 /usr/local/xpdf-chinese-simplified/CMap/gkai00mp.ttf 可以使用xftp将常用的中文字体上传到/usr/share/fonts/win，如宋体、微软雅黑、黑体、楷体等。另外去 网上下载 gkai00mp.ttf、gbsn00lp.ttf简体中文放到上面正确的路径下，参考http://shitouququ.blog.51cto.com/24569/1252930。\n转换时加上-s languagedir=/usr/local/xpdf-chinese-simplified/来加载语言包路径。\n另外据同事说在 windows 平台安装和转换效果会好一点，没有验证。\n参考\nlinux安装openoffice与SWFtools工具 仿豆丁网在线浏览文件方案openoffice.org 3+swftools+flexpaper swftools Installation ","permalink":"http://localhost:1313/2015/05/pdf2swf-preview/","summary":"\u003cp\u003e在公司OA和CRM系统遇到要实现在线查看word/jpg等文件的功能，按照开发小组的要求搭建了一套解决方案：OpenOffice + JodConvertor  + SWFTool+ FlexPaper，其中OpenOffice + JodConvertor用于将文档转化为PDF格式文档，SwfTool用于将PDF转化为SWF文档，FlexPaper用于展示。使用这个解决方案的最大好处就是跨平台且较为简单。\u003c/p\u003e","title":"仿豆丁网文件在线浏览解决方案搭建"},{"content":"1. 几大实时同步工具比较 1.1 inotify + rsync 最近一直在寻求生产服务服务器上的同步替代方案，原先使用的是inotify + rsync，但随着文件数量的增大到100W+，目录下的文件列表就达20M，在网络状况不佳或者限速的情况下，变更的文件可能10来个才几M，却因此要发送的文件列表就达20M，严重减低的带宽的使用效率以及同步效率；更为要紧的是，加入inotifywait在5s内监控到10个小文件发生变化，便会触发10个rsync同步操作，结果就是真正需要传输的才2-3M的文件，比对的文件列表就达200M。使用这两个组合的好处在于，它们都是最基本的软件，可以通过不同选项做到很精确的控制，比如排除同步的目录，同步多个模块或同步到多个主机。\n搭建过程参考 Linux下同步工具inotify+rsync使用详解 。\n1.2 sersync 后来听同事说 sersync 这么个工具可以提高同步的性能，也解决了同步大文件时出现异常的问题，所以就尝试了一下。sersync是国内的一个开发者开源出来的，使用c++编写，采用多线程的方式进行同步，失败后还有重传机制，对临时文件过滤，自带crontab定时同步功能。网上看到有人说性能还不错，说一下我的观点：\n国产开源，文档不是很全，在2011年之后就没更新了（googlecode都要快关闭了，其实可以转交其他人维护），网上关于它的使用和讨论都止于10年了 采用xml配置文件的方式，可读性比较好，但是有些原生的有些功能没有实现就没法使用了 无法实现多目录同步，只能通过多个配置文件启动多个进程 文件排除功能太弱。这个要看需求，不是每个人都需要排除子目录。而对于我的环境中，这个功能很重要，而且排除的规则较多 虽然提供插件的功能，但很鸡肋，因为软件本身没有持续更新，也没有看到贡献有其它插件出现（可能是我知识面不够，还用不到里面的refreshCDN plugin）。 虽然不懂c++，但大致看了下源码 FileSynchronize，拼接rsync命令大概在273行左右，最后一个函数就是排除选项，简单一点可以将--exclude=改成--eclude-from来灵活控制。有机会再改吧。\n另外，在作者的文章 Sersync服务器同步程序 项目简介与设计框架 评论中，说能解决上面 rsync + inotify中所描述的问题。阅读了下源码，这个应该是没有解决，因为在拼接rsync命令时，后面的目的地址始终是针对module的，只要执行rsync命令，就会对整个目录进行遍历，发送要比对的文件列表，然后再发送变化的文件。sersync只是减少了监听的事件，减少了rsync的次数——这已经是很大的改进，但每次rsync没办法改变。（如有其它看法可与我讨论）\n其实我们也不能要求每一个软件功能都十分健全，关键是看能否满足我们当下的特定的需求。所谓好的架构不是设计出来的，而是进化来的。目前使用sersync2没什么问题，而且看了它的设计思路应该是比较科学的，特别是过滤队列的设计。双向同步看起来也是可以实现。\n1.3 lsyncd 废话说这么多，本文就是介绍它了。有些博客说lsyncd是谷歌开源的，实际不是了，只是托管在了googlecode上而已，幸运的是已经迁移到github了：https://github.com/axkibe/lsyncd 。\nLysncd 实际上是lua语言封装了 inotify 和 rsync 工具，采用了 Linux 内核（2.6.13 及以后）里的 inotify 触发机制，然后通过rsync去差异同步，达到实时的效果。我认为它最令人称道的特性是，完美解决了 inotify + rsync海量文件同步带来的文件频繁发送文件列表的问题 —— 通过时间延迟或累计触发事件次数实现。另外，它的配置方式很简单，lua本身就是一种配置语言，可读性非常强。lsyncd也有多种工作模式可以选择，本地目录cp，本地目录rsync，远程目录rsyncssh。\n实现简单高效的本地目录同步备份（网络存储挂载也当作本地目录），一个命令搞定。\n2. 使用 lsyncd 本地目录实时备份 这一节实现的功能是，本地目录source实时同步到另一个目录target，而在source下有大量的文件，并且有部分目录和临时文件不需要同步。\n2.1 安装lsyncd 安装lsyncd极为简单，已经收录在ubuntu的官方镜像源里，直接通过apt-get install lsyncd就可以。 在Redhat系（我的环境是CentOS 6.2 x86_64 ），可以手动去下载 lsyncd-2.1.5-6.fc21.x86_64.rpm，但首先你得安装两个依赖yum install lua lua-devel。也可以通过在线安装，需要epel-release扩展包：\n1 2 # rpm -ivh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm # yum install lsyncd 源码编译安装 从源码编译安装可以使用最新版的lsyncd程序，但必须要相应的依赖库文件和编译工具：yum install lua lua-devel asciidoc cmake 。\n从 googlecode lsyncd 上下载的lsyncd-2.1.5.tar.gz，直接./configure、make \u0026amp;\u0026amp; make install就可以了。\n从github上下载lsyncd-master.zip 的2.1.5版本使用的是 cmake 编译工具，无法./configure：\n1 2 3 4 # uzip lsyncd-master.zip # cd lsyncd-master # cmake -DCMAKE_INSTALL_PREFIX=/usr/local/lsyncd-2.1.5 # make \u0026amp;\u0026amp; make install 我这个版本编译时有个小bug，如果按照INSTALL在build目录中make，会提示：\n1 2 3 4 5 6 [100%] Generating doc/lsyncd.1 Updating the manpage a2x: failed: source file not found: doc/lsyncd.1.txt make[2]: *** [doc/lsyncd.1] Error 1 make[1]: *** [CMakeFiles/manpage.dir/all] Error 2 make: *** [all] Error 2 解决办法是要么直接在解压目录下cmake，不要mkdir build，要么在CMakeList.txt中搜索doc字符串，在前面加上${PROJECT_SOURCE_DIR}。\n2.2 lsyncd.conf 下面都是在编译安装的情况下操作。\n2.2.1 lsyncd同步配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # cd /usr/local/lsyncd-2.1.5 # mkdir etc var # vi etc/lsyncd.conf settings { logfile =\u0026#34;/usr/local/lsyncd-2.1.5/var/lsyncd.log\u0026#34;, statusFile =\u0026#34;/usr/local/lsyncd-2.1.5/var/lsyncd.status\u0026#34;, inotifyMode = \u0026#34;CloseWrite\u0026#34;, maxProcesses = 7, -- nodaemon =true, } sync { default.rsync, source = \u0026#34;/tmp/src\u0026#34;, target = \u0026#34;/tmp/dest\u0026#34;, -- excludeFrom = \u0026#34;/etc/rsyncd.d/rsync_exclude.lst\u0026#34;, rsync = { binary = \u0026#34;/usr/bin/rsync\u0026#34;, archive = true, compress = true, verbose = true } } 到这启动 lsycnd 就可以完成实时同步了，默认的许多参数可以满足绝大部分需求，非常简单。\n2.2.2 lsyncd.conf配置选项说明 settings 里面是全局设置，--开头表示注释，下面是几个常用选项说明：\nlogfile 定义日志文件 stausFile 定义状态文件 nodaemon=true 表示不启用守护模式，默认 statusInterval 将lsyncd的状态写入上面的statusFile的间隔，默认10秒 inotifyMode 指定inotify监控的事件，默认是CloseWrite，还可以是Modify或CloseWrite or Modify maxProcesses 同步进程的最大个数。假如同时有20个文件需要同步，而maxProcesses = 8，则最大能看到有8个rysnc进程 maxDelays 累计到多少所监控的事件激活一次同步，即使后面的delay延迟时间还未到 sync 里面是定义同步参数，可以继续使用maxDelays来重写settings的全局变量。一般第一个参数指定lsyncd以什么模式运行：rsync、rsyncssh、direct三种模式：\ndefault.rsync ：本地目录间同步，使用rsync，也可以达到使用ssh形式的远程rsync效果，或daemon方式连接远程rsyncd进程； default.direct ：本地目录间同步，使用cp、rm等命令完成差异文件备份； default.rsyncssh ：同步到远程主机目录，rsync的ssh模式，需要使用key来认证\nsource 同步的源目录，使用绝对路径。\ntarget 定义目的地址.对应不同的模式有几种写法： /tmp/dest ：本地目录同步，可用于direct和rsync模式 172.29.88.223:/tmp/dest ：同步到远程服务器目录，可用于rsync和rsyncssh模式，拼接的命令类似于/usr/bin/rsync -ltsd --delete --include-from=- --exclude=* SOURCE TARGET，剩下的就是rsync的内容了，比如指定username，免密码同步 172.29.88.223::module ：同步到远程服务器目录，用于rsync模式 三种模式的示例会在后面给出。\ninit 这是一个优化选项，当init = false，只同步进程启动以后发生改动事件的文件，原有的目录即使有差异也不会同步。默认是true\ndelay 累计事件，等待rsync同步延时时间，默认15秒（最大累计到1000个不可合并的事件）。也就是15s内监控目录下发生的改动，会累积到一次rsync同步，避免过于频繁的同步。（可合并的意思是，15s内两次修改了同一文件，最后只同步最新的文件）\nexcludeFrom 排除选项，后面指定排除的列表文件，如excludeFrom = \u0026quot;/etc/lsyncd.exclude\u0026quot;，如果是简单的排除，可以使用exclude = LIST。 这里的排除规则写法与原生rsync有点不同，更为简单：\n监控路径里的任何部分匹配到一个文本，都会被排除，例如/bin/foo/bar可以匹配规则foo 如果规则以斜线/开头，则从头开始要匹配全部 如果规则以/结尾，则要匹配监控路径的末尾 ?匹配任何字符，但不包括/ *匹配0或多个字符，但不包括/ **匹配0或多个字符，可以是/ delete 为了保持target与souce完全同步，Lsyncd默认会delete = true来允许同步删除。它除了false，还有startup、running值，请参考 Lsyncd 2.1.x ‖ Layer 4 Config ‖ Default Behavior。\nrsync （提示一下，delete和exclude本来都是rsync的选项，上面是配置在sync中的，我想这样做的原因是为了减少rsync的开销）\nbwlimit 限速，单位kb/s，与rsync相同（这么重要的选项在文档里竟然没有标出） compress 压缩传输默认为true。在带宽与cpu负载之间权衡，本地目录同步可以考虑把它设为false perms 默认保留文件权限。 其它rsync的选项 其它还有rsyncssh模式独有的配置项，如host、targetdir、rsync_path、password_file，见后文示例。rsyncOps={\u0026quot;-avz\u0026quot;,\u0026quot;--delete\u0026quot;}这样的写法在2.1.*版本已经不支持。\nlsyncd.conf可以有多个sync，各自的source，各自的target，各自的模式，互不影响。\n2.3 启动lsyncd 使用命令加载配置文件，启动守护进程，自动同步目录操作。\nlsyncd -log Exec /usr/local/lsyncd-2.1.5/etc/lsyncd.conf 2.4 lsyncd.conf其它模式示例 以下配置本人都已经过验证可行，必须根据实际需要裁剪配置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 settings { logfile =\u0026#34;/usr/local/lsyncd-2.1.5/var/lsyncd.log\u0026#34;, statusFile =\u0026#34;/usr/local/lsyncd-2.1.5/var/lsyncd.status\u0026#34;, inotifyMode = \u0026#34;CloseWrite\u0026#34;, maxProcesses = 8, } -- I. 本地目录同步，direct：cp/rm/mv。 适用：500+万文件，变动不大 sync { default.direct, source = \u0026#34;/tmp/src\u0026#34;, target = \u0026#34;/tmp/dest\u0026#34;, delay = 1 maxProcesses = 1 } -- II. 本地目录同步，rsync模式：rsync sync { default.rsync, source = \u0026#34;/tmp/src\u0026#34;, target = \u0026#34;/tmp/dest1\u0026#34;, excludeFrom = \u0026#34;/etc/rsyncd.d/rsync_exclude.lst\u0026#34;, rsync = { binary = \u0026#34;/usr/bin/rsync\u0026#34;, archive = true, compress = true, bwlimit = 2000 } } -- III. 远程目录同步，rsync模式 + rsyncd daemon sync { default.rsync, source = \u0026#34;/tmp/src\u0026#34;, target = \u0026#34;syncuser@172.29.88.223::module1\u0026#34;, delete=\u0026#34;running\u0026#34;, exclude = { \u0026#34;.*\u0026#34;, \u0026#34;.tmp\u0026#34; }, delay = 30, init = false, rsync = { binary = \u0026#34;/usr/bin/rsync\u0026#34;, archive = true, compress = true, verbose = true, password_file = \u0026#34;/etc/rsyncd.d/rsync.pwd\u0026#34;, _extra = {\u0026#34;--bwlimit=200\u0026#34;} } } -- IV. 远程目录同步，rsync模式 + ssh shell sync { default.rsync, source = \u0026#34;/tmp/src\u0026#34;, target = \u0026#34;172.29.88.223:/tmp/dest\u0026#34;, -- target = \u0026#34;root@172.29.88.223:/remote/dest\u0026#34;, -- 上面target，注意如果是普通用户，必须拥有写权限 maxDelays = 5, delay = 30, -- init = true, rsync = { binary = \u0026#34;/usr/bin/rsync\u0026#34;, archive = true, compress = true, bwlimit = 2000 -- rsh = \u0026#34;/usr/bin/ssh -p 22 -o StrictHostKeyChecking=no\u0026#34; -- 如果要指定其它端口，请用上面的rsh } } -- V. 远程目录同步，rsync模式 + rsyncssh，效果与上面相同 sync { default.rsyncssh, source = \u0026#34;/tmp/src2\u0026#34;, host = \u0026#34;172.29.88.223\u0026#34;, targetdir = \u0026#34;/remote/dir\u0026#34;, excludeFrom = \u0026#34;/etc/rsyncd.d/rsync_exclude.lst\u0026#34;, -- maxDelays = 5, delay = 0, -- init = false, rsync = { binary = \u0026#34;/usr/bin/rsync\u0026#34;, archive = true, compress = true, verbose = true, _extra = {\u0026#34;--bwlimit=2000\u0026#34;}, }, ssh = { port = 1234 } } 上面的内容几乎涵盖了所有同步的模式，其中第III个要求像rsync一样配置rsyncd服务端，见本文开头。第IV、V配置ssh方式同步，达到的效果相同，但实际同步时你会发现每次同步都会提示输入ssh的密码，可以通过以下方法解决：\n在远端被同步的服务器上开启ssh无密码登录，请注意用户身份：\n1 2 3 4 user$ ssh-keygen -t rsa 一路回车... user$ cd ~/.ssh user$ cat id_rsa.pub \u0026gt;\u0026gt; authorized_keys 把id_rsa私钥拷贝到执行lsyncd的机器上\n1 2 3 user$ chmod 600 ~/.ssh/id_rsa 测试能否无密码登录 user$ ssh user@172.29.88.223 3. lsyncd的其它功能 lsyncd的功能不仅仅是同步，官方手册 Lsyncd 2.1.x ‖ Layer 2 Config ‖ Advanced onAction 高级功能提到，还可以监控某个目录下的文件，根据触发的事件自己定义要执行的命令，example是监控某个某个目录，只要是有jpg、gif、png格式的文件参数，就把它们转成pdf，然后同步到另一个目录。正好在我运维的一个项目中有这个需求，现在都是在java代码里转换，还容易出现异常，通过lsyncd可以代替这样的功能。但，门槛在于要会一点点lua语言（根据官方example还是可以写出来）。\n另外偶然想到个问题，同时设置了maxDelays和delay，当监控目录一直没有文件变化了，也会发生同步操作，虽然没有可rsync的文件。\nTO-DO：\n其它同步工具：csync2，clsync，btsync，drdb 。 lsyncd双向同步：GlusterFS 参考\nLsyncd21Manual （本文很大一部分翻译自官网手册） 使用lsyncd配置数据库备份多异地同步 如何实时同步大量小文件 Lsyncd 测试远程、本地目录自动同步 ","permalink":"http://localhost:1313/2015/05/lsyncd-synchronize-realtime/","summary":"\u003ch1 id=\"1-几大实时同步工具比较\"\u003e1. 几大实时同步工具比较\u003c/h1\u003e\n\u003ch2 id=\"11-inotify--rsync\"\u003e1.1 inotify + rsync\u003c/h2\u003e\n\u003cp\u003e最近一直在寻求生产服务服务器上的同步替代方案，原先使用的是\u003ccode\u003einotify +  rsync\u003c/code\u003e，但随着文件数量的增大到100W+，目录下的文件列表就达20M，在网络状况不佳或者限速的情况下，变更的文件可能10来个才几M，却因此要发送的文件列表就达20M，严重减低的带宽的使用效率以及同步效率；更为要紧的是，加入inotifywait在5s内监控到10个小文件发生变化，便会触发10个rsync同步操作，结果就是真正需要传输的才2-3M的文件，比对的文件列表就达200M。使用这两个组合的好处在于，它们都是最基本的软件，可以通过不同选项做到很精确的控制，比如排除同步的目录，同步多个模块或同步到多个主机。\u003c/p\u003e","title":"lsyncd实时同步搭建指南——取代rsync+inotify"},{"content":"———————— 只是无聊，轻松的写点东西，在 LOFTER上是不需要写标题的\n失算了，下午四点到了汽车站，没能买到16:10的汽车，最早也要晚上六点到深圳侨社那班。这原本打算七点就可到深圳，淡定的去会展中心吃个饭啥的，说话算数太不好意思了。\n两个小时的等车时间真够无聊的，比在哥哥家里兼工作室要好些。这两天说过来玩，其实也是带任务来的——为哥哥的天猫手表店拍实物图片，借我的MAC一用做背景。我问他卡斯曼、卡西欧官方没给你宝贝图片吗，他说不是，是想拍出自己的特色放在介绍里。千篇一律大家都去旗舰店买了，谁来照顾我们的手表店。想想也是，现在都讲究情怀！看到房间里单反、灯光箱、360度转动盘（不晓得是个什么gui），我几百块的小叶紫檀貔貅手串都派上用场了。看到用心到连饭都没时间煮的份上，我要不要帮忙推广一下呢。\n本来打算是今天早点回深圳，可听他说下午还有几块手表要拍，大概要2个小时，我又怎么能无耻的坚持带走电脑呢。临走的时候，哥跟我在qq上说了一句“大老远让你从深圳跑中山来，也没弄点好吃的（也没带你去珠海玩——自己脑补的），太忙太赶了”。八月份再过来，那时候丽景名筑的房子也装修好了，开个入住仪式。昨天也去新房子看了一眼，线路已经全部埋好了，正在给洗手间做防水测试，厅中间还是一堆沙子，只有天花板刷好了乳石灰。六月份能够装修完成，八月份入住，想想那个时候过去，大飘窗、高低儿童床、乐视tv，比现在这个出租屋要好的多了去。可是，可是，这意味着一个很大的问题，哥哥收入用于装修屋子（简单八万的样子），家里在建的四层楼房怎么办？ 昨天跟家里视频，老爸正在算这一笔账，告诉我个数字，30-40万，毛坯房。现在在农村修个房子（四层可以俯瞰全村了）的成本，差不多可以在中小城市买一个90平的。老一辈人还是希望待在家里吧。鸭梨好大，只能这么形容了。\n终于上车了，迅速占领了一个排前靠窗的位置坐了下来，正准备戴上耳机听听音乐，一个50来岁的中年人来到旁边坐了下来，他太太坐斜对面靠近走廊。然后问我说几号座位，我坐了他位置，原本他跟他太太一起坐。于是我就说现在不都没按位置坐吗，正跟他讨论如果真有人计较这个时，让就让呗，有个年青人人过来指着大叔的位置说这是他位置。好吧既然有人认真了，我就收一收我这“乡下来”的不按座位乘车的土鳖气息，但大叔为什么要骗我他跟他太太是一起的邻座。算了，小事不提，滚到了最后一排48号，还好不是正中间走廊的位置，不然一个急刹车就该跟司机say hi了。\n不确定到深圳的时间，很抱歉。再写眼睛就花了。ps:刚才汽车颠的一下我敢说飞出了一米高。\n——零点更新\n等车2个小时不说，路上竟然堵车，虎门大桥原本20分钟的路程竟然走了一个多小时，到晚上将近十点才落车，下车的地方也真特么偏僻，来回半天都没见着竹子林地铁站，果断叫了个的士，到深大地铁站转地铁。法克，那司机竟给绕，原本走深南大道起步价的路程，省省的开到30块，差评投诉！连翻不顺！洗洗睡。\n","permalink":"http://localhost:1313/2015/05/feel-wuyi-back/","summary":"\u003cp\u003e———————— 只是无聊，轻松的写点东西，在 LOFTER上是不需要写标题的\u003c/p\u003e\n\u003cp\u003e失算了，下午四点到了汽车站，没能买到16:10的汽车，最早也要晚上六点到深圳侨社那班。这原本打算七点就可到深圳，淡定的去会展中心吃个饭啥的，说话算数太不好意思了。\u003c/p\u003e","title":"五一回来了"},{"content":"五一去哪儿，我实在想不到更俗的标题了。去中山。说实在真不想去，我哥非要我带Mac回去让他拍照，给手表做陪衬。ps: 汽车就七个人，车厢也特么烂了，晃晃感觉要散了😳\n反正车上无聊，随便说说什么吧！昨晚，嗯，应该是失眠了。第二天睡到下午起来，窝在家里没事做（早知道就不那么快把《权利的游戏》看完了），五点的时候我竟然跑去公司加班了！\n加班也没做啥事，帮另一个同事调通了一个网络，然后在自己博客上更新了篇文章。赖到将近晚上八点半才走，本想在猫眼买张西乡天虹『左耳』的电影票，但没位置，想到一天没怎么吃饭（在公司吃了几包肉松饼和华夫饼干），在家门口沃尔玛楼下的爱尚堡点了份豪华午餐，坐了半个多小时起身才回去。晚上走在小区了，总有股淡淡的花香，却从来说不出名字，风吹的头发飘起，真的不是一般爽呢。但因为已经有十点多了，还是加快步伐推开了乌漆抹黑的家门，另外两个室友，一个回宜昌老家参加哥哥婚礼去了，一个去了阴盛阳衰的川大同学会。\n虽然今天还要赶车，但早睡这种事情很少发生在我身上。于是打开了电视，体育频道一个人没啥看的，央视一台播放什么劳动光荣的纪录片，五分钟换台了，想想还是去看宣传了很久的芒果台『真正男子汉』。额，杜海涛给我们的笑星形象永远不那么容易消失，这是节目，但也是在军队里，看着他总觉特意的去达到一种节目效果，他来部队参加训练是减肥。王宝强，真是个逗比，在教官检查违禁物品时宝宝那种呆萌老土的模样，笑抽了我，而且在后面打靶时的表现，蛮喜欢他的，他来部队是为了还原『士兵突击』里的许三多形象，想做一名真正的战士，这让我想到了不久前看过吴京的战狼，几次有一种每人都应该去参军的经历。我有个表弟（表哥？），就在去年过年时还跟我一起睡过，五年当兵回来，看他手持真枪的照片，威风凛凛。刘昊然，17岁，想在军队里完成他的成人礼，这名演员以后必火。袁弘，教官说他是一匹还没被驯服的野马，有血性，真男人。郭晓东，40岁的人，有过当兵的经历，可是带病参训，老婆不错😱。张丰毅，将近60岁的人，看过他不少电影，不是折腾，是表率。\n看完已经零点半了，什么，明天（5.2）去中山的东西还没收拾，可怕的拖延症。然后就是下了『澳门风云2』『天将雄狮』在手机上打发车上的时间，给充电宝充电、收拾衣服什么的。到了两点多，躺在床上却睡不着觉，空调开着第二天就闹肚子，不开又微热。眼睛眯着眯着，突然有个想法或想说什么，就打开笔记就记录了下来，好奇怪。其中有一个就是突然有个做APP的点子，想法不错，五一假后再查查资料。\n现在汽车正在路上飞驰，也坐满了人，旁边那个人的肉能不能不要碰我。就这样，再写下去手机电量怕是不足以支撑一部电影了。\n","permalink":"http://localhost:1313/2015/05/feel-wuyi-go/","summary":"\u003cp\u003e五一去哪儿，我实在想不到更俗的标题了。去中山。说实在真不想去，我哥非要我带Mac回去让他拍照，给手表做陪衬。ps: 汽车就七个人，车厢也特么烂了，晃晃感觉要散了😳\u003c/p\u003e","title":"五一去哪儿"},{"content":"本文不介绍iSCSI服务端的搭建过程，不然就会很累赘。主题就是怎么去完成iscsi网络存储的挂载过程，并顺带介绍一些必要的概念。\n1. iscsi介绍与initiator安装 1.1 iSCSI介绍 iSCSI简单来说，就是把SCSI指令通过TCP/IP协议封装起来，在以太网中传输。iSCSI 可以实现在IP网络上传递和运行SCSI协议，使其能够在诸如高速千兆以太网上进行数据存取，实现了数据的网际传递和管理。基于iSCSI建立的存储区域网（SAN）与基于光纤的FC-SAN相比，具有很好的性价比。\niSCSI属于端到端的会话层协议，它定义的是SCSI到TCP/IP的映射（如下图），即Initiator将SCSI指令和数据封装成iSCSI协议数据单元，向下提交给TCP层，最后封装成IP数据包在IP网络上传输，到达Target后通过解封装还原成SCSI指令和数据，再由存储控制器发送到指定的驱动器，从而实现SCSI命令和数据在IP网络上的透明传输。它整合了现有的存储协议SCSI和网络协议TCP/IP，实现了存储与TCP/IP网络的无缝融合。在本文中，将把发起器Initiator称为客户端，将目标器Target称为服务端以方便理解。\niSCSI 服务端和客户端的通讯就是一个在网络上封包和解包的过程，在网络的一端，数据包被封装成包括TCP/IP头、iSCSI 识别包和SCSI 数据三部分内容，传输到网络另一端时，这三部分内容分别被顺序地解开。为了保证安全，iSCSI 有约定操作顺序。在首次运行时，客户端（initiator）设备需要登录到服务端（target）中。任何一个接收到没有执行登录过程的客户端的iSCSI PDU （iSCSI rotocol Data Units，iSCSI 协议数据单元）服务端都将生成一个协议错误，并且关闭连接。在关闭会话之前，服务端可能发送回一个被驳回的iSCSI PDU。\n在工作时，iSCSI使SCSI数据块由原来的SCSI总线连接扩展到internet上，这一过程有些产品通过硬件来实现，这种硬件产品被简称为TOE（TCP Offload Engine），随着近年来服务器芯片技术的不断发展，服务器处理能力日益强劲，目前更为普遍的是通过软件来实现SCSI数据块的封装过程。这种软件通常被称为iSCSI Initiator软件/驱动。Initiator软件可以将以太网卡虚拟为iSCSI卡，接受和发送iSCSI数据报文，通过普通以太网卡来进行网络连接，但是需要占用CPU资源。另外的TOE和HBA连接转换方式都需要专门的硬件设备来完成，虽然相对昂贵但执行效率高，也可以减轻主机CPU的负载。本文客户端采用Initiator驱动的连接方式。\n1.2 Initiator安装 在Linux 2.6内核中提供了iscsi驱动，iSCSI 驱动（driver）使主机拥有了通过IP网络访问存储的能力，但还需要一个具体的客户端工具（Linux用户空间组件）初始化iSCSI驱动，即iscsi-initiator-utils，也是大家常说的open-iscsi。\n1 2 3 4 5 # rpm -qa|grep iscsi iscsi-initiator-utils-6.2.0.873-10.el6.x86_64 iscsi-initiator-utils-devel-6.2.0.873-10.el6.x86_64 # rpm -qi iscsi-initiator-utils （yum install iscsi-initiator-utils iscsi-initiator-utils-devel） 这个安装将iscsid、iscsiadm安装到 /sbin 目录下，它还将把默认的配置文件安装到/etc/iscsi/目录下：\n/etc/iscsi/iscsid.conf：所有刚发起的iSCSI session默认都将使用这个文件中的参数设定。 /etc/iscsi/initiatorname.iscsi：软件iSCSI initiator的intiator名称配置文件。 确保iscsid和iscsi两个服务器开机自启动，chkconfig --list |grep iscsi，在iscsi启动的时候，iscsid和iscsiadm会读取这两个配置文件。\nservice iscsid [status|start] service iscsi status 查看iscisi的信息，只有在连接成功后才输出 这里可能遇到start始终没有启动成功的信息输出，请继续往下执行discovery，一般会启动iscsid。\n1.3 open-iscsi initiator说明 open-iscsi包括两个守护进程iscsid和iscsi，其中iscsid是主进程，iscsi进程则主要负责根据配置在系统启动时进行发起端（Initiator）到服务端（target）的登录，建立发起端与服务端的会话，使主机在启动后即可使用通过iSCSI提供服务的存储设备。\niscsid进程实现iSCSI协议的控制路径以及相关管理功能。例如守护进程（指iscsid）可配置为在系统启动时基于持久化的iSCSI数据库内容，自动重新开始发现（discovery）目标设备。\nOpen-iSCSI是通过以下iSCSI数据库文件来实现永久配置的：\nDiscovery (/var/lib/iscsi/send_targets) 在 /var/lib/iscsi/send_targets 目录下包含iSCSI portals的配置信息，每个portal对应一个文件，文件名为“iSCSI portal IP，端口号”（例如172.29.88.61,3260）。 Node (/var/lib/iscsi/nodes) 在 /var/lib/iscsi/nodes 目录下，生成一个或多个以iSCSI存储服务器上的Target名命名的文件夹如iqn.2000-01.com.synology:themain-3rd.ittest，在该文件夹下有一个文件名为“iSCSI portal IP，编号” （例如172.29.88.62,3260,0）的配置参数文件default，该文件中是initiator登录target时要使用的参数，这些参数的设置是从/etc/iscsi/iscsi.conf中的参数设置继承而来的，可以通过iscsiadm对某一个参数文件进行更改（需要先注销到target的登录）。 iscsiadm是用来管理（更新、删除、插入、查询）iSCSI配置数据库文件的命令行工具，用户能够用它对iSCSI nodes、sessions、connections和discovery records进行一系列的操作。\niSCSI node是一个在网络上可用的SCSI设备标识符，在open-iscsi中利用术语node表示目标（target）上的门户（portal）。一个target可以有多个portal，portal 由IP地址和端口构成。\n2. 初次挂载网络存储 2.1 设置InitiatorName initiator名称用来唯一标识一个iSCSI Initiator端。保存此名称的配置文件为/etc/iscsi/initiatorname.iscsi：\n1 2 # vi /etc/iscsi/initiatorname.iscsi InitiatorName=iqn.2000-01.com.synology:themain-3rd.ittest 注意大小写，同时，必须顶格写，xxxx代表要设置的initiator名称，请遵循iqn命名规范，格式为iqn.domaindate.reverse.domain.name:optional_name。\n2.2 iSCSI Initiator配置 iSCSI Initiator的配置文件为/etc/iscsi/iscsid.conf,在iSCSI initiator的iscsid进程启动和执行iscsiadm命令时，将读取这个配置文件的内容，获取与SCSI目标进行交互的相关信息。\n2.2.1 添加CHAP认证 本组下的各个设置项主要用来指定Initiator与target验证方式。\n1 2 3 4 5 6 vi /etc/iscsi/iscsid.conf # To enable CHAP authentication set node.session.auth.authmethod node.session.auth.authmethod = CHAP 去掉注释 # To set a CHAP username and password for initiator node.session.auth.username = ittest 修改为网管提供的认证username/password node.session.auth.password = Storageittest 上面是在我的环境中最为简单的一种CHAP（Challenge Handshake Authentication Protocol）认证方式，而且只验证的节点会话initiator端。其实iSCSI验证可以是双向的，根据服务端的设置，可以验证节点会话的target端（username_in），验证发现会话的CHAP initiator，验证发现会话的CHAP target。（节点会话node.session即登录认证，发现会话discovery.sendtargets即查看）\n2.2.2 其他配置项 处理CHAP认证需要关注外，其它的都保持默认即可，但是你需要知道可以修改如:\n设置initiator与target端交互的超时时间 设置iscsid重试登录节点的次数 是否开机启动iscsid等待 2.3 扫描并登录到iqn连接 open-iscsi initiator-utils提供的管理命令为iscsiadm，此命令包括discovery、node、session几种模式，分别处理不同的情况。在客户端使用Target提供的存储空间前，必须在服务器上通过Initiator软件执行以下步骤：发现目标设备 \u0026ndash;\u0026gt; 登录目标设备 \u0026ndash;\u0026gt; 与目标设备建立会话，下面分别说明通过各个命令进行说明。\n2.3.1 discovery sendtargets 可以通过sendtargets方式（根据iscsi服务器端使用的方式不同还有slp、isns）发现属于你的iqn（iSCSI Qualified Name）：\n1 2 iscsiadm -m discovery -t sendtargets -p 172.29.88.62 iscsiadm -m discovery -t sendtargets -p 172.29.88.62:3260 |grep ittest 默认端口3260。discovery之前会自动启动iscsid服务，有时候service iscsid start启动没反应，可以通过这种方式启动服务。 此命令查询目标门户（Portal）为172.29.88.62:3260上的目标，查找成功后，返回相应的target ID，同时在/var/lib/iscsi/send_targets和 /var/lib/iscsi/nodes目录下记录相应的门户和节点信息。使用iscsiadm -m node命令，可以查看到发现的节点记录。\n2.3.2 node session login 在完成目标发现后，即可以登录到相应的节点，使用目标设备提供的存储空间：\n1 # iscsiadm -m node -T iqn.2000-01.com.synology:themain-3rd.ittest -p 172.29.88.62 --login -T后面跟target名称，--login等同于-l，\n登录目标节点成功后，即建立了initiator与target之间的会话（session），同时target提供的存储设备也挂载到主机中，在/dev目录下生成一个新的设备文件类似于sdb、sdc等。使用iscsiadm -m session -P 3（与service iscsi status相同）来查看连接会话信息。\n2.4 使用磁盘 — lvm LVM是非常流行的可修改磁盘分区大小的管理方式，可以根据你的需要使用使用lvm管理磁盘。 假设新存储的设备路径为/dev/sdb\n1 2 3 4 5 pvcreate /dev/sdb ## 在新存储上建立物理卷 pvdisplay ## 查看物理卷状态 vgcreate vg_ittest /dev/sdb ## 在该物理卷上建立名为vg_test的卷组 vgdisplay ## 查看已建立的卷组状态 lvcreate -l 100%FREE -n lv_static vg_ittest 在vg_ittest卷组上建立名为lv_static的逻辑卷，-L可指定分区大小，此处-l表示使用全部空间\n1 2 3 vgscan或lvdisplay ## 查看逻辑卷的状态 vgchange -ay ## 使卷组处于激活状态 mkfs.ext4 /dev/mapper/vg_ittest-lv_static ## 格式化已创建的逻辑卷，文件系统格式为ext4 格式化完毕后，使用mount命令挂载即可：\n1 mount -o acl,rw /dev/mapper/vg_ittest-lv_static /iscsi ## /iscsi为事先建立的挂载点 也可以根据需求划分成多个分区挂载。\n开机自动挂载\n1 2 3 vi /etc/rc.d/rc.local iscsiadm -m node -T iqn.2000-01.com.synology:themain-3rd.ittest -p 172.29.88.62 --login vgchange -ay \u0026amp;\u0026amp; mount -o acl,rw /dev/mapper/vg_ittest-lv_static /iscsi 3. 维护操作 3.1 正常断开重连网络存储 因为磁盘上就是数据（一般网络存储用于备份），因此尽量减少异常断开存储的可能性，所以保险起见先卸载，再断开连接(-u)。\n1 2 3 4 # umount /iscsi # vgchange -an \u0026amp;\u0026amp; vgscan # iscsiadm -m session # iscsiadm -m node -T iqn.2000-01.com.synology:themain-3rd.ittest -p 172.29.88.62 --logout 3.2 异常断开恢复 如果使用LVM管理磁盘，由于网络中断，或主机突然关机，会导致网络存储异常断开，下次启动后重新连接可能会报如下错误：\n1 2 3 4 5 6 7 8 # vgscan Reading all physical volumes. This may take a while... /dev/backupdrive1/backup: read failed after 0 of 4096 at 319836585984: Input/output error /dev/backupdrive1/backup: read failed after 0 of 4096 at 319836643328: Input/output error /dev/backupdrive1/backup: read failed after 0 of 4096 at 0: Input/output error /dev/backupdrive1/backup: read failed after 0 of 4096 at 4096: Input/output error Found volume group \u0026#34;backupdrive1\u0026#34; using metadata type lvm2 Found volume group \u0026#34;networkdrive\u0026#34; using metadata type lvm2 产生原因就是，在卷组（VG）失活（deactivate）之前就移除了外部的LVM设备。在你断开连接之前，需要保证以下命令被执行：\n1 # vgchange -an volume_group_name 解决方案就是，（假设你已经用vgchange -ay vg命令来激活卷组，但仍有 Input/output error 的错误信息。）执行命令vgchange -an volume group name，移除外部设备，稍候几分钟后再执行以下命令：\n1 2 # vgscan # vgchange -ay volume_group_name 3.3 进程数超标 iscsi存储使用正常，但ps -ef|grep iscsi则包含200+以上的类似于[iscsi_q_112]进程，并且无法kill，使用service iscsi status不断输出类似：\n1 2 3 4 5 iscsiadm: could not read session targetname: 5 iscsiadm: could not find session info for session30 iscsiadm: could not read session targetname: 5 iscsiadm: could not find session info for session31 ... 这个问题很纠结，但重启服务器是可以解决的。网上资料很少，我猜想是iscsid服务端设置认证方面的问题。\n4. iscsi的其它常用操作 列出所有target iscsiadm -m node\n连接所有target iscsiadm -m node -L all\n连接指定target iscsiadm -m node -T iqn.... -p 172.29.88.62 --login\n使用如下命令可以查看配置信息 iscsiadm -m node -o show -T iqn.2000-01.com.synology:rackstation.exservice-bak\n查看目前 iSCSI target 连接状态 iscsiadm -m session iscsiadm: No active sessions. (目前没有已连接的 iSCSI target)\n断开所有target iscsiadm -m node -U all\n断开指定target iscsiadm -m node -T iqn... -p 172.29.88.62 --logout\n删除所有node信息 iscsiadm -m node --op delete\n删除指定节点（/var/lib/iscsi/nodes目录下，先断开session） iscsiadm -m node -o delete -name iqn.2012-01.cn.nayun:test-01\n删除一个目标（/var/lib/iscsi/send_targets目录下） iscsiadm --mode discovery -o delete -p 172.29.88.62:3260\n参考\nCentOS客户端加载ISCSI磁盘\nlinux iscsi initiator 安装配置\nhttp://linux.vbird.org/linux_server/0460iscsi.php\n","permalink":"http://localhost:1313/2015/04/iscsi-san-initiator/","summary":"\u003cp\u003e本文不介绍iSCSI服务端的搭建过程，不然就会很累赘。主题就是怎么去完成iscsi网络存储的挂载过程，并顺带介绍一些必要的概念。\u003c/p\u003e\n\u003ch1 id=\"1-iscsi介绍与initiator安装\"\u003e1. iscsi介绍与initiator安装\u003c/h1\u003e\n\u003ch2 id=\"11-iscsi介绍\"\u003e1.1 iSCSI介绍\u003c/h2\u003e\n\u003cp\u003eiSCSI简单来说，就是把SCSI指令通过TCP/IP协议封装起来，在以太网中传输。iSCSI 可以实现在IP网络上传递和运行SCSI协议，使其能够在诸如高速千兆以太网上进行数据存取，实现了数据的网际传递和管理。基于iSCSI建立的存储区域网（SAN）与基于光纤的FC-SAN相比，具有很好的性价比。\u003c/p\u003e","title":"iscsi网络存储介绍及客户端配置操作"},{"content":"本文翻译自Howtoforge上的一篇文章 How To Use pfSense To Load Balance Your Web Servers。注意pfSense的负载均衡有两种：一是设置多个WAN做双线负载均衡，二是本文的为LAN内的web服务器做inbound-loadbalancer。\n这篇howto中展示了怎么使用pfSense 2.0 为你的多个web服务器配置负载均衡（load balancer）。这里假定在你的网络环境中已经拥有了一个pfSense服务器和2个以上的apache服务器，并且具有一定的pfSense知识。（参考图解pfSense软路由系统的使用（NAT功能）\n1. 前提 一个安装好的pfSense 2.0 机器（如果它是你的外围防火墙，建议安装在物理机上） 至少2个apache服务器（可以是虚拟机） 确保在apache服务器之间代码文件是同步的（rsync、cororsync或其它可以保持web服务器间文件更新） 2. 配置pfSense pfSense可以使用负载均衡的功能让特定的请求压力由多台服务器分担，这对于有多台应用的服务器很有帮助，因为你可以把负载压力分散到其它节点上而不是死磕一个节点。\n2.1 Monitor 我们正式开始。首先点击Services -\u0026gt; Load Balancers，然后选择Monitor标签。\n点击右边的+加号来添加一条记录，输入monitor的名字Name和描述Description（在这个示例名字和描述我都使用ApacheClusterMon），把类型Type设置成HTTP，主机地址Host设置一个还未使用的IP（后面我们将在这个IP上建立虚拟IP，这个虚拟IP会被分配到故障转移failover节点上，注：也有文章说把它设成WAN IP），HTTP Code保存默认的200 OK，然后点击Save保存并且使修改生效Apply Changes。 2.2 Pool 接着建立服务器池server pool。点击Pools标签的+按钮来添加一个池。\n在该示例我指定ApacheSrvPool为服务池名称，设置Mode为Load Balance，端口80（。这个端口时你后端服务器的监听端口，你当然可以设定其它应用的其它端口，不一定非是web）。为这个池设定上一步创建的ApacheClusterMon，依次将你的所有web服务器IP添加到这个池中Add to pool，保存并应用。 2.3 Virtual Server 最后一步，选择Virtual Servers标签页，点击+来添加一条记录。填写名称ApacheClusterVirtualServer、描述和IP地址，这个IP地址与第1步中说的未使用的IP相同，端口80，所有发送到这个WAN IP:port的连接都会被转发到服务器池中。虚拟服务器池Virtual Server Poll选择上一步创建的。提交并应用。 搞定！最后不要忘记为虚拟服务器IP和池添加防火墙规则。\n","permalink":"http://localhost:1313/2015/04/pfsense-loadbalancer/","summary":"\u003cp\u003e本文翻译自Howtoforge上的一篇文章 \u003ca href=\"https://www.howtoforge.com/how-to-use-pfsense-to-load-balance-your-web-servers\"\u003eHow To Use pfSense To Load Balance Your Web Servers\u003c/a\u003e。注意pfSense的负载均衡有两种：一是设置\u003ca href=\"https://doc.pfsense.org/index.php/Multi-WAN\"\u003e多个WAN做双线负载均衡\u003c/a\u003e，二是本文的为LAN内的\u003ca href=\"https://doc.pfsense.org/index.php/Inbound_Load_Balancing\"\u003eweb服务器做inbound-loadbalancer\u003c/a\u003e。\u003c/p\u003e\n\u003cp\u003e这篇howto中展示了怎么使用pfSense 2.0 为你的多个web服务器配置负载均衡（load balancer）。这里假定在你的网络环境中已经拥有了一个pfSense服务器和2个以上的apache服务器，并且具有一定的pfSense知识。（\u003cem\u003e参考\u003ca href=\"http://xgknight.com/2015/04/23/pfsense-usage/\"\u003e图解pfSense软路由系统的使用（NAT功能\u003c/a\u003e\u003c/em\u003e）\u003c/p\u003e","title":"怎么用pfSense为你的web服务做负载均衡（翻译）"},{"content":"pfsense是一款开源的路由和防火墙产品，它基于freebsd系统定制和开发。pfsene拥有友好的web的配置界面，且具有伸缩性强又不失强大性能，在众多开源网络防火墙中属于佼佼者。\n2004年，pfsense作为m0n0wall项目（基于freebsd内核的嵌入式软防火墙）的分支项目启动，增加了许多m0n0wall没有的功能(pfSense的官方网站称它为the better m0n0wall).pfSense除了包含宽带路由器的基本功能外,还有以下的特点:\n基于稳定可靠的FreeBSD操作系统,能适应全天候运行的要求 具有用户认证功能,使用Web网页的认证方式,配合RADIUS可以实现记费功能 完善的防火墙、流量控制和数据包功能,保证了网络的安全,稳定和高速运行 支持多条WAN线路和负载均衡功能,可大幅度提高网络出口带宽,在带宽拥塞时自动分配负载 内置了IPsec 和PPTP VPN功能,实现不同分支机构的远程互联或远程用户安全地访问内部网 支持802.1Q VLAN标准,可以通过软件模拟的方式使得普通网卡能识别802.1Q的标记,同时为多个VLAN的用户提供服务 支持使用额外的软件包来扩展pfSense功能,为用户提供更多的功能(如FTP和透明代理). 详细的日志功能,方便用户对网络出现的事件分析,统计和处理 使用Web管理界面进行配置(支持SSL),支持远程管理和软件版本自动在线升级 本文简单介绍pfSense的安装及配置过程，完成一个基本的路由器该有的功能，如访问局外网、设置防火墙规则、配置端口映射。这里演示在ESXi虚拟服务器上，解决IP不足的问题。\n创建虚拟机 首先去 https://www.pfsense.org/download/ 下载稳定版本的pfSense，如pfSense-LiveCD-2.2.2-RELEASE-amd64.iso.gz（网上看到有人提到这个版本不稳定，我在使用中偶尔也发现突然很慢，建议2.1.5）。在vSphere上创建虚拟机的过程省略，取名01_pfSense，创建虚拟机操作系统时选择“其他 -\u0026gt; FreeBSD 64位”，单CPU,512Mb内存，4G硬盘。将下载的系统解压成iso后挂载到CD/DVD，并“打开电源时连接”。 下图是网卡情况： 为pfSense分配两个网卡，分别是可以连接公司内网的172.29.88.1/24网段的vSphere_Admin端口组，和IP范围是172.30.31.1/24的内部局域网端口组VM Local。 记录下Mac地址 外网接口：00:0c:29:36:b6:c2 内网接口：00:0c:29:36:b6:cc\n安装pfsense 启动电源后出现欢迎界面，选择1.Boot pfSense [default]，或等待几秒钟自动选择，进入如下界面： 输入I，回车，然后是一个蓝屏，开始安装。\n也可以什么都不用管，系统会一直启动从CD启动得到一个完整的pfSense系统，因为没有安装所以在屏幕下方会有一个选项99） Install pfSense to a hard drive, etc.，输入99同样会进入下面的安装操作系统的过程。 一路保存默认：\u0026lt; Accept these Settings \u0026gt; → \u0026lt; Quick/Easy InStall \u0026gt; → erase all content \u0026lt; OK \u0026gt; → \u0026lt; Standard Kernel \u0026gt; → \u0026lt; Reboot \u0026gt;。\n重启后安装完成，断开CD介质。 详见见官网文档 https://doc.pfsense.org/index.php/Installing_pfSense 。\n下面开始配置内外网接口。\n分配接口 从上图可以看到系统默认将em0接口当做WAN（外网），em1当做LAN（内部局域网），但我们不确定em0就是在创建虚拟机时分配的外网接口，需要根据MAC地址判断。\n选择1) Assgin Interfaces，回车 首先询问你是否设置VLAN（用于划分多个子局域网网），Do you want to set up VLANs now [y|n]?，否n： 分配IP 选择2) Set interfce(s) IP address： 先配置WAN的IP，禁用DHCP,配置地址172.29.88.230/24，网关172.29.88.1，禁用IPV6： 再配置LAN，172.30.31.1/24，不配置网关： 完成后会提示可以在浏览器打开http://172.30.31.1/，通过webConfigurator来操作pfSense。\n已打通两端网络：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 sean@seanubt:~$ ssh admin@172.30.31.1 22 Password for admin@pfSense.domain: *** Welcome to pfSense 2.2.2-RELEASE-pfSense (amd64) on pfSense *** WAN (wan) -\u0026gt; em0 -\u0026gt; v4: 172.29.88.230/24 LAN (lan) -\u0026gt; em1 -\u0026gt; v4: 172.30.31.1/24 0) Logout (SSH only) 9) pfTop 1) Assign Interfaces 10) Filter Logs 2) Set interface(s) IP address 11) Restart webConfigurator 3) Reset webConfigurator password 12) pfSense Developer Shell 4) Reset to factory defaults 13) Upgrade from console 5) Reboot system 14) Disable Secure Shell (sshd) 6) Halt system 15) Restore recent configuration 7) Ping host 16) Restart PHP-FPM 8) Shell 7 Enter a host name or IP address: 172.29.88.56 PING 172.29.88.56 (172.29.88.56): 56 data bytes 64 bytes from 172.29.88.56: icmp_seq=0 ttl=64 time=1.406 ms 64 bytes from 172.29.88.56: icmp_seq=1 ttl=64 time=1.215 ms 64 bytes from 172.29.88.56: icmp_seq=2 ttl=64 time=0.480 ms --- 172.29.88.56 ping statistics --- 3 packets transmitted, 3 packets received, 0.0% packet loss round-trip min/avg/max/stddev = 0.480/1.034/1.406/0.399 ms Press ENTER to continue. *** Welcome to pfSense 2.2.2-RELEASE-pfSense (amd64) on pfSense *** WAN (wan) -\u0026gt; em0 -\u0026gt; v4: 172.29.88.230/24 LAN (lan) -\u0026gt; em1 -\u0026gt; v4: 172.30.31.1/24 0) Logout (SSH only) 9) pfTop 1) Assign Interfaces 10) Filter Logs 2) Set interface(s) IP address 11) Restart webConfigurator 3) Reset webConfigurator password 12) pfSense Developer Shell 4) Reset to factory defaults 13) Upgrade from console 5) Reboot system 14) Disable Secure Shell (sshd) 6) Halt system 15) Restore recent configuration 7) Ping host 16) Restart PHP-FPM 8) Shell 8 ping 172.30.31.20 PING 172.30.31.20 (172.30.31.20): 56 data bytes 64 bytes from 172.30.31.20: icmp_seq=0 ttl=64 time=0.239 ms 64 bytes from 172.30.31.20: icmp_seq=1 ttl=64 time=0.211 ms 登录 172.30.31.1是内部局域网的IP，所以只能通过另一台lan上的服务器的浏览器访问： 当然这样操作起来很不方便，，而且假如lan上的其它服务器都是linux而且没有图像界面，没办法使用webConfigurator了。端口转发似乎是一个比较好的方案：在某一台lan服务器上添加一个可以通过你的pc端访问的网卡（我这里的172.29.88.206，它的lan接口IP为172.30.31.20），然后使用rinetd工具转发到172.30.31.1。 这个方法似乎可选，但需要额外的设置： An HTTP_REFERER was detected other than what is defined in System -\u0026gt; Advanced (http://172.29.88.206:8008/index.php?logout). You can disable this check if needed in System -\u0026gt; Advanced -\u0026gt; Admin.\npfSense为了安全起见，不允许任何形式的转发来访问webConfigurator，根据你的需要决定是否关闭这个功能：System -\u0026gt; Advanced -\u0026gt; Admin，勾选Browser HTTP_REFERER enforcement -\u0026gt; Save -\u0026gt; Apply。 登陆的用户名默认为admin/pfsense 使用配置向导 前面是通过命令行的方法对接口和IP进行配置，也可以直接通过webGUI向导对WAN和LAN、网关等设置：System -\u0026gt; Setup Wizard，因为太过简单，就不贴图了。 在设置WAN接口时（Configure WAN Interface）注意两点：\nStatic IP Configuration 部分设置正确的IP和网关，否则会无法进出网络 RFC1918 Networks 默认是勾选的，这是为了避免WAN上也存在与LAN一样的网段。如果要允许wan的其他主机ping通该pfSense，则去掉勾 其它保持为空或默认值。\npfSense的NAT功能 即Port Forward，目的是为了WAN上的其他机器可以访问LAN内部的服务。 Friewall -\u0026gt; NAT 端口映射分为单端口和范围端口。但端口容易理解，访问WAN 172.29.88.230:8000 的 数据包都转发到内部LAN 172.30.31.20:8000；范围端口是在 from m to n 的端口范围内的数据包都发送到内部IP的对应端口上，减少规则的数量。 Save -\u0026gt; Apply Changes，与此同时pfSense会自动在防火墙里添加规则，Firewal -\u0026gt; Rules pfSense做负载均衡 其它功能 pfSense还有几大重要的功能，如快速搭建VPN服务器，作为前端负载均衡服务器，流量限制。由于工作中暂未用到，所以就不加说明了。\n关于负载均衡见 http://xgknight.com/2015/04/24/pfsense-loadbalancer/\n参考\n用pfSense搭建ESXi上的软路由\npfsense 企业应用实例\npfsense 研究- m0n0wall中国论坛\nPFsense学习 - 端口映射\npfSense 2.0 多 WAN 负载均衡设置指南 （中文）\n","permalink":"http://localhost:1313/2015/04/pfsense-usage/","summary":"\u003cp\u003epfsense是一款开源的路由和防火墙产品，它基于freebsd系统定制和开发。pfsene拥有友好的web的配置界面，且具有伸缩性强又不失强大性能，在众多开源网络防火墙中属于佼佼者。\u003c/p\u003e","title":"图解pfSense软路由系统的使用（NAT功能）"},{"content":"修改配置 要达到oracle随开机自启动，一般使用11g自带的dbstart脚本：$ORACLE_HOME/bin/dbstart，但要先修改/etc/oratab的内容，将N改成Y，表示允许实例自启动，假如有2个实例要启动，再写一行：\n1 2 $ vi /etc/oratab EXCRMPROD:/db/oracle/product/11.2.0/db_1:Y 然后在oracle用户下执行$ORACLE_HOME/bin/dbstart即可启动，日志被记录在$ORACLE_HOME/startup.log。但是，默认情况dbstart和dbshut脚本不能自动启动或关闭监听，所以也要加以修改：\n1 2 3 4 5 6 7 8 9 10 $ vi /db/oracle/product/11.2.0/db_1/bin/dbstart ## 找到下面的代码(约第80行)，在实际脚本代码的前面 # First argument is used to bring up Oracle Net Listener ORACLE_HOME_LISTNER=$1 ## 将此处的 ORACLE_HOME_LISTNER=$1 修改为 ORACLE_HOME_LISTNER=$ORACLE_HOME if [ ! $ORACLE_HOME_LISTNER ] ; then echo \u0026#34;ORACLE_HOME_LISTNER is not SET, unable to auto-start Oracle Net Listener\u0026#34; echo \u0026#34;Usage: $0 ORACLE_HOME\u0026#34; else LOG=$ORACLE_HOME_LISTNER/listener.log 同样也修改dbshut脚本（约第50行）：\n1 2 3 4 5 6 7 8 9 $ vi /db/oracle/product/11.2.0/db_1/bin/dbshut # The this to bring down Oracle Net Listener ORACLE_HOME_LISTNER=$ORACLE_HOME if [ ! $ORACLE_HOME_LISTNER ] ; then echo \u0026#34;ORACLE_HOME_LISTNER is not SET, unable to auto-stop Oracle Net Listener\u0026#34; echo \u0026#34;Usage: $0 ORACLE_HOME\u0026#34; else LOG=$ORACLE_HOME_LISTNER/listener.log 开机启动 这两个脚本在执行时会自动去搜索/etc/oratab文件的内容，将这两个命令分别加入开机启动和关闭脚本里。\n/etc/rc.local Linux系统开机初始化的最后过程会执行该脚本，加入以下内容：\n1 su - oracle -lc \u0026#34;$ORACLE_HOME/bin/dbstart\u0026#34; /etc/rc.local.shutdown 这个脚本时系统里没有的，完成的功能是关机自动停止服务，/etc/rc.d/rc.local.shutdown：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 #!/bin/bash # chkconfig: - 00 00 # description: Do custom commands before shutdown or reboot ### BEGIN INIT INFO # Provides: custom-halt # Required-Start: # Required-Stop: # Default-Start: 0 6 # Default-Stop: # Short-Description: Custom halt commands # Description: Do custom commands before shutdown or reboot ### END INIT INFO export ORACLE_BASE=/db/oracle export ORACLE_HOME=$ORACLE_BASE/product/11.2.0/db_1 export ORACLE_SID=EXCRMPROD export PATH=$PATH:$ORACLE_HOME/bin su - oracle -lc \u0026#34;$ORACLE_HOME/bin/dbshut /dev/null 2\u0026gt;\u0026amp;1\u0026#34; exit 让它运行在0和6运行级别runlevel：\n1 2 3 4 5 6 # chmod 755 /etc/rc.d/rc.local.shutdown # ln -s /etc/rc.d/rc.local.shutdown /etc/rc.local.shutdown # ln -s /etc/rc.d/rc.local.shutdown /etc/init.d/custom-halt # chkconfig --add custom-halt # chkconfig --level 06 custom-halt on 另外网上也有文章不是利用 oracle 自带的 dbstart 来实现自启动，而是自己写 service 脚本，执行 sqlplus 然后运行 shutdown immediate ，个人觉得这有点重复做oracle的事情了；还有把通过类似service oracle start/stop这样的形式去管理，方便是方便一点，但要知道oracle数据库轻易不会频繁重启，如有需要，我们更愿意自己使用sqlplus连上数据库，自己执行shutdown命令，因为对数据库的操作还是以慎重为主，在配置了Active Data Guard等复杂环境下，对备库也不适用，所以这里就没做这个工作。\n","permalink":"http://localhost:1313/2015/04/oracle_db_autostart_with_linux/","summary":"\u003ch2 id=\"修改配置\"\u003e修改配置\u003c/h2\u003e\n\u003cp\u003e要达到oracle随开机自启动，一般使用11g自带的dbstart脚本：\u003ccode\u003e$ORACLE_HOME/bin/dbstart\u003c/code\u003e，但要先修改\u003ccode\u003e/etc/oratab\u003c/code\u003e的内容，将N改成Y，表示允许实例自启动，假如有2个实例要启动，再写一行：\u003c/p\u003e","title":"配置 Oracle 11gR2 在 CentOS6 上开机自启动"},{"content":"本文完整记录了如何从物理服务器，保持所有环境配置信息，纹丝不动的迁移到虚拟机上，俗称 P2V 。采用的工具是VMware公司的 VMware vcenter vconverter standalone，它支持将windows和linux操作系统用作源，可以执行若干转换任务：\n将正在运行的远程物理机和虚拟机作为虚拟机导入到vCenter Server管理的独立ESX/ESXi或ESX/ESXi主机 将由VMware Workstation或Microsoft Hyper-V Server托管的虚拟机导入到vCenter Server管理的ESX/ESXi主机 将第三方备份或磁盘映像导入到vCenterServer管理的ESX/ESXi主机中 将旧版服务器迁移到新硬件，而不重新安装操作系统或应用程序软件等 完整功能见《Converter Standalone 用户指南》 Converter Standalone的组件，只能安装在Windows操作系统上：\nConverter Standalone Server —— 启用并执行虚拟机的导入和导出 Converter Standalone agent —— Converter Standalone Server会在Windows物理机上安装代理，从而将这些物理机作为虚拟机导入，完成后可以选择自动删除 Converter Standalone client —— 与Converter服务端配合使用，包括看到的用户界面、创建和管理转换任务等 Vmware vCenter Converter引导CD：是单独的组件，可用于在物理机上执行冷克隆 冷克隆可以创建一致的源计算机的精确副本，而我们更多的是进行热克隆，也就是源服务器在迁移过程中会继续工作，这就可能会出现某些文件不一致，但Converter Standalone会在热克隆后将目标虚拟机与与主机同步，同步执行过程是将在初始克隆期间更改的块从源复制到目标。\n本文记录的过程是，源主机是 SUSE 11.x 物理机，运行华为的智能呼叫中心应用，因此安装有Oracle数据库，对于数据文件和控制文件的一致性和安全性较高，所以建议先把oracle数据库关闭再操作；目标虚拟服务器是 ESXi 5.1，但我使用的Converter是 5.5-en，操作过程类似。下面正式开始\n源主机：172.30.31.0/24 ESXi: 172.29.88.0/24，与源主机IP段无法通信 Helper VM: 172.29.41.0/24，与上面两个IP段都通\n1. 设置源和目的主机地址 Source System 选择你要转换的源系统，物理机为 Powered-on machine，填写其他登陆信息： Destination System 填写要在哪个主机上创建虚拟机，也就是ESXi服务器地址: 这两个过程有个简短的拉去主机信息的过程。 2. 选择目标虚拟机和存放位置 Destination Virtual Machine 目标虚拟机名字默认是源hostname，不用选择folder： Destination Location\n选择新虚拟机要放在ESXi的哪个Datastore上，请确保有足够的磁盘空间，不能小于源系统实际使用的大小： 3. 为转换任务设置其它选项 这一步尤为关键，直接关乎后面转换的成败。\nData to copy\n设置目标虚拟机的磁盘和分区，我们可以看到自动获取的源分区信息，我这里因为硬盘资源有限，没有遵循默认的 Maintain size，但比Minmun size（在源SUSE下 df -h 看到的used大小）大。 CPU个数和内存大小默认也是与源主机保持一致。\nNetwork 网络设置这一块比较纠结。按理说源主机不需要与目的主机的网卡通信，只需要与Helper VM能互通即可，但我一直卡在这走不过去。源主机有2块网卡在使用，最后在这一步只设置了一块能ping同源主机的网卡，迁移完成后再手动添加剂一块网卡。如下是vmware官方知识库的Note：\nIn the Conversion wizard, ensure to select the virtual machine portgroup when configuring the network card. This virtual machine portgroup must be connected to the physical network that is routable via port 22 (SSH) in both directions from the source Linux server\u0026rsquo;s configured network IP address. The IP address entered must be routable to the IP address of the physical Linux source machine. Helper virtual machine IP address should able to ping the physical machine.\n图中看到VM Local是事先在vSphere Server上新建的端口组（portgroup），而且这个虚拟交换机vSwitch没有关联任何物理网卡： Helper VM network Helper VM是做转换时的一个临时操作系统，运行在目的主机上，从源主机拷贝数据。如果转化的时windows，则没有这个vm，取而代之的时再源主机上运行一个agent，所以转换windows要求ESXi与源主机能互通，而转换Linux则只需要设定的Helper VM network能与源主机22端口互通即可。 4. 开始转换 可以看到转换的信息汇总，finish则开始迁移转换过程。 测试在ESXi上可以看到会自动创建一台虚拟机并启动。等待转换完成。\n5. 问题 转换几次失败都是因为网络设置不当，转换到1%时报错： Error：event.ObtainHelperVmIpFailedEvent.summary\n解决办法就是手动设置HelperVm的IP，并确保能够与源主机通信。如果继续报错，修改目标地址网卡设置，比如去除只剩一个网卡（后续添加），也设置成HelpVm网段。参考 Convert: converter.fault.HelperVmFailedToObtainIpFault 。\n转换Windows Server 2003时还有可能会出现\n1 2 3 Unable tp locate the required Sysprep files. Please upload them under c:\\documents and settings\\all users\\application data\\vmware\\vmware vcenter converter standalone\\sysprep\\svr2003 on the converter server machine 解决办法是，需要下载WindowsServer2003-KB926028-v2-x86-CHS.exe，在cmd下执行WindowsServer2003-KB926028-v2-x86-CHS –x(不可以用winrar)，解压缩出来2个目录加一堆文件,在SP2QFE目录下找到deploy.cab，再将deploy.cab解压缩(winrar即可),得到10个文件,拷贝到所提示的 svr2003 目录。参考 Sysprep文件位置和版本 (2040984)。\n6. on windows 加入迁移的是windows主机，上面的操作略有不同，主要区别在于没有HelperVm，而是在需要转换的源主机上安装agent。所以要求ESXi与源主机必须能够直接通信才可以迁移。\n参考：\n操作VMware vCenter Converter 实现物理机迁移到虚拟机\nVMware vCenter Converter Standalone User\u0026rsquo;s Guide 5.5 （中文）\nVMware vCenter Converter Standalone 用户指南 中文4.3\n","permalink":"http://localhost:1313/2015/04/vmware-vcenter-vconverter/","summary":"\u003cp\u003e本文完整记录了如何从物理服务器，保持所有环境配置信息，纹丝不动的迁移到虚拟机上，俗称 P2V 。采用的工具是VMware公司的 \u003ccode\u003eVMware vcenter vconverter standalone\u003c/code\u003e，它支持将windows和linux操作系统用作源，可以执行若干转换任务：\u003c/p\u003e","title":"使用vmware vconverter从物理机迁移系统到虚拟机P2V（多图）"},{"content":"1. vagrant介绍 1.1 vagrant能做什么 做Web开发（java/php/python/ruby\u0026hellip;）少不了要在本地搭建好开发环境，虽然说目前各种脚本/语言都有对应的Windows版，甚至是一键安装包，但很多时候和Windows环境的兼容性（如配置文件、编译的模块）并不是那么好，麻烦的问题是实际部署的环境通常是Linux，常常还要面临着开发和部署环境不一致，上线前还要大量的调试。而如果让每个开发人员都自己去搭建本地环境，安装虚拟机、下载ISO镜像、选择规格安装创建vm、安装OS、配置，会耗费非常多的时间，如果是团队开发应该要尽量保持每个人的运行环境一致。此时vagrant正式你所需要的。不适用正式环境部署。\nvagrant实际上一套虚拟机管理工具，基于Ruby开发，底层支持VirtualBox、VMware甚至AWS、docker等作为虚拟化系统。我们可以通过 Vagrant 封装一个 Linux 的开发环境，分发给团队成员。成员可以在自己喜欢的桌面系统（Mac/Windows/Linux）上开发程序，代码却能统一在封装好的环境里运行，“代码在我机子上运行没有问题”这种说辞将成为历史。\n通过上面的介绍如果你还在困惑有virtualbox或vmware为什么还要加入vagrant，纠结于要不要使用，可以参考这个问答 使用vagrant的意义在哪，另外docker作为后起之秀也可以做vagrant能完成的事情，stackoverflow有关于两位作者讨论各自应用场景的精彩\u0026quot;互掐\u0026quot;，传送门→ （中文）。\n1.2 几个概念 Provider：供应商，在这里指Vagrant调用的虚拟化工具。Vagrant本身并没有能力创建虚拟机，它是调用一些虚拟化工具来创建，如VirtualBox、VMWare、Xen、Docker，甚至AWS，这些虚拟化工具只要安装好了，vagrant会自动封装在底层通过统一的命令调用。也就是说使用vagrant时你电脑上还需要安装对应的Provider，默认是免费开源的virtualbox。 Box：可被Vagrant直接使用的虚拟机镜像文件，大小根据内容的不同从200M-2G不等。针对不同的Provider，Box文件的格式是不一样的，从 vagrantcloud.com 你可以找到社区维护的box。\nVagrantfile：Vagrant根据Vagrantfile中的配置来创建虚拟机，是Vagrant的核心。在Vagrantfile文件中你需要指明使用哪个Box（可以下载好的或自己制作，或指定在线的URL地址），虚拟机使用的内存大小和CPU，需要预安装哪些软件，虚拟机的网络配置，与host的共享目录等。\nProvisioner：是Vagrant的插件的一种。大部分现成的box并不是你正好想要的，通过使用你熟悉的provisioner，比如Puppet，可以在你使用vagrant up启动虚拟机时自动的安装软件、修改配置等初始化操作。当然你也可以在最先启动虚拟机后，使用vagrant ssh进去然后手动安装软件，但毕竟不是所有人都是系统管理员，写好Vagrantfile后无需人工干预马上就可以使用vm。目前支持并实现的provisioning有Puppet、Salt、Ansible、Chef这些知名的自动化运维工具，当然需要一定的使用经验；也可以使用shell provisioner，故名思议这个插件就是通过执行shell命令完成统一的作用。\nGuest Additions：这个是常在下载 base box 介绍里有的，一般用来实现host到vm的端口转发、目录共享，在开发环境上都建议装上以便测试。\n2. 安装vagrant VirtualBox: 4.3.12，https://www.virtualbox.org/wiki/Download_Old_Builds_4_3 。我上手使用的是4.3.20，折腾出过几个问题，据说说4.3.12版本较稳定。 建议选择VirtualBox ，即使你电脑上已经安装VMware Workstation或Fushion，它的vagrant插件还是要收费的 Vagrant: 1.7.1，http://www.vagrantup.com/downloads-archive.html 选择适合你的平台（Windows、Mac、Linux），下载对应格式的安装包。如Mac下 vagrant_1.7.1.dmg、VirtualBox-4.3.20-96997-OSX.dmg 。\n3. 使用vagrant打造一个本地开发环境 本文将会演示从 nrel CentOS6.5 开始，安装必要的开发包、python、插件、Puppet，然后打包成一个box分发给团队的全过程。你也可以在别人box的基础上进一步通过Vagrantfile定制自己的环境。\n3.1 初始化 3.1.1 vagrant box add {box-name} {box-url} 1 2 3 4 5 6 7 8 9 10 11 $ vagrant box add ct65_00 Downloads/centos65.box ==\u0026gt; box: Adding box \u0026#39;ct65_00\u0026#39; (v0) for provider: box: Downloading: file:///Users/sean/Downloads/centos65.box ==\u0026gt; box: Successfully added box \u0026#39;ct65_00\u0026#39; (v0) for \u0026#39;virtualbox\u0026#39;! $ ll ~/.vagrant.d/boxes/ct65_00 $ vagrant box list # vagrant box list ct65_00 (virtualbox, 0) centos64-i386 (virtualbox, 0) 这一条命令就是根据给出的box（镜像）文件地址，解压一份到用户目录~/.vagrant.d/boxes/{box-name}/0/virtualbox/下，所以你尽量应该以同一用户来管理进行vagrant所有操作。\n*F*K GFW 在GFW保护之下，这简单获取box文件反而一开始就难到我们了。官方提供的在线安装在墙外是极为方便的，vagrant box add minimal/centos6便自动从vagrantcloud.com(现更名为https://atlas.hashicorp.com/search/boxes)下载，直接进入第二步。\n还有一种方法是，先vagrant init minimal/centos6，然后直接启动vagrant up --provider virtualbox。当然这些都与下载boxes到本地效果是一样的，下载方法就是在vagrantcloud.com上点开你所需要的box版本，然后再URL里加入/providers/virtualbox.box便得到文件地址，如 https://atlas.hashicorp.com/hashicorp/boxes/precise64 对应的文件为 https://atlas.hashicorp.com/hashicorp/boxes/precise64/providers/virtualbox.box 。\n在墙内直接在线安装启动box，会报错：\n1 2 3 4 5 6 7 8 The box \u0026#39;ubuntu/trusty64\u0026#39; could not be found or could not be accessed in the remote catalog. If this is a private box on HashiCorp\u0026#39;s Atlas, please verify you\u0026#39;re logged in via `vagrant login`. Also, please double-check the name. The expanded URL and error message are shown below: URL: [\u0026#34;https://atlas.hashicorp.com/ubuntu/trusty64\u0026#34;] Error: 一个办法是ubuntu来 http://uec-images.ubuntu.com/vagrant/ 下载，centos来 http://nrel.github.io/vagrant-boxes/ 下载。我也从墙外下了几个典型的box放到了自己的百度云上共享了:http://pan.baidu.com/s/1sjHQBa1 。\n2015-04-01更新：无意间发现现在不用梯子也可以访问了，Happy April Fool\u0026rsquo;s Day!\n3.1.2 vagrant init {box-name} 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 $ mkdir ~/vagrant \u0026amp;\u0026amp; cd ~/vagrant //这个目录的目的就是统一管理你的Vagrantfile $ vagrant init ct65_00 A `Vagrantfile` has been placed in this directory. You are now ready to `vagrant up` your first virtual environment! Please read the comments in the Vagrantfile as well as documentation on `vagrantup.com` for more information on using Vagrant. $ vi Vagrantfile ... Vagrant.configure(2) do |config| config.vm.box = \u0026#34;ct65_00\u0026#34; onfig.vm.network \u0026#34;forwarded_port\u0026#34;, guest: 80, host: 8080 # config.vm.synced_folder \u0026#34;../data\u0026#34;, \u0026#34;/vagrant_data\u0026#34; config.vm.provider \u0026#34;virtualbox\u0026#34; do |vb| vb.memory = \u0026#34;384\u0026#34; vb.cpus = 1 end config.vm.hostname = \u0026#34;vg-ct65_00.tp-link.net\u0026#34; ... init只是在当前目录生成一个Vagrantfile文件和.vagrant/目录，可以对它进行修改，比如定义 vm guest machine 的hostname、memory、cpu等，具体有关语法介绍见后文。\n用户后面up虚拟机，这个 box-name 与上面add的相同，如果是 base 则可以省略。\n3.2 启动虚拟机 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # vagrant up Bringing machine \u0026#39;default\u0026#39; up with \u0026#39;virtualbox\u0026#39; provider... ==\u0026gt; default: Importing base box \u0026#39;ct65_00\u0026#39;... ==\u0026gt; default: Matching MAC address for NAT networking... ==\u0026gt; default: Setting the name of the VM: v-box_default_1427284884787_97348 ==\u0026gt; default: Clearing any previously set network interfaces... ==\u0026gt; default: Preparing network interfaces based on configuration... default: Adapter 1: nat ==\u0026gt; default: Forwarding ports... default: 22 =\u0026gt; 2222 (adapter 1) ==\u0026gt; default: Booting VM... ==\u0026gt; default: Waiting for machine to boot. This may take a few minutes... default: SSH address: 127.0.0.1:2222 default: SSH username: vagrant default: SSH auth method: private key default: Warning: Connection timeout. Retrying... default: Warning: Connection timeout. Retrying... ... default: Warning: Remote connection disconnect. Retrying... default: Warning: Remote connection disconnect. Retrying... ==\u0026gt; default: Machine booted and ready! ==\u0026gt; default: Checking for guest additions in VM... ==\u0026gt; default: Mounting shared folders... default: /vagrant =\u0026gt; /root/vagrant/v-box/ct65_00 up过程是默认会根据当前目录下的Vagrantfile来启动vm，如果当前目录没有Vagrantfile，则去上层目录寻找，依次类推。第一次vagrant up ct65_00时会从~/.vagrant.d/boxes中导入相应的box文件到~/VirtualBox VMs/，可以通过vboxmanage showvminfo {VM-ID}看到该虚拟机的配置（Mac上为VBoxManage）。如果你想让虚拟机存储在指定位置，如我的Mac SSD硬盘空间贵，可以运行VirtualBox，手动设置存储/storage的路径。\n默认 localhost:2222 转发到 guest:22 以供ssh连接；用户名/密码：vagrant/vagrant；默认共享目录就是host上Vagrantfile所在目录；如果电脑配置比较低导致启动时间比较长，或者VirtualBox启动出错，可能会提示上面的 Connection timeout 。\n另外提示一下，某次我在Linux上测试，由于Linux host本身也是vSphere虚拟机，通过vagrant启动virtualbox另一个虚拟机（即嵌套），一直Retrying，后来根据上面 stackoverflow 打开了VBox GUI，发现是CPU架构的问题，一直堵塞，所以就不建议虚拟机上再装虚拟机了：\n1 VT-x/AMD-V hardware acceleration is not available on your system. Your 64-bit guest will fail to detect a 64-bit CPU and will not be able to boot. 3.2 连接虚拟机，初始化环境 vagrant ssh 1 2 3 $ vagrant ssh Last login: Tue Mar 31 02:15:38 2015 from 10.0.2.2 Welcome to your Vagrant-built virtual machine. 一般建立box时约定的用户名/密码：vagrant/vagrant，root密码也是 vagrant，默认的网络连接方式是Host-Only。\n定制你的环境 如安装jdk，创建用户，解压tomcat，修改server.xml，添加yum源等。这里一步到位，唯一要说明的是tomcat conf/server.xml 的 \u0026lt;Context path=\u0026quot;\u0026quot; docBase=\u0026quot;/vagrant_data\u0026quot; reloadable=\u0026quot;true\u0026quot; \u0026gt;...应用目录设置为共享目录。\n3.3 打包成box 3.3.1 安装必要软件 打包是为了分发出去，做扩展用\n1 # yum install -y lrzsz telnet vim puppet puppetmaster 如果你是从0开始建立一个box，当然还需要创建vagrant用户以及public key，具体可以参考如何制作一个vagrant的base box。\n3.3.2 安装Virtualbox Guest Additions 每个人电脑上安装的Virtualbox版本很可能不一样，vagrant up可能会有提示版本不兼容（同一大版本号还好，可省略这一步），导致host到guest共享目录模块失败，最终无法启动虚拟机。\n安装方法可以有 vagrant-vbguest（注意这是vagrant插件，不是virtualbox插件），使用超级详细，只需执行vagrant plugin install vagrant-vbguest，默认从本地找 VBoxGuestAdditions.iso （各平台路径一般都可以找到），如果没找到则去http://download.virtualbox.org/virtualbox/%{version}/VBoxGuestAdditions_%{version}.iso 下载，直接启动vm便可安装或更新virtualbox guest additions ，甚至可以通过vagrant vbguest命令给正在运行的vm安装，缺点是 plugin install 得连网。下面是手动在vm内部安装：\n一般最小化的box不带有CDROM，需要通过VirtualBox图形化界面添加一个DVD/CD存储设备，然后在启动VM后 Devices -\u0026gt; Insert Guest Additions CD 。（相信你可以可以找到办法直接挂载 .iso 文件到vm里面，免去添加多余设备）\nfor linux : /usr/share/virtualbox/VBoxGuestAdditions.iso for Mac : /Applications/VirtualBox.app/Contents/MacOS/VBoxGuestAdditions.iso for Windows : %PROGRAMFILES%/Oracle/VirtualBox/VBoxGuestAdditions.iso\n1 2 3 $ sudo yum install linux-headers-$(uname -r) build-essential dkms $ sudo mount /dev/cdrom /media/cdrom $ sudo sh /media/cdrom/VBoxLinuxAdditions.run --nox11 官方参考：http://docs.vagrantup.com/v2/virtualbox/boxes.html\n3.3.3 vagrant package 打包导出：\n1 2 3 4 5 vagrant package --output sean-vg-ct65_ts.box ==\u0026gt; default: Attempting graceful shutdown of VM... ==\u0026gt; default: Clearing any previously set forwarded ports... ==\u0026gt; default: Exporting VM... ==\u0026gt; default: Compressing package to: /Users/sean/vagrant/sean-vg-ct65_ts.box 当前目录下若存在同名package.box则会export失败。打包的来源并不是.vagrant.d而是VirtualBox虚拟机本身，可以通过--base vm-name来指定所导出的虚拟机名称，--vagrantfile file-pathname可以将Vagrantfile直接封进box中。以后就可以把这个 .box 文件分发给开发人员使用了。\n4. 其他 4.1 命令 vagrant suspend将虚拟机置于休眠状态。这时候主机会保存虚拟机的当前状态。再用vagrant up启动虚拟机时能够返回之前工作的状态。这种方式优点是休眠和启动速度都很快，只有几秒钟。缺点是需要额外的磁盘空间来存储当前状态。\nvagrant halt则是关机。如果想再次启动还是使用vagrant up命令，不过需要多花些时间。\nvagrant destroy则会将虚拟机从磁盘中删除。如果想重新创建还是使用vagrant up命令。\nvagrant reload从Vagrantfile重新启动虚拟机。\nvagrant global-status输出所有虚拟机当前运行状态，关机、已启动等。\n另外1.2以上版本的Vagrant还引用了插件机制。可以通过vagrant plugin来添加各种各样的plugin，这给Vagrant的应用带来了更大的灵活性和针对性。比如可以添加vagrant-windows的插件来增加对windows系统的支持，通过添加vagrant-aws插件来实现给AWS创建虚拟机的功能。你也可以编写自己的插件。由于Vagrant是ruby写的一个gem，其插件的编写也是使用的Ruby语言。\n关于 Vagrantfile说明以及网络、多机器管理的配置，见 Varantfile说明。\n4.2 问题集 选用配置略高一点的电脑做host，否则启动会相当慢而且会提示Warning: Connection timeout. Retrying...，如果在300s内没有boot up，你可能需要启用GUI界面可以帮我们诊断一些启动失败的问题，vb.gui = true。坚决不要在虚拟机里玩vagrant！\n不要轻易在VirtualBox图形界面下强行关闭虚拟机，可能会出现意想不到的错误，如 The guest machine entered an invalid state while waiting for it to boot. Valid states are \u0026lsquo;starting, running\u0026rsquo;. The machine is in the \u0026lsquo;poweroff\u0026rsquo; state \u0026hellip; 针对这个问题的解决办法，issue 2175 没能搞定，直接destroy重来。\n我在ubuntu trustry 64-bit 安装virtualbox时，提示依赖没装（libgl1-mesa-glx libqt4-network libqt4-opengl libqtcore4 libqtgui4 libxcursor1 libxinerama1 libxmu6 libxt6）， 使用apt-get install libqt4-opengl来安装上面的依赖，如果报错The following packages have unmet dependencies...，执行apt-get -f install 解决。\n安装 virtualbox guest additions 失败 在 3.3.2节安装Virtualbox Guest Additions时，运行./media/cdrom/VBoxLinuxAdditions.run后提示：\n1 2 3 4 5 6 The headers for the current running kernel were not found. If the following module compilation fails then this could be the reason. The missing package can be probably installed with yum install kernel-devel-2.6.32-431.el6.x86_64 Building the main Guest Additions module [FAILED] ... 关机后启动虚拟机，相应的会提示：\n1 2 3 4 5 6 7 8 9 10 11 Failed to mount folders in Linux guest. This is usually because the \u0026#34;vboxsf\u0026#34; file system is not available. Please verify that the guest additions are properly installed in the guest and can work properly. The command attempted was: mount -t vboxsf -o uid=id -u vagrant,gid=getent group vagrant | cut -d: -f3 vagrant /vagrant mount -t vboxsf -o uid=id -u vagrant,gid=id -g vagrant vagrant /vagrant The error output from the last command was: /sbin/mount.vboxsf: mounting failed with the error: No such device 原因就是旧版本卸载成功但新版本guest additions却因为yum install kernel-devel找不到软件包（No package available）失败。这种情况很少见，kernel-devel 一般都可以装上去解决。如果像我这样提示死活没这个软件包的，换个box吧！\n硬盘扩容 进入到虚拟机后，通过df -h你可能看到磁盘空间不足，需要扩容（不允许缩小空间），就可以通过以下方法完成。\n手动方式，与是否使用vagrant无关 halt关闭虚拟机虚拟机后，使用 VBoxManage modifyhd box-disk1.vdi --resize 10240 即完成修改。但是如果虚拟机磁盘格式创建时使用的是vmdk，则不支持直接vmdk格式修改，需要通过VBoxManage clonehd box_disk1.vmdk box_disk2.vdi --format VDI转换成vdi格式，然后在图形化VirtualBox中选择这个新的磁盘。另外提醒一句，这里的扩容是修改动态分配的磁盘的虚拟大小而不是实际大小，所以假如resize后的值比预分配的磁盘要小的话，会提示 Progress state: VBOX_E_NOT_SUPPORTED ..VBoxManage: error: Resize hard disk operation for this format is not implemented yet! 相关参考：Resizing disk space on vagrant box、 VirtualBox VBOX_E_NOT_SUPPORTED Drive Resize Error、Resize a Hard Disk for a Virtual Machine 。\n通过Vagrantfile指令修改\n1 2 3 config.vm.provider \u0026#34;virtualbox\u0026#34; do |vb| vb.customize \u0026#39;pre-boot\u0026#39;, [\u0026#39;modifyhd\u0026#39;, \u0026#39;e91678c3-b49b-489b-b280-4e138533252d\u0026#39;, \u0026#39;--resize\u0026#39;, \u0026#39;10240\u0026#39;] end 上面那串数字字母，是虚拟磁盘的UUID，可以先通过ps -ef|grep Virtual(Mac, virtualbox in Linux )查到虚拟机UUID，再通过VBoxManage showvminfo {VM UUID}|grep vdi看到这个 disk UUID。参考 Add some way to increase disk space from Vagrantfile。 扩容完成后把Vagrantfile中对应的部分去掉，以免每次启动都进行这步操作。\nHello Vagrant 使用 Vagrant 打造跨平台开发环境 Vagrant安装配置 Creating a Base Box 如何制作一个vagrant的base box http://blog.icodeu.com/?tag=vagrant ","permalink":"http://localhost:1313/2015/03/vagrant/","summary":"\u003ch1 id=\"1-vagrant介绍\"\u003e1. vagrant介绍\u003c/h1\u003e\n\u003ch2 id=\"11-vagrant能做什么\"\u003e1.1 vagrant能做什么\u003c/h2\u003e\n\u003cp\u003e做Web开发（java/php/python/ruby\u0026hellip;）少不了要在本地搭建好开发环境，虽然说目前各种脚本/语言都有对应的Windows版，甚至是一键安装包，但很多时候和Windows环境的兼容性（如配置文件、编译的模块）并不是那么好，麻烦的问题是实际部署的环境通常是Linux，常常还要面临着开发和部署环境不一致，上线前还要大量的调试。而如果让每个开发人员都自己去搭建本地环境，安装虚拟机、下载ISO镜像、选择规格安装创建vm、安装OS、配置，会耗费非常多的时间，如果是团队开发应该要尽量保持每个人的运行环境一致。此时vagrant正式你所需要的。不适用正式环境部署。\u003c/p\u003e","title":"在Mac在Mac/win7下上使用Vagrant打造本地开发环境"},{"content":"很久没有像今天这样坐下来写东西了，也不知道抽的什么风，大上午背着电脑跑到南山图书馆来了，可能是实在想不到大好的周末能做些什么吧。其实也倒不是心血来潮，过年回到深圳以后，很长一段时间都在思考过去，规划以后的方向，零零碎碎的记录了一些，但至今未能成文。但今天不是讲规划，而是——习惯，晚睡的习惯。\n作为刚24的满血青年，很多人可能会反驳晚一点睡算什么，此时不任性何时才任性。我倒不是说晚睡不行，问题是我因何而晚睡。最近一直在看池建强老师的《MacTalk-人生元编程》这本书，无论Apple的联合创始人沃茨，还是微软的艾伦，在初期哪一个不是没日没夜的工作。当然咱无法与这些传奇人物比拟，但至少说明熬夜，要值得，如果我是在熬夜积累自己，或能对改善以后的状况，我就觉得值得。\n可是现在我们大多数人熬夜在干嘛呢，包括我也有反思自己。\n这里先说说我的熬夜习惯从何而来吧。大学时候有电脑开始。那时候除了学业，还有部分学生工作，再有就是qq，往往深夜凌晨一两点还在挂着电脑qq，还记得太晚不睡免得有同学说，特意到了1点左右调成隐身，一边看电影，还一边刷微博。当时有个玩的较好的室友，他的原则是过点（0点）必睡，我还曾与他争论过“到点睡觉，规规矩矩”“大学时不疯狂一下没多大意义”，可是现在我回头想来我也并没有因为比他多熬几个夜而记起怎样怎样刻骨铭心的记忆。现在想来更难以理解的是，我大三大四好像竟然是因为学习任务而熬夜加班加点，甚至考研的时间里依旧毫无规律，噢不，有规律的熬夜，而且愈发厉害熬到3点。这样都能考上的话我就不用坐在这里一边埋怨一边writing了。当然还有部分属于我个人的故事……\n也就是这样习惯，毕业后延续到现在，不过较好的一点是没那么严重，平日晚一点到1点，因为考虑到第二天还要上班这样一个事实，一到周末，又毅然决然的熬到凌晨三四点，而大部分情况是在看电影电视，似乎周五的晚上是从11点开始，周六的白天从下午一点开始……\n写到这里，我倒不是谴责自己晚睡这样一个习惯，因为我相信肯定还是有很大一部分人跟我一样有着凌晨一点才睡的习惯，目前跟我一起合租的同事就是两个活生生的例子，更不是告诉自己“熬夜对身体有害”这样一个众所周知的烂道理。有些人熬夜是迫不得已，而我是因为三四年时间形成的习惯。我依然坚持大学里我对室友说的那个观点（前提是我是男的，身体也没什么旧疾），熬夜疯一下可以，问题是干什么。有多少人可以熬夜而不用考虑明天。\n最近上班没什么特别的工作，拿出不少时间去简书上看看文章，或搜到某个人博客，就闲来无事的点开Archive列表，随机点开看看。看到人家几年来做的点点滴滴，同龄人群里，我却丝毫想不起那时候我在做什么，依旧是同龄人我现在正在学的东西，人家两三年前就在用了。这也不难解释我现在的处境了。不止一次有过努力追赶别人的想法，可是晚上一回到家，不是迷上电视就是电脑手机。回家前我计划要做的事情实施了吗？这样是会有一点点累，可我24岁的年龄过着如此安逸的生活，这不是我应得的。来自家里的压力，我应该是努力在工作技能上积累，在生活情商上积累，而我没那么多时间，慢慢来…\n一个人的努力是孤独的，也是幸运的。毫无理由的晚睡，第二天迷迷糊糊起床，这不是我想要的状态。想要有所作为，可能就因为一个不经意的习惯而磨损了自己的动力。\n我想象这样一个场景：\n早上提前30分钟（七点）起来，轻轻松松的洗漱，打扮，然后从容的吃个早饭，车上看看知乎。\n上班时间，没事少刷朋友圈，早中晚看几次就行了。中午看看新闻，午休一觉，快速进入工作状态，不能再迷糊半个小时（这也成习惯了吧）。\n下午三四点上班累了，走动走动，聊聊天，打打水。眼睛酸了，滴滴眼药水（买了别浪费）\n晚上下班车上，听听歌。早的话，跟室友一起买买菜做做饭。\n10点以后是自己的时间，我可以舒舒服服的洗个澡，不开电脑，然后看一个半小时的书，或者看看新闻和喜欢的节目，再或者利用好Mac学点东西，写点东西。\n周末，九点钟起来。偶尔聚聚，逛逛，但至少拿出一天时间去图书馆，家里真不适合学习、阅读和写作。拿一个晚上去打打球，看看电影什么的。\n有人会说，不就是晚睡而已吗，至于这样吗，功利性太强了！\n就我目前各方面不稳定因素来说，我觉得有必要这样一个list。把平时和睡前那些零碎时间利用起来，安安静静的坚持多看几书，不再拘泥于自己知道的小圈子，才会发现更多机会。\n——闹钟真是一个伟大的发明，它让你放心的入睡，也无情的把你叫醒，为了减轻你的埋怨还允许你贪睡。\n","permalink":"http://localhost:1313/2015/03/sleep-late-for-what/","summary":"\u003cp\u003e很久没有像今天这样坐下来写东西了，也不知道抽的什么风，大上午背着电脑跑到南山图书馆来了，可能是实在想不到大好的周末能做些什么吧。其实也倒不是心血来潮，过年回到深圳以后，很长一段时间都在思考过去，规划以后的方向，零零碎碎的记录了一些，但至今未能成文。但今天不是讲规划，而是——习惯，晚睡的习惯。\u003c/p\u003e","title":"习惯晚睡"},{"content":"php连接oracle数据库虽然不是最佳拍档，但组内开发确实有这样需求。如果没有参考合适的文档，这个过程还是挺折磨人的，下面是一个记录，原型是国外的一篇博客 Installing PDO_OCI and OCI8 PHP extensions on CentOS 6.4 64bit。\n假设你已经安装好php的环境，php版本为5.3，要连接的oracle服务器是 11g R2，操作系统版本CentOS 6.4 x86_64。如果没有安装php，可以通过以下命令安装：\n1 2 3 # yum install php php-pdo # yum install php-devel php-pear php-fpm php-gd php-ldap \\ php-mbstring php-xml php-xmlrpc php- zlib zlib-devel bc libaio glibc 假如web服务器使用apache。\n1. 安装InstantClient instantclient是oracle的连接数据库的简单客户端，不用安装一个500Moracle客户端就可以连接oracle数据库，有windows和linux版本。从 这里 选择需要的版本下载，只需Basic和Devel两个rpm包。\n1 2 3 4 5 6 7 安装 # rpm -ivh oracle-instantclient11.2-basic-11.2.0.4.0-1.x86_64.rpm # rpm -ivh oracle-instantclient11.2-devel-11.2.0.4.0-1.x86_64.rpm 软链接 # ln -s /usr/include/oracle/11.2/client64 /usr/include/oracle/11.2/client # ln -s /usr/lib/oracle/11.2/client64 /usr/lib/oracle/11.2/client 64位系统需要创建32位的软链接，这里可能是一个遗留bug，不然后面编译会出问题。\n接下来还要让系统能够找到oracle客户端的库文件，修改LD_LIBRARY_PATH：\n1 2 3 # vi /etc/profile.d/oracle.sh export ORACLE_HOME=/usr/lib/oracle/11.2/client64 export LD_LIBRARY_PATH=$ORACLE_HOME/lib 执行source /etc/profile.d/oracle.sh使环境变量生效。\n2. 安装PDO_OCI 在连接互联网的情况下，通过pecl在线安装php的扩展非常简单，参考 How to install oracle instantclient and pdo_oci on ubuntu machine 。\n从https://pecl.php.net/package/PDO_OCI下载 PDO_OCI-1.0.tgz 源文件。\n1 2 3 # wget https://pecl.php.net/get/PDO_OCI-1.0.tgz # tar -xvf PDO_OCI-1.0.tgz # cd PDO_OCI-1.0 由于PDO_OCI很久没有更新，所以下面需要编辑ODI_OCI-1.0文件夹里的config.m4文件来让它支持11g：\n1 2 3 4 5 6 7 8 # 在第10行左右找到与下面类似的代码，添加这两行： elif test -f $PDO_OCI_DIR/lib/libclntsh.$SHLIB_SUFFIX_NAME.11.2; then PDO_OCI_VERSION=11.2 # 在第101行左右添加这几行： 11.2) PHP_ADD_LIBRARY(clntsh, 1, PDO_OCI_SHARED_LIBADD) ;; 编译安装pdo_oci扩展：（安装完成后可在 /usr/lib64/php/modules/pdo_oci.so 找到这个模块）\n1 2 3 4 $ phpize $ ./configure --with-pdo-oci=instantclient,/usr,11.2 $ make $ sudo make install 要启用这个扩展，在/etc/php.d/下新建一个pdo_oci.ini文件，内容：\n1 extension=pdo_oci.so 验证安装成功：\n1 2 3 4 5 6 7 # php -i|grep oci 看到类似下面的内容则安装成功: /etc/php.d/pdo_oci.ini, PDO drivers =\u0026gt; oci, sqlite 或 # php -m 3. 安装OCI8 从 https://pecl.php.net/package/oci8 下载oci8-2.0.8.tgz源文件。\n1 2 3 # wget https://pecl.php.net/get/oci8-2.0.8.tgz # tar -xvf oci8-2.0.8.tgz # cd oci8-2.0.8 编译安装oci8扩展：\n1 2 3 4 # phpize # ./configure --with-oci8=shared,instantclient,/usr/lib/oracle/11.2/client64/lib # make # make install 要启用这个扩展，在/etc/php.d/下新建一个oci8.ini文件，内容：\n1 extension=oci8.so 验证安装成功：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # php -i|grep oci8 /etc/php.d/oci8.ini, oci8 oci8.connection_class =\u0026gt; no value =\u0026gt; no value oci8.default_prefetch =\u0026gt; 100 =\u0026gt; 100 oci8.events =\u0026gt; Off =\u0026gt; Off oci8.max_persistent =\u0026gt; -1 =\u0026gt; -1 oci8.old_oci_close_semantics =\u0026gt; Off =\u0026gt; Off oci8.persistent_timeout =\u0026gt; -1 =\u0026gt; -1 oci8.ping_interval =\u0026gt; 60 =\u0026gt; 60 oci8.privileged_connect =\u0026gt; Off =\u0026gt; Off oci8.statement_cache_size =\u0026gt; 20 =\u0026gt; 20 OLDPWD =\u0026gt; /usr/local/src/oci8-2.0.8 _SERVER[\u0026#34;OLDPWD\u0026#34;] =\u0026gt; /usr/local/src/oci8-2.0.8 最后别忘了重启逆web服务器如apache，可以通过phpinfo()来确保扩展是否成功安装。\n4. 测试连接 在你web服务器如apache的php目录下创建testoci.php：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 \u0026lt;?php $conn = oci_connect(\u0026#39;username\u0026#39;, \u0026#39;password\u0026#39;, \u0026#39;172.29.88.178/DBTEST\u0026#39;); $stid = oci_parse($conn, \u0026#39;select table_name from user_tables\u0026#39;); oci_execute($stid); echo \u0026#34;\u0026lt;table\u0026gt;\\n\u0026#34;; while (($row = oci_fetch_array($stid, OCI_ASSOC+OCI_RETURN_NULLS)) != false) { echo \u0026#34;\u0026lt;tr\u0026gt;\\n\u0026#34;; foreach ($row as $item) { echo \u0026#34; \u0026lt;td\u0026gt;\u0026#34;.($item !== null ? htmlentities($item, ENT_QUOTES) : \u0026#34;\u0026amp;nbsp;\u0026#34;).\u0026#34;\u0026lt;/td\u0026gt;\\n\u0026#34;; } echo \u0026#34;\u0026lt;/tr\u0026gt;\\n\u0026#34;; } echo \u0026#34;\u0026lt;/table\u0026gt;\\n\u0026#34;; ?\u0026gt; 访问这个页面就应该可以得到结果了。\n参考\nInstalling PDO_OCI and OCI8 PHP extensions on CentOS 6.4 64bit 在 Linux 和 Windows 上安装 PHP 和 Oracle Instant Client php5.3安装oracle的扩展oci8与pdo_oci ","permalink":"http://localhost:1313/2015/03/install-pdo-oci-oci8-phpext/","summary":"\u003cp\u003ephp连接oracle数据库虽然不是最佳拍档，但组内开发确实有这样需求。如果没有参考合适的文档，这个过程还是挺折磨人的，下面是一个记录，原型是国外的一篇博客 \u003ca href=\"http://shiki.me/blog/installing-pdo_oci-and-oci8-php-extensions-on-centos-6-4-64bit/\"\u003eInstalling PDO_OCI and OCI8 PHP extensions on CentOS 6.4 64bit\u003c/a\u003e。\u003c/p\u003e","title":"php5.3连接oracle的客户端及pdo_oci模块安装"},{"content":"问题 在 CentOS 6.4 x86_64 上无论通过yum或rpm安装软件时，出现以下错误：\n1 2 3 4 5 yum install glibc-devel ... error: rpmts_HdrFromFdno: Header V3 RSA/SHA1 Signature, key ID c105b9de: BAD ... Problem opening package *.el6.x86_64.rpm 分析 rpm -ivh单独去安装软件也提示上面的错误。rpm -qa 无法列出系统中安装过的软件包，但许多库文件和软件命令是存在的。也尝试过rpm --rebuilddb来重建数据库，但情况依然没有得到改善（centos官网说千万不要在系统broken的情况下rebuilddb，不然有可能变成destroy）\n由上面的推断可知问题出现在rpm这个软件包管理工具本身，但此时又无法通过rpm来重新安装自己，所以只能找到具体是什么因素导致的。好在官网的这篇较新的文章正好就是解决该BUG：WARNING: nss-softokn-3.14.3-19.el6_6 updates may be broken ：\n大致是说当你使用yum update去更新你的系统时，nss-softokn、nss-softokn-freebl和其它软件一起都得到更新，所以不会有问题。但如果单独去更新某一个软件，如yum update nss-softokn或yum install \u0026lt;software\u0026gt;引起它的依赖包也升级，使得nss-softokn和nss-softokn-freebl版本不匹配，就会导致 rpm/yum 全面停止工作，表现就是上面的key .. BAD。\n解决 解决起来也很方便，首先你可以通过cat /var/log/messages|grep nss看到nss-softokn-freebl的版本：\n1 2 3 4 5 # cat /var/log/messages|grep nss-softokn Mar 2 09:56:18 poprod yum[14920]: Updated: nss-softokn-3.14.3-19.el6_6.x86_64 Mar 2 14:43:29 poprod yum[33040]: Installed: nss-softokn-freebl-3.14.3-19.el6_6.x86_64 Mar 2 14:44:14 poprod yum[33047]: Installed: nss-softokn-freebl-3.14.3-19.el6_6.x86_64 ... 下载 nss-softokn-freebl-3.14.3-19.el6_6.x86_64.rpm：\n1 wget ftp://195.220.108.108/linux/centos/6.6/updates/x86_64/Packages/nss-softokn-freebl-3.14.3-19.el6_6.x86_64.rpm 解压rpm：\n1 rpm2cpio nss-softokn-freebl-3.14.3-19.el6_6.x86_64.rpm | cpio -idmv 复制 libfreeblpriv3.* 覆盖旧的库文件：\n1 2 cp ./lib64/libfreeblpriv3.* /lib64/ cp ./lib64/libfreebl3* /lib64/ 试一下 yum install gcc 看能否正常工作，如果不行，继续下一步：\n1 2 wget http://mirror.centos.org/centos/6/os/x86_64/Packages/yum-3.2.29-60.el6.centos.noarch.rpm rpm -ivh --nodeps yum-3.2.29-60.el6.centos.noarch.rpm 应该就好了：\n1 2 rpm -qa yum install glibc-devel 参考\nhttp://unix.stackexchange.com/questions/179344/big-trouble-rpm-empty-db-install-v3-rsa-sha1-signature-key-bad-yumrepo-erro https://www.centos.org/forums/viewtopic.php?p=214791\u0026amp;f=13#p215140 http://blog.chinaunix.net/uid-26085226-id-4545167.html ","permalink":"http://localhost:1313/2015/03/rpm-yum-recover/","summary":"\u003ch1 id=\"问题\"\u003e问题\u003c/h1\u003e\n\u003cp\u003e在 CentOS 6.4 x86_64 上无论通过yum或rpm安装软件时，出现以下错误：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e5\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-go\" data-lang=\"go\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nx\"\u003eyum\u003c/span\u003e \u003cspan class=\"nx\"\u003einstall\u003c/span\u003e \u003cspan class=\"nx\"\u003eglibc\u003c/span\u003e\u003cspan class=\"o\"\u003e-\u003c/span\u003e\u003cspan class=\"nx\"\u003edevel\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e...\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kt\"\u003eerror\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nx\"\u003erpmts_HdrFromFdno\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nx\"\u003eHeader\u003c/span\u003e \u003cspan class=\"nx\"\u003eV3\u003c/span\u003e \u003cspan class=\"nx\"\u003eRSA\u003c/span\u003e\u003cspan class=\"o\"\u003e/\u003c/span\u003e\u003cspan class=\"nx\"\u003eSHA1\u003c/span\u003e \u003cspan class=\"nx\"\u003eSignature\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e \u003cspan class=\"nx\"\u003ekey\u003c/span\u003e \u003cspan class=\"nx\"\u003eID\u003c/span\u003e \u003cspan class=\"nx\"\u003ec105b9de\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e \u003cspan class=\"nx\"\u003eBAD\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"o\"\u003e...\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nx\"\u003eProblem\u003c/span\u003e \u003cspan class=\"nx\"\u003eopening\u003c/span\u003e \u003cspan class=\"kn\"\u003epackage\u003c/span\u003e \u003cspan class=\"o\"\u003e*\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nx\"\u003eel6\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nx\"\u003ex86_64\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"nx\"\u003erpm\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003ch2 id=\"分析\"\u003e分析\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003erpm -ivh\u003c/code\u003e单独去安装软件也提示上面的错误。\u003ccode\u003erpm -qa\u003c/code\u003e 无法列出系统中安装过的软件包，但许多库文件和软件命令是存在的。也尝试过\u003ccode\u003erpm --rebuilddb\u003c/code\u003e来重建数据库，但情况依然没有得到改善（centos官网说千万不要在系统broken的情况下rebuilddb，不然有可能变成destroy）\u003c/p\u003e","title":"rpm或yum安装软件提示error-rpmts_HdrFromFdno-key-ID-BAD"},{"content":"今天因为使用百度云同步盘出错，导致我的文件永远丢失，忍无可忍又给“百度倾听”发了条牢骚。\n事情是这样的，我在 MarkdownPad2 修改最近写的3篇文章，文章正好在百度云同步盘的同步目录下，因为一直养成了一边编辑一边Ctrl+S保存的习惯，难道由于这3篇文章反复修改，百度云同步盘竟然支撑不住？弹出窗口大概是说同步出错，需要重启应用（近期出现过好几次），随手点了个确定，MarkdownPad2提示我当前编辑的文件不存在，是否继续保留在窗口，反正文章修改完了，也没多想，duang，悲剧发生了，两个小星期的成果都不见了。还在失落当中……\n为什么叫“又”呢，因为在去年1月份的时候也在手机上使用过百度云同步盘，不记得是同步什么，也不是文件丢失。Android版有一个“仅在wifi下同步”的选项，像我这种3G流量哪够同步文件使用啊，当时还觉得挺贴心的，开着应用在后台一上午，中午吃饭拿起手看时，尼玛提示我本月流量已超50多M，也给百度意见反馈写了200多字的声讨书，结果几天后回复的内容不知是从哪摘抄的一段无价值的内容。还有一次是登录注销的问题，20多天后才回复邮件，结尾还不忘带上小米的广告，简直让用户抓狂。（邮件正文就不贴了，每每出现这样的问题都十分狂躁，不少脏话）\n我想这样的同步工具最多对于百度是个附属产品，并不能带来多大收益，在团队投入上并不尽心。给我自己的教诲是，选择产品或工具，不能因为公司名声大而就给予信任，一个公司能够把一件事情做好了就会迎来不错的口碑，选择它的主打产品。说到这里不得不继续吐槽了，百度搜索应该是它的命脉了，但对于我用习惯了google来说，没有条件不得不使用百度搜索，索引到的结果，唉~ 大！惊！失！色！\n如此种种，不得不让我怀疑百度其他产品的使用问题。\n无奈 Dropbox 在国内被封，也只有偶尔在家用电脑时打开VPN才能访问，被百度云同步盘伤过那么多次心之后，感觉再也不会用了，还是老老实实挂VPN吧，虽麻烦但也免去了不必要的担忧。\n","permalink":"http://localhost:1313/2015/02/baidu-complain/","summary":"\u003cp\u003e今天因为使用百度云同步盘出错，导致我的文件永远丢失，忍无可忍\u003cstrong\u003e又\u003c/strong\u003e给“百度倾听”发了条牢骚。\u003c/p\u003e\n\u003cp\u003e事情是这样的，我在 MarkdownPad2 修改最近写的3篇文章，文章正好在百度云同步盘的同步目录下，因为一直养成了一边编辑一边\u003ccode\u003eCtrl+S\u003c/code\u003e保存的习惯，难道由于这3篇文章反复修改，百度云同步盘竟然支撑不住？弹出窗口大概是说同步出错，需要重启应用（近期出现过好几次），随手点了个确定，MarkdownPad2提示我当前编辑的文件不存在，是否继续保留在窗口，反正文章修改完了，也没多想，duang，悲剧发生了，两个小星期的成果都不见了。还在失落当中……\u003c/p\u003e","title":"我为何厌恶百度的产品"},{"content":"本文通过实际操作来演示Kubernetes的使用，因为环境有限，集群部署在本地3个ubuntu上，主要包括如下内容：\n部署环境介绍，以及Kubernetes集群逻辑架构 安装部署Open vSwitch跨机器容器通信工具 安装部署Etcd和Kubernetes的各大组件 演示Kubernetes管理容器和服务 关于 Kubernetes 系统架构及组件介绍见这里。\n1. 部署环境及架构 vSphere: 5.1 操作系统: ubuntu 14.04 x86_64 Open vSwith版本: 2.0.2 Kubernetes: v0.7.2 Etcd版本: 2.0.0-rc.1 Docker版本: 1.4.1 服务器信息： Role Hostname IP Address APIServer kubernetes 172.29.88.206 Minion minion1 172.29.88.207 Minion minion2 172.29.88.208 在详细介绍部署Kubernetes集群前，先给大家展示下集群的逻辑架构。从下图可知，整个系统分为两部分，第一部分是Kubernetes APIServer，是整个系统的核心，承担集群中所有容器的管理工作；第二部分是minion，运行Container Daemon，是所有容器栖息之地，同时在minion上运行Open vSwitch程序，通过GRE Tunnel负责minions之间Pod的网络通信工作。 2. 安装Open vSwitch及配置GRE 为了解决跨minion之间Pod的通信问题，我们在每个minion上安装Open vSwtich，并使用GRE或者VxLAN使得跨机器之间P11od能相互通信，本文使用GRE，而VxLAN通常用在需要隔离的大规模网络中。对于Open vSwitch的介绍请参考另一篇文章Open vSwitch。\n1 sudo apt-get install openvswitch-switch bridge-utils 安装完Open vSwitch和桥接工具后，接下来便建立minion0和minion1之间的隧道。首先在minion1和minion2上分别建立OVS Bridge：\n1 # ovs-vsctl add-br obr0 接下来建立gre，并将新建的gre0添加到obr0，在minion1上执行如下命令：\n1 # ovs-vsctl add-port obr0 gre0 -- set Interface gre0 type=gre options:remote_ip=172.29.88.208 上面的remoute_ip是另一台服务minion2上的对外IP。\n在minion2上执行：\n1 # ovs-vsctl add-port obr0 gre0 -- set Interface gre0 type=gre options:remote_ip=172.29.88.207 至此，minion1和minion2之间的隧道已经建立。然后我们在minion1和minion2上创建Linux网桥kbr0替代Docker默认的docker0（我们假设minion1和minion2都已安装Docker），设置minion1的kbr0的地址为172.17.1.1/24， minion2的kbr0的地址为172.17.2.1/24，并添加obr0为kbr0的接口，以下命令在minion1和minion2上执行：\n1 2 3 4 5 # brctl addbr kbr0 //创建linux bridge代替docker0 # brctl addif kbr0 obr0 //添加obr0为kbr0的接口 # ip link set dev docker0 down //设置docker0为down状态 # ip link del dev docker0 //删除docker0，可选 查看这些接口的状态：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # service openvswitch-switch status # ovs-vsctl show 9d248403-943c-41c0-b2d0-3f9b130cdd3f Bridge \u0026#34;obr0\u0026#34; Port \u0026#34;gre0\u0026#34; Interface \u0026#34;gre0\u0026#34; type: gre options: {remote_ip=\u0026#34;172.29.88.207\u0026#34;} Port \u0026#34;obr0\u0026#34; Interface \u0026#34;obr0\u0026#34; type: internal ovs_version: \u0026#34;2.0.2\u0026#34; # brctl show bridge name\tbridge id\tSTP enabled\tinterfaces docker0\t8000.56847afe9799\tno\tkbr0\t8000.620ff7ee9c49\tno\tobr0 为了使新建的kbr0在每次系统重启后任然有效，我们在minion1的/etc/network/interfaces文件中追加内容如下：（在CentOS上会有些不一样）\n1 2 3 4 5 6 7 # vi /etc/network/interfaces auto kbr0 iface kbr0 inet static address 172.17.1.1 netmask 255.255.255.0 gateway 172.17.1.0 dns-nameservers 172.31.1.1 同样在minion2上追加类似内容，只需修改address为172.17.2.1和gateway为172.17.2.0即可，然后执行ip link set dev kbr0 up，你能在minion1和minion2上发现kbr0都设置了相应的IP地址。为了验证我们创建的隧道是否能通信，我们在minion1和minion2上相互ping对方kbr0的IP地址，从下面的结果发现是不通的，经查找这是因为在minion1和minion2上缺少访问172.17.1.1和172.17.2.1的路由，因此我们需要添加路由保证彼此之间能通信：\n1 2 3 4 5 minion1上执行: # ip route add 172.17.2.0/24 via 172.29.88.208 dev eth0 minion2上执行: # ip route add 172.17.1.0/24 via 172.29.88.207 dev eth0 现在可以ping通对方的虚拟网络了：\n1 2 3 4 5 6 7 8 $ ping 172.17.2.1 PING 172.17.2.1 (172.17.2.1) 56(84) bytes of data. 64 bytes from 172.17.2.1: icmp_seq=1 ttl=64 time=0.334 ms 64 bytes from 172.17.2.1: icmp_seq=2 ttl=64 time=0.253 ms ^C --- 172.17.2.1 ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 999ms rtt min/avg/max/mdev = 0.253/0.293/0.334/0.043 ms 下面安装 Kubernetes APIServer 及kubelet、proxy等服务。\n3. 安装Kubernetes APIServer 3.1 下载安装kubernetes各组件 可以自己从源码编译kubernetes（需要安装golang环境），也可以从GitHub Kubernetes repo release page.选择编译好的二进制版本（v0.7.2）下载，为了方便后面启动或关闭kubernetes组件，我们同时下载二进制包和源码包：\n1 2 3 4 # cd /usr/local/src # wget https://github.com/coreos/etcd/releases/download/v2.0.0-rc.1/etcd-v2.0.0-rc.1-linux-amd64.tar.gz # wget https://github.com/GoogleCloudPlatform/kubernetes/releases/download/v0.7.2/kubernetes.tar.gz # wget https://github.com/GoogleCloudPlatform/kubernetes/archive/v0.7.2.zip 然后解压下载的kubernetes和etcd包，并在kubernetes(minion1)、minion2上创建目录/opt/bin\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # mkdir /opt/bin //这一步APIserver和所有minions上都要创建 解压kubernetes src# tar xf kubernetes.tar.gz # ll drwxr-xr-x 3 501 staff 4096 Dec 19 02:32 etcd-v2.0.0-rc.1-linux-amd64/ -rw-r--r-- 1 root root 6223584 Jan 6 14:39 etcd-v2.0.0-rc.1-linux-amd64.tar.gz drwxr-xr-x 7 root root 4096 Nov 20 06:35 kubernetes/ -rw-r--r-- 1 root root 82300483 Jan 6 14:37 kubernetes.tar.gz -rw-r--r-- 1 root root 9170754 Jan 9 14:47 v0.7.2.zip # cd kubernetes/server # tar xf kubernetes-server-linux-amd64.tar.gz # cd kubernetes/server/bin/ APIserver本身需要的是kube-apiserver kube-scheduler kube-controller-manager kubecfg四个 # cp -a kube* /opt/bin/ 把proxy和kubelet复制到其他minions，确保这些文件都是可执行的 # scp kube-proxy kubelet root@172.29.88.207:/opt/bin # scp kube-proxy kubelet root@172.29.88.208:/opt/bin /opt/bin并没有加入系统PATH，所以kube-apiserver -version是看不到结果，但在后面配置的服务中会自动加入（PATH=$PATH:/opt/bin）。\n3.2 解压安装etcd etcd在这里的作用是服务发现存储仓库，通俗的来讲就是记录kubernetes启动了多少pods、services、replicationController以及它们的信息等，详细介绍见这里。此外版本2.0与v0.4.6在启动参数上的写法有一定差别。\n# tar xf etcd-v2.0.0-rc.1-linux-amd64.tar.gz \u0026amp;\u0026amp; cd etcd-v2.0.0-rc.1-linux-amd64/ # cp -a etcd etcdctl /opt/bin 3.3 配置kube-apiserver等为upstart脚本启动 这一步主要是为了管理kube-apiserver等进程的方便，避免每次都手动启动各服务、添加冗长的启动参数选项，而且在不同的系统平台下kubernetes已经提供了相应的工具。\n1 2 3 4 5 6 7 8 9 10 11 12 解压kubernetes*源码包* src# unzip xf v0.7.2.zip \u0026amp;\u0026amp; cd kubernetes-0.7.2 这里比较奇怪的是最新release版本源码的cluster目录下是有ubuntu子目录的，但latest之前的下载后没有ubuntu目录 # cd cluster/ubuntu # ll .. 2 root root 4096 Jan 8 17:39 default_scripts/ 各组件默认启动参数 .. 2 root root 4096 Jan 8 17:39 init_conf/ upstart启动方式 .. 2 root root 4096 Jan 8 17:39 initd_scripts/ service启动方式，与upstart选其一 .. 1 root root 1213 Jan 8 08:53 util.sh* # ./util.sh util.sh脚本就是把当前目录下的service/upstart脚本、默认参数配置文件复制到/etc下，可以通过service etcd start的形式管理kubernetes。由于kubernetes更新速度极快，项目的文件和目录结构经常变化，请找准文件。接下来我们需要修改那些只适合本机使用的默认参数。（请注意备份先，因为后面能否正常跨机器管理docker与这些选项有关，特别是IP）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 etcd官方建议使用新的2379端口代替4001 # vi /etc/default/etcd ETCD_OPTS=\u0026#34;-listen-client-urls=http://0.0.0.0:4001\u0026#34; # vi /etc/default/kube-apiserver KUBE_APISERVER_OPTS=\u0026#34;--address=0.0.0.0 \\ --port=8080 \\ --etcd_servers=http://127.0.0.1:4001 \\ --logtostderr=true \\ --portal_net=11.1.1.0/24\u0026#34; # vi /etc/default/kube-scheduler KUBE_SCHEDULER_OPTS=\u0026#34;--logtostderr=true \\ --master=127.0.0.1:8080\u0026#34; # vi /etc/default/kube-controller-manager KUBE_CONTROLLER_MANAGER_OPTS=\u0026#34;--master=127.0.0.1:8080 \\ --machines=172.29.88.207,172.29.88.208 \\ --logtostderr=true\u0026#34; * 复制kubelet、kube-proxy等到minion1： # scp /etc/default/{kubelet,kube-proxy} 172.29.88.207:/etc/default/ # scp /etc/init.d/{kubelet,kube-proxy} 172.29.88.207:/etc/init.d/ # scp /etc/init/{kubelet.conf,kube-proxy.conf} 172.29.88.207:/etc/init/ 1 2 3 4 5 6 7 8 9 10 11 12 13 * 在minion1端进行 # vi /etc/default/kubelet KUBELET_OPTS=\u0026#34;--address=172.29.88.207 \\ --port=10250 \\ --hostname_override=172.29.88.207 \\ --etcd_servers=http://172.29.88.206:4001 \\ --logtostderr=true\u0026#34; # vi /etc/default/kube-proxy KUBE_PROXY_OPTS=\u0026#34;--etcd_servers=http://172.29.88.207:4001 \\ --logtostderr=true\u0026#34; (对minion2重复上面 * 两个步骤，把上面.207改成.208) 上面的各配置文件就是对应命令的选项，具体含义使用-h。这里只简单说明：\netcd服务APIserver和minions都要访问，也就是其他组件的--etcd_servers值（带http前缀） kube-apiserver监听在8080端口，也就是其他组件的--master值；--portal_net地址段不能与docker的桥接网卡kbr0重复，指定docker容器的IP段 etcd、kube-apiserver、kube-scheduler、kube-controller-manager运行在apiserver（服务）端，kubelet、kube-proxy运行在minion（客户端） kube-controller-manager使用预先定义pod模板创建pods，保证指定数量的replicas在运行，默认监听在master的127.0.0.1:10252 kubelet默认监听端口10250，也正是apiserver的--kubelet_port的值 3.4 启动 重启docker 接下来重启minion1、minion2上的Docker daemon（注意使用的网桥）：\n# docker -d -b kbr0 由于后面的测试可能需要在线下载images，所以如果你的服务器无法访问docker hub，上面启动时记得设置HTTP_PROXY代理。\n启动apiserver\n# service etcd start # service kube-apiserver start kube-apiserver启动后会自动运行kube-scheduler、kube-controller-manager，但修改配置后依然可以单独重启各个服务如service kube-contoller-manager restart。这些服务的日志可以从/var/log/upstart/kube*找到。\n在minion1、minion2上启动kubelet、kube-proxy：\n# service kubelet start # service kube-proxy start 4. 使用kubecfg部署测试应用 为了方便，我们使用Kubernetes提供的例子Guestbook（下载的源码example目录下可以找到）来演示Kubernetes管理跨机器运行的容器，下面我们根据Guestbook的步骤创建容器及服务。在下面的过程中如果是第一次操作，可能会有一定的等待时间，状态处于pending，这是因为第一次下载images需要一段时间。\n4.1 创建redis-master Pod和redis-master服务 配置管理操作都在apiserver上执行，并且都是基于实现编写好的json格式。涉及到下载docker镜像的部分，如果没有外网，可能需要修改image的值或使用自己搭建的docker-registry：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # cd kubernetes-0.7.2/examples/guestbook/ # cat redis-master.json { \u0026#34;id\u0026#34;: \u0026#34;redis-master\u0026#34;, \u0026#34;kind\u0026#34;: \u0026#34;Pod\u0026#34;, \u0026#34;apiVersion\u0026#34;: \u0026#34;v1beta1\u0026#34;, \u0026#34;desiredState\u0026#34;: { \u0026#34;manifest\u0026#34;: { \u0026#34;version\u0026#34;: \u0026#34;v1beta1\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;redis-master\u0026#34;, \u0026#34;containers\u0026#34;: [{ \u0026#34;name\u0026#34;: \u0026#34;master\u0026#34;, \u0026#34;image\u0026#34;: \u0026#34;dockerfile/redis\u0026#34;, \u0026#34;cpu\u0026#34;: 100, \u0026#34;ports\u0026#34;: [{ \u0026#34;containerPort\u0026#34;: 6379, \u0026#34;hostPort\u0026#34;: 6379 }] }] } }, \u0026#34;labels\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;redis-master\u0026#34; } } # kubecfg -h http://172.29.88.206:8080 -c redis-master.json create pods # kubecfg -h http://172.29.88.206:8080 -c redis-master-service.json create services 完成上面的操作后，我们可以看到如下redis-master Pod被调度到172.29.88.207： （下面直接list实际上是省略了-h http://127.0.0.1:8080）\n1 2 3 4 5 6 7 8 9 10 11 12 # kubecfg list pods Name Image(s) Host Labels Status ---------- ---------- ---------- ---------- ---------- redis-master dockerfile/redis 172.29.88.207/ name=redis-master Running 查看services： # kubecfg list services Name Labels Selector IP Port ---------- ---------- ---------- ---------- ------ kubernetes component=apiserver,provider=kubernetes 11.1.1.233 443 kubernetes-ro component=apiserver,provider=kubernetes 11.1.1.204 80 redis-master name=redis-master name=redis-master 11.1.1.175 6379 发现除了redis-master的服务之外，还有两个Kubernetes系统默认的服务kubernetes-ro和kubernetes。而且我们可以看到每个服务都有一个服务IP及相应的端口，对于服务IP，是一个虚拟地址，根据apiserver的portal_net选项设置的CIDR表示的IP地址段来选取，在我们的集群中设置为11.1.1.0/24。为此每新创建一个服务，apiserver都会在这个地址段中随机选择一个IP作为该服务的IP地址，而端口是事先确定的。对redis-master服务，其服务地址为11.1.1.175，端口为6379，与minion主机映射的端口也是6379。\n4.2 创建redis-slave Pod和redis-slave服务 1 2 # kubecfg -h http://172.29.88.206:8080 -c redis-slave-controller.json create replicationControllers # kubecfg -h http://172.29.88.206:8080 -c redis-slave-service.json create services 注意上面的redis-slave-controller.json有个\u0026quot;replicas\u0026quot;: 2、\u0026quot;hostPort\u0026quot;: 6380，因为我们的集群中只有2个minions，如果为3的话，就会导致有2个Pod会调度到同一台minion上，产生端口冲突，有一个Pod会一直处于pending状态，不能被调度（可以通过日志看到原因）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # kubecfg list pods Name Image(s) Host Labels Status ---------- ---------- ---------- ---------- -------- 2c2a06...c2971614d brendanburns/redis-slave 172.29.88.208/ name=redisslave,uses=redis-master Running 2c2ad5...c2971614d brendanburns/redis-slave 172.29.88.207/ name=redisslave,uses=redis-master Running redis-master dockerfile/redis 172.29.88.207/ name=redis-master Running # kubecfg list services Name Labels Selector IP Port ---------- ---------- ---------- ---------- -------- kubernetes component=apiserver,provider=kubernetes 11.1.1.233 443 kubernetes-ro component=apiserver,provider=kubernetes 11.1.1.204 80 redis-master name=redis-master name=redis-master 11.1.1.175 6379 redisslave name=redisslave name=redisslave 11.1.1.131 6379 4.3 创建Frontend Pod和Frontend服务 前面2步都是guestbook的redis数据存储，现在部署应用：(修改frontend-controller.json的replicas为2)\n1 2 # kubecfg -h http://172.29.88.206:8080 -c frontend-controller.json create replicationControllers # kubecfg -h http://172.29.88.206:8080 -c frontend-service.json create services 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # kubecfg -h http://172.29.88.206:8080 list pods Name Image(s) Host Labels Status ---------- ---------- ---------- ---------- ---------- 2c2a06...c2971614d brendanburns/redis-slave 172.29.88.208/ name=redisslave,uses=redis-master Running 2c2ad5...c2971614d brendanburns/redis-slave 172.29.88.207/ name=redisslave,uses=redis-master Running d87744...c2971614d kubernetes/example-guestbook-php-redis 172.29.88.207/ name=frontend,uses=redisslave,redis-master Running redis-master dockerfile/redis 172.29.88.207/ name=redis-master Running 1370b9...c2971614d kubernetes/example-guestbook-php-redis 172.29.88.208/ name=frontend,uses=redisslave,redis-master Running # kubecfg -h http://172.29.88.206:8080 list services Name Labels Selector IP Port ---------- ---------- ---------- ---------- ------ redis-master name=redis-master name=redis-master 11.1.1.175 6379 redisslave name=redisslave name=redisslave 11.1.1.131 6379 frontend name=frontend name=frontend 11.1.1.124 80 kubernetes component=apiserver,provider=kubernetes 11.1.1.233 443 kubernetes-ro component=apiserver,provider=kubernetes 11.1.1.204 80 通过查看可知 Frontend Pod 也被调度到两台minion，服务IP为11.1.1.124，端口是80，映射到外面minions的端口为8000（可以通过ps -ef|grep docker-proxy发现）。\n4.4 其他操作（更新、删除、查看） 删除 除此之外，你可以删除Pod、Service，如删除minion1上的redis-slave Pod：\nkubecfg -h http://172.29.88.206:8080 delete pods/2c2ad505-96fd-11e4-9c0b-000c2971614d Status ---------- Success 格式为services/服务Name、pods/pods名字，不必关心从哪个minion上删除了。需要提醒的是，这里pods的replcas为2，所以即使删除了这个pods，kubernetes为自动为你重新启动一个。\n更新 更新ReplicationController的Replicas数量：\n1 2 3 4 5 # kubecfg list replicationControllers Name Image(s) Selector Replicas ---------- ---------- ---------- ---------- frontendController kubernetes/example-guestbook-php-redis name=frontend 2 redisSlaveController brendanburns/redis-slave name=redisslave 2 把frontendController的Replicas更新为1，则这行如下命令，然后再通过上面的命令查看frontendController信息，发现Replicas已变为1：\nkubecfg -h http://172.29.88.206:8080 resize frontendController 1 查看 Kubernetes内置提供了一个简单的UI来查看pods、services、replicationControllers，但极其简陋，暂时可以忽略，访问http://172.29.88.206:8080/static/#/groups//selector/： 在浏览器访问api：http://172.29.88.206:8080/api/v1beta1/replicationControllers 。 etcd做服务发现，可以通过api访问其内容，访问http://172.29.88.206:4001/v2/keys/registry/services/endpoints/default ，得到json格式数据。\n4.5 演示guestbook 通过上面的结果可知当前提供前端服务的PHP和提供数据存储的后端服务Redis master的Pod分别运行在172.29.88.208和172.29.88.207上，即容器运行在不同主机上，还有Redis slave也运行在两台不同的主机上，它会从Redis master同步前端写入Redis master的数据。下面我们从两方面验证Kubernetes能提供跨机器间容器的通信：\n浏览器访问留言簿 在浏览器打开http://${IPAddress}:8000，IPAddress为PHP容器运行的minion的IP地址，其暴漏的端口为8000，这里IP_Address为172.29.88.208。打开浏览器会显示如下信息： 你可以输入信息并提交，然后Submit按钮下方会显示你输入的信息： 由于前端PHP容器和后端Redis master容器分别在两台minion上，因此PHP在访问Redis master服务时一定得跨机器通信，可见Kubernetes的实现方式避免了用link只能在同一主机上实现容器间通信的缺陷。\n从redis后端验证 我们从后端数据层验证不同机器容器间的通信。根据上面的输出结果发现Redis slave和Redis master分别调度到两台不同的minion上，在172.29.88.207主机上执行docker exec -ti e5941db7e424 /bin/sh，e5941db7e424 master的容器ID（docker ps），进入容器后通过redis-cli命令查看从浏览器输入的信息如下：\n1 2 3 4 5 6 # docker exec -ti e5941db7e424 /bin/sh # redis-cli 127.0.0.1:6379\u0026gt; keys * 1) \u0026#34;messages\u0026#34; 127.0.0.1:6379\u0026gt; get messages \u0026#34;,Hi, Sean,Kubernetes,,llll,abc,\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\xd4\\xb0\\xef\\xbf\\xbd,sync info,\u0026#34; 类似可以在172.29.88.208的redis-slave上看到同样的内容。由此可见Redis master和Redis slave之间数据同步正常，OVS GRE隧道技术使得跨机器间容器正常通信。\n4.6 排错提示 所有的kubelet必须起来，否则报错F0319 16:56:08.058335 9960 kubecfg.go:438] Got request error: The requested resource does not exist. 必须使用-b启动docker，否则无法访问8000端口，redis-slave也没同步 注意pods一直处于Pending或Failed状态时去apiserver或其他组件日志里查看错误，是否是由于端口绑定冲突导致。 参考\nCentOS 7实战Kubernetes部署\nkubernetes-examples-guestbook\ngetting_started_guides-ubuntu_single_node\n基于kubernetes构建Docker集群管理详解\n","permalink":"http://localhost:1313/2015/02/docker-kubernetes-deploy2/","summary":"\u003cp\u003e本文通过实际操作来演示Kubernetes的使用，因为环境有限，集群部署在本地3个ubuntu上，主要包括如下内容：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e部署环境介绍，以及Kubernetes集群逻辑架构\u003c/li\u003e\n\u003cli\u003e安装部署Open vSwitch跨机器容器通信工具\u003c/li\u003e\n\u003cli\u003e安装部署Etcd和Kubernetes的各大组件\u003c/li\u003e\n\u003cli\u003e演示Kubernetes管理容器和服务\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e关于 Kubernetes 系统架构及组件介绍见\u003ca href=\"http://xgknight.com/2015/02/03/docker-kubernetes-arch-introduction/\"\u003e这里\u003c/a\u003e。\u003c/p\u003e","title":"在ubuntu上部署Kubernetes管理docker集群示例"},{"content":"本文来源于Infoq的一篇文章（见参考部分），并在难懂的地方自己理解的基础上做了修改。实际在ubuntu上部署 kubernetes 操作另见 文章 。\nTogether we will ensure that Kubernetes is a strong and open container management framework for any application and in any environment, whether in a private, public or hybrid cloud. \u0026ndash;Urs Hölzle, Google\nKubernetes 作为Docker生态圈中重要一员，是Google多年大规模容器管理技术的开源版本，是产线实践经验的最佳表现。如Urs Hölzle所说，无论是公有云还是私有云甚至混合云，Kubernetes将作为一个为任何应用，任何环境的容器管理框架无处不在。正因为如此，目前受到各大巨头及初创公司的青睐，如Microsoft、VMWare、Red Hat、CoreOS、Mesos等，纷纷加入给Kubernetes贡献代码。随着Kubernetes社区及各大厂商的不断改进、发展，Kuberentes将成为容器管理领域的领导者。\n接下来我们一起探索Kubernetes是什么、能做什么以及怎么做。\n1. 什么是Kubernetes Kubernetes是Google开源的容器集群管理系统，使用Golang开发，其提供应用部署、维护、扩展机制等功能，利用Kubernetes能方便地管理跨机器运行容器化的应用，其主要功能如下：\n使用Docker对应用程序包装(package)、实例化(instantiate)、运行(run)。 以集群的方式运行、管理跨机器的容器。 解决Docker跨机器容器之间的通讯问题。 Kubernetes的自我修复机制使得容器集群总是运行在用户期望的状态。 当前Kubernetes支持GCE、vShpere、CoreOS、OpenShift、Azure等平台，除此之外，也可以直接运行在物理机上。\n这个官方给出的完整的架构图：（可在新标签页打开查看大图）\n2. Kubernetes的主要概念 2.1 Pods 在Kubernetes系统中，调度的最小颗粒不是单纯的容器，而是抽象成一个Pod，Pod是一个可以被创建、销毁、调度、管理的最小的部署单元。把相关的一个或多个容器（Container）构成一个Pod，通常Pod里的容器运行相同的应用。Pod包含的容器运行在同一个Minion(Host)上，看作一个统一管理单元，共享相同的volumes和network namespace/IP和Port空间。\n2.2 Services Services也是Kubernetes的基本操作单元，是真实应用服务的抽象，每一个服务后面都有很多对应的容器来支持，通过Proxy的port和服务selector决定服务请求传递给后端提供服务的容器，对外表现为一个单一访问地址，外部不需要了解后端如何运行，这给扩展或维护后端带来很大的好处。\n这一点github上的官网文档 services.md 讲的特别清楚。\n2.3 Replication Controllers Replication Controller，理解成更复杂形式的pods，它确保任何时候Kubernetes集群中有指定数量的pod副本(replicas)在运行，如果少于指定数量的pod副本(replicas)，Replication Controller会启动新的Container，反之会杀死多余的以保证数量不变。Replication Controller使用预先定义的pod模板创建pods，一旦创建成功，pod 模板和创建的pods没有任何关联，可以修改 pod 模板而不会对已创建pods有任何影响，也可以直接更新通过Replication Controller创建的pods。对于利用 pod 模板创建的pods，Replication Controller根据 label selector 来关联，通过修改pods的label可以删除对应的pods。Replication Controller主要有如下用法：\nRescheduling 如上所述，Replication Controller会确保Kubernetes集群中指定的pod副本(replicas)在运行， 即使在节点出错时。\nScaling 通过修改Replication Controller的副本(replicas)数量来水平扩展或者缩小运行的pods。\nRolling updates Replication Controller的设计原则使得可以一个一个地替换pods来滚动更新（rolling updates）服务。\nMultiple release tracks 如果需要在系统中运行multiple release的服务，Replication Controller使用labels来区分multiple release tracks。\n以上三个概念便是用户可操作的REST对象。Kubernetes以RESTfull API形式开放的接口来处理。\n2.4 Labels service和replicationController只是建立在pod之上的抽象，最终是要作用于pod的，那么它们如何跟pod联系起来呢？这就引入了label的概念：label其实很好理解，就是为pod加上可用于搜索或关联的一组key/value标签，而service和replicationController正是通过label来与pod关联的。为了将访问Service的请求转发给后端提供服务的多个容器，正是通过标识容器的labels来选择正确的容器；Replication Controller也使用labels来管理通过 pod 模板创建的一组容器，这样Replication Controller可以更加容易，方便地管理多个容器。\n如下图所示，有三个pod都有label为\u0026quot;app=backend\u0026quot;，创建service和replicationController时可以指定同样的label:\u0026ldquo;app=backend\u0026rdquo;，再通过label selector机制，就将它们与这三个pod关联起来了。例如，当有其他frontend pod访问该service时，自动会转发到其中的一个backend pod。 3. Kubernetes构件 Kubenetes整体框架如下图，主要包括kubecfg、Master API Server、Kubelet、Minion(Host)以及Proxy。 3.1 Master Master定义了Kubernetes 集群Master/API Server的主要声明，包括Pod Registry、Controller Registry、Service Registry、Endpoint Registry、Minion Registry、Binding Registry、RESTStorage以及Client, 是client(Kubecfg)调用Kubernetes API，管理Kubernetes主要构件Pods、Services、Minions、容器的入口。Master由API Server、Scheduler以及Registry等组成。从下图可知Master的工作流主要分以下步骤：\nKubecfg将特定的请求，比如创建Pod，发送给Kubernetes Client。 Kubernetes Client将请求发送给API server。 API Server根据请求的类型，比如创建Pod时storage类型是pods，然后依此选择何种REST Storage API对请求作出处理。 REST Storage API对的请求作相应的处理。 将处理的结果存入高可用键值存储系统Etcd中。 在API Server响应Kubecfg的请求后，Scheduler会根据Kubernetes Client获取集群中运行Pod及Minion信息。 依据从Kubernetes Client获取的信息，Scheduler将未分发的Pod分发到可用的Minion节点上。 下面是Master的主要构件的详细介绍。\n3.1.1 Minion Registry Minion Registry负责跟踪Kubernetes 集群中有多少Minion(Host)。Kubernetes封装Minion Registry成实现Kubernetes API Server的RESTful API接口REST，通过这些API，我们可以对Minion Registry做Create、Get、List、Delete操作，由于Minon只能被创建或删除，所以不支持Update操作，并把Minion的相关配置信息存储到etcd。除此之外，Scheduler算法根据Minion的资源容量来确定是否将新建Pod分发到该Minion节点。\n可以通过curl http://{master-apiserver-ip}:4001/v2/keys/registry/minions/来验证etcd中存储的内容。\n3.1.2 Pod Registry Pod Registry负责跟踪Kubernetes集群中有多少Pod在运行，以及这些Pod跟Minion是如何的映射关系。将Pod Registry和Cloud Provider信息及其他相关信息封装成实现Kubernetes API Server的RESTful API接口REST。通过这些API，我们可以对Pod进行Create、Get、List、Update、Delete操作，并将Pod的信息存储到etcd中，而且可以通过Watch接口监视Pod的变化情况，比如一个Pod被新建、删除或者更新。\n3.1.3 Service Registry Service Registry负责跟踪Kubernetes集群中运行的所有服务。根据提供的Cloud Provider及Minion Registry信息把Service Registry封装成实现Kubernetes API Server需要的RESTful API接口REST。利用这些接口，我们可以对Service进行Create、Get、List、Update、Delete操作，以及监视Service变化情况的watch操作，并把Service信息存储到etcd。\n3.1.4 Controller Registry Controller Registry负责跟踪Kubernetes集群中所有的Replication Controller，Replication Controller维护着指定数量的pod 副本(replicas)拷贝，如果其中的一个容器死掉，Replication Controller会自动启动一个新的容器，如果死掉的容器恢复，其会杀死多出的容器以保证指定的拷贝不变。通过封装Controller Registry为实现Kubernetes API Server的RESTful API接口REST， 利用这些接口，我们可以对Replication Controller进行Create、Get、List、Update、Delete操作，以及监视Replication Controller变化情况的watch操作，并把Replication Controller信息存储到etcd。\n3.1.5 Endpoints Registry Endpoints Registry负责收集Service的endpoint，比如Name：\u0026ldquo;mysql\u0026rdquo;，Endpoints: [\u0026ldquo;10.10.1.1:1909\u0026rdquo;，\u0026ldquo;10.10.2.2:8834\u0026rdquo;]，同Pod Registry，Controller Registry也实现了Kubernetes API Server的RESTful API接口，可以做Create、Get、List、Update、Delete以及watch操作。\n3.1.6 Binding Registry Binding包括一个需要绑定Pod的ID和Pod被绑定的Host，Scheduler写Binding Registry后，需绑定的Pod被绑定到一个host。Binding Registry也实现了Kubernetes API Server的RESTful API接口，但Binding Registry是一个write-only对象，所有只有Create操作可以使用， 否则会引起错误。\n3.1.7 Scheduler Scheduler收集和分析当前Kubernetes集群中所有Minion节点的资源(内存、CPU)负载情况，然后依此分发新建的Pod到Kubernetes集群中可用的节点。由于一旦Minion节点的资源被分配给Pod，那这些资源就不能再分配给其他Pod， 除非这些Pod被删除或者退出， 因此，Kubernetes需要分析集群中所有Minion的资源使用情况，保证分发的工作负载不会超出当前该Minion节点的可用资源范围。具体来说，Scheduler做以下工作：\n实时监测Kubernetes集群中未分发的Pod。 实时监测Kubernetes集群中所有运行的Pod，Scheduler需要根据这些Pod的资源状况安全地将未分发的Pod分发到指定的Minion节点上。 Scheduler也监测Minion节点信息，由于会频繁查找Minion节点，Scheduler会缓存一份最新的信息在本地。 最后，Scheduler在分发Pod到指定的Minion节点后，会把Pod相关的信息Binding写回API Server。 3.2 Kubelet 根据上图可知Kubelet是Kubernetes集群中每个Minion和Master API Server的连接点，Kubelet运行在每个Minion上，是Master API Server和Minion之间的桥梁，接收Master API Server分配给它的commands和work，与持久性键值存储etcd、file、server和http进行交互，读取配置信息。Kubelet的主要工作是管理Pod和容器的生命周期，其包括Docker Client、Root Directory、Pod Workers、Etcd Client、Cadvisor Client以及Health Checker组件，具体工作如下：\n通过Worker给Pod异步运行特定的Action 设置容器的环境变量 给容器绑定Volume 给容器绑定Port 根据指定的Pod运行一个单一容器 杀死容器 给指定的Pod创建network 容器 删除Pod的所有容器 同步Pod的状态 从cAdvisor获取container info、 pod info、 root info、 machine info 检测Pod的容器健康状态信息 在容器中运行命令。 3.3 Proxy Proxy是为了解决外部网络能够访问跨机器集群中容器提供的应用服务而设计的，运行在每个Minion上。Proxy提供TCP/UDP sockets的proxy，每创建一种Service，Proxy主要从etcd获取Services和Endpoints的配置信息（也可以从file获取），然后根据配置信息在Minion上启动一个Proxy的进程并监听相应的服务端口，当外部请求发生时，Proxy会根据Load Balancer将请求分发到后端正确的容器处理。\n所以Proxy不但解决了同一主宿机相同服务端口冲突的问题，还提供了Service转发服务端口对外提供服务的能力，Proxy后端使用了随机、轮循负载均衡算法。关于更多 kube-proxy 的内容 KUBERNETES代码走读之MINION NODE 组件 KUBE-PROXY 。\n4. etcd etcd在上面架构图上提到过几次，但它并不是kubernetes的一部分，它是 CoreOS 团队发起的一个管理配置信息和服务发现（service discovery）项目，目标是构建一个高可用的分布式键值（key-value）数据库。与kubernetes和docker一样还是在快速迭代开发中的产品，没有ZooKeeper那样成熟。有机会再另外通过文章介绍。\n参考\nKubernetes系统架构简介\nAn Introduction to Kubernetes\nKubernetes-DESIGN （Kubernetes 设计概要）\n怎样构建一个容器集群\n","permalink":"http://localhost:1313/2015/02/docker-kubernetes-arch-introduction/","summary":"\u003cp\u003e本文来源于Infoq的一篇文章（见参考部分），并在难懂的地方自己理解的基础上做了修改。实际在ubuntu上部署 kubernetes 操作另见 \u003ca href=\"http://xgknight.com/2015/02/07/docker-kubernetes-deploy2/\"\u003e文章\u003c/a\u003e 。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eTogether we will ensure that Kubernetes is a strong and open container management framework for any application and in any environment, whether in a private, public or hybrid cloud.  \u0026ndash;Urs Hölzle, Google\u003c/p\u003e","title":"开源容器集群管理系统Kubernetes架构及组件介绍"},{"content":"本需求是自己负责的一个生产系统上，有大量以zip和rar结尾的压缩文件散落在文件系统的各个文件夹，先在需要把压缩包里包含某一个特定文件（如tftpd32.exe或Tftpd32.exe，版本较旧），全都替换成比较新的tftpd32.exe版本。压缩文件总数约5000个，需要替换的数量约1500个。\n因为是生产环境，不敢轻易乱动，所以脚本考虑的因素就非常多，不允许中间执行过程出现异常，所以找到文件后实际执行替换操作之前做好备份，并且将操作过程记录日志。\n以下几点需要考虑：\n分别处理zip和rar文件，为减低脚本的复杂程度，分作两个shell脚本。 rar在Linux下默认是没有安装解压缩工具，下载rarlinux-x64-5.2.0.tar.gz zip包中文件含有中文文件名，unzip测试解压缩或列出内容时出现文件名乱码，原因是zip在压缩时不记录当时的编码格式。这个问题非常棘手，乱码打进压缩包是绝对不允许的，网上有几种解压办法有几种办法都不能很好的应对我的场景：并不需要实际解压zip文件，而只需使用 l ——列出文件列表、获取目录及文件名，d ——从压缩包中直接删除某个文件，a ——向压缩包添加一个文件。实际解压到文件系统上是不是乱码我们并不关心。 最后的解决办法是使用p7zip工具，配合LANG变量解决。 向压缩包里添加新文件时，要保持里面的目录结构，则必须在文件系统上存在同样的 相对目录/文件 。所以每次都要在脚本执行目录下创建临时目录tmp_dir，还要及时删除。但如果文件在压缩包的根目录下，这个临时目录就是当前脚本执行目录。 有可能会存在一个压缩包中多个文件夹中包含不止一个tftpd32.exe文件。 每个文件都有一个CRC值，处理文件名大小写不同但实质是同一个文件时有效。 以下脚本使用说明：\n变量说明 filelist 变量设定你所需要检查的压缩文件列表（绝对路径），可以通过find /your/dir/ -name *.rar | sort | uniq \u0026gt; testfile。与脚本在相同目录下，并且为unix格式 existlist 变量是从filelist文件中得到的包含特定文件的列表，脚本执行完后可以查看 errorlist 变量是从filelist文件列表中得到的不包含特定文件的列表，当然也有可能这个压缩文件本身不完整 filebak 变量指定要替换的那个压缩文件备份的目录 oldfile 指定要替换的那个文件名 newfile 指定新文件的文件名，注意这个文件一定要在脚本当前目录下 binrar,bin7z 指定解压缩命令目录，因为7z和rar都不是CentOS自带的 fl 是filelist文件列表里的每一条记录 exist 压缩文件fl的内容列表里包含tftpd32.exe的记录，可能有多行 dirfiles 处理exist的结果，形如压缩包里的目录结构 your/dir/tftpd32.exe，可能有多行 df 是dirfiles中的单行记录，它的前面目录部分便是tmp_dir 是否有必要root用户执行看个人情况，执行后部分文件的属主可能会变，可用chown user1.user1 -R /your/dir/恢复 有部分zip文件无法使用7z，但文件本身正常，从日志可以看到error信息 tftpd32.exe区分大小写，如果要查找替换Tftpd32.exe请修改后在执行（确保grep没有-i选项） 可以处理的情况 压缩文件中无tftpd32.exe 要替换的tftpd32.exe文件在压缩文件根目录下 要替换的tftpd32.exe在嵌套子目录中 压缩文件中存在多个tftpd32.exe 压缩文件本身存在问题 该脚本有一定的危险性（虽然已备份），在正式环境中运行之前一定要多做测试。并且运行一次之后，谨慎运行第二次，因为可能会导致备份被覆盖（可换备份目录） 假如出现异常，要从备份文件恢复所有修改的文件，可以根据$existlist和filebak下的目录列表拼凑cp语句 建议执行方法./rar_new.sh | tee your.log，事后可从your.log中查看日志 处理rar的脚本rar_new.sh:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 #!/bin/bash filelist=\u0026#34;testfile\u0026#34; # filelist=\u0026#34;crm_rar.txt\u0026#34; existlist=\u0026#34;${filelist}.exist\u0026#34; errorlist=\u0026#34;${filelist}.not\u0026#34; filebak=\u0026#34;/crmbak/rarbak\u0026#34; oldfile=tftpd32.exe newfile=tftpd32.exe binrar=\u0026#34;/usr/bin/rar\u0026#34; IFS=$\u0026#39;\\n\u0026#39; echo \u0026#34;files list bellow have ${oldfile}:\u0026#34; \u0026gt; $existlist echo \u0026#34;files list bellow do not have ${oldfile} or may have error:\u0026#34; \u0026gt; $errorlist for fl in `cat $filelist` do # ${oldfile} exist or not, file error or not exist=`$binrar l $fl |grep ${oldfile}` if [ $? -ne 0 ];then echo \u0026#34;$fl\u0026#34; \u0026gt;\u0026gt; $errorlist continue else # get extracting dir and filename, could be more than one file dirfiles=`echo \u0026#34;$exist\u0026#34; | awk \u0026#39;{for (i=5;i\u0026lt;=NF;i++) printf $i\u0026#34; \u0026#34; ; print \u0026#34;\u0026#34;}\u0026#39;` fi # echo \u0026#34;$exist\u0026#34; if [ \u0026#34;$dirfiles\u0026#34; != \u0026#34;\u0026#34; ];then echo \u0026#34;$fl\u0026#34; | tee -a $existlist # backup original file /bin/cp -af \u0026#34;$fl\u0026#34; \u0026#34;$filebak/\u0026#34; echo \u0026#34;--- $fl is backed up in $filebak\u0026#34; echo \u0026#34; $dirfiles\u0026#34; for df in `echo \u0026#34;$dirfiles\u0026#34;` do # create temp directory to put new ${newfile} for compress tmp_dir=$( echo \u0026#34;$df\u0026#34; | awk -F \u0026#39;/\u0026#39; \u0026#39;{for(i=1;i\u0026lt;NF;i++) printf\u0026#34;%s/\u0026#34;,$i} {print \u0026#34;\u0026#34;}\u0026#39; ) if [ ${#tmp_dir} -ne 0 ];then mkdir -p \u0026#34;$tmp_dir\u0026#34; \u0026amp;\u0026amp; cp -af ${newfile} \u0026#34;$tmp_dir\u0026#34; fi # start delete old file and add new one $binrar d \u0026#34;$fl\u0026#34; \u0026#34;$tmp_dir\u0026#34;${oldfile} \u0026amp;\u0026amp; $binrar a \u0026#34;$fl\u0026#34; \u0026#34;$tmp_dir\u0026#34;${newfile} if [ $? -ne 0 ];then echo \u0026#34;--- rar file $fl may have error, you SHOULD check it\u0026#34; fi if [ ${#tmp_dir} -ne 0 ];then rm -f \u0026#34;$tmp_dir\u0026#34;${newfile} \u0026amp;\u0026amp; rmdir -p \u0026#34;$tmp_dir\u0026#34; if [ $? -ne 0 ];then echo \u0026#34;--- tmp_dir $tmp_dir delete fail\u0026#34; fi fi done echo \u0026#34;--- old deleted, new added\u0026#34; fi done 处理zip的脚本zip_new.sh:(两脚本相差很小，主要是为了谨慎起见减低脚本的复杂度)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 #!/bin/bash # filelist=\u0026#34;test_filelist\u0026#34; filelist=\u0026#34;crm_zip.txt\u0026#34; existlist=\u0026#34;${filelist}.exist\u0026#34; errorlist=\u0026#34;${filelist}.not\u0026#34; filebak=\u0026#34;/crmbak/zipbak\u0026#34; oldfile=tftpd32.exe newfile=tftpd32.exe bin7z=\u0026#34;/usr/bin/7z\u0026#34; export LANG=\u0026#34;zh_CN.GB18030\u0026#34; IFS=$\u0026#39;\\n\u0026#39; echo \u0026#34;files list bellow have ${oldfile}:\u0026#34; \u0026gt; $existlist echo \u0026#34;files list bellow do not have ${oldfile} or may have error:\u0026#34; \u0026gt; $errorlist for fl in `cat $filelist` do # ${oldfile} exist or not, file error or not exist=`$bin7z l $fl |grep ${oldfile}` if [ $? -ne 0 ];then echo \u0026#34;$fl\u0026#34; \u0026gt;\u0026gt; $errorlist continue else # get extracting dir and filename, could be more than one file dirfiles=`echo \u0026#34;$exist\u0026#34; | awk \u0026#39;{for (i=6;i\u0026lt;=NF;i++) printf $i\u0026#34; \u0026#34; ; print \u0026#34;\u0026#34;}\u0026#39;` fi # echo ===== \u0026#34;$dirfiles\u0026#34; if [ \u0026#34;$dirfiles\u0026#34; != \u0026#34;\u0026#34; ];then echo \u0026#34;$fl\u0026#34; | tee -a $existlist # backup original file /bin/cp -af \u0026#34;$fl\u0026#34; \u0026#34;$filebak/\u0026#34; echo \u0026#34;--- $fl is backed up in $filebak\u0026#34; echo \u0026#34; $dirfiles\u0026#34; for df in `echo \u0026#34;$dirfiles\u0026#34;` do # create temp directory to put new ${newfile} for compress tmp_dir=$( echo \u0026#34;$df\u0026#34; | awk -F \u0026#39;/\u0026#39; \u0026#39;{for(i=1;i\u0026lt;NF;i++) printf\u0026#34;%s/\u0026#34;,$i} {print \u0026#34;\u0026#34;}\u0026#39; ) if [ ${#tmp_dir} -ne 0 ];then mkdir -p \u0026#34;$tmp_dir\u0026#34; \u0026amp;\u0026amp; cp -af ${newfile} \u0026#34;$tmp_dir\u0026#34; fi # start delete old file and add new one $bin7z d \u0026#34;$fl\u0026#34; \u0026#34;$tmp_dir\u0026#34;${oldfile} \u0026amp;\u0026amp; $bin7z a \u0026#34;$fl\u0026#34; \u0026#34;$tmp_dir\u0026#34;${newfile} if [ $? -ne 0 ];then echo \u0026#34;--- zip file $fl may have error, you SHOULD check it\u0026#34; fi if [ ${#tmp_dir} -ne 0 ];then rm -f \u0026#34;$tmp_dir\u0026#34;${newfile} \u0026amp;\u0026amp; rmdir -p \u0026#34;$tmp_dir\u0026#34; if [ $? -ne 0 ];then echo \u0026#34;--- tmp_dir $tmp_dir delete fail\u0026#34; fi fi done echo \u0026#34;--- old deleted, new added\u0026#34; fi done ","permalink":"http://localhost:1313/2015/01/shell-batch-replace-files-from-rar-zip/","summary":"\u003cp\u003e本需求是自己负责的一个生产系统上，有大量以zip和rar结尾的压缩文件散落在文件系统的各个文件夹，先在需要把压缩包里包含某一个特定文件（如tftpd32.exe或Tftpd32.exe，版本较旧），全都替换成比较新的tftpd32.exe版本。压缩文件总数约5000个，需要替换的数量约1500个。\u003c/p\u003e","title":"Linux下rar及zip压缩包中批量替换某文件脚本"},{"content":"可以说LDIF文件是OpenLDAP操作数据或修改配置的一切来源，下面是实际通过客户端工具操作的具体示例。（openldap安装及配置过程见这里）。\n1. 添加组织或条目 创建一个Marketing部门，添加一个dn记录：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # cat add_entry.ldif dn: ou=Marketing, dc=example,dc=com changetype: add objectclass: top objectclass: organizationalUnit ou: Marketing dn: cn=Pete Minsky,ou=Marketing,dc=example,dc=com changetype: add objectclass: person objectclass: organizationalPerson objectclass: inetOrgPerson cn: Pete Minsky sn: Pete ou: Marketing description: sb, sx description: sx uid: pminsky 1 2 3 4 5 # ldapmodify -xWD \u0026#39;cn=admin,dc=example,dc=com\u0026#39; -f add_entry.ldif 或去掉changetype后 # ldapmodify -a -xWD \u0026#39;cn=admin,dc=example,dc=com\u0026#39; -f add_entry.ldif # ldapadd -xWD \u0026#39;cn=admin,dc=example,dc=com\u0026#39; -f add.ldif 2. 修改组织或条目 添加mail属性，修改sn的值，删除一个description属性：\n1 2 3 4 5 6 7 8 9 10 11 # cat modify_entry.ldif dn: cn=Pete Minsky,ou=Marketing,dc=example,dc=com changetype: modify add: mail mail: pminsky@example.com - replace: sn sn: Minsky - delete: description description: sx 1 2 # ldapmodify -xWD \u0026#39;cn=admin,dc=example,dc=com\u0026#39; -f modify_entry.ldif # ldapsearch -xD \u0026#39;cn=admin,dc=mydomain,dc=net\u0026#39; -b \u0026#39;ou=People,dc=mydomain,dc=net\u0026#39; -s sub \u0026#39;objectclass=*\u0026#39; -w tplink -LLL 3. 重命名条目 1 2 3 4 dn: cn=Pete Minsky,ou=Marketing,dc=example,dc=com changetype: modrdn newrdn: cn=Susan Jacobs deleteoldrdn: 1 modrdn只允许修改dn最左边的部分，且不能重命名带叶子或分支的子树，如果要将一个用户移动到另一个部门下，只能在新部门创建dn，然后删除旧的dn。\n4. 删除组织或条目 LDAP协议只能删除无分支的叶子dn：\n1 2 3 4 5 6 # cat delete_entry.ldif dn: cn=Susan Jacobs,ou=Marketing,dc=example,dc=com changetype: delete 或 # ldapdelete -xWD \u0026#34;cn=admin,dc=example,dc=com\u0026#34; -h localhost -p 389 \u0026#34;cn=Susan Jacobs,ou=Marketing,dc=example,dc=com\u0026#34; 5. LDIF配置backend OpenLDAP的配置采用以cn=config为根的目录树的形式组织起来，采用config作为database，默认情况下包括admin或root用户都没有访问权限，需要赋予读写权限，然而赋予修改权限要求首先要提供认证信息，初始化安装后的cn=config是没有credentials\n1 2 3 4 5 6 # ldapmodify -Y EXTERNAL -H ldapi:/// -f modify_config.ldif SASL/EXTERNAL authentication started SASL username: gidNumber=0+uidNumber=0,cn=peercred,cn=external,cn=auth SASL SSF: 0 modifying entry \u0026#34;olcDatabase={0}config,cn=config\u0026#34; ldap_modify: Insufficient access (50) 所以这里不得不手动编辑olcDatabase={0}config.ldif文件，获得最初认证权限（虽然官方不推荐手动修改配置）：\n1 2 # vi /etc/ldap/slapd.d/cn\\=config/olcDatabase\\=\\{0\\}config.ldif olcRootPW: {SSHA}your_slappasswd_secret 重启slapd后(不是说不用重启吗)便可以修改config：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # ldapwhoami -x -D cn=config -W 修改示例： # ldapmodify -xWD \u0026#39;cn=config\u0026#39; Enter LDAP Password: dn: olcDatabase={0}config,cn=config changetype: modify replace: olcRootDN olcRootDN: cn=config - replace: olcRootPW olcRootPW: {SSHA}your_slappasswd_secret modifying entry \u0026#34;olcDatabase={0}config,cn=config\u0026#34; 在/etc/ldap/slapd.d/cn=config/olcDatabase={0}config.ldif中olcRootDN变成base64加密后的值（两个\u0026quot;:\u0026quot;）。\n最后，如果要在slapd服务未启动的情况下修改配置可以通过以下命令转换成ldif中间文件：\n1 2 3 # slapcat -n0 -F /etc/ldap/slapd.d/ \u0026gt; /tmp/config-in-portable-format.ldif 编辑ldif文件后，重新shengc slapd.d目录 # slapadd -n0 -F /tmp/slapd.d -l /tmp/config-in-portable-format.ldif 使用这类命令行工具有助于对 LDAP concept 理解，如果要达到快速配置的效果，可以使用 ldapbrowser 或 Apache Directory Studio 图形化工具，特别是 Apache Directory Studio 不仅提供了 LDAP Browser/Editor 的功能，还能编辑LDIF文件和自定义schema，智能提示非常友好。 参考\nChapter 6.1.1: OpenLDAP using OLC (cn=config)\nLDIF Tutorial: slapd.conf\n","permalink":"http://localhost:1313/2015/01/openldap_ldif_example/","summary":"\u003cp\u003e可以说LDIF文件是OpenLDAP操作数据或修改配置的一切来源，下面是实际通过客户端工具操作的具体示例。（openldap安装及配置过程见\u003ca href=\"http://xgknight.com/2015/01/21/openldap-install-guide-ssl/\"\u003e这里\u003c/a\u003e）。\u003c/p\u003e","title":"LDIF修改ldap记录或配置示例"},{"content":"本文采用的是从源码编译安装，适合Ubuntu和CentOS平台，通过apt-get或yum方式安装参考补充部分。openldap原理介绍参考这里。\n环境： Ubuntu: 14.04.1 (trusty), x86_64 OpenLDAP: 2.4.31 Berkery DB: 5.1.29\n1 安装 1.1 准备编译环境和依赖包 1 2 # apt-get install build-essential # apt-get install libssl-dev 下载openldap-2.4.31.tgz和db-5.1.29.NC.tar.gz并解压：\n1 2 3 4 5 6 7 8 9 # cd /usr/local/src src# wget ftp://ftp.openldap.org/pub/OpenLDAP/openldap-release/openldap-2.4.31.tgz # wget http://download.oracle.com/berkeley-db/db-5.1.29.NC.tar.gz # tar -zxf openldap-2.4.31.tgz # tar -zxf db-5.1.29.NC.tar.gz # cd db-5.1.29.NC/build_unix/ # ../dist/configure --prefix=/usr/local/berkeleydb-5.1 # make \u0026amp;\u0026amp; make install 建议人工指定--prefix，默认会安装到/usr/local/BerkeleyDB.5.1。上面的make过程会比较长，另外如果gcc版本在4.7及以上，可能会出现如下warning，可以忽略：\n1 2 ../src/dbinc/atomic.h:179:19: warning: conflicting types for built-in function ‘__atomic_compare_exchange’ [enabled by default] 1.2 安装openldap 设置一些环境变量，修改/etc/profile或/etc/bash.bashrc：\n1 2 3 4 5 6 7 export BERKELEYDB_HOME=\u0026#34;/usr/local/berkeleydb-5.1\u0026#34; export CPPFLAGS=\u0026#34;-I$BERKELEYDB_HOME/include\u0026#34; export LDFLAGS=\u0026#34;-L$BERKELEYDB_HOME/lib\u0026#34; export LD_LIBRARY_PATH=\u0026#34;$BERKELEYDB_HOME/lib\u0026#34; export LDAP_HOME=\u0026#34;/usr/local/openldap-2.4\u0026#34; export PATH=\u0026#34;$PATH:$BERKELEYDB_HOME/bin:$LDAP_HOME/bin:$LDAP_HOME/sbin:$LDAP_HOME/libexec\u0026#34; 其实只要在后面编译openldap时能找到lib和include下的库就行了，不止上面设置环境变量一种办法，解决办法还有直接复制对应的库文件到/usr/lib和/usr/include，或修改/etc/ld.so.conf.d，选其一即可。\n编译安装：\n1 2 3 4 openldap-2.4.31# ./configure --prefix=/usr/local/openldap-2.4 # make depend # make # make install 出错提示解决：\n如果没设置CPPFLAGS，上面的configure过程可能会提示configure: error: BDB/HDB: BerkeleyDB not available。\n如果提示\n1 2 configure: error: MozNSS not found - please specify the location to the NSPR and NSS header files in CPPFLAGS and the location to the NSPR and NSS libraries in LDFLAGS (if not in the system location) 或\n1 configure: error: no acceptable C compiler found in $PATH 请检查第一步的依赖是否已经安装，查看openldap解压目录下的README看到REQUIRED SOFTWARE。\n2 配置 2.1 基本配置 /usr/local/openldap-2.4目录结构：\n1 2 3 4 5 6 7 8 bin/ --客户端工具如ldapadd、ldapsearch etc/ --包含主配置文件slapd.conf、schema、DB_CONFIG等 include/ lib/ libexec/ --服务端启动工具slapd sbin/ --服务端工具如slappasswd share/ var/ --bdb数据、log存放目录 2.1.1 配置root密码 1 2 3 4 # slappasswd New password: Re-enter new password: {SSHA}phAvkua+5B7UNyIAuoTMgOgxF8kxekIk 2.1.2 修改后的slapd.conf 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 include\t/usr/local/openldap-2.4.31/etc/openldap/schema/core.schema include\t/usr/local/openldap-2.4.31/etc/openldap/schema/cosine.schema include\t/usr/local/openldap-2.4.31/etc/openldap/schema/inetorgperson.schema pidfile\t/usr/local/openldap-2.4.31/var/run/slapd.pid argsfile\t/usr/local/openldap-2.4.31/var/run/slapd.args loglevel 256 logfile /usr/local/openldap-2.4.31/var/slapd.log database\tbdb suffix\t\u0026#34;dc=mydomain,dc=net\u0026#34; rootdn\t\u0026#34;cn=root,dc=mydomain,dc=net\u0026#34; rootpw\t{SSHA}UK4eGUq3ujR1EYrOL2MRzMBJmo7qGyY3 directory\t/usr/local/openldap-2.4.31/var/openldap-data index\tobjectClass\teq 根据自己的需要加入schema，suffix一般填入域名，rootdn处是管理ldap数据的管理员用户，rootpw便是使用slappasswd生成的加密密码。\n2.1.3 启动slapd服务 1 # /usr/local/openldap-2.4.31/libexec/slapd 会自动使用etc/openldap/slapd.conf作为配置文件启动，并写入/usr/local/openldap-2.4.31/var/run/slapd.args中。这里有个问题未解决，配置loglevel和logfile但始终都看不到记录的日志，启动时加入-d 256能正常输出到屏幕上。\n2.1.4 测试数据 编辑一个添加entries的文件test.ldif：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 dn: dc=mydomain,dc=net objectClass: dcObject objectClass: organization dc: mydomain o: mydomain.Inc dn: cn=root,dc=mydomain,dc=net objectClass: organizationalRole cn: root dn: ou=itsection,dc=mydomain,dc=net ou: itsection objectClass: organizationalUnit dn: cn=sean,ou=itsection,dc=mydomain,dc=net ou: itsection cn: sean sn: zhouxiao objectClass: inetOrgPerson objectClass: organizationalPerson 插入数据：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 查看（匿名） # ldapsearch -x -b \u0026#39;\u0026#39; -s base \u0026#39;(objectclass=*)\u0026#39; namingContexts 添加（读入密码） # ldapadd -x -D \u0026#34;cn=root,dc=mydomain,dc=net\u0026#34; -W -f test.ldif 验证 # ldapsearch -x -b \u0026#39;dc=mydomain,dc=net\u0026#39; \u0026#39;(objectClass=*)\u0026#39; 或手动添加条目 # ldapadd -x -D \u0026#34;cn=root,dc=mydomain,dc=net\u0026#34; -W Enter LDAP Password: dn:cn=Angelababy,ou=itsection,dc=mydomain,dc=net cn:Angelababy sn:baby objectClass:inetOrgPerson objectClass:organizationalPerson adding new entry \u0026#34;cn=baby,ou=itsection,dc=mydomain,dc=net\u0026#34; 到这里，一个简易版的LDAP服务就搭建好了，下面介绍一些额外的高级配置。\n2.2 配置TLS加密传输 在某些应用环境下可能需要加密传输ldap里的信息，配置TLS难点在于证书的生成。关于SSL加密证书的介绍请参考ssl-tls，下面我们自己搭建CA，快速自签署ssl证书。\n2.2.1 自签署ssl证书 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 (1) 生成根密钥 # cd /etc/ssl/demoCA/ # openssl genrsa -out private/cakey.pem 2048 (2) 生成根证书，位于/etc/ssl/demoCA/下（CentOS位于/etc/pki/CA） # openssl req -new -x509 -key private/cakey.pem -out cacert.pem (3) 初始化CA demoCA# mkdir private newcerts # touch newcerts index.txt serial # echo \u0026#34;00\u0026#34; \u0026gt; serial (4) 在ldap服务器上生成ssl密钥（可以是/tmp/certs下） # openssl genrsa -out ldap.key (5) 为ldap生成证书签署请求（所填写内容尽量与第2步相同） Common Name填写主机名或域名，password留空 # openssl req -new -key ldap.key -out ldap.csr (6) ca根据请求签发证书，得到.crt证书文件 # openssl ca -in ldap.key -out ldap.crt 如果在你的环境中已经有一个证书授权中心CA，那么只需要在ldap服务器上使用openssl生成密钥.key和签署请求.csr（第4、5步），然后将.csr发给CA服务器来生成证书.crt（第6步）。\n2.2.2 在slapd.conf中加入TLS 1 2 3 4 5 6 7 8 9 10 可以是其它能访问的位置 # mkdir $OPENLDAP_HOME/etc/openldap/cacerts # cp cacert.pem $OPENLDAP_HOME/etc/openldap/cacerts # cp ldap.crt $OPENLDAP_HOME/etc/openldap/ # cp ldap.key $OPENLDAP_HOME/etc/openldap/ 在etc/openldap/slapd.conf中加入以下信息 TLSCACertificateFile /usr/local/openldap-2.4/etc/openldap/cacerts/cacert.pem TLSCertificateFile /usr/local/openldap-2.4/etc/openldap/ldap.crt TLSCertificateKeyFile /usr/local/openldap-2.4/etc/openldap/ldap.key 2.2.3 重新启动slapd 1 2 3 4 # killall slapd 关闭slapd standalone daemon # ./libexec/slapd -h \u0026#39;ldap://0.0.0.0:389/ ldaps://0.0.0.0:636/ ldapi:///\u0026#39; 或只监听636加密端口 # ./libexec/slapd -h \u0026#39;ldaps://0.0.0.0:636/\u0026#39; 如果是正式环境使用加密的话，389端口前的IP换成127.0.0.1。\n2.2.4 验证 ldapsearch 使用自带的ldapsearch或ldapadd客户端工具来连接slapd，需要设置ldap.conf或~/.ldaprc文件中的TLS_CACERT为信任的根证书才能使用，否则会提示\n1 2 TLS certificate verification: Error, self signed certificate in certificate chain TLS trace: SSL3 alert write:fatal:unknown CA 所以在在使用ldapsearch的服务器上修改/etc/ldap/ldap.conf：（man ldap.conf）\nBASE dc=mydomain,dc=net URI ldaps://apptest.mydomain.net:636 TLS_CACERT /usr/local/openldap-2.4/etc/openldap/cacerts/cacert.pem （当然也可以TLS_REQCERT never来信任根证书）\n使用：\nldapsearch -x -D \u0026quot;cn=root,dc=mydomain,dc=net\u0026quot; -W -LLL 或写全 ldapsearch -x -b 'dc=mydomain,dc=net' '(objectClass=*)' -H ldaps://apptest.mydomain.net:636 -D \u0026quot;cn=root,dc=mydomain,dc=net\u0026quot; -W 需要注意的是，URI后的 Server name 必须与签署证书使用的 Common name 一致。另外在ldap server本地执行ldapsearch默认使用的客户端配置文件是$LDAP_HOME/etc/openldap/ldap.conf。\nLDAPBrower 另外一种方式是使用第三方LDAP客户端连接工具，如LDAPBrower：\n连接： 信任根证书： 查看（可Add entries）： 3 补充 3.1 apt-get安装 通过apt-get在Ubuntu上安装OpenLDAP。\n1 2 # dpkg -l|grep libdb 查看berkeleydb是否安装 # apt-get install slapd ldap-utils 安装过程中会提示输入admin密码。\n安装完成后默认已经启动了slapd进程，与自己手动编译不同的是默认采用的配置文件有点区别：\n1 2 # ps -ef|grep slapd ... /usr/sbin/slapd -h ldap:/// ldapi:/// -g openldap -u openldap -F /etc/ldap/slapd.d /etc/ldap/slapd.d 是2.4.x版本新采用的配置文件目录，但手动编辑slapd.d目录下ldif是非常痛苦的，如果你不习惯新的配置目录格式，你可以通过修改/etc/default/slapd中的SLAPD_CONF=为SLAPD_CONF=\u0026quot;/etc/ldap/slapd.conf\u0026quot;。\nslapd.conf配置形式官方已经废弃了但依然支持，你还可以选择在编辑完熟悉的slapd.conf后使用openldap提供的slaptest工具将它转换成slapd.d配置目录：\n1 2 3 # mv /etc/ldap/slapd.d{,.dist} 先删除（备份）原目录 # slaptest -f /etc/ldap/slapd.conf -F /etc/ldap/slapd.d/ 转换成新的配置目录格式 # chown -R openldap:openldap /etc/ldap/slapd.d/ 修改权限 3.2 slapd-config配置形式的说明 我们把就的配置方式叫slapd.conf，新的配置方式叫slapd-config或olc（OpenLDAP Configuration，也可以理解为online config）。slapd.d目录内包含许多ldif文件，就是slapd.conf中的内容转化成ldif格式，以构成一棵根为cn=config的目录树，这棵树包含了许多结点，如：cn=module{0}, cn=schema, olcDatabase={1}bdb……所有配置信息就是这些结点的属性。结构如下图： 使用这种新的配置目录的好处在于：\n通过Overlay截获修改这些目录属性的信息，然后对相应的数据结构进行修改，即管理员可以像修改其它目录属性一样修改cn=config目录树下的目录信息，并且修改后即时生效，无需重启服务器。 管理员不用像以前那样对服务器的配置文件进行修改，而是可以在任何能够连上ldap服务器的地方对配置文件内容进行修改，没有地域的限制。 但是当你需要配置多个backend时，slapd-config方式需要2.4.33版本以后才支持，此前的版本还只能使用slapd.conf方式。\nLDIF配置格式大致如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 # global configuration settings dn: cn=config objectClass: olcGlobal cn: config \u0026lt;global config settings\u0026gt; # schema definitions dn: cn=schema,cn=config objectClass: olcSchemaConfig cn: schema \u0026lt;system schema\u0026gt; dn: cn={X}core,cn=schema,cn=config objectClass: olcSchemaConfig cn: {X}core \u0026lt;core schema\u0026gt; # additional user-specified schema ... # backend definitions dn: olcBackend=\u0026lt;typeA\u0026gt;,cn=config objectClass: olcBackendConfig olcBackend: \u0026lt;typeA\u0026gt; \u0026lt;backend-specific settings\u0026gt; # database definitions dn: olcDatabase={X}\u0026lt;typeA\u0026gt;,cn=config objectClass: olcDatabaseConfig olcDatabase: {X}\u0026lt;typeA\u0026gt; \u0026lt;database-specific settings\u0026gt; # subsequent definitions and settings ... 我们有时候会发现ldif里面会有一些条目是带{0}这样的数字，这是因为ldap数据库本身是无序的，这些索引一样的数字是用来强制一些依赖于其他配置的设置能够按照正确的顺序先后生效。不过它不用我们去关心，在添加entries时如果有需要会自动生成。\nldif文件中大部分属性和objectClass是以olc开头的，与就的配置风格slapd.conf有着一对一的属性配置选项，如olcDatabase: {1}hdb与database bdb对应。\n更多内容请参考 OpenLDAP Software 2.4 Administrator\u0026rsquo;s Guide 。 3.3 slapd-config修改示例(LDIF) 见 LDIF修改ldap记录或配置示例。\n3.4 LDAP访问控制示例 待续\n3.5 OpenLDAP复制配置（replication） 待续\n4 参考 Install and Configure an OpenLDAP Server with SSL on Debian Wheezy\nopenldap doc quickstart\nOpenLDAP的安装和配置(含TLS和复制）\nopenldap学习笔记(安装配置openldap-2.3.32)\n","permalink":"http://localhost:1313/2015/01/openldap-install-guide-ssl/","summary":"\u003cp\u003e本文采用的是从源码编译安装，适合Ubuntu和CentOS平台，通过\u003ccode\u003eapt-get\u003c/code\u003e或\u003ccode\u003eyum\u003c/code\u003e方式安装参考补充部分。openldap原理介绍参考\u003ca href=\"http://xgknight.com/2015/01/15/openldap_introduction/\"\u003e这里\u003c/a\u003e。\u003c/p\u003e","title":"OpenLDAP(2.4.3x)服务器搭建及配置说明"},{"content":"关于SSL/TLS介绍见文章 SSL/TLS原理详解。 关于证书授权中心CA以及数字证书等概念，请移步 OpenSSL 与 SSL 数字证书概念贴 。\nopenssl是一个开源程序的套件、这个套件有三个部分组成：一是libcryto，这是一个具有通用功能的加密库，里面实现了众多的加密库；二是libssl，这个是实现ssl机制的，它是用于实现TLS/SSL的功能；三是openssl，是个多功能命令行工具，它可以实现加密解密，甚至还可以当CA来用，可以让你创建证书、吊销证书。\n默认情况ubuntu和CentOS上都已安装好openssl。CentOS 6.x 上有关ssl证书的目录结构：\n1 2 3 4 5 6 7 8 9 10 11 /etc/pki/CA/ newcerts 存放CA签署（颁发）过的数字证书（证书备份目录） private 用于存放CA的私钥 crl 吊销的证书 /etc/pki/tls/ cert.pem 软链接到certs/ca-bundle.crt certs/ 该服务器上的证书存放目录，可以房子自己的证书和内置证书 ca-bundle.crt 内置信任的证书 private 证书密钥存放目录 openssl.cnf openssl的CA主配置文件 1. 颁发证书 1.1 修改CA的一些配置文件 CA要给别人颁发证书，首先自己得有一个作为根证书，我们得在一切工作之前修改好CA的配置文件、序列号、索引等等。\nvi /etc/pki/tls/openssl.cnf：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 ... [ CA_default ] dir = /etc/pki/CA # Where everything is kept certs = $dir/certs # Where the issued certs are kept crl_dir = $dir/crl # Where the issued crl are kept database = $dir/index.txt # database index file. #unique_subject = no # Set to \u0026#39;no\u0026#39; to allow creation of # several ctificates with same subject. new_certs_dir = $dir/newcerts # default place for new certs. certificate = $dir/cacert.pem # The CA certificate serial = $dir/serial # The current serial number crlnumber = $dir/crlnumber # the current crl number # must be commented out to leave a V1 CRL crl = $dir/crl.pem # The current CRL private_key = $dir/private/cakey.pem # The private key RANDFILE = $dir/private/.rand # private random number file ... default_days = 3650 # how long to certify for ... # For the CA policy [ policy_match ] countryName = match stateOrProvinceName = optional localityName = optional organizationName = optional organizationalUnitName = optional commonName = supplied emailAddress = optional ... [ req_distinguished_name ] countryName = Country Name (2 letter code) countryName_default = CN countryName_min = 2 countryName_max = 2 stateOrProvinceName = State or Province Name (full name) stateOrProvinceName_default = GD ... [ req_distinguished_name ] 部分主要是颁证时一些默认的值，可以不动 一定要注意[ policy_match ]中的设定的匹配规则，是有可能因为证书使用的工具不一样，导致即使设置了csr中看起来有相同的countryName,stateOrProvinceName等，但在最终生成证书时依然报错：\n1 2 3 4 5 Using configuration from /usr/lib/ssl/openssl.cnf Check that the request matches the signature Signature ok The stateOrProvinceName field needed to be the same in the CA certificate (GuangDong) and the request (GuangDong) touch index.txt serial： 在CA目录下创建两个初始文件：\n1 2 # touch index.txt serial # echo 01 \u0026gt; serial 1.2 生成根密钥 1 2 # cd /etc/pki/CA/ # openssl genrsa -out private/cakey.pem 2048 为了安全起见，修改cakey.pem私钥文件权限为600或400，也可以使用子shell生成( umask 077; openssl genrsa -out private/cakey.pem 2048 )，下面不再重复。\n1.3 生成根证书 使用req命令生成自签证书：\n1 # openssl req -new -x509 -key private/cakey.pem -out cacert.pem 会提示输入一些内容，因为是私有的，所以可以随便输入（之前修改的openssl.cnf会在这里呈现），最好记住能与后面保持一致。上面的自签证书cacert.pem应该生成在/etc/pki/CA下。\n1.4 为我们的nginx web服务器生成ssl密钥 以上都是在CA服务器上做的操作，而且只需进行一次，现在转到nginx服务器上执行：\n1 2 # cd /etc/nginx/ssl # openssl genrsa -out nginx.key 2048 这里测试的时候CA中心与要申请证书的服务器是同一个。\n1.5 为nginx生成证书签署请求 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # openssl req -new -key nginx.key -out nginx.csr ... Country Name (2 letter code) [AU]:CN State or Province Name (full name) [Some-State]:GD Locality Name (eg, city) []:SZ Organization Name (eg, company) [Internet Widgits Pty Ltd]:COMPANY Organizational Unit Name (eg, section) []:IT_SECTION Common Name (e.g. server FQDN or YOUR name) []:your.domain.com Email Address []: Please enter the following \u0026#39;extra\u0026#39; attributes to be sent with your certificate request A challenge password []: An optional company name []: ... 同样会提示输入一些内容，其它随便，除了Commone Name一定要是你要授予证书的服务器域名或主机名，challenge password不填。\n1.6 私有CA根据请求来签署证书 接下来要把上一步生成的证书请求csr文件，发到CA服务器上，在CA上执行：\n1 2 3 4 # openssl ca -in nginx.csr -out nginx.crt 另外在极少数情况下，上面的命令生成的证书不能识别，试试下面的命令： # openssl x509 -req -in server.csr -CA /etc/pki/CA/cacert.pem -CAkey /etc/pki/CA/private/cakey.pem -CAcreateserial -out server.crt 上面签发过程其实默认使用了-cert cacert.pem -keyfile cakey.pem，这两个文件就是前两步生成的位于/etc/pki/CA下的根密钥和根证书。将生成的crt证书发回nginx服务器使用。\n到此我们已经拥有了建立ssl安全连接所需要的所有文件，并且服务器的crt和key都位于配置的目录下，剩下的是如何使用证书的问题。\n2. 使用ssl证书 2.1 一般浏览器 浏览器作为客户端去访问https加密的服务器，一般不用去手动做其他设置，如https://www.google.com.hk，这是因为Chrome、FireFox、Safari、IE等浏览器已经内置了大部分常用的CA的根证书，但自建CA的根证书就不再浏览器的信任列表中，访问时会提示如下： IE浏览器 谷歌浏览器 安装网站证书后（同时也有信任的根证书），地址栏一般会显示绿色小锁 证书信息 导入证书到浏览器的方法：http://cnzhx.net/blog/self-signed-certificate-as-trusted-root-ca-in-windows/\n2.2 为linux系统添加根证书 这一步不是必须的，一般出现在开发测试环境中，而且具体的应用程序应该提供添加证书的方法。\ncurl工具可以在linux上模拟发送请求，但当它去访问https加密网站时就会提示如下信息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 # curl https://sean:sean@registry.domain.com:8000/ curl: (60) Peer certificate cannot be authenticated with known CA certificates More details here: http://curl.haxx.se/docs/sslcerts.html curl performs SSL certificate verification by default, using a \u0026#34;bundle\u0026#34; of Certificate Authority (CA) public keys (CA certs). If the default bundle file isn\u0026#39;t adequate, you can specify an alternate file using the --cacert option. If this HTTPS server uses a certificate signed by a CA represented in the bundle, the certificate verification probably failed due to a problem with the certificate (it might be expired, or the name might not match the domain name in the URL). If you\u0026#39;d like to turn off curl\u0026#39;s verification of the certificate, use the -k (or --insecure) option. 提示上面的信息说明curl在linux的证书信任集里没有找到根证书，你可以使用curl --insecure来不验证证书的可靠性，这只能保证数据是加密传输的但无法保证对方是我们要访问的服务。使用curl --cacert cacert.pem可以手动指定根证书路径。我们也可以把根证书添加到系统（CentOS 5,6）默认的bundle：\n1 2 3 4 5 # cp /etc/pki/tls/certs/ca-bundle.crt{,.bak} 备份以防出错 # cat /etc/pki/CA/cacert.pem \u0026gt;\u0026gt; /etc/pki/tls/certs/ca-bundle.crt # curl https://sean:sean@registry.domain.com:8000 \u0026#34;docker-registry server (dev) (v0.8.1)\u0026#34; 2.3 nginx 在nginx配置文件（可能是/etc/nginx/sites-available/default）的server指令下添加：\n1 2 3 ssl on; ssl_certificate /etc/nginx/ssl/nginx.crt; ssl_certificate_key /etc/nginx/ssl/nginx.key; 同时注意 server_name 与证书申请时的 Common Name 要相同，打开443端口。当然关于web服务器加密还有其他配置内容，如只对部分URL加密，对URL重定向实现强制https访问，请参考其他资料。\n3 关于证书申请 注意，如果对于一般的应用，管理员只需生成“证书请求”（后缀大多为.csr），它包含你的名字和公钥，然后把这份请求交给诸如verisign等有CA服务公司（当然，连同几百美金），你的证书请求经验证后，CA用它的私钥签名，形成正式的证书发还给你。管理员再在web server上导入这个证书就行了。如果你不想花那笔钱，或者想了解一下原理，可以自己做CA。从ca的角度讲，你需要CA的私钥和公钥。从想要证书的服务器角度将，需要把服务器的证书请求交给CA。\n如果你要自己做CA，别忘了客户端需要导入CA的证书（CA的证书是自签名的，导入它意味着你“信任”这个CA签署的证书）。而商业CA的一般不用，因为它们已经内置在你的浏览器中了。\n参考\nCentOS6.5下openssl加密解密及CA自签颁发证书详解\n基于 OpenSSL 的 CA 建立及证书签发\nopenssl建立证书，非常详细配置ssl+apache\nThe Secure Sockets Layer and Transport Layer Security\n","permalink":"http://localhost:1313/2015/01/openssl-self-sign-ca/","summary":"\u003cp\u003e关于SSL/TLS介绍见文章 \u003ca href=\"http://xgknight.com/2015/01/07/tls-ssl\"\u003eSSL/TLS原理详解\u003c/a\u003e。\n关于证书授权中心CA以及数字证书等概念，请移步 \u003ca href=\"http://xgknight.com/2015/01/15/openssl-certificate-encryption\"\u003eOpenSSL 与 SSL 数字证书概念贴\u003c/a\u003e 。\u003c/p\u003e\n\u003cp\u003eopenssl是一个开源程序的套件、这个套件有三个部分组成：一是\u003ccode\u003elibcryto\u003c/code\u003e，这是一个具有通用功能的加密库，里面实现了众多的加密库；二是\u003ccode\u003elibssl\u003c/code\u003e，这个是实现ssl机制的，它是用于实现TLS/SSL的功能；三是openssl，是个多功能命令行工具，它可以实现加密解密，甚至还可以当CA来用，可以让你创建证书、吊销证书。\u003c/p\u003e","title":"基于OpenSSL自建CA和颁发SSL证书"},{"content":"1. 目录服务 目录是一个为查询、浏览和搜索而优化的专业分布式数据库，它呈树状结构组织数据，就好象Linux/Unix系统中的文件目录一样。目录数据库和关系数据库不同，它有优异的读性能，但写性能差，并且没有事务处理、回滚等复杂功能，不适于存储修改频繁的数据。所以目录天生是用来查询的，就好象它的名字一样。\n目录服务是由目录数据库和一套访问协议组成的系统。类似以下的信息适合储存在目录中：\n企业员工信息，如姓名、电话、邮箱等； 公用证书和安全密钥； 公司的物理设备信息，如服务器，它的IP地址、存放位置、厂商、购买时间等； LDAP是轻量目录访问协议(Lightweight Directory Access Protocol)的缩写，LDAP是从X.500目录访问协议的基础上发展过来的，目前的版本是v3.0。与LDAP一样提供类似的目录服务软件还有ApacheDS、Active Directory、Red Hat Directory Service 。\n2. LDAP特点 LDAP的结构用树来表示，而不是用表格。正因为这样，就不能用SQL语句了 LDAP可以很快地得到查询结果，不过在写方面，就慢得多 LDAP提供了静态数据的快速查询方式 Client/server模型，Server 用于存储数据，Client提供操作目录信息树的工具 这些工具可以将数据库的内容以文本格式（LDAP 数据交换格式，LDIF）呈现在您的面前 LDAP是一种开放Internet标准，LDAP协议是跨平台的Interent协议 3. LDAP组织数据的方式 4. 基本概念 在浏览LDAP相关文档时经常会遇见一些概念，下面是常见概念的简单解释。\n4.1 Entry 条目，也叫记录项，是LDAP中最基本的颗粒，就像字典中的词条，或者是数据库中的记录。通常对LDAP的添加、删除、更改、检索都是以条目为基本对象的。\ndn：每一个条目都有一个唯一的标识名（distinguished Name ，DN），如上图中一个 dn：\u0026ldquo;cn=baby,ou=marketing,ou=people,dc=mydomain,dc=org\u0026rdquo; 。通过DN的层次型语法结构，可以方便地表示出条目在LDAP树中的位置，通常用于检索。\nrdn：一般指dn逗号最左边的部分，如cn=baby。它与RootDN不同，RootDN通常与RootPW同时出现，特指管理LDAP中信息的最高权限用户。\nBase DN：LDAP目录树的最顶部就是根，也就是所谓的“Base DN\u0026quot;，如\u0026quot;dc=mydomain,dc=org\u0026quot;。\n4.2 Attribute 每个条目都可以有很多属性（Attribute），比如常见的人都有姓名、地址、电话等属性。每个属性都有名称及对应的值，属性值可以有单个、多个，比如你有多个邮箱。\n属性不是随便定义的，需要符合一定的规则，而这个规则可以通过schema制定。比如，如果一个entry没有包含在 inetorgperson 这个 schema 中的objectClass: inetOrgPerson，那么就不能为它指定employeeNumber属性，因为employeeNumber是在inetOrgPerson中定义的。\nLDAP为人员组织机构中常见的对象都设计了属性(比如commonName，surname)。下面有一些常用的别名：\n属性 别名 语法 描述 值(举例) commonName cn Directory String 姓名 sean surname sn Directory String 姓 Chow organizationalUnitName ou Directory String 单位（部门）名称 IT_SECTION organization o Directory String 组织（公司）名称 example telephoneNumber Telephone Number 电话号码 110 objectClass 内置属性 organizationalPerson 4.3 ObjectClass 对象类是属性的集合，LDAP预想了很多人员组织机构中常见的对象，并将其封装成对象类。比如人员（person）含有姓（sn）、名（cn）、电话(telephoneNumber)、密码(userPassword)等属性，单位职工(organizationalPerson)是人员(person)的继承类，除了上述属性之外还含有职务（title）、邮政编码（postalCode）、通信地址(postalAddress)等属性。\n通过对象类可以方便的定义条目类型。每个条目可以直接继承多个对象类，这样就继承了各种属性。如果2个对象类中有相同的属性，则条目继承后只会保留1个属性。对象类同时也规定了哪些属性是基本信息，必须含有(Must 活Required，必要属性)：哪些属性是扩展信息，可以含有（May或Optional，可选属性）。\n对象类有三种类型：结构类型（Structural）、抽象类型(Abstract)和辅助类型（Auxiliary）。结构类型是最基本的类型，它规定了对象实体的基本属性，每个条目属于且仅属于一个结构型对象类。抽象类型可以是结构类型或其他抽象类型父类，它将对象属性中共性的部分组织在一起，称为其他类的模板，条目不能直接集成抽象型对象类。辅助类型规定了对象实体的扩展属性。每个条目至少有一个结构性对象类。\n对象类本身是可以相互继承的，所以对象类的根类是top抽象型对象类。以常用的人员类型为例，他们的继承关系： 下面是inetOrgPerson对象类的在schema中的定义，可以清楚的看到它的父类SUB和可选属性MAY、必要属性MUST(继承自organizationalPerson)，关于各属性的语法则在schema中的attributetype定义。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # inetOrgPerson # The inetOrgPerson represents people who are associated with an # organization in some way. It is a structural class and is derived # from the organizationalPerson which is defined in X.521 [X521]. objectclass ( 2.16.840.1.113730.3.2.2 NAME \u0026#39;inetOrgPerson\u0026#39; DESC \u0026#39;RFC2798: Internet Organizational Person\u0026#39; SUP organizationalPerson STRUCTURAL MAY ( audio $ businessCategory $ carLicense $ departmentNumber $ displayName $ employeeNumber $ employeeType $ givenName $ homePhone $ homePostalAddress $ initials $ jpegPhoto $ labeledURI $ mail $ manager $ mobile $ o $ pager $ photo $ roomNumber $ secretary $ uid $ userCertificate $ x500uniqueIdentifier $ preferredLanguage $ userSMIMECertificate $ userPKCS12 ) ) 4.4 Schema 对象类（ObjectClass）、属性类型（AttributeType）、语法（Syntax）分别约定了条目、属性、值，他们之间的关系如下图所示。所以这些构成了模式(Schema)——对象类的集合。条目数据在导入时通常需要接受模式检查，它确保了目录中所有的条目数据结构都是一致的。 schema（一般在/etc/ldap/schema/目录）在导入时要注意前后顺序。\n4.5 backend \u0026amp; database ldap的后台进程slapd接收、响应请求，但实际存储数据、获取数据的操作是由Backends做的，而数据是存放在database中，所以你可以看到往往你可以看到backend和database指令是一样的值如 bdb 。一个 backend 可以有多个 database instance，但每个 database 的 suffix 和 rootdn 不一样。openldap 2.4版本的模块是动态加载的，所以在使用backend时需要moduleload back_bdb指令。\nbdb是一个高性能的支持事务和故障恢复的数据库后端，可以满足绝大部分需求。许多旧文档里（包括官方）说建议将bdb作为首选后端服务（primary backend），但2.4版文档明确说hdb才是被首先推荐使用的，这从 2.4.40 版默认安装后的配置文件里也可以看出。hdb是基于bdb的，但是它通过扩展的索引和缓存技术可以加快数据访问，修改entries会更有效率，有兴趣可以访问上的链接或slapd.backends。\n另外config是特殊的backend，用来在运行时管理slapd的配置，它只能有一个实例，甚至无需显式在slapd.conf中配置。\n4.6 TLS \u0026amp; SASL 分布式LDAP 是以明文的格式通过网络来发送信息的，包括client访问ldap的密码（当然一般密码已然是二进制的），SSL/TLS 的加密协议就是来保证数据传送的保密性和完整性。\nSASL （Simple Authenticaion and Security Layer）简单身份验证安全框架，它能够实现openldap客户端到服务端的用户验证，也是ldapsearch、ldapmodify这些标准客户端工具默认尝试与LDAP服务端认证用户的方式（前提是已经安装好 Cyrus SASL）。SASL有几大工业实现标准：Kerberos V5、DIGEST-MD5、EXTERNAL、PLAIN、LOGIN。\nKerberos V5是里面最复杂的一种，使用GSSAPI机制，必须配置完整的Kerberos V5安全系统，密码不再存放在目录服务器中，每一个dn与Kerberos数据库的主体对应。DIGEST-MD5稍微简单一点，密码通过saslpasswd2生成放在sasldb数据库中，或者将明文hash存到LDAP dn的userPassword中，每一个authid映射成目录服务器的dn，常和SSL配合使用。参考将 LDAP 客户端配置为使用安全性\nEXTERNAL一般用于初始化添加schema时使用，如ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/core.ldif。\n4.7 LDIF LDIF（LDAP Data Interchange Format，数据交换格式）是LDAP数据库信息的一种文本格式，用于数据的导入导出，每行都是“属性: 值”对，见 openldap ldif格式示例\nOpenLDAP(2.4.3x)服务器安装配置方法见这里。\n参考\nLDAP基础概念\nLDAP-HOWTO\nopenldap doc admin24\n","permalink":"http://localhost:1313/2015/01/openldap_introduction/","summary":"\u003ch2 id=\"1-目录服务\"\u003e1. 目录服务\u003c/h2\u003e\n\u003cp\u003e目录是一个为查询、浏览和搜索而优化的专业分布式数据库，它呈树状结构组织数据，就好象Linux/Unix系统中的文件目录一样。目录数据库和关系数据库不同，它有优异的读性能，但写性能差，并且没有事务处理、回滚等复杂功能，不适于存储修改频繁的数据。所以目录天生是用来查询的，就好象它的名字一样。\u003c/p\u003e","title":"LDAP服务器的概念和原理简单介绍"},{"content":"SSL/TLS 介绍见文章 SSL/TLS原理详解。 如果你想快速自建CA然后签发数字证书，请移步 基于OpenSSL自建CA和颁发SSL证书 。\n首先简单区分一下HTTPS、SSL、OpenSSL三者的关系：\nSSL是在客户端和服务器之间建立一条SSL安全通道的安全协议，而OpenSSL是TLS/SSL协议的开源实现，提供开发库和命令行程序。常说的HTTPS是HTTP的加密版，底层使用的加密协议是SSL。\n1. PKI、CA与证书 PKI 就是 Public Key Infrastructure 的缩写，翻译过来就是公开密钥基础设施。它是利用公开密钥技术所构建的，解决网络安全问题的，普遍适用的一种基础设施;是一种遵循既定标准的密钥管理平台,它能够为所有网络应用提供加密和数字签名等密码服务及所必需的密钥和证书管理体系。\nPKI既不是一个协议，也不是一个软件，它是一个标准，在这个标准之下发展出的为了实现安全基础服务目的的技术统称为PKI。可以说CA(认证中心)是PKI的核心，而数字证书是PKI的最基本元素，还有如apache等服务器、浏览器等客户端、银行等应用，都是pki的组件。这篇文章可以帮助理解：PKI/CA 技术的介绍 。\n1.1 CA 为保证用户之间在网上传递信息的安全性、真实性、可靠性、完整性和不可抵赖性\nCA 机构，又称为证书认证中心 (Certificate Authority) 中心，是一个负责发放和管理数字证书的第三方权威机构，它负责管理PKI结构下的所有用户(包括各种应用程序)的证书，把用户的公钥和用户的其他信息捆绑在一起，在网上验证用户的身份。CA机构的数字签名使得攻击者不能伪造和篡改证书。\n认证中心主要有以下5个功能：\n证书的颁发：接收、验证用户(包括下级认证中心和最终用户)的数字证书的申请。可以受理或拒绝 证书的更新：认证中心可以定期更新所有用户的证书，或者根据用户的请求来更新用户的证书 证书的查询：查询当前用户证书申请处理过程；查询用户证书的颁发信息，这类查询由目录服务器ldap来完成 证书的作废：由于用户私钥泄密等原因，需要向认证中心提出证书作废的请求；证书已经过了有效期，认证中心自动将该证书作废。认证中心通过维护证书作废列表 (Certificate Revocation List,CRL) 来完成上述功能。 证书的归档：证书具有一定的有效期，证书过了有效期之后就将作废，但是我们不能将作废的证书简单地丢弃，因为有时我们可能需要验证以前的某个交易过程中产生的数字签名，这时我们就需要查询作废的证书。 1.2 Certificate 1.2.1 X.509标准 \u0026ldquo;SSL证书\u0026quot;这个词是一个相对较大的概念，整个PKI体系中有很多SSL证书格式标准。PKI的标准规定了PKI的设计、实施和运营，规定了PKI各种角色的\u0026quot;游戏规则\u0026rdquo;，提供数据语法和语义的共同约定。x.509是PKI中最重要的标准，它定义了公钥证书的基本结构，可以说PKI是在X.509标准基础上发展起来的：\nSSL公钥证书 证书废除列表CRL(Certificate revocation lists 证书黑名单) 参考 http://en.wikipedia.org/wiki/X.509 。\n另外一个常用的标准是PKCS#12，通常采用pfx,p12作为文件扩展名，openssl和java的keytool工具都可以用作生产此类格式的证书。\n1.2.2 ssl公钥证书格式 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 1. 证书版本号(Version) 版本号指明X.509证书的格式版本，现在的值可以为: 1) 0: v1 2) 1: v2 3) 2: v3 也为将来的版本进行了预定义 2. 证书序列号(Serial Number) 序列号指定由CA分配给证书的唯一的\u0026#34;数字型标识符\u0026#34;。当证书被取消时，实际上是将此证书的序列号放入由CA签发的CRL中， 这也是序列号唯一的原因。 3. 签名算法标识符(Signature Algorithm) 签名算法标识用来指定由CA签发证书时所使用的\u0026#34;签名算法\u0026#34;。算法标识符用来指定CA签发证书时所使用的: 1) 公开密钥算法 2) hash算法 example: sha256WithRSAEncryption 须向国际知名标准组织(如ISO)注册 4. 签发机构名(Issuer) 此域用来标识签发证书的CA的X.500 DN(DN-Distinguished Name)名字。包括: 1) 国家(C) 2) 省市(ST) 3) 地区(L) 4) 组织机构(O) 5) 单位部门(OU) 6) 通用名(CN) 7) 邮箱地址 5. 有效期(Validity) 指定证书的有效期，包括: 1) 证书开始生效的日期时间 2) 证书失效的日期和时间 每次使用证书时，需要检查证书是否在有效期内。 6. 证书用户名(Subject) 指定证书持有者的X.500唯一名字。包括: 1) 国家(C) 2) 省市(ST) 3) 地区(L) 4) 组织机构(O) 5) 单位部门(OU) 6) 通用名(CN) 7) 邮箱地址 7. 证书持有者公开密钥信息(Subject Public Key Info) 证书持有者公开密钥信息域包含两个重要信息: 1) 证书持有者的公开密钥的值 2) 公开密钥使用的算法标识符。此标识符包含公开密钥算法和hash算法。 8. 扩展项(extension) X.509 V3证书是在v2的基础上一标准形式或普通形式增加了扩展项，以使证书能够附带额外信息。标准扩展是指 由X.509 V3版本定义的对V2版本增加的具有广泛应用前景的扩展项，任何人都可以向一些权威机构，如ISO，来 注册一些其他扩展，如果这些扩展项应用广泛，也许以后会成为标准扩展项。 9. 签发者唯一标识符(Issuer Unique Identifier) 签发者唯一标识符在第2版加入证书定义中。此域用在当同一个X.500名字用于多个认证机构时，用一比特字符串 来唯一标识签发者的X.500名字。可选。 10. 证书持有者唯一标识符(Subject Unique Identifier) 持有证书者唯一标识符在第2版的标准中加入X.509证书定义。此域用在当同一个X.500名字用于多个证书持有者时， 用一比特字符串来唯一标识证书持有者的X.500名字。可选。 11. 签名算法(Signature Algorithm) 证书签发机构对证书上述内容的签名算法 example: sha256WithRSAEncryption 12. 签名值(Issuer\u0026#39;s Signature) 证书签发机构对证书上述内容的签名值 example:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 Certificate: Data: Version: 3 (0x2) Serial Number: 9 (0x9) Signature Algorithm: sha256WithRSAEncryption Issuer: C=CN, ST=GuangDong, L=ShenZhen, O=COMPANY Technologies Co., Ltd, OU=IT_SECTION, CN=registry.example.com.net/emailAddress=zhouxiao@example.com.net Validity Not Before: Feb 11 06:04:56 2015 GMT Not After : Feb 8 06:04:56 2025 GMT Subject: C=CN, ST=GuangDong, L=ShenZhen, O=TP-Link Co.,Ltd., OU=Network Management, CN=172.31.1.210 Subject Public Key Info: Public Key Algorithm: rsaEncryption Public-Key: (2048 bit) Modulus: 00:a4:b0:dd:eb:c1:cf:5d:47:61:a6:ea:ef:8b:aa: 4b:f0:b4:2c:d8:96:c7:7c:ac:fa:c7:35:88:53:d0: ... 8a:76:dc:8f:8c:44:c8:0b:3c:36:88:5f:01:f0:44: 4e:81:e6:7a:2b:ff:ba:da:33:a5:27:11:c6:f0:08: 6e:f3 Exponent: 65537 (0x10001) X509v3 extensions: X509v3 Basic Constraints: CA:FALSE Netscape Comment: OpenSSL Generated Certificate X509v3 Subject Key Identifier: 07:C6:87:B7:C1:1E:28:E8:96:3F:EB:40:1E:82:41:45:CA:81:B6:3D X509v3 Authority Key Identifier: keyid:A4:C2:14:6A:39:D1:95:1E:BD:DF:3B:92:4A:5C:12:42:1B:BC:53:B8 Signature Algorithm: sha256WithRSAEncryption 0c:c6:81:70:cd:0a:2d:94:4f:cb:a4:1d:ef:9e:8e:e4:73:ae: 50:62:a8:9c:64:ef:56:0f:41:fe:6b:b4:d3:07:37:39:2c:ed: ... 6f:62:61:b8:03:d7:97:31:ab:05:44:20:07:65:8b:ad:e2:cc: ad:65:73:f6:82:0f:9e:65:d0:ae:b7:1e:fd:9f:c1:d7:41:6c: 0f:06:95:ee -----BEGIN CERTIFICATE----- MIIEMDCCAxigAwIBAgIBCTANBgkqhkiG9w0BAQsFADCBtTELMAkGA1UEBhMCQ04x EjAQBgNVBAgMCUd1YW5nRG9uZzERMA8GA1UEBwwIU2hlblpoZW4xJjAkBgNVBAoM ... ujwwRar6pPzusO95WuS93HsNmL2ZFZ63DS4LcW9iYbgD15cxqwVEIAdli63izK1l c/aCD55l0K63Hv2fwddBbA8Gle4= -----END CERTIFICATE----- 2. 附：数据加密的基础知识 对称密钥加密 对称密钥加密（一个密钥），也叫做共享密钥加密或机密密钥加密，使用发件人和收件人共同拥有的单个密钥。这种密钥既用于加密，也用于解密，叫做机密密钥。对称密钥加密是加密大量数据的一种行之有效的方法。\n对称密钥加密有许多种算法如DES,RC4,IDEA等，但所有这些算法都有一个共同的目的：以可还原的方式将明文 （未加密的数据转换为暗文。暗文使用加密密钥编码，对于没有解密密钥的任何人来说它都是没有意义的。由于对称密钥加密在加密和解密时使用相同的密钥，所以这种加密过程的安全性取决于是否有未经授权的人获得了对称密钥。\n衡量对称算法优劣的主要尺度是其密钥的长度。密钥越长，在找到解密数据所需的正确密钥之前必须测试的密钥数量就越多。需要测试的密钥越多，破解这种算法就越困难。\n公钥加密 公钥加密使用两个密钥:一个公钥和一个私钥，这两个密钥在数学上是相关的。为了与对称密钥加密相对照，公钥加密有时也叫做不对称密钥加密。在公钥加密中，公钥可在通信双方之间公开传递，或在公用储备库中发布，但相关的私钥是保密的。只有使用私钥才能解密用公钥加密的数据。使用私钥加密的数据只能用公钥解密。下图中，发件人拥有收件人的公钥，并用它加密了一封邮件，但只有收件人掌握解密该邮件的有关私钥。 公钥算法的主要局限在于，这种加密形式的速度相对较低。实际上，通常仅在关键时刻才使用公钥算法，如在实体之间交换对称密钥时，或者在签署一封邮件的散列时（散列是通过应用一种单向数学函数获得的一个定长结果，对于数据而言，叫做散列算法）。将公钥加密与其它加密形式（如对称密钥加密）结合使用，可以优化性能，如数字签名和密钥交换。\n常用公钥算法：\nRSA：适用于数字签名和密钥交换。 是目前应用最广泛的公钥加密算法，特别适用于通过 Internet 传送的数据，RSA算法以它的三位发明者的名字命名。 DSA：仅适用于数字签名。 数字签名算法 (Digital Signature Algorithm, DSA) 由美国国家安全署 (United States National Security Agency, NSA) 发明，已作为数字签名的标准。DSA 算法的安全性取决于自计算离散算法的困难。这种算法，不适用于数据加密。 Diffie-Hellman：仅适用于密钥交换。 Diffie-Hellman 是发明的第一个公钥算法，以其发明者 Whitfield Diffie 和 Martin Hellman 的名字命名。Diffie-Hellman 算法的安全性取决于在一个有限字段中计算离散算法的困难。 单向散列算法 散列，也称为散列值或消息摘要 ，是一种与基于密钥（对称密钥或公钥）的加密不同的数据转换类型。散列就是通过把一个叫做散列算法的单向数学函数应用于数据，将任意长度的一块数据转换为一个定长的、不可逆转的数字，其长度通常在128～256位之间。所产生的散列值的长度应足够长，因此使找到两块具有相同散列值的数据的机会很少。如发件人生成邮件的散列值并加密它，然后将它与邮件本身一起发送。而收件人同时解密邮件和散列值，并由接收到的邮件产生另外一个散列值，然后将两个散列值进行比较。如果两者相同，邮件极有可能在传输期间没有发生任何改变。\n下面是几个常用的散列函数：\nMD5：是RSA数据安全公司开发的一种单向散列算法，MD5被广泛使用，可以用来把不同长度的数据块进行暗码运算成一个128位的数值。 SHA-1：与 DSA 公钥算法相似，安全散列算法1（SHA-1）也是由 NSA 设计的，并由 NIST 将其收录到 FIPS 中，作为散列数据的标准。它可产生一个 160 位的散列值。SHA-1 是流行的用于创建数字签名的单向散列算法。 MAC（Message Authentication Code）：消息认证代码，是一种使用密钥的单向函数，可以用它们在系统上或用户之间认证文件或消息，常见的是HMAC（用于消息认证的密钥散列算法）。 CRC（Cyclic Redundancy Check）：循环冗余校验码，CRC校验由于实现简单，检错能力强，被广泛使用在各种数据校验应用中。占用系统资源少，用软硬件均能实现，是进行数据传输差错检测地一种很好的手段（CRC 并不是严格意义上的散列算法，但它的作用与散列算法大致相同，所以归于此类）。 数字签名：结合使用公钥与散列算法 数字签名是邮件、文件或其它数字编码信息的发件人将他们的身份与信息绑定在一起（即为信息提供签名）的方法。对信息进行数字签名的过程，需要将信息与由发件人掌握的秘密信息一起转换（使用私钥）为叫做签名的标记。数字签名用于公钥环境（任何人都可以拥有）中，它通过验证发件人确实是他或她所声明的那个人，并确认收到的邮件与发送的邮件完全相同。\n散列算法处理数据的速度比公钥算法快得多。散列数据还缩短了要签名的数据的长度，因而加快了签名过程。\n密钥交换：结合使用对称密钥与公钥 对称密钥算法非常适合于快速并安全地加密数据。但其缺点是，发件人和收件人必须在交换数据之前先交换机密密钥。结合使用加密数据的对称密钥算法与交换机密密钥的公钥算法可产生一种既快速又灵活的解决方案。\n参考 openSSL命令、PKI、CA、SSL证书原理\nX.509 wikipeida\nPKI 基础知识\n数字证书及CA的扫盲介绍\n","permalink":"http://localhost:1313/2015/01/openssl-certificate-encryption/","summary":"\u003cp\u003eSSL/TLS 介绍见文章 \u003ca href=\"http://xgknight.com/2015/01/07/tls-ssl\"\u003eSSL/TLS原理详解\u003c/a\u003e。\n如果你想快速自建CA然后签发数字证书，请移步 \u003ca href=\"http://xgknight.com/2015/01/18/openssl-self-sign-ca\"\u003e基于OpenSSL自建CA和颁发SSL证书 \u003c/a\u003e 。\u003c/p\u003e\n\u003cp\u003e首先简单区分一下HTTPS、SSL、OpenSSL三者的关系：\u003c/p\u003e\n\u003cp\u003eSSL是在客户端和服务器之间建立一条SSL安全通道的安全协议，而OpenSSL是TLS/SSL协议的开源实现，提供开发库和命令行程序。常说的HTTPS是HTTP的加密版，底层使用的加密协议是SSL。\u003c/p\u003e","title":"OpenSSL 与 SSL 数字证书概念贴"},{"content":"本文大部分整理自网络，相关文章请见文后参考。\n关于证书授权中心CA以及数字证书等概念，请移步 OpenSSL 与 SSL 数字证书概念贴 ，如果你想快速自建CA然后签发数字证书，请移步 基于OpenSSL自建CA和颁发SSL证书 。\nSSL/TLS作为一种互联网安全加密技术，原理较为复杂，枯燥而无味，我也是试图理解之后重新整理，尽量做到层次清晰。正文开始。\n1. SSL/TLS概览 1.1 整体结构 SSL是一个介于HTTP协议与TCP之间的一个可选层，其位置大致如下: SSL：（Secure Socket Layer，安全套接字层），为Netscape所研发，用以保障在Internet上数据传输之安全，利用数据加密(Encryption)技术，可确保数据在网络上之传输过程中不会被截取。当前版本为3.0。它已被广泛地用于Web浏览器与服务器之间的身份认证和加密数据传输。 SSL协议位于TCP/IP协议与各种应用层协议之间，为数据通讯提供安全支持。SSL协议可分为两层： SSL记录协议（SSL Record Protocol）：它建立在可靠的传输协议（如TCP）之上，为高层协议提供数据封装、压缩、加密等基本功能的支持。 SSL握手协议（SSL Handshake Protocol）：它建立在SSL记录协议之上，用于在实际的数据传输开始前，通讯双方进行身份认证、协商加密算法、交换加密密钥等。\nTLS：(Transport Layer Security，传输层安全协议)，用于两个应用程序之间提供保密性和数据完整性。 TLS 1.0是IETF（Internet Engineering Task Force，Internet工程任务组）制定的一种新的协议，它建立在SSL 3.0协议规范之上，是SSL 3.0的后续版本，可以理解为SSL 3.1，它是写入了 RFC 的。该协议由两层组成： TLS 记录协议（TLS Record）和 TLS 握手协议（TLS Handshake）。较低的层为 TLS 记录协议，位于某个可靠的传输协议（例如 TCP）上面。\nSSL/TLS协议提供的服务主要有：\n认证用户和服务器，确保数据发送到正确的客户机和服务器； 加密数据以防止数据中途被窃取； 维护数据的完整性，确保数据在传输过程中不被改变。 1.2 TLS与SSL的差异 版本号：TLS记录格式与SSL记录格式相同，但版本号的值不同，TLS的版本1.0使用的版本号为SSLv3.1。 报文鉴别码：SSLv3.0和TLS的MAC算法及MAC计算的范围不同。TLS使用了RFC-2104定义的HMAC算法。SSLv3.0使用了相似的算法，两者差别在于SSLv3.0中，填充字节与密钥之间采用的是连接运算，而HMAC算法采用的是异或运算。但是两者的安全程度是相同的。 伪随机函数：TLS使用了称为PRF的伪随机函数来将密钥扩展成数据块，是更安全的方式。 报警代码：TLS支持几乎所有的SSLv3.0报警代码，而且TLS还补充定义了很多报警代码，如解密失败（decryption_failed）、记录溢出（record_overflow）、未知CA（unknown_ca）、拒绝访问（access_denied）等。 密文族和客户证书：SSLv3.0和TLS存在少量差别，即TLS不支持Fortezza密钥交换、加密算法和客户证书。 certificate_verify和finished消息：SSLv3.0和TLS在用certificate_verify和finished消息计算MD5和SHA-1散列码时，计算的输入有少许差别，但安全性相当。 加密计算：TLS与SSLv3.0在计算主密值（master secret）时采用的方式不同。 填充：用户数据加密之前需要增加的填充字节。在SSL中，填充后的数据长度要达到密文块长度的最小整数倍。而在TLS中，填充后的数据长度可以是密文块长度的任意整数倍（但填充的最大长度为255字节），这种方式可以防止基于对报文长度进行分析的攻击。 TLS的主要增强内容\nTLS的主要目标是使SSL更安全，并使协议的规范更精确和完善。TLS 在SSL v3.0 的基础上，提供了以下增强内容：\n更安全的MAC算法 更严密的警报 “灰色区域”规范的更明确的定义 TLS对于安全性的改进\n对于消息认证使用密钥散列法：TLS 使用“消息认证代码的密钥散列法”（HMAC），当记录在开放的网络（如因特网）上传送时，该代码确保记录不会被变更。SSLv3.0还提供键控消息认证，但HMAC比SSLv3.0使用的（消息认证代码）MAC 功能更安全。 增强的伪随机功能（PRF）：PRF生成密钥数据。在TLS中，HMAC定义PRF。PRF使用两种散列算法保证其安全性。如果任一算法暴露了，只要第二种算法未暴露，则数据仍然是安全的。 改进的已完成消息验证：TLS和SSLv3.0都对两个端点提供已完成的消息，该消息认证交换的消息没有被变更。然而，TLS将此已完成消息基于PRF和HMAC值之上，这也比SSLv3.0更安全。 一致证书处理：与SSLv3.0不同，TLS试图指定必须在TLS之间实现交换的证书类型。 特定警报消息：TLS提供更多的特定和附加警报，以指示任一会话端点检测到的问题。TLS还对何时应该发送某些警报进行记录。 2. 密钥协商过程——TLS握手 SSL协议分为两部分：Handshake Protocol和Record Protocol。其中Handshake Protocol用来协商密钥，协议的大部分内容就是通信双方如何利用它来安全的协商出一份密钥。 Record Protocol则定义了传输的格式。\n由于非对称加密的速度比较慢，所以它一般用于密钥交换，双方通过公钥算法协商出一份密钥，然后通过对称加密来通信，当然，为了保证数据的完整性，在加密前要先经过HMAC的处理。\nSSL缺省只进行server端的认证，客户端的认证是可选的。以下是其流程图（摘自TLS协议）。 2.1 客户端发出请求（ClientHello） 由于客户端(如浏览器)对一些加解密算法的支持程度不一样，但是在TLS协议传输过程中必须使用同一套加解密算法才能保证数据能够正常的加解密。在TLS握手阶段，客户端首先要告知服务端，自己支持哪些加密算法，所以客户端需要将本地支持的加密套件(Cipher Suite)的列表传送给服务端。除此之外，客户端还要产生一个随机数，这个随机数一方面需要在客户端保存，另一方面需要传送给服务端，客户端的随机数需要跟服务端产生的随机数结合起来产生后面要讲到的 Master Secret 。\n综上，在这一步，客户端主要向服务器提供以下信息：\n支持的协议版本，比如TLS 1.0版 一个客户端生成的随机数，稍后用于生成\u0026quot;对话密钥\u0026quot; 支持的加密方法，比如RSA公钥加密 支持的压缩方法 2.2 服务器回应（SeverHello) 上图中，从Server Hello到Server Done，有些服务端的实现是每条单独发送，有服务端实现是合并到一起发送。Sever Hello和Server Done都是只有头没有内容的数据。\n服务端在接收到客户端的Client Hello之后，服务端需要将自己的证书发送给客户端。这个证书是对于服务端的一种认证。例如，客户端收到了一个来自于称自己是www.alipay.com的数据，但是如何证明对方是合法的alipay支付宝呢？这就是证书的作用，支付宝的证书可以证明它是alipay，而不是财付通。证书是需要申请，并由专门的数字证书认证机构(CA)通过非常严格的审核之后颁发的电子证书。颁发证书的同时会产生一个私钥和公钥。私钥由服务端自己保存，不可泄漏。公钥则是附带在证书的信息中，可以公开的。证书本身也附带一个证书电子签名，这个签名用来验证证书的完整性和真实性，可以防止证书被串改。另外，证书还有个有效期。\n在服务端向客户端发送的证书中没有提供足够的信息（证书公钥）的时候，还可以向客户端发送一个 Server Key Exchange，\n此外，对于非常重要的保密数据，服务端还需要对客户端进行验证，以保证数据传送给了安全的合法的客户端。服务端可以向客户端发出 Cerficate Request 消息，要求客户端发送证书对客户端的合法性进行验证。比如，金融机构往往只允许认证客户连入自己的网络，就会向正式客户提供USB密钥，里面就包含了一张客户端证书。\n跟客户端一样，服务端也需要产生一个随机数发送给客户端。客户端和服务端都需要使用这两个随机数来产生Master Secret。\n最后服务端会发送一个Server Hello Done消息给客户端，表示Server Hello消息结束了。\n综上，在这一步，服务器的回应包含以下内容：\n确认使用的加密通信协议版本，比如TLS 1.0版本。如果浏览器与服务器支持的版本不一致，服务器关闭加密通信 一个服务器生成的随机数，稍后用于生成\u0026quot;对话密钥\u0026quot; 确认使用的加密方法，比如RSA公钥加密 服务器证书 2.3 客户端回应（Certificate Verify） Client Key Exchange\n如果服务端需要对客户端进行验证，在客户端收到服务端的 Server Hello 消息之后，首先需要向服务端发送客户端的证书，让服务端来验证客户端的合法性。\nCertificate Verify 接着，客户端需要对服务端的证书进行检查，如果证书不是可信机构颁布、或者证书中的域名与实际域名不一致、或者证书已经过期，就会向访问者显示一个警告，由其选择是否还要继续通信。如果证书没有问题，客户端就会从服务器证书中取出服务器的公钥。然后，向服务器发送下面三项信息：\n一个随机数。该随机数用服务器公钥加密，防止被窃听 编码改变通知，表示随后的信息都将用双方商定的加密方法和密钥发送 客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时也是前面发送的所有内容的hash值，用来供服务器校验 上面第一项的随机数，是整个握手阶段出现的第三个随机数，它是客户端使用一些加密算法(例如：RSA, Diffie-Hellman)产生一个48个字节的Key，这个Key叫 PreMaster Secret，很多材料上也被称作 PreMaster Key。\nChangeCipherSpec ChangeCipherSpec是一个独立的协议，体现在数据包中就是一个字节的数据，用于告知服务端，客户端已经切换到之前协商好的加密套件（Cipher Suite）的状态，准备使用之前协商好的加密套件加密数据并传输了。\n在ChangecipherSpec传输完毕之后，客户端会使用之前协商好的加密套件和Session Secret加密一段 Finish 的数据传送给服务端，此数据是为了在正式传输应用数据之前对刚刚握手建立起来的加解密通道进行验证。\n2.4 服务器的最后回应（Server Finish） 服务端在接收到客户端传过来的 PreMaster 加密数据之后，使用私钥对这段加密数据进行解密，并对数据进行验证，也会使用跟客户端同样的方式生成 Session Secret，一切准备好之后，会给客户端发送一个 ChangeCipherSpec，告知客户端已经切换到协商过的加密套件状态，准备使用加密套件和 Session Secret加密数据了。之后，服务端也会使用 Session Secret 加密一段 Finish 消息发送给客户端，以验证之前通过握手建立起来的加解密通道是否成功。\n根据之前的握手信息，如果客户端和服务端都能对Finish信息进行正常加解密且消息正确的被验证，则说明握手通道已经建立成功，接下来，双方可以使用上面产生的Session Secret对数据进行加密传输了。\n2.5 几个secret Secret Keys 上面的分析和讲解主要是为了突出握手的过程，所以PreMaster secret，Master secret，session secret都是一代而过，但是对于Https，SSL/TLS深入的理解和掌握，这些Secret Keys是非常重要的部分。所以，准备把这些Secret Keys抽出来单独分析和讲解。\n我们先来看看这些Secret Keys的生成过程以及作用流程图： PreMaster secret PreMaster Secret是在客户端使用RSA或者Diffie-Hellman等加密算法生成的。它将用来跟服务端和客户端在Hello阶段产生的随机数结合在一起生成 Master Secret。在客户端使用服务端的公钥对PreMaster Secret进行加密之后传送给服务端，服务端将使用私钥进行解密得到PreMaster secret。也就是说服务端和客户端都有一份相同的PreMaster secret和随机数。\nPreMaster secret前两个字节是TLS的版本号，这是一个比较重要的用来核对握手数据的版本号，因为在Client Hello阶段，客户端会发送一份加密套件列表和当前支持的SSL/TLS的版本号给服务端，而且是使用明文传送的，如果握手的数据包被破解之后，攻击者很有可能串改数据包，选择一个安全性较低的加密套件和版本给服务端，从而对数据进行破解。所以，服务端需要对密文中解密出来对的PreMaster版本号跟之前Client Hello阶段的版本号进行对比，如果版本号变低，则说明被串改，则立即停止发送任何消息。\n关于PreMaster Secret(Key)的计算请参考 Https SSL/TLS PreMaster/Master Secret(Key)计算。\nMaster secret 上面已经提到，由于服务端和客户端都有一份相同的PreMaster secret和随机数，这个随机数将作为后面产生Master secret的种子，结合PreMaster secret，客户端和服务端将计算出同样的Master secret。\nMaster secret是有系列的hash值组成的，它将作为数据加解密相关的secret的 Key Material 的一部分。Key Material最终解析出来的数据如下： 其中，write MAC key，就是session secret或者说是session key。Client write MAC key是客户端发数据的session secret，Server write MAC secret是服务端发送数据的session key。MAC(Message Authentication Code)，是一个数字签名，用来验证数据的完整性，可以检测到数据是否被串改。\n关于Session Secret(Key)的计算请参考 Https SSL/TLS Session Secret(Key)计算。\n2.6 应用数据传输 在所有的握手阶段都完成之后，就可以开始传送应用数据了。应用数据在传输之前，首先要附加上MAC secret，然后再对这个数据包使用write encryption key进行加密。在服务端收到密文之后，使用Client write encryption key进行解密，客户端收到服务端的数据之后使用Server write encryption key进行解密，然后使用各自的write MAC key对数据的完整性包括是否被串改进行验证。\n2.7 总结 SSL客户端（也是TCP的客户端）在TCP链接建立之后，发出一个ClientHello来发起握手，这个消息里面包含了自己可实现的算法列表和其它一些需要的消息，SSL的服务器端会回应一个ServerHello，这里面确定了这次通信所需要的算法，然后发过去自己的证书（里面包含了身份和自己的公钥）。Client在收到这个消息后会生成一个秘密消息，用SSL服务器的公钥加密后传过去，SSL服务器端用自己的私钥解密后，会话密钥协商成功，双方可以用同一份会话密钥来通信了。\n3. 附：密钥协商的形象化比喻 如果上面的说明不够清晰，这里我们用个形象的比喻，我们假设A与B通信，A是SSL客户端，B是SSL服务器端，加密后的消息放在方括号[]里，以突出明文消息的区别。双方的处理动作的说明用圆括号（）括起。\nA：我想和你安全的通话，我这里的对称加密算法有DES,RC5,密钥交换算法有RSA和DH，摘要算法有MD5和SHA。\nB：我们用DES－RSA－SHA这对组合好了。 这是我的证书，里面有我的名字和公钥，你拿去验证一下我的身份（把证书发给A）。 目前没有别的可说的了。\nA：（查看证书上B的名字是否无误，并通过手头早已有的CA的证书验证了B的证书的真实性，如果其中一项有误，发出警告并断开连接，这一步保证了B的公钥的真实性） （产生一份秘密消息，这份秘密消息处理后将用作加密密钥，加密初始化向量（IV）和hmac的密钥。将这份秘密消息-协议中称为per_master_secret-用B的公钥加密，封装成称作ClientKeyExchange的消息。由于用了B的公钥，保证了第三方无法窃听） 我生成了一份秘密消息，并用你的公钥加密了，给你（把ClientKeyExchange发给B） 注意，下面我就要用加密的办法给你发消息了！ （将秘密消息进行处理，生成加密密钥，加密初始化向量和hmac的密钥） [我说完了]\nB：（用自己的私钥将ClientKeyExchange中的秘密消息解密出来，然后将秘密消息进行处理，生成加密密钥，加密初始化向量和hmac的密钥，这时双方已经安全的协商出一套加密办法了）\n注意，我也要开始用加密的办法给你发消息了！ [我说完了]\nA: [我的秘密是\u0026hellip;]\nB: [其它人不会听到的\u0026hellip;]\n4. SSL安全性 SecurityPortal在2000年底有一份文章《The End of SSL and SSH?》激起了很多的讨论， 目前也有一些成熟的工具如dsniff（http://www.monkey.org/~dugsong/dsniff/）可以通过man in the middle攻击来截获https的消息。\n从上面的原理可知，SSL的结构是严谨的，问题一般出现在实际不严谨的应用中。常见的攻击就是middle in the middle攻击，它是指在A和B通信的同时，有第三方C处于信道的中间，可以完全听到A与B通信的消息，并可拦截，替换和添加这些消息。\nSSL可以允许多种密钥交换算法，而有些算法，如DH，没有证书的概念，这样A便无法验证B的公钥和身份的真实性，从而C可以轻易的冒充，用自己的密钥与双方通信，从而窃听到别人谈话的内容。 而为了防止middle in the middle攻击，应该采用有证书的密钥交换算法。 有了证书以后，如果C用自己的证书替换掉原有的证书之后，A的浏览器会弹出一个警告框进行警告，但又有多少人会注意这个警告呢？ 由于美国密码出口的限制，IE，netscape等浏览器所支持的加密强度是很弱的，如果只采用浏览器自带的加密功能的话，理论上存在被破解可能。 5. 代理 下面探讨一下SSL的代理是怎样工作的 当在浏览器里设置了https的代理，而且里输入了https://www.example.com之后，浏览器会与proxy建立tcp链接，然后向其发出这么一段消息：\nCONNECT server.example.com:443 HTTP/1.1 Host: server.example.com:443 然后proxy会向webserver端建立tcp连接,之后，这个代理便完全成了个内容转发装置。浏览器与web server会建立一个安全通道，因此这个安全通道是端到端的，尽管所有的信息流过了proxy,但其内容proxy是无法解密和改动的（当然要由证书的支持，否则这个地方便是个man in the middle攻击的好场所，见上面的安全部分）。\nCA证书以及如何使用OpenSSL自签署，见文章OpenSSL自签署证书 。\n6. 参考 Https(SSL/TLS)原理详解\nKeyless SSL: The Nitty Gritty Technical Details\nSSL与TLS的区别以及介绍\nSSL/TLS协议运行机制的概述\nSSL/TLS/WTLS原理\nTransport Layer Security (TLS)\n传输层安全协议\nSurvival guides - TLS/SSL and SSL (X.509) Certificates\n","permalink":"http://localhost:1313/2015/01/tls-ssl/","summary":"\u003cp\u003e本文大部分整理自网络，相关文章请见文后参考。\u003c/p\u003e\n\u003cp\u003e关于证书授权中心CA以及数字证书等概念，请移步 \u003ca href=\"http://xgknight.com/2015/01/15/openssl-certificate-encryption\"\u003eOpenSSL 与 SSL 数字证书概念贴\u003c/a\u003e ，如果你想快速自建CA然后签发数字证书，请移步 \u003ca href=\"http://xgknight.com/2015/01/18/openssl-self-sign-ca\"\u003e基于OpenSSL自建CA和颁发SSL证书 \u003c/a\u003e 。\u003c/p\u003e","title":"SSL/TLS原理详解"},{"content":" 青春是一道明媚的伤痕，疼的酣畅淋漓，走的跌跌撞撞，她不顾一切遍体鳞伤，但仍庆幸，生命中仍有人为她执着与疯狂。\n很久没有静下来总结过自己了，拥有大把的自由时间反而没有停下来写写东西。还记得上一次这种类似的总结是在毕业那会儿，qq空间里被各种日志刷屏，于是自己也写过一篇，只是没发，现在也找不到去哪里了。这里就唠一唠过去的2014吧。\n完全想不起来2014上半年做过什么事情，就像7月1号换房子之后时间河流断开了一样。一年总的说来，没什么太大变化，很失败。定过的计划，下过的决心，好像没有几件做成的。就拿体重来说，天天喊着要多吃饭，要增肥，可偏偏不爱吃长相不好的肉。这里可能就有拉仇恨的嫌疑了，毕竟嚷嚷要减肥的比要增肥的多的去了。爹妈没生好只能后天自己努力了，于是买了个电子秤，天天在家“吃饱了cheng”——唉声叹气远比眉开眼笑次数多，为了身体也是蛮拼的了。\n相比以前来说，比较欣慰的是运动的频率多了，从夏热天一直到10月份，基本每周都会和小明去游泳。经常感到郁闷的是在游泳池里游泳怎么小明还要带上一瓶脉动，我就从来没感到过口渴……不说了，池里的水没少喝，到现在蛙泳还不敢游到中点，真是废。天变凉后，正巧室友要出国，把全新的羽毛球拍放我这，于是不出意外每周都会跟峰哥他们去打球，逐渐的爱上在球场上酣畅淋漓的感觉，从一开始只是玩玩，到有意识的练技术，再到看电视里的比赛，不知不觉快成为一种习惯了，这个习惯与能不能邂逅到运动型的妹子无关 -_-#，是不是，经常去隔壁王叔叔家打洞的小明。。\n曾经我是一个比较宅的人，很少出去离校旅行但也不玩游戏，就莫名其妙的忙碌。我讨厌宅，更害怕一个人，所以六七月份找房子的时候从没考虑过单间，人是需要同伴才不会孤独，哪怕是走在路上看到个漂亮姑娘可以来吐槽的“腐友”。但同时我也经常会很安静，比如在下班车上跑到人少座位，一个人占着两个座，靠外的放包，靠窗的看外面，从疲惫的眼睛上取下眼镜，不必看得太清，单曲循环或随机播放着手机里的歌曲，成了装逼犯。下半年也随同事、朋友去阳江、阳朔玩过，爬了两次梧桐山，部门活动也没缺席过，算是改变闷*的历程吧。还计划过找时间去厦门转转，去哈尔滨看雪（不要问我雪是谁），由于种种原因都被搁浅了。\n除了频率并不算高的体育锻炼和户外运动，酒桌、KTV也没少去，刚来公司那会儿的几个同事现在也成了最好的朋友，年轻的同龄人在一起也没什么束缚，谁谁过生日撮一顿，好久没聚了就到谁家吃火锅。KTV倒不是我乐意去的地方，玩玩游戏、骰子还可以，唱歌也就只能吧唧跟着吼两句，不能认真。从前就没练过，五音不全，也回不到过去傲娇耍个性，也许我有其它过人之处我自己都没发现呢！如果非到打击我说，“上帝给我关上了一扇门，又顺手帮我关了一扇窗”，那就是逼我破门向前了。\n其它方面，可能因为本身一年来并没有什么成就，没攒下多少money，还过着这样安逸的生活，所有偶尔会“痛心疾首”一番，在手机上做个笔记计划点什么，劲头一过又看电视、玩手机去了，还时常忘记给爸妈打电话，即使说在电话里说来说去就那些内容。记得有一次脚踝无缘无故疼起来，最严重的时候都站不住了，成功了领到了来深圳第一份病历，这事在朋友圈散开后让我哥告诉了爸妈，随后几天每天都打电话来问好些没，果然是亲生的…这里还要谢谢周围还有网上留言关心过我的人，岁月淘沙能留下的是何其珍贵。中秋之前特意去广州看过爸妈，前几个月也从香港带了些药去，只是岁月不饶人，而我还太年轻，哥哥生意刚有起色而嫂子马上生小孩，怎么越想压力越大呢，难道这就是属羊的命不好？偶还是相信事在人为吧！\n其实有时候觉得我还是挺幸运的，周围很多人都是学习的对象。人不是要成为谁，有的人会侃，有的人会耍，还有的人思考问题敏捷、思维方式不同，可能说起来有点虚无但真真切切是我从不同的人身上感受到的。虽然不必互相过分对比，但我认为正能量的东西还是很愿意去多多接触。根深，暑假来我这逗留过一段时间，它是少数让我觉得读研还是有用的几人，想到什么便说什么，敢于闯荡（有爱大声说啊）；德义，也是跟我睡过同一张床铺的，有明确的规划和目标，有见解（高富帅带我飞）；小明，活泼可爱任性又偶尔带点深沉（求别喷），经常能想他人之未想，会做饭。等等这些优秀的朋友、同学、同事，让我偶尔觉得无所适从，告诉自己未来还有很多事情要做……\n工作方面，虽然占据了大部分时间，但并没有那么多可说的，能说的都是槽点。不是吐槽一下网络管理课那群没脑子的，就是工作没啥事闲着淡腾，用同样的话反复回答为什么加班——没事才加班。其实真不是非要加班，因为确实是不加班回家也没事做，看电视玩手机到晚上依然要1点睡觉，正如前面说的就目前这个阶段来说，何必过得太安逸呢。都说在TP的员工成熟起来会很慢，所以闲着闲着就需要自己去思考出路。IT运维的工作（DBA?），在这样有限的环境里，只能靠自己去学习，所以有80%时间我是借着工作内容关联或技术调研的名义在学着其它东西，零碎时间逛逛社区和问答网站。也买了些数据分析与金融方面的书，只是一直没有看过，这也将成为2015年计划的一部分了，权当小说看了。\n规划性的东西这里就不说了，自己有个底就行，太过形式或太过庄重都不好。只说一个字，不要闹“2015年新年计划就是搞定2014年那些原定于2013年完成的安排，不为别的，只为兑现2012年时 要完成2011年计划的诺言。”的笑话就OK。\n回头看，整篇写起来还真是天马行空，想到哪写到哪，连标题都想不到好一点的，没什么逻辑、文采可言，只是做个记录，剩下的交给心情……\n","permalink":"http://localhost:1313/2014/12/feel-2014-end/","summary":"\u003cblockquote\u003e\n\u003cp\u003e青春是一道明媚的伤痕，疼的酣畅淋漓，走的跌跌撞撞，她不顾一切遍体鳞伤，但仍庆幸，生命中仍有人为她执着与疯狂。\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e\u003cimg alt=\"feel-jxzlmd1\" loading=\"lazy\" src=\"http://github.com/seanlook/sean-notes-comment/raw/main/static/feel-jxzlmd1.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003e很久没有静下来总结过自己了，拥有大把的自由时间反而没有停下来写写东西。还记得上一次这种类似的总结是在毕业那会儿，qq空间里被各种日志刷屏，于是自己也写过一篇，只是没发，现在也找不到去哪里了。这里就唠一唠过去的2014吧。\u003c/p\u003e","title":"只怕时间走的太过匆忙，忘记了躲在角落中的我"},{"content":"Shipyard（github）是建立在docker集群管理工具Citadel之上的可以管理容器、主机等资源的web图形化工具。包括core和extension两个版本，core即shipyard主要是把多个 Docker host上的 containers 统一管理（支持跨越多个host），extension即shipyard-extensions添加了应用路由和负载均衡、集中化日志、部署等。\n1. 几个概念 engine 一个shipyard管理的docker集群可以包含一个或多个engine（引擎），一个engine就是监听tcp端口的docker daemon。shipyard管理docker daemon、images、containers完全基于Docker API，不需要做其他的修改。另外，shipyard可以对每个engine做资源限制，包括CPU和内存；因为TCP监听相比Unix socket方式会有一定的安全隐患，所以shipyard还支持通过SSL证书与docker后台进程安全通信。\nrethinkdb RethinkDB是一个shipyard项目的一个docker镜像，用来存放账号（account）、引擎（engine）、服务密钥（service key）、扩展元数据（extension metadata）等信息，但不会存储任何有关容器或镜像的内容。一般会启动一个shipyard/rethinkdb容器shipyard-rethinkdb-data来使用它的/data作为数据卷供另外rethinkdb一个挂载，专门用于数据存储。\n2. 搭建过程 修改tcp监听 Shipyard 要管理和控制 Docker host 的话需要先修改 Docker host 上的默认配置使其监听tcp端口(可以继续保持Unix socket）。有以下2种方式\nsudo docker -H tcp://0.0.0.0:4243 -H unix:///var/run/docker.sock -d 启动docker daemon。如果为了避免每次启动都写这么长的命令，可以直接在/etc/init/docker.conf中修改。 修改/etc/default/docker的DOCKER_OPTS DOCKER_OPTS=\u0026quot;-H tcp://127.0.0.1:4243 -H unix:///var/run/docker.sock\u0026quot;。这种方式在我docker version 1.4.1 in ubuntu 14.04上并没有生效。 1 2 3 4 5 重启服务 $ sudo docker -H tcp://0.0.0.0:4243 -H unix:///var/run/docker.sock -d 验证 $ netstat -ant |grep 4243 tcp6 0 0 :::4243 :::* LISTEN 启动rethinkdb shipyard（基于Python/Django）在v1版本时安装过程比较复杂，既可以通过在host上安装，也可以部署shipyard镜像（包括shipyard-agent、shipyard-deploy等组件）。v2版本简化了安装过程，启动两个镜像就完成：\n1 2 3 4 5 6 7 获取一个/data的数据卷 $sudo docker run -it -d --name shipyard-rethinkdb-data \\ --entrypoint /bin/bash shipyard/rethinkdb -l 使用数据卷/data启动RethinkDB docker run -it -P -d --name shipyard-rethinkdb \\ --volumes-from shipyard-rethinkdb-data shipyard/rethinkdb 部署shipyard镜像 启动shipyard控制器：\n1 2 sudo docker run -it -p 8080:8080 -d --name shipyard \\ --link shipyard-rethinkdb:rethinkdb shipyard/shipyard 至此已经可以通过浏览器访问http://host:8080来访问shipyard UI界面了。\n第一次run后，关闭再次启动时直接使用：\n1 2 sudo docker stop shipyard shipyard-rethinkdb shipyard-rethinkdb-data sudo docker start shipyard-rethinkdb-data shipyard-rethinkdb shipyard 图示 登录： 默认用户名/密码为 admin/shipyard\n主界面： Dashboard展示在添加engine时指定的CPU以及内存的使用情况。\n容器： shipyard管理的所有docker主机的所有容器，包括stop和running状态的。可以直接点击DEPLOY按钮来从镜像运行出其他容器，与docker run的选项几乎相同，可以限制CPU和内存的使用，详见shipyard的containers文档。\n容器操作： 可以stop、start、restart容器，通过LOGS可以看到容器日志输出，SCALE可以批量（规模化）部署该容器，这个操作与容器的Type属性息息相关。因为shipyard可以管理多个host的docker容器，所以启动一个容器的type可以是：service——可以在具有相同label的engine上运行；unique——一个host上只允许某个镜像的一个实例运行；host——在指定的host上运行容器，启动的时候通过--label host:\u0026lt;host-id\u0026gt;语法指定docker host。\nengine管理： 一个engine就是一个docker daemon，docker daemon下启动着多个containers，可以对engine限制一个整体的CPU和内存限制，shipyard通过TCP端口连接daemon。需要注意的是docker client与server的版本问题：（因为shipyard目前还在快速的完善过程，不同版本的docker应该是向下兼容的）\n1 2 curl -X GET http://172.29.88.223:4243/v1.15/containers/json client and server don\u0026#39;t have same version (client : 1.15, server: 1.13) 3. shipyard-cli 目前图形化界面能做的操作其实很少，正在强大的是通过shipyard提供的命令行窗口（称作Shipyard CLI）进行管理，参考http://shipyard-project.com/docs/usage/cli/ 启动命令行交互模式：\nsudo docker run --rm -it shipyard/shipyard-cli 使用它甚至可以替代docker客户端。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 sean@seanubt:~$ sudo docker run -it shipyard/shipyard-cli shipyard cli\u0026gt; shipyard help NAME: shipyard - manage a shipyard cluster USAGE: shipyard [global options] command [command options] [arguments...] VERSION: 2.0.8 COMMANDS: login\tlogin to a shipyard cluster change-password\tupdate your password accounts\tshow accounts add-account\tadd account delete-account\tdelete account containers\tlist containers inspect\tinspect container run\trun a container stop\tstop a container restart\trestart a container scale\tscale a container logs\tshow container logs destroy\tdestroy a container engines\tlist engines add-engine\tadd shipyard engine remove-engine\tremoves an engine inspect-engine\tinspect an engine service-keys\tlist service keys add-service-key\tadds a service key remove-service-key\tremoves a service key extensions\tshow extensions add-extension\tadd extension remove-extension\tremove an extension webhook-keys\tlist webhook keys add-webhook-key\tadds a webhook key remove-webhook-key\tremoves a webhook key info\tshow cluster info events\tshow cluster events help, h\tShows a list of commands or help for one command GLOBAL OPTIONS: --help, -h\tshow help --generate-bash-completion\t--version, -v\tprint the version 登录shipyard shipyard cli\u0026gt; shipyard login URL: http://172.29.88.205:8080 Username: admin Password: 查看containers shipyard cli\u0026gt; shipyard containers 启动一个容器 shipyard cli\u0026gt; shipyard run --name nginx:1.7.6 --container-name web_test \\ --cpus 0.2 \\ --memory 64 \\ --type service \\ --hostname nginx-test \\ --domain example.com \\ --link redis:db \\ --port tcp/172.29.88.205:81:8081 \\ --port tcp/::8000 \\ --restart \u0026#34;on-failure:5\u0026#34; \\ --env FOO=bar \\ --label dev \\ 查看容器日志（只能接容器ID，暂不能使用容器名） shipyard cli\u0026gt; shipyard logs ff2761d 关闭并移除容器 shipyard cli\u0026gt; shipyard destroy \u0026lt;container_id\u0026gt; 不一一列举。。。\n","permalink":"http://localhost:1313/2014/12/docker-shipyard-centralized-management-webui/","summary":"\u003cp\u003e\u003ca href=\"http://shipyard-project.com/\"\u003eShipyard\u003c/a\u003e（\u003ca href=\"https://github.com/shipyard/shipyard\"\u003egithub\u003c/a\u003e）是建立在docker集群管理工具\u003ca href=\"https://github.com/citadel/citadel\"\u003eCitadel\u003c/a\u003e之上的可以管理容器、主机等资源的web图形化工具。包括\u003ca href=\"https://github.com/shipyard/shipyard\"\u003ecore\u003c/a\u003e和\u003ca href=\"https://github.com/shipyard/shipyard-extensions\"\u003eextension\u003c/a\u003e两个版本，core即shipyard主要是把多个 Docker host上的 containers 统一管理（支持跨越多个host），extension即shipyard-extensions添加了应用路由和负载均衡、集中化日志、部署等。\u003c/p\u003e","title":"Docker集中化web界面管理平台shipyard"},{"content":"本文简单介绍docker使用到的部分核心技术，但不做深入探究，因为每一个技术都是一个独立的项目，有机会再分别详细介绍。 来源地址：http://www.infoq.com/cn/articles/docker-core-technology-preview\nLinux Namespace （实例隔离）## The purpose of each namespace is to wrap a particular global system resource in an abstraction that makes it appear to the processes within the namespace that they have their own isolated instance of the global resource.\n每个用户实例之间相互隔离，互不影响。一般的硬件虚拟化方法给出的方法是VM，而LXC给出的方法是container，更细一点讲就是kernel namespace。其中pid、net、ipc、mnt、uts、user等namespace将container的进程、网络、消息、文件系统、UTS(\u0026ldquo;UNIX Time-sharing System\u0026rdquo;)和用户空间隔离开。\npid namespace 不同用户的进程就是通过pid namespace隔离开的，且不同 namespace 中可以有相同pid。所有的LXC进程在docker中的父进程为docker进程，每个lxc进程具有不同的namespace。同时由于允许嵌套，因此可以很方便的实现 Docker in Docker。\n** net namespace ** 有了 pid namespace, 每个namespace中的pid能够相互隔离，但是网络端口还是共享host的端口。网络隔离是通过net namespace实现的， 每个net namespace有独立的 network devices, IP addresses, IP routing tables, /proc/net 目录。这样每个container的网络就能隔离开来。LXC在此基础上有5种网络类型，docker默认采用veth的方式将container中的虚拟网卡同host上的一个docker bridge—docker0连接在一起。\n** ipc namespace ** container中进程交互还是采用linux常见的进程间交互方法(interprocess communication - IPC), 包括常见的信号量、消息队列和共享内存。然而与VM不同，container 的进程间交互实际上还是host上具有相同pid namespace中的进程间交互，因此需要在IPC资源申请时加入namespace信息 - 每个IPC资源有一个唯一的 32bit ID。\n** mnt namespace ** 类似chroot，将一个进程放到一个特定的目录执行。mnt namespace允许不同namespace的进程看到的文件结构不同，这样每个 namespace 中的进程所看到的文件目录就被隔离开了。同chroot不同，每个namespace中的container在/proc/mounts`的信息只包含所在namespace的mount point。\n** uts namespace ** UTS(\u0026ldquo;UNIX Time-sharing System\u0026rdquo;) namespace允许每个container拥有独立的hostname和domain name, 使其在网络上可以被视作一个独立的节点而非Host上的一个进程。\n** user namespace ** 每个container可以有不同的 user 和 group id, 也就是说可以以container内部的用户在container内部执行程序而非Host上的用户。\n有了以上6种namespace从进程、网络、IPC、文件系统、UTS和用户角度的隔离，一个container就可以对外展现出一个独立计算机的能力，并且不同container从OS层面实现了隔离。 然而不同namespace之间资源还是相互竞争的，仍然需要类似ulimit来管理每个container所能使用的资源——LXC 采用的是cgroup。\n参考\nPaaS under the hood, episode 1: kernel namespaces， [中文] http://blog.blackwhite.tw/2013/12/docker.html cgroup （资源配额） cgroups 实现了对资源的配额和度量。cgroups 的使用非常简单，提供类似文件的接口，在 /cgroup目录下新建一个文件夹即可新建一个group，在此文件夹中新建task文件，并将pid写入该文件，即可实现对该进程的资源控制。具体的资源配置选项可以在该文件夹中新建子subsystem，{子系统前缀}.{资源项} 是典型的配置方法， 如memory.usage_in_bytes就定义了该group 在subsystem memory中的一个内存限制选项。\n我们主要关心cgroups可以限制哪些资源，即有哪些subsystem是我们关心。\ncpu 在cgroup中，并不能像硬件虚拟化方案一样能够定义CPU能力，但是能够定义CPU轮转的优先级，因此具有较高CPU优先级的进程会更可能得到CPU运算。 通过将参数写入cpu.shares,即可定义改cgroup的CPU优先级 - 这里是一个相对权重，而非绝对值。当然在cpu这个subsystem中还有其他可配置项，手册中有详细说明。\ncpuacct 产生cgroup任务的cpu资源报告\ncpuset cpusets 定义了有几个CPU可以被这个group使用，或者哪几个CPU可以供这个group使用。在某些场景下，单CPU绑定可以防止多核间缓存切换，从而提高效率\nmemory 设置每个cgroup的内存限制以及产生内存资源报告\nblkio block IO相关的统计和限制，byte/operation统计和限制(IOPS等)，读写速度限制等，但是这里主要统计的都是同步IO\nnet_cls 标记每个网络包以供cgroup方便使用\ndevices 允许或拒绝cgroup任务对设备的访问\nfreezer 暂停和恢复cgroup任务\n参考\nPaaS Under the Hood, Episode 2: cgroups https://www.kernel.org/doc/Documentation/cgroups/ http://en.wikipedia.org/wiki/Cgroups LXC（LinuX Container） LXC (LinuX Container) is an operating system-level virtualization method for running multiple isolated Linux systems (containers) on a single control host. This is accomplished through kernel level isolation.\n借助于namespace的隔离机制和cgroup限额功能，LXC提供了一套统一的API和工具来建立和管理container，LXC利用了如下 kernel 的特性：\nKernel namespaces (ipc, uts, mount, pid, network and user) Apparmor and SELinux profiles (security) Seccomp policies Chroots (using pivot_root) Kernel capabilities Control groups (cgroups) LXC 旨在提供一个共享kernel的 OS 级虚拟化方法，在执行时不用重复加载Kernel，且container的kernel与host共享，因此可以大大加快container的 启动过程，并显著减少内存消耗。\n这篇stackoverflow上的问题和答案很好地诠释了Docker和LXC的区别，能够让你更好的了解什么是Docker， 简单翻译下就是以下几点：\nPortable deployment across machines Docker提供了一种可移植的配置标准化机制，允许你一致性地在不同的机器上运行同一个Container；而LXC本身可能因为不同机器的不同配置而无法方便地移植运行； Application-centric Docker以App为中心，为应用的部署做了很多优化，而LXC的帮助脚本主要是聚焦于如何机器启动地更快和耗更少的内存； Automatic build Docker为App提供了一种自动化构建机制（Dockerfile），包括打包，基础设施依赖管理和安装等等； Versioning Docker提供了一种类似git的Container版本化的机制，允许你对你创建过的容器进行版本管理，依靠这种机制，你还可以下载别人创建的Container，甚至像git那样进行合并； Component reuse Docker Container是可重用的，依赖于版本化机制，你很容易重用别人的Container（叫Image），作为基础版本进行扩展； Sharing Docker Container是可共享的，有点类似github一样，Docker有自己的INDEX，你可以创建自己的Docker用户并上传和下载Docker Image； Tool ecosystem Docker提供了很多的工具链，形成了一个生态系统；这些工具的目标是自动化、个性化和集成化，包括对PAAS平台的支持等。 参考\nhttp://linuxcontainers.org/ http://en.wikipedia.org/wiki/LXC http://marceloneves.org/papers/pdp2013-containers.pdf (性能测试) http://article.sciencepublishinggroup.com/pdf/10.11648.j.ajnc.20130204.11.pdf AUFS Docker对container的使用基本是建立在LXC基础之上的，然而LXC存在的问题是难以移动——难以通过标准化的模板制作、重建、复制和移动 container。在以VM为基础的虚拟化手段中，有image和snapshot可以用于VM的复制、重建以及移动的功能。想要通过container来实现快速的大规模部署和更新, 这些功能不可或缺。Docker正是利用AUFS来实现对container的快速更新——在docker0.7中引入了storage driver, 支持AUFS, VFS, device mapper, 也为BTRFS以及ZFS引入提供了可能。\nAUFS (Another Union FS) 是一种 Union FS，简单来说就是支持将不同目录挂载到同一个虚拟文件系统下(unite several directories into a single virtual filesystem)的文件系统, 更进一步的理解, AUFS支持为每一个成员目录（类似Git Branch）设定readonly、readwrite 和 whiteout-able 权限, 同时 AUFS 里有一个类似分层的概念, 对 readonly 权限的 branch 可以逻辑上进行修改(增量地, 不影响 readonly 部分的)。通常 Union FS 有两个用途, 一方面可以实现不借助 LVM、RAID 将多个disk挂到同一个目录下, 另一个更常用的就是将一个 readonly 的 branch 和一个 writeable 的 branch 联合在一起，Live CD正是基于此方法可以允许在 OS image 不变的基础上允许用户在其上进行一些写操作。Docker 在 AUFS 上构建的 container image 也正是如此，接下来我们从启动 container 中的 linux 为例来介绍 docker 对AUFS特性的运用。\n典型的启动Linux运行需要两个FS: bootfs + rootfs：\nbootfs（boot file system）主要包含 bootloader 和 kernel, bootloader主要是引导加载kernel, 当boot成功后 kernel 被加载到内存中后 bootfs就被umount了。rootfs (root file system) 包含的就是典型 Linux 系统中的 /dev, /proc, /bin, /etc等标准目录和文件。\n由此可见对于不同的linux发行版, bootfs基本是一致的, rootfs会有差别, 因此不同的发行版可以公用bootfs 如下图：\n典型的Linux在启动后，首先将 rootfs 置为 readonly，进行一系列检查，然后将其切换为 \u0026ldquo;readwrite\u0026rdquo; 供用户使用。在docker中，起初也是将 rootfs 以readonly方式加载并检查，然而接下来利用 union mount 的将一个 readwrite 文件系统挂载在 readonly 的rootfs之上，并且允许再次将下层的 file system设定为readonly 并且向上叠加，这样一组readonly和一个writeable的结构构成一个container的运行目录，每一个被称作一个Layer。如下图：\n得益于AUFS的特性，每一个对readonly层文件/目录的修改都只会存在于上层的writeable层中。这样由于不存在竞争，多个container可以共享readonly的layer。所以docker将readonly的层称作 \u0026ldquo;image\u0026rdquo;——对于container而言整个rootfs都是read-write的，但事实上所有的修改都写入最上层的writeable层中，image不保存用户状态，可以用于模板、重建和复制。\n上层的image依赖下层的image，因此docker中把下层的image称作父image，没有父image的image称作base image。\n因此想要从一个image启动一个container，docker会先加载其父image直到base image，用户的进程运行在writeable的layer中。所有parent image中的数据信息以及 ID、网络和lxc管理的资源限制等具体container的配置，构成一个docker概念上的container。如下图：\n由此可见，采用AUFS作为docker的container的文件系统，能够提供如下好处:\n节省存储空间：多个container可以共享base image存储 快速部署：如果要部署多个container，base image可以避免多次拷贝 内存更省：因为多个container共享base image, 以及OS的disk缓存机制，多个container中的进程命中缓存内容的几率大大增加 升级更方便：相比于 copy-on-write 类型的FS，base-image也是可以挂载为可writeable的，可以通过更新base image而一次性更新其之上的container 允许在不更改base-image的同时修改其目录中的文件：所有写操作都发生在最上层的writeable层中，这样可以大大增加base image能共享的文件内容。 以上5条 1-3 条可以通过 copy-on-write 的FS实现，4可以利用其他的union mount方式实现, 5只有AUFS实现的很好，这也是为什么Docker一开始就建立在AUFS之上。\n由于AUFS并不会进入linux主干 (According to Christoph Hellwig, linux rejects all union-type filesystems but UnionMount.), 同时要求kernel版本3.0以上(docker推荐3.8及以上)，因此在RedHat工程师的帮助下在docker0.7版本中实现了driver机制, AUFS只是其中的一个driver, 在RHEL中采用的则是Device Mapper的方式实现的container文件系统。\n参考\nPAAS Under the Hood, Episode 3: AUFS http://docs.docker.com/terms/layer/ http://docs.docker.com/terms/filesystem/ 全文参考 http://tiewei.github.io/cloud/Docker-Getting-Start/\nhttps://docker.cn/a/1\nhttp://blog.dotcloud.com/category/under-the-hood\nhttp://www.slideshare.net/BodenRussell/realizing-linux-containerslxc\n","permalink":"http://localhost:1313/2014/12/docker-core-technology-preview/","summary":"\u003cp\u003e本文简单介绍docker使用到的部分核心技术，但不做深入探究，因为每一个技术都是一个独立的项目，有机会再分别详细介绍。\n来源地址：http://www.infoq.com/cn/articles/docker-core-technology-preview\u003c/p\u003e","title":"【转+改】Docker核心技术预览"},{"content":"1. docker是什么 Docker is an open-source engine that automates the deployment of any application as a lightweight, portable, self-sufficient container that will run virtually anywhere.\nDocker是 PaaS 提供商dotCloud开源的一个基于 LXC 的高级容器引擎， 源代码托管在 Github 上, 基于go语言并遵从Apache2.0协议开源。Docker近期非常火热，无论是从 GitHub 上的代码活跃度，还是Redhat宣布在RHEL7中正式支持Docker，都给业界一个信号，这是一项创新型的技术解决方案。就连 Google 公司的 Compute Engine 也支持 docker 在其之上运行，国内“BAT”先锋企业百度Baidu App Engine(BAE)平台也是以Docker作为其PaaS云基础。\nDocker产生的目的就是为了解决以下问题：\n环境管理复杂：从各种OS到各种中间件再到各种App，一款产品能够成功发布，作为开发者需要关心的东西太多，且难于管理，这个问题在软件行业中普遍存在并需要直接面对。Docker可以简化部署多种应用实例工作，比如Web应用、后台应用、数据库应用、大数据应用比如Hadoop集群、消息队列等等都可以打包成一个Image部署。 云计算时代的到来：AWS的成功，引导开发者将应用转移到云上, 解决了硬件管理的问题，然而软件配置和管理相关的问题依然存在 (AWS cloudformation是这个方向的业界标准, 样例模板可参考这里)。Docker的出现正好能帮助软件开发者开阔思路，尝试新的软件管理方法来解决这个问题。 虚拟化手段的变化：云时代采用标配硬件来降低成本，采用虚拟化手段来满足用户按需分配的资源需求以及保证可用性和隔离性。然而无论是KVM还是Xen，在 Docker 看来都在浪费资源，因为用户需要的是高效运行环境而非OS，GuestOS既浪费资源又难于管理，更加轻量级的LXC更加灵活和快速。 LXC的便携性：LXC在 Linux 2.6 的 Kernel 里就已经存在了，但是其设计之初并非为云计算考虑的，缺少标准化的描述手段和容器的可便携性，决定其构建出的环境难于分发和标准化管理(相对于KVM之类image和snapshot的概念)。Docker就在这个问题上做出了实质性的创新方法。 Docker的主要特性如下：\n文件系统隔离：每个进程容器运行在完全独立的根文件系统里。 资源隔离：可以使用cgroup为每个进程容器分配不同的系统资源，例如CPU和内存。 网络隔离：每个进程容器运行在自己的网络命名空间里，拥有自己的虚拟接口和IP地址。 写时复制：采用写时复制方式创建根文件系统，这让部署变得极其快捷，并且节省内存和硬盘空间。 日志记录：Docker将会收集和记录每个进程容器的标准流（stdout/stderr/stdin），用于实时检索或批量检索。 变更管理：容器文件系统的变更可以提交到新的映像中，并可重复使用以创建更多的容器。无需使用模板或手动配置。 交互式Shell：Docker可以分配一个虚拟终端并关联到任何容器的标准输入上，例如运行一个一次性交互shell。 2. 比较 2.1 docker vs 传统虚拟化技术 作为一种新兴的虚拟化方式，Docker 跟传统的虚拟化方式（xen、kvm、vmware）相比具有众多的优势。\n首先，Docker 容器的启动可以在秒级实现，这相比传统的虚拟机方式要快得多。 其次，Docker 对系统资源的利用率很高，一台主机上可以同时运行数千个 Docker 容器。容器除了运行其中应用外，基本不消耗额外的系统资源，使得应用的性能很高，同时系统的开销尽量小。传统虚拟机方式运行 10 个不同的应用就要起 10 个虚拟机，而Docker 只需要启动 10 个隔离的应用即可。\n具体说来，Docker 在如下几个方面具有较大的优势。\n更快速的交付和部署 对开发和运维（devop）人员来说，最希望的就是一次创建或配置，可以在任意地方正常运行。 开发者可以使用一个标准的镜像来构建一套开发容器，开发完成之后，运维人员可以直接使用这个容器来部署代码。 Docker 可以快速创建容器，快速迭代应用程序，并让整个过程全程可见，使团队中的其他成员更容易理解应用程序是如何创建和工作的。 Docker 容器很轻很快！容器的启动时间是秒级的，大量地节约开发、测试、部署的时间。\n更高效的虚拟化 Docker 容器的运行不需要额外的 hypervisor 支持，它是内核级的虚拟化，因此可以实现更高的性能和效率。\n更轻松的迁移和扩展 Docker 容器几乎可以在任意的平台上运行，包括物理机、虚拟机、公有云、私有云、个人电脑、服务器等。 这种兼容性可以让用户把一个应用程序从一个平台直接迁移到另外一个。 更简单的管理\n使用 Docker，只需要小小的修改，就可以替代以往大量的更新工作。所有的修改都以增量的方式被分发和更新，从而实现自动化并且高效的管理。\n对比传统虚拟机总结：\n特性 容器 虚拟机 启动 秒级 分钟级 硬盘使用 一般为 MB 一般为 GB 性能 接近原生 弱于 系统支持量 单机支持上千个容器 一般几十个 2.2 docker vs lxc Docker以Linux容器LXC为基础，实现轻量级的操作系统虚拟化解决方案。在LXC的基础上Docker进行了进一步的封装，让用户不需要去关心容器的管理，使得操作更为简便，具体改进有：\nPortable deployment across machines Docker提供了一种可移植的配置标准化机制，允许你一致性地在不同的机器上运行同一个Container；而LXC本身可能因为不同机器的不同配置而无法方便地移植运行； Application-centric Docker以App为中心，为应用的部署做了很多优化，而LXC的帮助脚本主要是聚焦于如何机器启动地更快和耗更少的内存； Automatic build Docker为App提供了一种自动化构建机制（Dockerfile），包括打包，基础设施依赖管理和安装等等； Versioning Docker提供了一种类似git的Container版本化的机制，允许你对你创建过的容器进行版本管理，依靠这种机制，你还可以下载别人创建的Container，甚至像git那样进行合并； Component reuse Docker Container是可重用的，依赖于版本化机制，你很容易重用别人的Container（叫Image），作为基础版本进行扩展； Sharing Docker Container是可共享的，有点类似github一样，Docker有自己的INDEX，你可以创建自己的Docker用户并上传和下载Docker Image； Tool ecosystem Docker提供了很多的工具链，形成了一个生态系统；这些工具的目标是自动化、个性化和集成化，包括对PAAS平台的支持等。 3. docker应用场景 Docker作为一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。Docker可以自动化打包和部署任何应用、创建一个轻量级私有PaaS云、搭建开发测试环境、部署可扩展的Web应用等。这决定了它在企业中的应用场景是有限的，Docker将自己定位为“分发应用的开放平台”，其网站上也明确地提到了Docker的典型应用场景：\nAutomating the packaging and deployment of applications Creation of lightweight, private PAAS environments Automated testing and continuous integration/deployment Deploying and scaling web apps, databases and backend services 对应用进行自动打包和部署，创建轻量、私有的PAAS环境，自动化测试和持续整合与部署，部署和扩展Web应用、数据库和后端服务。\n平台即服务一般与大数据量系统同在，反观当前我司各IT系统，可以在以下情形下使用docker替代方案：\n结合vagrant或supervisor，搭建统一的开发、测试环境 多个开发人员共同进行一个项目，就必须保持开发环境完全一致，部署到测试环境、正式环境后，最好都是同一套环境，通过容器来保存状态，分发给开发人员或部署，可以让“代码在我机子上运行没有问题”这种说辞将成为历史。 对memcached、mysql甚至tomcat，打包成一个个容器，避免重复配置 比如将一个稳定版本的、已配置完善的mysql，固化在一个镜像中，假如有新的环境要用到mysql数据库，便不需要重新安装、配置，而只需要启动一个容器瞬间完成。tomcat应用场景更多，可以将不同版本的jvm和tomcat打包分发，应用于多tomcat集群，或在测试服务器上隔离多个不同运行环境要求的测试应用（例如旧系统采用的是jdk6，新系统在jdk7上开发，但共用同一套测试环境）。 docker不足\nLXC是基于cgroup等linux kernel功能的，因此container的guest系统只能是linux base的 隔离性相比KVM之类的虚拟化方案还是有些欠缺，所有container公用一部分的运行库 网络管理相对简单，主要是基于namespace隔离 cgroup的cpu和cpuset提供的cpu功能相比KVM的等虚拟化方案相比难以度量(所以dotcloud主要是安内存收费) container随着用户进程的停止而销毁，container中的log等用户数据不便收集 另外，Docker是面向应用的，其终极目标是构建PAAS平台，而现有虚拟机主要目的是提供一个灵活的计算资源池，是面向架构的，其终极目标是构建一个IAAS平台，所以它不能替代传统虚拟化解决方案。目前在容器可管理性方面，对于方便运维，提供UI来管理监控各个containers的功能还不足，还都是第三方实现如DockerUI、Dockland、Shipyard等。\n4. docker组成部分 Docker使用客户端-服务器(client-server)架构模式。Docker客户端会与Docker守护进程进行通信。Docker守护进程会处理复杂繁重的任务，例如建立、运行、发布你的Docker容器。Docker客户端和守护进程可以运行在同一个系统上，当然你也可以使用Docker客户端去连接一个远程的Docker守护进程。Docker客户端和守护进程之间通过socket或者RESTful API进行通信。\n更多内容请参考：Docker核心技术预览 及docker常用管理命令。\n4.1 images（镜像）## Docker 镜像就是一个只读的模板。例如，一个镜像可以包含一个完整的 ubuntu 操作系统环境，里面仅安装了 Apache 或用户需要的其它应用程序。 镜像可以用来创建 Docker 容器。 Docker 提供了一个很简单的机制来创建镜像或者更新现有的镜像，用户甚至可以直接从其他人那里下载一个已经做好的镜像来直接使用。\n4.2 container（容器）## Docker 利用容器来运行应用。容器是从镜像创建的运行实例。它可以被启动、开始、停止、删除。每个容器都是相互隔离的、保证安全的平台。可以把容器看做是一个简易版的 Linux 环境（包括root用户权限、进程空间、用户空间和网络空间等）和运行在其中的应用程序。 镜像是只读的，容器在启动的时候创建一层可写层作为最上层。\n4.3 repository（仓库）## 仓库是集中存放镜像文件的场所。有时候会把仓库和仓库注册服务器（Registry）混为一谈，并不严格区分。实际上，仓库注册服务器上往往存放着多个仓库，每个仓库中又包含了多个镜像，每个镜像有不同的标签（tag）。\n4.3.1 公开仓库### docker团队控制的top-level的顶级repository，即Docker Hub，存放了数量庞大的镜像供用户下载，任何人都能读取，里面包含了许多常用的镜像，如ubuntu, mysql ,redis, python等。\n4.3.2 个人公共库### 个人公共库也是被托管在Docker Hub上，网络上的其它用户也可以pull你的仓库（如docker pull seanloook/centos6）你可以在修改完自己的container之后，通过commit命令把它变成本地的一个image，push到自己的个人公共库。（在此之前你需要docker login登录，或者vi ~/.dockercfg。）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 从镜像运行出一个容器 docker run -t -i 68edf809afe7 /bin/bash 记录下CONTAINER ID docker ps -l CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 1528136ff541 172.29.88.222:5000/centos6:latest /bin/bash 40 minutes ago Exited (0) .. sad_mestorf 从将容器提交成一个新的image (format is \u0026#34;sudo docker commit \u0026lt;container_id\u0026gt; \u0026lt;username\u0026gt;/\u0026lt;imagename\u0026gt;\u0026#34;) # docker commit -m \u0026#34; new images /docker.sean \u0026#34; -a \u0026#34;docker New\u0026#34; fcbd0a5348ca seanloook/centos6:test_tag_sean fe022762070b09866eaab47bc943ccb796e53f3f416abf3f2327481b446a9503 docker images可以看到这个新的镜像 # docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE seanloook/centos6 test_tag_sean fe022762070b About an hour ago 212.7 MB sean:5000/library/centos6 latest 68edf809afe7 3 weeks ago 212.7 MB 在你commit为一个image后，通过push可以推送到个人公共registry中。此时需要login后才能push（当然没有设定login的Username，在第一次push时也会提示输入），接下来比较有意思。\n1 2 3 4 5 # docker login https://index.docker.io/v1/ Username: seanloook Password: Email: seanlook7@gmail.com Login Succeeded 如果你已经有docker官网的账号，则只需要输入正确的用户名和密码就可以登录，邮箱不做验证； 如果所输入的Username不存在，则这一步便是自动从官网创建一个账号，并发送一封确认邮件，以后也可以从https://hub.docker.com/repos/ 登录。（是不是太简单了?）\nlogin的同时，也会在~/.dockercfg中加入认证信息\n1 2 # cat ~/.dockercfg {\u0026#34;https://index.docker.io/v1/\u0026#34;:{\u0026#34;auth\u0026#34;:\u0026#34;c2Vhbmxvb29rOk15UGFzc3dvcmQ=\u0026#34;,\u0026#34;email\u0026#34;:\u0026#34;seanlook7@gmail.com\u0026#34;}} 其中auth=base64(username:password)，base64编码与解码。\n保存到个人公共库上，push可以是repos，格式docker push \u0026lt;username\u0026gt;/\u0026lt;repo_name\u0026gt;：\n1 2 3 4 5 6 7 8 9 # docker push seanloook/centos6:test_tag_sean The push refers to a repository [seanloook/centos6] (len: 1) Sending image list Pushing repository seanloook/centos6 (1 tags) 511136ea3c5a: Image already pushed, skipping 5b12ef8fd570: Image already pushed, skipping 68edf809afe7: Image already pushed, skipping fe022762070b: Image successfully pushed Pushing tag for rev [fe022762070b] on {https://cdn-registry-1.docker.io/v1/repositories/seanloook/centos6/tags/test_tag_sean} 上面的push操作也可以是docker push seanloook/centos6（但不能是docker push fe022762070b）。\n这些镜像其他人也可以搜索得到docker search seanloo。\n4.3.3 私有仓库### 首先与另外一种仓库区分——Docker Hub Private Repository，它简单理解为公网上的个人私有库，与上面的个人公共库相对应，在Docker Hub上Create Repository时选择Private便是，只有你自己才可以读写。\n这里所说的私有仓库是指自己在本地服务器上搭建的专属自己的内部仓库docker-registry，俗称“私服”，供无法访问互联网的内部网络使用，或者镜像到本地一份以加快pull、push的速度。\n它与公共仓库最明显的区分就是repository的命名，如必须使用带.的主机名或域名，后面必须接:port，如sean.tp-link.net:5000/centos6:your_tag_name，而公共仓库第一个斜杠前表示的是登录用户名。命名关系到推送到哪个服务器的哪个位置，更过内容可以关注搭建docker内网私服（docker-registry with nginx\u0026amp;ssl on centos）。\n4.4 运行一个容器的内部过程 docker client告诉docker daemon运行一个容器，例如：docker run -i -t ubuntu /bin/bash 让我们分解一下这个命令，docker client启动使用一个二进制的docker命令，最小的docker client需要你告诉docker daemon你的容器是从哪个docker镜像构建的，你希望在容器内部运行哪个命令。所以启动过程如下：\nPulling the ubuntu image docker检查是否存在ubuntu镜像，如果本地不存在ubuntu镜像，则docker会到docker index下载。 Creates a new container 利用镜像创建容器 Allocates a filesystem and mounts a read-write layer 为镜像创建文件系统层和read-write层 Allocates a network / bridge interface 为容器创建网络接口，使容器和本地机器可以通讯 Sets up an IP address 在地址池中为容器分配一个可用的IP地址 Executes a process that you specify 运行你的应用 Captures and provides application output 连接log的标准输入、输出、错误，以使你直到你的应用是否正常运行 参考 深入浅出Docker（一）：Docker核心技术预览 Docker源码分析（一）：Docker架构\nDocker Architecture based on v1.3\nDocker简介与入门\n","permalink":"http://localhost:1313/2014/12/docker-introduction/","summary":"\u003ch1 id=\"1-docker是什么\"\u003e1. docker是什么\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003eDocker is an open-source engine that automates the deployment of any application as a lightweight, portable, self-sufficient container that will run virtually anywhere.\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e\u003ca href=\"https://www.docker.com/\"\u003eDocker\u003c/a\u003e是 PaaS 提供商\u003ca href=\"https://www.dotcloud.com/\"\u003edotCloud\u003c/a\u003e开源的一个基于 LXC 的高级容器引擎， \u003ca href=\"https://github.com/docker/docker\"\u003e源代码\u003c/a\u003e托管在 Github 上, 基于go语言并遵从Apache2.0协议开源。Docker近期非常火热，无论是从 GitHub 上的代码活跃度，还是Redhat宣布在\u003ca href=\"http://server.cnw.com.cn/server-os/htm2014/20140616_303249.shtml\"\u003eRHEL7中正式支持Docker\u003c/a\u003e，都给业界一个信号，这是一项创新型的技术解决方案。就连 Google 公司的 Compute Engine 也支持 docker 在其之上运行，国内“BAT”先锋企业百度Baidu App Engine(BAE)平台也是\u003ca href=\"http://blog.docker.com/2013/12/baidu-using-docker-for-its-paas/\"\u003e以Docker作为其PaaS云基础\u003c/a\u003e。\u003c/p\u003e","title":"Docker简介"},{"content":"1. rsync 1.1 什么是rsync rsync是一个远程数据同步工具，可通过LAN/WAN快速同步多台主机间的文件。它使用所谓的“Rsync演算法”来使本地和远程两个主机之间的文件达到同步，这个算法只传送两个文件的不同部分，而不是每次都整份传送，因此速度相当快。所以通常可以作为备份工具来使用。\n运行Rsync server的机器也叫backup server，一个Rsync server可同时备份多个client的数据；也可以多个Rsync server备份一个client的数据。Rsync可以搭配ssh甚至使用daemon模式。Rsync server会打开一个873的服务通道(port)，等待对方rsync连接。连接时，Rsync server会检查口令是否相符，若通过口令查核，则可以开始进行文件传输。第一次连通完成时，会把整份文件传输一次，下一次就只传送二个文件之间不同的部份。\n基本特点：\n可以镜像保存整个目录树和文件系统； 可以很容易做到保持原来文件的权限、时间、软硬链接等； 无须特殊权限即可安装； 优化的流程，文件传输效率高； 可以使用rcp、ssh等方式来传输文件，当然也可以通过直接的socket连接； 支持匿名传输。 命令语法： rsync的命令格式可以为以下六种： rsync [OPTION]… SRC DEST rsync [OPTION]… SRC [USER@]HOST:DEST rsync [OPTION]… [USER@]HOST:SRC DEST rsync [OPTION]… [USER@]HOST::SRC DEST rsync [OPTION]… SRC [USER@]HOST::DEST rsync [OPTION]… rsync://[USER@]HOST[:PORT]/SRC [DEST]\n对应于以上六种命令格式，我们可以总结rsync有2种不同的工作模式：\nshell模式：使用远程shell程序（如ssh或rsh）进行连接。当源路径或目的路径的主机名后面包含一个冒号分隔符时使用这种模式，rsync安装完成后就可以直接使用了，无所谓启动。（目前没有尝试过这个方法） daemon模式：使用TCP直接连接rsync daemon。当源路径或目的路径的主机名后面包含两个冒号，或使用rsync://URL时使用这种模式，无需远程shell，但必须在一台机器上启动rsync daemon，默认端口873，这里可以通过rsync --daemon使用独立进程的方式，或者通过xinetd超级进程来管理rsync后台进程。 当rsync作为daemon运行时，它需要一个用户身份。如果你希望启用chroot，则必须以root的身份来运行daemon，监听端口，或设定文件属主；如果不启用chroot，也可以不使用root用户来运行daemon，但该用户必须对相应的模块拥有读写数据、日志和lock file的权限。当rsync以daemon模式运行时，它还需要一个配置文件——rsyncd.conf。修改这个配置后不必重启rsync daemon，因为每一次的client连接都会去重新读取该文件。\n我们一般把DEST远程服务器端成为rsync Server，运行rsync命令的一端SRC称为Client。\n安装： rsync在CentOS6上默认已经安装，如果没有则可以使用yum install rsync -y，服务端和客户端是同一个安装包。\n1 # rsync -h 1.2 同步测试 关于rsync命令的诸多选项说明，见另外一篇文章rsync与inotifywait命令和配置选项说明。\n1.2.1 本机文件夹同步 1 # rsync -auvrtzopgP --progress /root/ /tmp/rsync_bak/ 会看到从/root/传输文件到/tmp/rsync_bak/的列表和速率，再运行一次会看到sending incremental file list下没有复制的内容，可以在/root/下touch某一个文件再运行看到只同步了修改过的文件。\n上面需要考虑以下问题：\n删除/root/下的文件不会同步删除/tmp/rsync_bak，除非加入--delete选项 文件访问时间等属性、读写等权限、文件内容等有任何变动，都会被认为修改 目标目录下如果文件比源目录还新，则不会同步 源路径的最后是否有斜杠有不同的含义：有斜杠，只是复制目录中的文件；没有斜杠的话，不但要复制目录中的文件，还要复制目录本身 1.3 同步到远程服务器 在服务器间rsync传输文件，需要有一个是开着rsync的服务，而这一服务需要两个配置文件，说明当前运行的用户名和用户组，这个用户名和用户组在改变文件权限和相关内容的时候有用，否则有时候会出现提示权限问题。配置文件也说明了模块、模块化管理服务的安全性，每个模块的名称都是自己定义的，可以添加用户名密码验证，也可以验证IP，设置目录是否可写等，不同模块用于同步不同需求的目录。\n1.3.1 服务端配置文件 ** /etc/rsyncd.conf： **\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 #2014-12-11 by Sean uid=root gid=root use chroot=no max connections=10 timeout=600 strict modes=yes port=873 pid file=/var/run/rsyncd.pid lock file=/var/run/rsyncd.lock log file=/var/log/rsyncd.log [module_test] path=/tmp/rsync_bak2 comment=rsync test logs auth users=sean uid=sean gid=sean secrets file=/etc/rsyncd.secrets read only=no list=no hosts allow=172.29.88.204 hosts deny=0.0.0.0/32 这里配置socket方式传输文件，端口873，[module_test]开始定义一个模块，指定要同步的目录（接收）path，授权用户，密码文件，允许哪台服务器IP同步（发送）等。关于配置文件中选项的详细说明依然参考rsync与inotifywait命令和配置选项说明。\n经测试，上述配置文件每行后面不能使用#来来注释\n** /etc/rsyncd.secrets： **\n1 sean:passw0rd 一行一个用户，用户名:密码。请注意这里的用户名和密码与操作系统的用户名密码无关，可以随意指定，与/etc/rsyncd.conf中的auth users对应。\n修改权限：chmod 600 /etc/rsyncd.d/rsync_server.pwd。\n1.3.2 服务器启动rsync后台服务 修改/etc/xinetd.d/rsync文件，disable 改为 no\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # default: off # description: The rsync server is a good addition to an ftp server, as it \\ #\tallows crc checksumming etc. service rsync { disable\t= no flags\t= IPv6 socket_type = stream wait = no user = root server = /usr/bin/rsync server_args = --daemon log_on_failure += USERID } 执行service xinetd restart会一起重启rsync后台进程，默认使用配置文件/etc/rsyncd.conf。也可以使用/usr/bin/rsync --daemon --config=/etc/rsyncd.conf。\n为了以防rsync写入过多的无用日志到/var/log/message（容易塞满从而错过重要的信息），建议注释掉/etc/xinetd.conf的success：\n1 # log_on_success = PID HOST DURATION EXIT 如果使用了防火墙，要添加允许IP到873端口的规则。\n1 2 3 # iptables -A INPUT -p tcp -m state --state NEW -m tcp --dport 873 -j ACCEPT # iptables -L 查看一下防火墙是不是打开了 873端口 # netstat -anp|grep 873 建议关闭selinux，可能会由于强访问控制导致同步报错。\n1.3.3 客户端测试同步 单向同步时，客户端只需要一个包含密码的文件。 /etc/rsync_client.pwd：\n1 passw0rd chmod 600 /etc/rsync_client.pwd\n命令： 将本地/root/目录同步到远程172.29.88.223的/tmp/rsync_bak2目录（module_test指定）：\n1 /usr/bin/rsync -auvrtzopgP --progress --password-file=/etc/rsync_client.pwd /root/ sean@172.29.88.223::module_test 当然你也可以将远程的/tmp/rsync_bak2目录同步到本地目录/root/tmp：\n1 /usr/bin/rsync -auvrtzopgP --progress --password-file=/etc/rsync_client.pwd sean@172.29.88.223::module_test /root/ 从上面两个命令可以看到，其实这里的服务器与客户端的概念是很模糊的，rsync daemon都运行在远程172.29.88.223上，第一条命令是本地主动推送目录到远程，远程服务器是用来备份的；第二条命令是本地主动向远程索取文件，本地服务器用来备份，也可以认为是本地服务器恢复的一个过程。\n1.4 rsync不足 与传统的cp、tar备份方式相比，rsync具有安全性高、备份迅速、支持增量备份等优点，通过rsync可以解决对实时性要求不高的数据备份需求，例如定期的备份文件服务器数据到远端服务器，对本地磁盘定期做数据镜像等。\n随着应用系统规模的不断扩大，对数据的安全性和可靠性也提出的更好的要求，rsync在高端业务系统中也逐渐暴露出了很多不足，首先，rsync同步数据时，需要扫描所有文件后进行比对，进行差量传输。如果文件数量达到了百万甚至千万量级，扫描所有文件将是非常耗时的。而且正在发生变化的往往是其中很少的一部分，这是非常低效的方式。其次，rsync不能实时的去监测、同步数据，虽然它可以通过crontab方式进行触发同步，但是两次触发动作一定会有时间差，这样就导致了服务端和客户端数据可能出现不一致，无法在应用故障时完全的恢复数据。基于以上原因，rsync+inotify组合出现了！\n2. inotify-tools 2.1 什么是inotify inotify是一种强大的、细粒度的、异步的文件系统事件监控机制，Linux内核从2.6.13开始引入，允许监控程序打开一个独立文件描述符，并针对事件集监控一个或者多个文件，例如打开、关闭、移动/重命名、删除、创建或者改变属性。\nCentOS6自然已经支持： 使用ll /proc/sys/fs/inotify命令，是否有以下三条信息输出，如果没有表示不支持。\n1 2 3 4 total 0 -rw-r--r-- 1 root root 0 Dec 11 15:23 max_queued_events -rw-r--r-- 1 root root 0 Dec 11 15:23 max_user_instances -rw-r--r-- 1 root root 0 Dec 11 15:23 max_user_watches /proc/sys/fs/inotify/max_queued_evnets表示调用inotify_init时分配给inotify instance中可排队的event的数目的最大值，超出这个值的事件被丢弃，但会触发IN_Q_OVERFLOW事件。 /proc/sys/fs/inotify/max_user_instances表示每一个real user ID可创建的inotify instatnces的数量上限。 /proc/sys/fs/inotify/max_user_watches表示每个inotify instatnces可监控的最大目录数量。如果监控的文件数目巨大，需要根据情况，适当增加此值的大小。 inotify-tools：\ninotify-tools是为linux下inotify文件监控工具提供的一套C的开发接口库函数，同时还提供了一系列的命令行工具，这些工具可以用来监控文件系统的事件。 inotify-tools是用c编写的，除了要求内核支持inotify外，不依赖于其他。inotify-tools提供两种工具，一是inotifywait，它是用来监控文件或目录的变化，二是inotifywatch，它是用来统计文件系统访问的次数。\n下载inotify-tools-3.14-1.el6.x86_64.rpm，通过rpm包安装：\n1 2 3 4 5 6 # rpm -ivh /apps/crm/soft_src/inotify-tools-3.14-1.el6.x86_64.rpm warning: /apps/crm/soft_src/inotify-tools-3.14-1.el6.x86_64.rpm: Header V3 DSA/SHA1 Signature, key ID 4026433f: NOKEY Preparing... ########################################### [100%] 1:inotify-tools ########################################### [100%] # rpm -qa|grep inotify inotify-tools-3.14-1.el5.x86_64 2.2 inotifywait使用示例 监控/root/tmp目录文件的变化：\n1 2 /usr/bin/inotifywait -mrq --timefmt \u0026#39;%Y/%m/%d-%H:%M:%S\u0026#39; --format \u0026#39;%T %w %f\u0026#39; \\ -e modify,delete,create,move,attrib /root/tmp/ 上面的命令表示，持续监听/root/tmp目录及其子目录的文件变化，监听事件包括文件被修改、删除、创建、移动、属性更改，显示到屏幕。执行完上面的命令后，在/root/tmp下创建或修改文件都会有信息输出：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 2014/12/11-15:40:04 /root/tmp/ new.txt 2014/12/11-15:40:22 /root/tmp/ .new.txt.swp 2014/12/11-15:40:22 /root/tmp/ .new.txt.swx 2014/12/11-15:40:22 /root/tmp/ .new.txt.swx 2014/12/11-15:40:22 /root/tmp/ .new.txt.swp 2014/12/11-15:40:22 /root/tmp/ .new.txt.swp 2014/12/11-15:40:23 /root/tmp/ .new.txt.swp 2014/12/11-15:40:31 /root/tmp/ .new.txt.swp 2014/12/11-15:40:32 /root/tmp/ 4913 2014/12/11-15:40:32 /root/tmp/ 4913 2014/12/11-15:40:32 /root/tmp/ 4913 2014/12/11-15:40:32 /root/tmp/ new.txt 2014/12/11-15:40:32 /root/tmp/ new.txt~ 2014/12/11-15:40:32 /root/tmp/ new.txt ... 3. rsync组合inotify-tools完成实时同步 这一步的核心其实就是在客户端创建一个脚本rsync.sh，适用inotifywait监控本地目录的变化，触发rsync将变化的文件传输到远程备份服务器上。为了更接近实战，我们要求一部分子目录不同步，如/root/tmp/log和临时文件。\n3.1 创建排除在外不同步的文件列表 排除不需要同步的文件或目录有两种做法，第一种是inotify监控整个目录，在rsync中加入排除选项，简单；第二种是inotify排除部分不监控的目录，同时rsync中也要加入排除选项，可以减少不必要的网络带宽和CPU消耗。我们选择第二种。\n3.1.1 inotifywait排除 这个操作在客户端进行，假设/tmp/src/mail/2014/以及/tmp/src/mail/2015/cache/目录下的所有文件不用同步，所以不需要监控，/tmp/src/下的其他文件和目录都同步。（其实对于打开的临时文件，可以不监听modify时间而改成监听close_write）\ninotifywait排除监控目录有--exclude \u0026lt;pattern\u0026gt;和--fromfile \u0026lt;file\u0026gt;两种格式，并且可以同时使用，但主要前者可以用正则，而后者只能是具体的目录或文件。\n1 2 3 # vi /etc/inotify_exclude.lst： /tmp/src/pdf @/tmp/src/2014 使用fromfile格式只能用绝对路径，不能使用诸如*正则表达式去匹配，@表示排除。\n如果要排除的格式比较复杂，必须使用正则，那只能在inotifywait中加入选项，如--exclude '(.*/*\\.log|.*/*\\.swp)$|^/tmp/src/mail/(2014|201.*/cache.*)'，表示排除/tmp/src/mail/以下的2014目录，和所有201*目录下的带cache的文件或目录，以及/tmp/src目录下所有的以.log或.swp结尾的文件。\n3.1.2 rsync排除 使用inotifywait排除监控目录的情况下，必须同时使用rsync排除对应的目录，否则只要有触发同步操作，必然会导致不该同步的目录也会同步。与inotifywait类似，rsync的同步也有--exclude和--exclude-from两种写法。\n个人还是习惯将要排除同步的目录卸载单独的文件列表里，便于管理。使用--include-from=FILE时，排除文件列表用绝对路径，但FILE里面的内容请用相对路径，如： /etc/rsyncd.d/rsync_exclude.lst：\n1 2 3 4 5 6 7 8 9 10 11 mail/2014/ mail/201*/201*/201*/.??* mail??* src/*.html* src/js/ src/ext3/ src/2014/20140[1-9]/ src/201*/201*/201*/.??* membermail/ membermail??* membermail/201*/201*/201*/.??* 排除同步的内容包括，mail下的2014目录，类似2015/201501/20150101/下的临时或隐藏文件，等。\n3.2 客户端同步到远程的脚本rsync.sh 下面是一个完整的同步脚本，请根据需要进行裁剪，rsync.sh：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 #rsync auto sync script with inotify #2014-12-11 Sean #variables current_date=$(date +%Y%m%d_%H%M%S) source_path=/tmp/src/ log_file=/var/log/rsync_client.log #rsync rsync_server=172.29.88.223 rsync_user=sean rsync_pwd=/etc/rsync_client.pwd rsync_module=module_test INOTIFY_EXCLUDE=\u0026#39;(.*/*\\.log|.*/*\\.swp)$|^/tmp/src/mail/(2014|20.*/.*che.*)\u0026#39; RSYNC_EXCLUDE=\u0026#39;/etc/rsyncd.d/rsync_exclude.lst\u0026#39; #rsync client pwd check if [ ! -e ${rsync_pwd} ];then echo -e \u0026#34;rsync client passwod file ${rsync_pwd} does not exist!\u0026#34; exit 0 fi #inotify_function inotify_fun(){ /usr/bin/inotifywait -mrq --timefmt \u0026#39;%Y/%m/%d-%H:%M:%S\u0026#39; --format \u0026#39;%T %w %f\u0026#39; \\ --exclude ${INOTIFY_EXCLUDE} -e modify,delete,create,move,attrib ${source_path} \\ | while read file do /usr/bin/rsync -auvrtzopgP --exclude-from=${RSYNC_EXCLUDE} --progress --bwlimit=200 --password-file=${rsync_pwd} ${source_path} ${rsync_user}@${rsync_server}::${rsync_module} done } #inotify log inotify_fun \u0026gt;\u0026gt; ${log_file} 2\u0026gt;\u0026amp;1 \u0026amp; --bwlimit=200用于限制传输速率最大200kb，因为在实际应用中发现如果不做速率限制，会导致巨大的CPU消耗。\n在客户端运行脚本# ./rsync.sh即可实时同步目录。\n疑问 对于rsync的同步海量存在一个疑问，假如我的文件数很多即使在排除不监控和不同步目录的情况下依然有10万个文件，仅文件列表就达10M，那么岂不是每一次有文件产生或修改都会触发同步，很容易导致大部分情况下在传输文件列表和进行列表的比对，仅同步一个小文件而使用的网络带宽和CPU代价很高，特别是网络状况不佳时，上一次的列表还未传送完，又有新的文件产生触发发送文件列表。不知道rsync内部有没有这样的处理？\n其他功能：双向同步、sersync2实时同步多远程服务器\n参考 How Rsync Works 用 inotify 监控 Linux 文件系统事件 Inotify: 高效、实时的Linux文件系统事件监控框架 rsync 的核心算法 ","permalink":"http://localhost:1313/2014/12/rsync_inotify_setup/","summary":"\u003ch1 id=\"1-rsync\"\u003e1. rsync\u003c/h1\u003e\n\u003ch2 id=\"11-什么是rsync\"\u003e1.1 什么是rsync\u003c/h2\u003e\n\u003cp\u003ersync是一个远程数据同步工具，可通过LAN/WAN快速同步多台主机间的文件。它使用所谓的“Rsync演算法”来使本地和远程两个主机之间的文件达到同步，这个算法只传送两个文件的不同部分，而不是每次都整份传送，因此速度相当快。所以通常可以作为备份工具来使用。\u003c/p\u003e","title":"Linux下同步工具inotify+rsync使用详解"},{"content":"Linux上有功能强大的tar命令，tar最初是为了制作磁带备份（tape archive）而设计的，它的作用是把文件和目录备份到磁带中，然后从磁带中提取或恢复文件。现在我们可以使用tar来备份数据到任何存储介质上。它是文件级备份，不必考虑底层文件系统类别，并且支持增量备份。\n1. 部分常用选项 -z, --gzip：使用gzip工具（解）压缩，后缀一般为.gz -c, --create：tar打包，后缀一般为.tar -f, --file=：后面立刻接打包或压缩后得到的文件名 -x, --extract：解包命令，与-c对应 -p：保留备份数据的原本权限和属性 -g：后接增量备份的快照文件 -C：指定解压缩的目录 --exclude：排除不打包的目录或文件，支持正则匹配 其他\n-X, --exclude-from：在一个文件中列出要排除的目录或文件（在--exclude=较多时使用） -t, --list：列出备份档案中的文件列表，不与-c、-x同时出现 -j, --bzip2：使用bzip2工具（解）压缩，后缀一般为.bz2 -P：保留绝对路径，解压时同样会自动解压到绝对路径下 -v：（解）压缩过程显示文件处理过程，常用但不建议对大型文件使用 2. 增量备份（网站）数据 许多系统（应用或网站）每天都有静态文件产生，对于一些比较重要的静态文件如果有进行定期备份的需求，就可以通过tar打包压缩备份到指定的地方，特别是对一些总文件比较大比较多的情况，还可以利用-g选项来做增量备份。\n备份的目录最好使用相对路径，也就是进入到需要备份的根目录下\n具体示例方法如下。\n1 2 3 4 5 备份当前目录下的所有文件 # tar -g /tmp/snapshot_data.snap -zcpf /tmp/data01.tar.gz . 在需要恢复的目录下解压恢复 # tar -zxpf /tmp/data01.tar.gz -C . -g选项可以理解备份时给目录文件做一个快照，记录权限和属性等信息，第一次备份时/tmp/snapshot_data.snap不存在，会新建一个并做完全备份。当目录下的文件有修改后，再次执行第一条备份命令（记得修改后面的档案文件名），会自动根据-g指定的快照文件，增量备份修改过的文件，包括权限和属性，没有动过的文件不会重复备份。\n另外需要注意上面的恢复，是“保留恢复”，即存在相同文件名的文件会被覆盖，而原目录下已存在（但备份档案里没有）的，会依然保留。所以如果你想完全恢复到与备份文件一模一样，需要清空原目录。如果有增量备份档案，则还需要使用同样的方式分别解压这些档案，而且要注意顺序。\n下面演示一个比较综合的例子，要求：\n备份/tmp/data目录，但cache目录以及临时文件排除在外 由于目录比较大（\u0026gt;4G），所以全备时分割备份的档案（如每个备份档案文件最大1G） 保留所有文件的权限和属性，如用户组和读写权限 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # cd /tmp/data 做一次完全备份 # rm -f /tmp/snapshot_data.snap # tar -g /tmp/snapshot_data.snap -zcpf - --exclude=./cache ./ | split -b 1024M - /tmp/bak_data$(date -I).tar.gz_ 分割后文件名后会依次加上aa,ab,ac,...，上面最终的备份归档会保存成 bak_data2014-12-07.tar.gz_aa bak_data2014-12-07.tar.gz_ab bak_data2014-12-07.tar.gz_ac ... 增量备份 可以是与完全备份一模一样的命令，但需要注意的是假如你一天备份多次，可能导致档案文件名重复，那么就会导致 备份实现，因为split依然会从aa,ab开始命名，如果一天的文件产生（修改）量不是特别大，那么建议增量部分不 分割处理了：（ 一定要分割的话，文件名加入更细致的时间如$(date +%Y-%m-%d_%H) ） # tar -g /tmp/snapshot_data.snap -zcpf /tmp/bak_data2014-12-07.tar.gz --exclude=./cache ./ 第二天增备 # tar -g /tmp/snapshot_data.snap -zcpf /tmp/bak_data2014-12-08.tar.gz --exclude=./cache ./ 恢复过程\n1 2 3 4 5 6 7 8 9 恢复完全备份的档案文件 可以选择是否先清空/tmp/data/目录 # cat /tmp/bak_data2014-12-07.tar.gz_* | tar -zxpf - -C /tmp/data/ 恢复增量备份的档案文件 $ tar –zxpf /tmp/bak_data2014-12-07.tar.gz -C /tmp/data/ $ tar –zxpf /tmp/bak_data2014-12-08.tar.gz -C /tmp/data/ ... 一定要保证是按时间顺序恢复的，像下面文件名规则也可以使用上面通配符的形式 如果需要定期备份，如每周一次全备，每天一次增量备份，则可以结合crontab实现。\n3. 备份文件系统 备份文件系统方法有很多，例如cpio, rsync, dump, tar，这里演示一个通过tar备份整个Linux系统的例子，整个备份与恢复过程与上面类似。 首先Linux（这里是CentOS）有一部分目录是没必要备份的，如/proc、/lost+found、/sys、/mnt、/media、/dev、/proc、/tmp，如果是备份到磁带/dev/st0则不必关心那么多，因为我这里是备份到本地/backup目录，所以也需要排除，还有其它一些NFS或者网络存储挂载的目录。\n1 2 3 4 5 6 7 8 9 10 11 12 创建排除列表文件 # vi /backup/backup_tar_exclude.list /backup /proc /lost+found /sys /mnt /media /dev /tmp $ tar -zcpf /backup/backup_full.tar.gz -g /backup/tar_snapshot.snap --exclude-from=/backup/tar_exclude.list / 4. 注意 使用tar无论是备份数据还是文件系统，需要考虑是在原系统上恢复还是另一个新的系统上恢复。\ntar备份极度依赖于文件的atime属性， 文件所属用户是根据用户ID来确定的，异机恢复需要考虑相同用户拥有相同USERID 备份和恢复的过程尽量不要运行其他进程，可能会导致数据不一致 软硬连接文件可以正常恢复 参考 tar高级教程：增量备份、定时备份、网络备份 Linux服务器数据备份恢复的详细讲解 ","permalink":"http://localhost:1313/2014/12/tar_backup_filesystem/","summary":"\u003cp\u003eLinux上有功能强大的tar命令，tar最初是为了制作磁带备份（tape archive）而设计的，它的作用是把文件和目录备份到磁带中，然后从磁带中提取或恢复文件。现在我们可以使用tar来备份数据到任何存储介质上。它是文件级备份，不必考虑底层文件系统类别，并且支持增量备份。\u003c/p\u003e","title":"tar命令高级用法——备份数据"},{"content":"1. 语法选项说明 -h, --host=name 主机名\n-P[ port_num], --port=port_num 用于连接MySQL服务器的的TCP/IP端口号\n--master-data 这个选项可以把binlog的位置和文件名添加到输出中，如果等于1，将会打印成一个CHANGE MASTER命令；如果等于2，会加上注释前缀。并且这个选项会自动打开--lock-all-tables，除非同时设置了--single-transaction（这种情况下，全局读锁只会在开始dump的时候加上一小段时间，不要忘了阅读--single-transaction的部分）。在任何情况下，所有日志中的操作都会发生在导出的准确时刻。这个选项会自动关闭--lock-tables。\n-x, --lock-all-tables 锁定所有库中所有的表。这是通过在整个dump的过程中持有全局读锁来实现的。会自动关闭--single-transaction和--lock-tables。\n--single-transaction 通过将导出操作封装在一个事务内来使得导出的数据是一个一致性快照。只有当表使用支持MVCC的存储引擎（目前只有InnoDB）时才可以工作；其他引擎不能保证导出是一致的。当导出开启了--single-transaction选项时，要确保导出文件有效（正确的表数据和二进制日志位置），就要保证没有其他连接会执行如下语句：ALTER TABLE, DROP TABLE, RENAME TABLE, TRUNCATE TABLE，这会导致一致性快照失效。这个选项开启后会自动关闭--lock-tables。\n-l, --lock-tables 对所有表加读锁。（默认是打开的，用--skip-lock-tables来关闭，上面的选项会把关闭-l选项）\n-F, --flush-logs 在开始导出前刷新服务器的日志文件。注意，如果你一次性导出很多数据库（使用 -databases=或--all-databases选项），导出每个库时都会触发日志刷新。例外是当使用了--lock-all-tables或--master-data时：日志只会被刷新一次，那个时候所有表都会被锁住。所以如果你希望你的导出和日志刷新发生在同一个确定的时刻，你需要使用--lock-all-tables，或者--master-data配合--flush-logs。\n--delete-master-logs 备份完成后删除主库上的日志。这个选项会自动打开``\u0026ndash;master-data`。\n--opt 同-add-drop-table, --add-locks, --create-options, --quick, --extended-insert, --lock-tables, --set-charset, --disable-keys。（默认已开启，--skip-opt关闭表示这些选项保持它的默认值）应该给你为读入一个MySQL服务器的尽可能最快的导出，--compact差不多是禁用上面的选项。\n-q, --quick\n不缓冲查询，直接导出至stdout。（默认打开，用--skip-quick来关闭）该选项用于转储大的表。\n--set-charset 将SET NAMES default_character_set加到输出中。该选项默认启用。要想禁用SET NAMES语句，使用--skip-set-charset。\n--add-drop-tables 在每个CREATE TABLE语句前添加DROP TABLE语句。默认开启。\n--add-locks 在每个表导出之前增加LOCK TABLES并且之后UNLOCK TABLE。(为了使得更快地插入到MySQL)。默认开启。\n--create-option 在CREATE TABLE语句中包括所有MySQL表选项。默认开启，使用--skip-create-options来关闭。\n-e, --extended-insert 使用全新多行INSERT语法，默认开启（给出更紧缩并且更快的插入语句）\n-d, --no-data 不写入表的任何行信息。如果你只想得到一个表的结构的导出，这是很有用的。\n--add-drop-database 在create数据库之前先DROP DATABASE，默认关闭，所以一般在导入时需要保证数据库已存在。\n--default-character-set= 使用的默认字符集。如果没有指定，mysqldump使用utf8。\n-B, --databases 转储几个数据库。通常情况，mysqldump将命令行中的第1个名字参量看作数据库名，后面的名看作表名。使用该选项，它将所有名字参量看作数据库名。CREATE DATABASE IF NOT EXISTS db_name和USE db_name语句包含在每个新数据库前的输出中。\n--tables 覆盖--database选项。选项后面的所有参量被看作表名。\n-u[ name], --user= 连接服务器时使用的MySQL用户名。\n-p[password], --password[=password] 连接服务器时使用的密码。如果你使用短选项形式(-p)，不能在选项和密码之间有一个空格。如果在命令行中，忽略了--password或-p选项后面的 密码值，将提示你输入一个。\n2. 示例 导出一个数据库：\n1 2 3 4 $ mysqldump -h localhost -uroot -ppassword \\ --master-data=2 --single-transaction --add-drop-table --create-options --quick \\ --extended-insert --default-character-set=utf8 \\ --databases discuz \u0026gt; backup-file.sql 导出一个表：\n1 $ mysqldump -u pak -p --opt --flush-logs pak t_user \u0026gt; pak-t_user.sql 将备份文件压缩：\n1 2 3 $ mysqldump -hhostname -uusername -ppassword --databases dbname | gzip \u0026gt; backup-file.sql.gz 对应的还原动作为 gunzip \u0026lt; backup-file.sql.gz | mysql -uusername -ppassword dbname 导入数据库：\n1 2 3 4 mysql\u0026gt; use target_dbname mysql\u0026gt; source /mysql/backup/path/backup-file.sql 或 $ mysql target_dbname \u0026lt;backup-file.sql 导入还有一个mysqlimport命令，暂未研究。\n直接从一个数据库向另一个数据库转储：\nmysqldump -u用户名 -p --opt dbname | mysql --host remote_host -C dbname2 关于增量备份与恢复请参考：MySQL增量备份与恢复实例。\n参考 4.5.4 mysqldump — A Database Backup Program 总结：MySQL备份与恢复的三种方法 mysql备份与还原（含增量） ","permalink":"http://localhost:1313/2014/12/mysql_mysqldump_options_examples/","summary":"\u003ch3 id=\"1-语法选项说明\"\u003e1. 语法选项说明\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003e-h, --host=name\u003c/code\u003e\n主机名\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003e-P[ port_num], --port=port_num\u003c/code\u003e\n用于连接MySQL服务器的的TCP/IP端口号\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003e--master-data\u003c/code\u003e\n这个选项可以把binlog的位置和文件名添加到输出中，如果等于1，将会打印成一个\u003ccode\u003eCHANGE MASTER\u003c/code\u003e命令；如果等于2，会加上注释前缀。并且这个选项会自动打开\u003ccode\u003e--lock-all-tables\u003c/code\u003e，除非同时设置了\u003ccode\u003e--single-transaction\u003c/code\u003e（这种情况下，全局读锁只会在开始dump的时候加上一小段时间，不要忘了阅读\u003ccode\u003e--single-transaction\u003c/code\u003e的部分）。在任何情况下，所有日志中的操作都会发生在导出的准确时刻。这个选项会自动关闭\u003ccode\u003e--lock-tables\u003c/code\u003e。\u003c/p\u003e","title":"MySQL备份命令mysqldump参数说明与示例"},{"content":"小量的数据库可以每天进行完整备份，因为这也用不了多少时间，但当数据库很大时，就不太可能每天进行一次完整备份了，这时候就可以使用增量备份。增量备份的原理就是使用了mysql的binlog日志。 本次操作的MySQL版本为5.5.40 for Linux (x86_64)。\n增量备份要确保打开了二进制日志，参考mysql的日志系统：\n1 mysql\u0026gt; show variables like \u0026#39;%log_bin%\u0026#39;; 首先对pak数据库做一个完整备份：\n1 $ mysqldump -h localhost -upak -ppwd -P3306 --master-data=2 --single-transaction --opt pak \u0026gt; pak_bak_full.sql 这时候就会得到一个全备文件pak_bak_full.sql。mysqldump操作会导致滚动一次log，假设新的binlog文件是mysql-bin.000002。\n1. 模拟插入数据和误操作 a. 在pak库的某个表插入一些数据，然后执行flush logs命令。这时将会产生一个新的二进制日志文件mysql-bin.000003，mysql-bin.000002则保存了全备过后的所有更改，既增加记录的操作也保存在了mysql-bin.00002中。\nb. 再在pak库中的t_user表中增加两条记录，然后误删除t_user表。t_user中增加记录的操作和删除表的操作都记录在mysql-bin.000003中。\n2. 开始恢复 恢复过程不要记录日志：\n1 mysql \u0026gt; set global sql_log_bin=0; 3. 首先导入全备数据 1 2 3 $ mysql -h localhost -upak -ppwd \u0026lt; pak_bak_full.sql 或 mysql\u0026gt; source /path/backup/pak_bak_full.sql 我们也可以看到全备时的binlog位置：\n1 2 head -50 backup-file.sql |grep \u0026#39;CHANGE MASTER\u0026#39; -- CHANGE MASTER TO MASTER_LOG_FILE=\u0026#39;mysql-bin.000001\u0026#39;, MASTER_LOG_POS=4321; 查看当前所在二进制日志中的位置：\n1 mysql\u0026gt; show master status; 根据上面两个position能大概确定需要完整恢复哪几个binlog文件。\n4. 恢复mysql-bin.000002 在待恢复的position或时间点以前、全备以后的binlog需要全部恢复，多个文件以空格隔开\n1 $ mysqlbinlog /var/lib/mysql/mysql-bin.000002 | mysql -uroot -p 此时查询可以得到前两条数据。\n5. 恢复部分mysql-bin.000003 这个日志中包括了新增记录和误删表两个部分，我们需要恢复到新增记录之后、误删操作以前的位置。\n如果知道误操作的命令如DROP TABLE，则可以通过下面的方法在binlog文件中找到误操作之前的那个position： （如下面的信息显示，误操作DROP TABLE之前的pos是775，在datetime 141204 15:08:04或pos 882时完成DROP TABLE操作）\n1 2 3 4 5 6 7 8 9 $ mysqlbinlog /var/lib/mysql/mysql-bin.000003 |grep -C 5 \u0026#39;DROP TABLE\u0026#39; #141204 15:07:05 server id 1 end_log_pos 775 Xid = 376 COMMIT/*!*/; # at 775 #141204 15:08:04 server id 1 end_log_pos 882 Query\tthread_id=10\texec_time=0\terror_code=0 SET TIMESTAMP=1417676884/*!*/; DROP TABLE `t_user` /* generated by server */ /*!*/; # at 882 恢复命令：\n1 $ mysqlbinlog /var/lib/mysql/mysql-bin.000003 --stop-position=775 | mysql -h localhost -uroot -p 如果position难以确定，但知道需要恢复到的确切（服务器）时间，也可以使用datetime：\n1 $ mysqlbinlog /var/lib/mysql/mysql-bin.000003 --stop-datetime=\u0026#34;2014-12-04 15:08:00\u0026#34; | mysql -uroot -p 如果不是误操作导致的，而是迁移数据库，那么不需要position或datetime，使用所有binlog文件增量恢复即可。\n确定恢复成功后记得打开日志记录：\n1 mysql \u0026gt; set global sql_log_bin=1; 报错 unknown variable \u0026lsquo;default-character-set=utf8\u0026rsquo; 在使用mysqlbinlog查看二进制日志的时候，提示下面的错误： /usr/local/mysql/bin/mysqlbinlog: unknown variable \u0026lsquo;default-character-set=utf8\u0026rsquo;\n原因是在我为了统一mysql客户端到服务端的的字符编码，在/etc/my.cnf文件的[client]、[mysqld]等节加入了default-character-set = utf8，mysqlbinlog会从my.cnf中的[client]读取配置，但奈何mysqlbinlog并不认识这个选项（据说是个bug）导致的。\n应对这个bug的方法有两个： 第一，自然是注释到[client]中的这个字符集配置； 第二，改用loose-default-character-set = utf8。在选项前加了loose-，表示当程序不认识此选项时会略过此选项，并给出一个警告。\n","permalink":"http://localhost:1313/2014/12/mysql_incremental_backup_example/","summary":"\u003cp\u003e小量的数据库可以每天进行完整备份，因为这也用不了多少时间，但当数据库很大时，就不太可能每天进行一次完整备份了，这时候就可以使用增量备份。增量备份的原理就是使用了mysql的binlog日志。\n本次操作的MySQL版本为\u003ccode\u003e5.5.40 for Linux (x86_64)\u003c/code\u003e。\u003c/p\u003e","title":"MySQL增量备份与恢复实例"},{"content":"这是自己曾经写的一个oracle 11gR2在CentOS6 x86_64服务器上，一键配置安装环境的脚本，能快速完成安装前环境的配置。\n具体完成以下工作：\n备份系统配置文件，以防出错 添加oracle用户和用户组 创建安装目录 关闭selinux 在.bash_profile中修改环境变量 修改sysctl.conf文件 修改limits.conf文件 修改PAM的login文件 安装必要的依赖包 使用注意事项：\nroot的用户执行，chmod +x oraclePreInstCheck.sh ./oraclePreInstCheck.sh运行后，请仔细阅读说明，再决定是否使用该脚本 该脚本默认参数适用于2核4G内存的环境，你可以根据需要修改kernelset()部分 执行完后，你检查一下你的安装目录及权限（默认/db/oracle） 该脚本会有提示输入的地方，请不要挑战它的健壮性，比如输入安装根目录时，不要带入空格 脚本只需执行一次，修改系统参数如sysctl.conf之前，都有备份成xxx.ora_bak 请确保可以通过yum方式安装软件包（使用挂载DVD镜像或联网） 建议结合tee将执行过程记录在日志文件中，./oraclePreInstCheck.sh | tee oraclePreInstCheck.log oraclePreInstCheck.sh：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 #!/bin/bash # author zhouxiao # date 2014-03-07 # description oracle 11g R2 for linux 6.0+ x86_64 安装辅助脚本 #定义常量 SYSCTL=/etc/sysctl.conf LIMITS=/etc/security/limits.conf PAM=/etc/pam.d/login PROFILE=/etc/profile BASH_PROFILE=/home/oracle/.bash_profile #循环变量 i=1 #定义显示颜色 #颜色定义 信息(33黄色) 警示(31红色) 过程(36浅蓝) usage() { echo \u0026#34;Scripts: initialize the required env settings for Oracle 11gR2 installation on Linux 6.0+ x86_64\u0026#34; echo \u0026#34;Make sure you have prepared conditions list bellow:\u0026#34; echo -e \u0026#34; \\n\\e[1;33m yum, hosts, user oracle\u0026#39;s passwd, oralce SID, DISPLAY location \\e[0m\u0026#34; echo \u0026#34;The Script will backup config files with .ora_bak in case failure \u0026#34; echo \u0026#34;The Script will set the following change:\u0026#34; echo \u0026#34; - add user oracle and group oinstall/dba/oper, etc.\u0026#34; echo \u0026#34; - make directory ORACLE_HOME and change owner\u0026#34; echo \u0026#34; - modify oracle .bash_profile\u0026#34; echo \u0026#34; - modify /etc/sysctl.conf kernel parameters like shmall/shmmax\u0026#34; echo \u0026#34; - modify /etc/security/limits.conf \u0026#34; echo \u0026#34; - install necessary packages like libgcc/libaio/unixODBC, etc.\u0026#34; echo \u0026#34; - IF anything goes wrong, you need to recover ora_bak files manually.\u0026#34; echo -e \u0026#34;\\n\\e[1;33m Continue? (y/n [n]): \\e[0m\u0026#34; read singal if [ $singal != \u0026#34;y\u0026#34; ]; then exit 0 else echo \u0026#34;God Bless you! Settings started.\u0026#34; echo \u0026#34;\u0026#34; echo \u0026#34;\u0026#34; fi } #判断执行用户是否root isroot() { if [ $USER != \u0026#34;root\u0026#34; ];then echo -e \u0026#34;\\n\\e[1;31m the user must be root,and now you user is $USER,please su to root. \\e[0m\u0026#34; exit4 else echo -e \u0026#34;\\n\\e[1;36m check root ... OK! \\e[0m\u0026#34; fi } #挂在光盘到/mnt/cdrom目录下 mount_cdrom() { echo -e \u0026#34;\\n\\e[1;31m please insert RHEL to CDROM,press any key ...\\e[0m\u0026#34; read -n 1 if [ -d /mnt/cdrom ];then mount -t auto -o ro /dev/cdrom /mnt/cdrom else mkdir -p /mnt/cdrom mount -t auto -o ro /dev/cdrom /mnt/cdrom fi if [ $? -eq 0 ];then echo -e \u0026#34;\\n\\e[1;36m CDROM mount on /mnt/cdrom ... OK! \\e[0m\u0026#34; fi } #设置yum本地光盘源 yum_repo() { rm -rf /etc/yum.repos.d/* \u0026amp;\u0026amp; cat \u0026lt;\u0026lt;EOF \u0026gt;\u0026gt; /etc/yum.repos.d/Server.repo [Server] name=MyRPM baseurl=file:///mnt/cdrom/Server enabled=1 gpgkey=file:///mnt/cdrom/RPM-GPG-KEY-redhat-release EOF if [ $? -eq 0 ];then echo -e \u0026#34;\\n\\e[1;36m /etc/yum.repos.d/Server.repo ... OK! \\e[0m\u0026#34; fi } #添加oracle用户，添加oracle用户所属组oinstall及附加组dba ouseradd() { if [[ `grep \u0026#34;oracle\u0026#34; /etc/passwd` != \u0026#34;\u0026#34; ]];then userdel -r oracle fi if [[ `grep \u0026#34;oinstall\u0026#34; /etc/group` = \u0026#34;\u0026#34; ]];then groupadd -g 501 oinstall fi if [[ `grep \u0026#34;dba\u0026#34; /etc/group` = \u0026#34;\u0026#34; ]];then groupadd -g 502 dba groupadd -g 503 oper groupadd -g 504 asmadmin groupadd -g 506 asmdba groupadd -g 505 asmoper fi useradd oracle -g oinstall -G dba,asmdba,oper \u0026amp;\u0026amp; echo $1 |passwd oracle --stdin if [ $? -eq 0 ];then echo -e \u0026#34;\\n\\e[1;36m oracle\u0026#39;s password updated successfully --- OK! \\e[0m\u0026#34; else echo -e \u0026#34;\\n\\e[1;31m oracle\u0026#39;s password set faild. --- NO!\\e[0m\u0026#34; fi } #检查oracle所需软件包并安装 packagecheck() { for package in binutils compat-libcap1 compat-libstdc++-33 compat-libstdc++-33*i686 gcc gcc-c++ glibc glibc-2*i686 glibc-devel glibc-devel-2*i686 glibc-headers-2.* libgcc libgcc-4*i686 libstdc++ libstdc++-4*i686 libstdc++-devel libstdc++-devel-4*i686 libaio-0* libaio-0*i686 libaio-devel libaio-devel-0*i686 unixODBC unixODBC-2*i686 unixODBC-devel unixODBC-devel-2*i686 make sysstat ksh do rpm -q $package 2\u0026gt; /dev/null if [ $? != 0 ];then yum -y install $package 2\u0026gt; /dev/null echo -e \u0026#34;\\n\\e[1;36m $package is installed ... OK! \\e[0m\u0026#34; fi done } #安装桌面套件 X Window System / Desktop xdesk() { LANG=C yum -y groupinstall \u0026#34;X Window System\u0026#34; \u0026#34;Desktop\u0026#34; if [ $? -eq 0 ];then echo -e \u0026#34;\\n\\e[1;36m $package is already installed ... OK! \\e[0m\u0026#34; fi } # 设置内核参数 # shmall 物理内存\u0026lt;8G =2097152 \u0026gt;8G MemTotal/4kb # shmmax 物理内存\u0026lt;8G = 4294967296 \u0026gt;8G 16GMemTotal = 10G=10*1024^3 kernelset() { cp $SYSCTL{,.ora_bak} \u0026amp;\u0026amp; cat \u0026lt;\u0026lt;EOF \u0026gt;\u0026gt;$SYSCTL fs.aio-max-nr = 1048576 fs.file-max = 6815744 kernel.shmall = 2097152 kernel.shmmax = 4294967296 kernel.shmmni = 4096 kernel.sem = 250 32000 100 128 net.ipv4.ip_local_port_range = 9000 65500 net.core.rmem_default = 262144 net.core.rmem_max = 4194304 net.core.wmem_default = 262144 net.core.wmem_max = 1048576 EOF if [ $? -eq 0 ];then echo -e \u0026#34;\\n\\e[1;36m kernel parameters updated successfully --- OK! \\e[0m\u0026#34; fi sysctl -p } #设置oracle资源限制 oralimit() { cp $LIMITS{,.ora_bak} \u0026amp;\u0026amp; cat \u0026lt;\u0026lt;EOF \u0026gt;\u0026gt; $LIMITS oracle soft nproc 2047 oracle hard nproc 16384 oracle soft nofile 1024 oracle hard nofile 65536 oracle soft stack 10240 EOF if [ $? -eq 0 ];then echo -e \u0026#34;\\n\\e[1;36m $LIMITS updated successfully ... OK! \\e[0m\u0026#34; fi cat $LIMITS | grep \u0026#39;^o\u0026#39; } #设置login文件 setlogin() { cp $PAM{,.ora_bak} \u0026amp;\u0026amp; cat \u0026lt;\u0026lt;EOF \u0026gt;\u0026gt;$PAM session required pam_limits.so EOF if [ $? -eq 0 ];then echo -e \u0026#34;\\n\\e[1;36m $PAM updated successfully ... OK! \\e[0m\u0026#34; fi } #设置profile文件 setprofile() { cp $PROFILE{,.ora_bak} \u0026amp;\u0026amp; cat \u0026lt;\u0026lt;EOF \u0026gt;\u0026gt;$PROFILE if [ $USER = \u0026#34;oracle\u0026#34; ];then if [ $SHELL = \u0026#34;/bin/ksh\u0026#34; ];then ulimit -p 16384 ulimit -n 65536 else ulimit -u 16384 -n 65536 fi fi EOF if [ $? -eq 0 ];then echo -e \u0026#34;\\n\\e[1;36m $PROFILE updated successfully ... OK! \\e[0m\u0026#34; fi } #设置oracle的profile文件 setbash_profile() { cp $BASH_PROFILE{,.ora_bak} \u0026amp;\u0026amp; cat \u0026lt;\u0026lt;EOF \u0026gt;\u0026gt; $BASH_PROFILE umask 022 #oracle settings TMP=/tmp; export TMP TMPDIR=\\$TMP; export TMPDIR ORACLE_BASE=$1/oracle ORACLE_HOME=\\$ORACLE_BASE/product/11.2.0/db_1 ORACLE_SID=$2 PATH=\\$ORACLE_HOME/bin/:\\$PATH LANG=en_US.UTF-8 ORACLE_TERM=xterm export ORACLE_BASE ORACLE_HOME ORACLE_SID ORACLE_TERM LD_LIBRARY_PATH=\\$ORACLE_HOME/lib:/lib:/usr/lib; export LD_LIBRARY_PATH CLASSPATH=\\$ORACLE_HOME/jre:\\$ORACLE_HOME/jlib:\\$ORACLE_HOME/rdbms/jlib export CLASSPATH EOF if [ $? -eq 0 ];then echo -e \u0026#34;\\n\\e[1;36m $BASH_PROFILE updated successfully ... OK! \\e[0m\u0026#34; fi su - oracle -c source $BASH_PROFILE } #系统环境检查 oscheck() { #查看内存大小是否大于1G echo -e \u0026#34;\\n check MEM Size ...\u0026#34; if [ `cat /proc/meminfo | grep MemTotal | awk \u0026#39;{print $2}\u0026#39;` -lt 1048576 ];then echo -e \u0026#34;\\n\\e[1;33m Memory Small \\e[0m\u0026#34; exit 1 else echo -e \u0026#34;\\n\\e[1;36m Memory checked PASS \\e[0m\u0026#34; fi #查看tmp空间大小 echo -e \u0026#34;\\n check tmpfs Size ...\u0026#34; cp /etc/fstab{,.ora_bak} while true;do if [ `df | awk \u0026#39;/tmpfs/ {print $2}\u0026#39;` -lt 1048576 ];then echo -e \u0026#34;\\n\\e[1;33m tmpfs Smaill \\e[0m\u0026#34; sed -i \u0026#39;/tmpfs/s/defaults/defaults,size=1G/\u0026#39; /etc/fstab \u0026amp;\u0026amp; mount -o remount /dev/shm if [ $? != 0 ];then i=i+1 if [ $i -eq 3 ];then echo -e \u0026#34;\\n\\e[1;31m set tmpfs faild. \\e[0m\u0026#34; exit 3 fi else echo -e \u0026#34;\\n\\e[1;36 tmpfs updated successfully. \\e[0m\u0026#34; break fi else echo -e \u0026#34;\\n\\e[1;36m tmpfs checked PASS \\e[0m\u0026#34; break fi done } usage #停止防火墙IPTABLES service iptables stop #chkconfig iptables off #关闭SELINUX cp /etc/selinux/config{,.ora_bak} \u0026amp;\u0026amp; sed -i \u0026#39;/SELINUX/s/enforcing/disabled/;/SELINUX/s/permissive/disabled/\u0026#39; /etc/selinux/config setenforce 0 #执行以上函数 isroot #oscheck #yum_repo #mount_cdrom packagecheck #xdesk kernelset oralimit setlogin setprofile echo -e \u0026#34;\\n\\e[1;33m please input oracle\u0026#39;s user passwd: \\e[0m\u0026#34; read oraclepw ouseradd $oraclepw echo -e \u0026#34;\\n\\e[1;33m please input oracle install PATH (default /db) \\e[0m\u0026#34; read oraclepath if [ -z $oraclepath ];then oraclepath=/db fi if [ ! -x \u0026#34;$oraclepath\u0026#34; ];then mkdir -p \u0026#34;$oraclepath\u0026#34; chown oracle.oinstall $oraclepath echo -e \u0026#34;\\n\\e[1;36 $oraclepath created. \\e[0m\u0026#34; fi echo -e \u0026#34;\\n\\e[1;33m please input oracle_sid, just for env (default TSDB) \\e[0m\u0026#34; read orasid if [ -z orasid ];then orasid=TSDB fi setbash_profile $oraclepath $orasid mkdir -p $oraclepath/oracle/product/11.2.0/db_1 \u0026amp;\u0026amp; chown -R oracle:oinstall $oraclepath \u0026amp;\u0026amp; chmod -R 755 $oraclepath unset i echo -e \u0026#34;\\n\\e[1;33m please input where to display the X Window (default 127.0.0.1:0.0) \\e[0m\u0026#34; read xdpy if [ -z $xdpy ];then xdpy=127.0.0.1:0.0 fi su - oracle -c export DISPLAY=$xdpy \u0026amp;\u0026amp; host + echo -e \u0026#34;\\n\\e[1;35m Oracle install pre-setting finish! \u0026amp;\u0026amp; please run oracle installer as user oracle \\e[0m\u0026#34; ","permalink":"http://localhost:1313/2014/12/oracle11gr2_installation_precheck_scripts/","summary":"\u003cp\u003e这是自己曾经写的一个oracle 11gR2在CentOS6 x86_64服务器上，一键配置安装环境的脚本，能快速完成安装前环境的配置。\u003c/p\u003e\n\u003cp\u003e具体完成以下工作：\u003c/p\u003e","title":"Oracle单实例安装环境一键配置脚本（CentOS6 + 11gR2 ）"},{"content":"最近有个在大学玩的比较好现在在读研的同学，来询问我一些如何给老师做精品课程在线测试系统的问题，从沟通中我忍不住从个人的角度来表达一下感想和担忧。\n首先从我接收到的信息来看，高校导师为了给自己擅长的课程评选上学校、市级或省级精品课程，急于完成一个展示成果的平台，只要能在最短的时间内提交所能看的见的成果，那就表明有效率和实力。所以这个在线测试系统只需要能够展示一个页面，页面上有单项、多选题，提交测试后直接显示对错和总分，无需记录测试者姓名等其他任何与试题无关的信息，也就是没有数据库。差不多就是一个静态页面了，对错的判断，包括答案都固定在代码里面了。我相信稍微了解IT软件开发的人都知道，这样的系统设计可以让人感到无语，当然还有很多不是计算机类专业的，可能看不懂这些，只关心最终实现的效果达到预期就行。偏偏导师和所交予任务的学生，都不懂设计和编程。所以当我说至少应该有个数据库时，“太麻烦，不懂，周期太长”。由于是出于帮忙的目的，也就没有说太多的话来打击他的积极性，说多了反而有点表现自己有多牛B的嫌疑，就硬着头皮做了个demo。\n由此可见大学老师为评上精品课程，那种急功近利的心理，只要对外宣传“我们有一个在线测评系统来检验学生学习效果，blablabla\u0026hellip;”，然后评选小组比对评选规则里面有“在线测评”，加分！但请问像上面那样的系统意义何在？老师不知道有谁做过测试，不知道分数，只知道“当前浏览xxx次”，学生完全取决于是否主动。我想如果老师把这个测评当做一个硬性要求或作为所熟知却非常神秘的“平时成绩”的一部分，那只能是通过某种方式提交测试截图了。我心还想，在线测评系统一次性完成上线，是不是就再也不会修改了，加题减题，都要大动干戈的去修改后台代码，丝毫没有规划以后的扩展，当然也许我想多了，因为“这就是很简单的一个测试系统”，嗯，都说是测试而不是正式环境了，认真你就输了。\n这里做个小插曲。我们生活的环境，充斥着太多的指标、太多的名声。想起上周在我司门口早上卖炸酱面的摊贩被城管执法包围那件事。每天早上这位大叔家的炸酱面是附近最好吃的，每天都排着很长的队，如果不赶时间我和同事们都会优先选择这家。大家都生活不易，城管也是，起早贪黑，四处蹲点追赶流动摊贩，因为没有业绩没有完成指标，如何回去交差。又想起电视里报道过某地的交警每月要达到罚款20万的指标，这说多了其实就是社会问题了，我们这些小众市民除了旁观，祈祷不要发生在我们身上，还能做些什么呢。指标本应该是一个积极充满正能量的、督促机构上进的一个目标，但是如果是为了充数而不择手段去实现，急功近利，那就变质了。\n就在线测评问题来说，个人觉得比较合适的做法，应该是要具有一个长远的观念，为何学校不统一做一个在线测评系统，其他各个课程申请账号，获得出题的资格，自由的在后台添加题目，是否需要记录分数和姓名，老师还可以统计对比各班的情况，甚至在评上精品课程以后，作为进一步考核的数据来源，一次投入，无限产出。相比每门课程做重复低效的工作，一眼就可以看出利弊了。导师舍不得花钱请廉价的学生开发一个拿得出手的系统，只能让手下的研究生“自己看着办”。\n另外一方面是我对研究生所表现出来的担忧，是关于学习方法和学习能力。研究生最后毕业靠的是一纸论文，我相信会有高水平有独立见解的论文，但大部分论文“借鉴”的成分会不会太高呢？我们原创性的东西太少了，习惯捡现成的东西，包括我自己也是，写一份配置文档需要google许多文章，然后东抄西拆，拼接起来，但至少它都是实践有效了，对于我个人来说具有较大的参考价值。然而在大学里养成了这样的习惯，就会慢慢的丧失学习能力，遇见要解决一个全新的问题，第一反应不是自己去网上检索，而是找到会的直接问“这个怎么做？”。我该如何回答是好呢？\n提问也是有智慧的，问得太宽泛，需要与回答者反复沟通来确认具体的问题，才给出什么样的答案。依然是最初的例子，同学使用ASP.NET来做一个在线测试系统，但他完全不懂编程，于是就问了我“有哪些方法，要准备啥”（还好不是宽泛的问“要怎么做”），我告诉他一些流程性的东西，要基本会一些什么，但他说他是小白，编程基础几乎为零。还是为了快速拿出成果，于是我就违心的打开了2年没有点开竟然没有卸载的Visual Studio 2010，一边搜索，一边拖拉控件，许多基本知识都忘了，做了个及其简陋的demo，拙劣的后台代码自己都不忍直视。我一直不承认自己是个程序猿，实际上也不是，但依然偶尔会兼职一下。很难说我是不是把自己同学给害了，没害是这种可快速复制、完成任务的技能已经学会了，毕竟这一次之后他再也不必学习编程，害他是我把现成的东西给他了。其实任何一本书、任何一篇博客教程都可以自己琢磨快速搞定，而不是一出现问题“表格怎么做”、“图片怎么查”，我真就回了一句“ 搜索关键字 ‘html 表格’、‘asp.net 插入图片’ ”，当然一部分原因是当时忙，没有时间手把手教。\n遇到问题，自己查阅资料，自己去理解，练习独立的去面对、解决问题，琢磨不明白的再去问，这样也不会浪费对方太多时间。当然简单一句话的能搞定的问题，也没必要说让提问者去走冤枉路，大概就是这个“度”的问题区分了人与人之间的差距和性格吧，无所谓绝对的对错。\n写这么多，有点不自量力了，额，请看到的同学不要对号入座，没有任何针对性和攻击性。\n","permalink":"http://localhost:1313/2014/11/thoughts_about_graduate_from_course/","summary":"\u003cp\u003e最近有个在大学玩的比较好现在在读研的同学，来询问我一些如何给老师做精品课程在线测试系统的问题，从沟通中我忍不住从个人的角度来表达一下感想和担忧。\u003c/p\u003e","title":"关于研究生的一点担忧"},{"content":"Docker可以从Dockerfile中一步一步的读取指令来自动的创建镜像，常使用Dockerfile来创建用户自定义的镜像。格式如下：\n1 2 # Comment INSTRUCTION arguments 虽然前面的指令大小写不敏感，但习惯性的还是建议大写。docker是严格按照顺序（#注释起来的忽略）运行指令的。 下面逐个来介绍几个必要的指令。\nFROM 1 2 3 FROM \u0026lt;image\u0026gt; 或 FROM \u0026lt;image\u0026gt;:\u0026lt;tag\u0026gt; 在Dockerfile中第一条非注释INSTRUCTION一定是FROM，它决定了以哪一个镜像作为基准，\u0026lt;image\u0026gt;首选本地是否存在，如果不存在则会从公共仓库下载（当然也可以使用私有仓库的格式）。\nRUN 1 2 3 RUN \u0026lt;commnad\u0026gt; 或 RUN [\u0026#34;executable\u0026#34;, \u0026#34;param1\u0026#34;, \u0026#34;param2\u0026#34;] RUN指令会在当前镜像的顶层执行任何命令，并commit成新的（中间）镜像，提交的镜像会在后面继续用到。 上面看到RUN后的格式有两种写法。\nshell格式，相当于执行/bin/sh -c \u0026quot;\u0026lt;command\u0026gt;\u0026quot;：\n1 RUN apt-get install vim -y exec格式，不会触发shell，所以$HOME这样的环境变量无法使用，但它可以在没有bash的镜像中执行，而且可以避免错误的解析命令字符串：\n1 2 3 RUN [\u0026#34;apt-get\u0026#34;, \u0026#34;install\u0026#34;, \u0026#34;vim\u0026#34;, \u0026#34;-y\u0026#34;] 或 RUN [\u0026#34;/bin/bash\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;apt-get install vim -y\u0026#34;] 与shell风格相同 ENTRYPOINT ENTRYPOINT命令设置在容器启动时执行命令，如果有多个ENTRYPOINT指令，那只有最后一个生效。有以下两种命令格式：\n1 2 3 ENTRYPOINT [\u0026#34;executable\u0026#34;, \u0026#34;param1\u0026#34;, \u0026#34;param2\u0026#34;] 数组/exec格式，推荐 或 ENTRYPOINT command param1 param2 shell格式 比如：\n1 docker run -i -t --rm -p 80:80 nginx 使用exec格式，在docker run \u0026lt;image\u0026gt;的所有参数，都会追加到ENTRYPOINT之后，并且会覆盖CMD所指定的参数（如果有的话）。当然可以在run时使用--entrypoint来覆盖ENTRYPOINT指令。 使用shell格式，ENTRYPOINT相当于执行/bin/sh -c \u0026lt;command..\u0026gt;，这种格式会忽略docker run和CMD的所有参数。\n以推荐使用的exec格式为例： 我们可以使用ENTRYPOINT来设置基本不会变化的命令，用CMD来设置其它的可能改变的默认启动命令或选项（docker run会覆盖的）。\n1 2 3 FROM ubuntu ENTRYPOINT [\u0026#34;top\u0026#34;, \u0026#34;-b\u0026#34;] CMD [\u0026#34;-c\u0026#34;] docker build -t registry.tp-link.net:8000/ubuntu:dockerfile_test . 运行\n1 2 3 4 5 6 7 8 9 10 $ docker run -it --rm --name test 44f178c416b0 -H 这里的top后的选项会追加到上面的ENTRYPOINT，同时会覆盖CMD的，所以实际相当于执行top -b -H，没有-c： top - 04:32:07 up 10 days, 11:27, 0 users, load average: 0.01, 0.03, 0.00 Threads: 1 total, 1 running, 0 sleeping, 0 stopped, 0 zombie %Cpu(s): 0.1 us, 0.1 sy, 0.0 ni, 99.7 id, 0.2 wa, 0.0 hi, 0.0 si, 0.0 st KiB Mem: 4056784 total, 3749188 used, 307596 free, 209372 buffers KiB Swap: 0 total, 0 used, 0 free. 571388 cached Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1 root 20 0 19688 1208 940 R 0.0 0.0 0:00.01 top 如果在使用的docker版本在v1.3及以上，则可以使用docker exec继续在容器中验证，看到完整的top命令docker exec -it test ps aux\nCMD 1 2 3 CMD [\u0026#34;executable\u0026#34;,\u0026#34;param1\u0026#34;,\u0026#34;param2\u0026#34;] （数组/exec格式） CMD [\u0026#34;param1\u0026#34;,\u0026#34;param2\u0026#34;] (as default parameters to ENTRYPOINT) CMD command param1 param2 (shell格式) 一个Dockerfile里只能有一个CMD，如果有多个，只有最后一个生效。CMD指令的主要功能是在build完成后，为了给docker run启动到容器时提供默认命令或参数，这些默认值可以包含可执行的命令，也可以只是参数（此时可执行命令就必须提前在ENTRYPOINT中指定）。\n它与ENTRYPOINT的功能极为相似，区别在于如果docker run后面出现与CMD指定的相同命令，那么CMD会被覆盖；而ENTRYPOINT会把容器名后面的所有内容都当成参数传递给其指定的命令（不会对命令覆盖）。另外CMD还可以单独作为ENTRYPOINT的所接命令的可选参数。 CMD与RUN的区别在于，RUN是在build成镜像时就运行的，先于CMD和ENTRYPOINT的，CMD会在每次启动容器的时候运行，而RUN只在创建镜像时执行一次，固化在image中。\n举例1：\n1 2 3 4 5 6 Dockerfile: CMD [\u0026#34;echo CMD_args\u0026#34;] 运行 docker run \u0026lt;image\u0026gt; echo run_arg 结果 输出 run_arg 因为echo run_arg覆盖了CMD。如果run后没有echo run_arg，则输出CMD_args。\n举例2：\n1 2 3 4 5 6 Dockerfile: ENTRYPOINT [\u0026#34;echo\u0026#34;, \u0026#34;ENTRYPOINT_args\u0026#34;] 运行 docker run \u0026lt;image\u0026gt; run_arg 结果 输出 ENTRYPOINT_args run_arg 因为echo run_arg追加到ENTRYPOIINT的echo后面了。如果在ENTRYPOINT后再加入一行CMD [\u0026quot;CMD_args\u0026quot;]，则结果依旧，除非去掉run后的所有参数。 当出现ENTRYPOINT指令时CMD指令只可能(当ENTRYPOINT指令使用exec方式执行时)被当做ENTRYPOINT指令的参数使用，其他情况则会被忽略。\nEXPOSE EXPOSE指令告诉容器在运行时要监听的端口，但是这个端口是用于多个容器之间通信用的（links），外面的host是访问不到的。要把端口暴露给外面的主机，在启动容器时使用-p选项。 示例：\n1 2 # expose memcached(s) port EXPOSE 11211 11212 ADD 1 ADD \u0026lt;src\u0026gt;... \u0026lt;dest\u0026gt; 将文件\u0026lt;src\u0026gt;拷贝到container的文件系统对应的路径\u0026lt;dest\u0026gt;下。 \u0026lt;src\u0026gt;可以是文件、文件夹、URL，对于文件和文件夹\u0026lt;src\u0026gt;必须是在Dockerfile的相对路径下（build context path），即只能是相对路径且不能包含../path/。 \u0026lt;dest\u0026gt;只能是容器中的绝对路径。如果路径不存在则会自动级联创建，根据你的需要是\u0026lt;dest\u0026gt;里是否需要反斜杠/，习惯使用/结尾从而避免被当成文件。 示例：\n1 2 3 4 5 6 7 支持模糊匹配 ADD hom* /mydir/ # adds all files starting with \u0026#34;hom\u0026#34; ADD hom?.txt /mydir/ # ? is replaced with any single character ADD requirements.txt /tmp/ RUN pip install /tmp/requirements.txt ADD . /tmp/ 另外ADD支持远程URL获取文件，但官方认为是strongly discouraged，建议使用wget或curl代替。 ADD还支持自动解压tar文件，比如ADD trusty-core-amd64.tar.gz /会线自动解压内容再COPY到在容器的/目录下。\nADD只有在build镜像的时候运行一次，后面运行container的时候不会再重新加载，也就是你不能在运行时通过这种方式向容器中传送文件，-v选项映射本地到容器的目录。\nCOPY Same as \u0026lsquo;ADD\u0026rsquo; but without the tar and remote url handling.\nCOPY的语法与功能与ADD相同，只是不支持上面讲到的\u0026lt;src\u0026gt;是远程URL、自动解压这两个特性，但是Best Practices for Writing Dockerfiles建议尽量使用COPY，并使用RUN与COPY的组合来代替ADD，这是因为虽然COPY只支持本地文件拷贝到container，但它的处理比ADD更加透明，建议只在复制tar文件时使用ADD，如ADD trusty-core-amd64.tar.gz /。\nENV 用于设置环境变量：\n1 ENV \u0026lt;key\u0026gt; \u0026lt;value\u0026gt; 设置了后，后续的RUN命令都可以使用，当运行生成的镜像时这些环境变量依然有效，如果需要在运行时更改这些环境变量可以在运行docker run时添加-env \u0026lt;key\u0026gt;=\u0026lt;value\u0026gt;参数来修改。\nVOLUME VOLUME指令用来在容器中设置一个挂载点，可以用来让其他容器挂载以实现数据共享或对容器数据的备份、恢复或迁移。请参考文章docker容器间通信\nWORKDIR WORKDIR指令用于设置Dockerfile中的RUN、CMD和ENTRYPOINT指令执行命令的工作目录(默认为/目录)，该指令在Dockerfile文件中可以出现多次，如果使用相对路径则为相对于WORKDIR上一次的值，例如WORKDIR /a，WORKDIR b，RUN pwd最终输出的当前目录是/a/b。（RUN cd /a/b，RUN pwd是得不到/a/b的）\nONBUILD ONBUILD指令用来设置一些触发的指令，用于在当该镜像被作为基础镜像来创建其他镜像时(也就是Dockerfile中的FROM为当前镜像时)执行一些操作，ONBUILD中定义的指令会在用于生成其他镜像的Dockerfile文件的FROM指令之后被执行，上述介绍的任何一个指令都可以用于ONBUILD指令，可以用来执行一些因为环境而变化的操作，使镜像更加通用。\n注意：\nONBUILD中定义的指令在当前镜像的build中不会被执行。 可以通过查看docker inspect \u0026lt;image\u0026gt;命令执行结果的OnBuild键来查看某个镜像ONBUILD指令定义的内容。 ONBUILD中定义的指令会当做引用该镜像的Dockerfile文件的FROM指令的一部分来执行，执行顺序会按ONBUILD定义的先后顺序执行，如果ONBUILD中定义的任何一个指令运行失败，则会使FROM指令中断并导致整个build失败，当所有的ONBUILD中定义的指令成功完成后，会按正常顺序继续执行build。 ONBUILD中定义的指令不会继承到当前引用的镜像中，也就是当引用ONBUILD的镜像创建完成后将会清除所有引用的ONBUILD指令。 ONBUILD指令不允许嵌套，例如ONBUILD ONBUILD ADD . /data是不允许的。 ONBUILD指令不会执行其定义的FROM或MAINTAINER指令。 例如，Dockerfile使用如下的内容创建了镜像 image-A ：\n1 2 3 4 [...] ONBUILD ADD . /app/src ONBUILD RUN /usr/local/bin/python-build --dir /app/src [...] 如果基于 image-A 创建新的镜像时，新的Dockerfile中使用FROM image-A指定基础镜像时，会自动执行ONBUILD指令内容，等价于在后面添加了两条指令。\n1 2 3 4 5 FROM image-A #Automatically run the following ADD . /app/src RUN /usr/local/bin/python-build --dir /app/src USER 为运行镜像时或者任何接下来的RUN指令指定运行用户名或UID：\nUSER daemon MAINTAINER 使用MAINTAINER指令来为生成的镜像署名作者\nMAINTAINER author's name mailaddress The .dockerignore file .dockerignore用来忽略上下文目录中包含的一些image用不到的文件，它们不会传送到docker daemon。规则使用go语言的匹配语法。如：\n1 2 3 $ cat .dockerignore .git tmp* 更多内容参考Dockerfile最佳实践系列。官方有个Dockerfile tutorial练习Dockerfile的写法，非常简单但对于养成良好的格式、注释有一些帮助。\nDockerfile示例 下面的Dockerfile是MySQL官方镜像的构建过程。从ubuntu基础镜像开始构建，安装mysql-server、配置权限、映射目录和端口，CMD在从这个镜像运行到容器时启动mysql。其中VOLUME定义的两个可挂载点，用于在host中挂载，因为数据库保存在主机上而非容器中才是比较安全的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 # # MySQL Dockerfile # # https://github.com/dockerfile/mysql # # Pull base image. FROM dockerfile/ubuntu # Install MySQL. RUN \\ apt-get update \u0026amp;\u0026amp; \\ DEBIAN_FRONTEND=noninteractive apt-get install -y mysql-server \u0026amp;\u0026amp; \\ rm -rf /var/lib/apt/lists/* \u0026amp;\u0026amp; \\ sed -i \u0026#39;s/^\\(bind-address\\s.*\\)/# \\1/\u0026#39; /etc/mysql/my.cnf \u0026amp;\u0026amp; \\ sed -i \u0026#39;s/^\\(log_error\\s.*\\)/# \\1/\u0026#39; /etc/mysql/my.cnf \u0026amp;\u0026amp; \\ echo \u0026#34;mysqld_safe \u0026amp;\u0026#34; \u0026gt; /tmp/config \u0026amp;\u0026amp; \\ echo \u0026#34;mysqladmin --silent --wait=30 ping || exit 1\u0026#34; \u0026gt;\u0026gt; /tmp/config \u0026amp;\u0026amp; \\ echo \u0026#34;mysql -e \u0026#39;GRANT ALL PRIVILEGES ON *.* TO \\\u0026#34;root\\\u0026#34;@\\\u0026#34;%\\\u0026#34; WITH GRANT OPTION;\u0026#39;\u0026#34; \u0026gt;\u0026gt; /tmp/config \u0026amp;\u0026amp; \\ bash /tmp/config \u0026amp;\u0026amp; \\ rm -f /tmp/config # Define mountable directories. VOLUME [\u0026#34;/etc/mysql\u0026#34;, \u0026#34;/var/lib/mysql\u0026#34;] # Define working directory. WORKDIR /data # Define default command. CMD [\u0026#34;mysqld_safe\u0026#34;] # Expose ports. EXPOSE 3306 使用：\n1 2 3 4 $ docker build -t=\u0026#34;dockerfile/mysql\u0026#34; github.com/dockerfile/mysql 或下载Dockerfile内容再当前目录： $ docker build -t=\u0026#34;dockerfile/mysql\u0026#34; . （提示，上述第一条命令，如果你的host不可以连接Docker Hub，那么需要在启动docker服务时使用HTTP_PROXY=——用于build的时更新下载软件，同时执行docker build的终端设置http_proxy和https_proxy用于下载Dockerfile）\n运行：\n1 2 3 $ docker run -d --name mysql -p 3306:3306 dockerfile/mysql 或 $ docker run -it --rm --link mysql:mysql dockerfile/mysql bash -c \u0026#39;mysql -h $MYSQL_PORT_3306_TCP_ADDR\u0026#39; 参考 Dockerfile Reference 中文 Dockerfile详解 dockerpool-build-instructions https://docs.docker.com/reference/builder/ https://docs.docker.com/articles/dockerfile_best-practices/ http://syntaxsugar.cn/2014/07/09/dockerfile/ ","permalink":"http://localhost:1313/2014/11/dockerfile-introduction/","summary":"\u003cp\u003eDocker可以从\u003ccode\u003eDockerfile\u003c/code\u003e中一步一步的读取指令来自动的创建镜像，常使用Dockerfile来创建用户自定义的镜像。格式如下：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e2\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-fallback\" data-lang=\"fallback\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e# Comment\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003eINSTRUCTION arguments\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e虽然前面的指令大小写不敏感，但习惯性的还是建议大写。docker是严格按照顺序（\u003ccode\u003e#\u003c/code\u003e注释起来的忽略）运行指令的。\n下面逐个来介绍几个必要的指令。\u003c/p\u003e","title":"Dockerfile指令详解"},{"content":"主要思路： 1. Docker Registry 说明 关于如何创建和使用本地仓库，其实已经有很多文章介绍了。因为docker技术正处于发展和完善阶段，所以有些文章要么内容已经过时，要么给出了错误的配置，导致无法正常创建仓库。本文记录的是个人完整的搭建过程，docker version为1.1.2。\n官方提供了Docker Hub网站来作为一个公开的集中仓库。然而，本地访问Docker Hub速度往往很慢，并且很多时候我们需要一个本地的私有仓库只供网内使用。\nDocker仓库实际上提供两方面的功能，一个是镜像管理，一个是认证。前者主要由docker-registry项目来实现，通过http服务来上传下载；后者可以通过docker-index（闭源）项目或者利用现成认证方案（如nginx）实现http请求管理。\ndocker-registry既然也是软件应用，自然最简单的方法就是使用官方提供的已经部署好的镜像registry。官方文档中也给出了建议，直接运行sudo docker run -p 5000:5000 registry命令。这样确实能启动一个registry服务器，但是所有上传的镜像其实都是由docker容器管理，放在了/var/lib/docker/\u0026hellip;.某个目录下。而且一旦删除容器，镜像也会被删除。因此，我们需要想办法告诉docker容器镜像应该存放在哪里。registry镜像中启动后镜像默认位置是/tmp/registry，因此直接映射这个位置即可，比如到本机的/opt/data/registry目录下。\n2. 在CentOS上搭建docker私服 2.1 安装docker-registry 方法有多种，直接运行下面的命令：\n1 # docker run -d -e SETTINGS_FLAVOR=dev -e STORAGE_PATH=/tmp/registry -v /opt/data/registry:/tmp/registry -p 5000:5000 registry 如果本地没有拉取过docker-registry，则首次运行会pull registry，运行时会映射路径和端口，以后就可以从/opt/data/registry下找到私有仓库都存在哪些镜像，通过主机的哪个端口可以访问。 你也可以把项目 https://github.com/docker/docker-registry.git 克隆到本地，然后使用Dockerfile来build镜像：\n1 2 3 4 5 6 7 8 9 10 11 12 13 # git clone https://github.com/docker/docker-registry.git # cd docker-registry \u0026amp;\u0026amp; mkdir -p /opt/data/registry # docker build -t \u0026#34;local-sean\u0026#34; . build完成后，就可以运行这个docker-registry 我们先配置自己的config.yml文件，第一种方法是直接在run的时候指定变量 # cp config/config_sample.yml /opt/data/registry/config.yml # vi /opt/data/registry/config.yml ##这里可以设置本地存储SETTINGS_FLAVOR=dev，local STORAGE_PATH:/tmp/registry等待 # docker run -d -v /opt/data/registry:/tmp/registry -p 5000:5000 -e DOCKER_REGISTRY_CONFIG=/tmp/registry/config.yml registry 或 docker run -d -e SETTINGS_FLAVOR=dev -e STORAGE_PATH=/tmp/registry -v /db/docker-images:/tmp/registry -p 5000:5000 registry 2.2 客户端使用 要从私服上获取镜像或向私服提交镜像，现在变得非常简单，只需要在仓库前面加上私服的地址和端口，形如172.29.88.222:5000/centos6。注意，这里可以选择不使用IP，而是用hostname，如registry.domain.com:5000，但不能仅用不带.的主机名registry，docker会认为registry是用户名，建议使用带域名的hostname加port来表示。\n于是在另外一台要使用docker的主机上就可以通过这台私服拉取和推送镜像了：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 从私服上搜索存在哪些可用镜像 # curl -X GET http://sean.domain.com:5000/v1/search {\u0026#34;num_results\u0026#34;: 2, \u0026#34;query\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;results\u0026#34;: [{\u0026#34;description\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;library/centos6\u0026#34;}, {\u0026#34;description\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;library/nginx\u0026#34;}]} 按条件搜索nginx # curl -X GET http://sean.domain.com:5000/v1/search?q=centos6 拉取image到本地 docker pull library/centos6 ## 本地对份镜像启动起来，形成container ## 给container去另外一个名字 # docker tag 68edf809afe7 registry.domain.com:5000/centos6-test ## 最后将新的docker images推送到私服上 docker push registry.domain.com:5000/centos6-test 第一次push到私服上时会提示用户名、密码和邮箱，创建即可。也可以在docker私服端加入认证机制。\n3. 加入nginx认证 （请在实际操作以前，先阅读完本节，再确定是否在前端加入nginx）\n3.1 安装及配置nginx 从上面的过程可以看到，除非防火墙限制，否则任何主机可以创建账号并想私服推送镜像，更安全的做法是在外层加入登录认证机制。\n1 2 3 4 5 6 7 8 9 10 最好安装1.4.x版本，不然下面的有些配置可能会不兼容 # yum install nginx 创建两个登录用户 # htpasswd -c /etc/nginx/docker-registry.htpasswd sean New password: Re-type new password: Adding password for user sean # htpasswd /etc/nginx/docker-registry.htpasswd itsection 为了让nginx使用这个密码文件，并且转发8080端口的请求到Docker Registry，新增nginx配置文件 vi /etc/nginx/sites-enabled/docker-registry：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 # For versions of Nginx \u0026gt; 1.3.9 that include chunked transfer encoding support # Replace with appropriate values where necessary upstream docker-registry { server localhost:5000; } server { listen 8080; server_name sean.domain.com; -- your registry server_name # ssl on; # ssl_certificate /etc/ssl/certs/docker-registry; # ssl_certificate_key /etc/ssl/private/docker-registry; proxy_set_header Host $http_host; # required for Docker client sake proxy_set_header X-Real-IP $remote_addr; # pass on real client IP client_max_body_size 0; # disable any limits to avoid HTTP 413 for large image uploads # required to avoid HTTP 411: see Issue #1486 (https://github.com/dotcloud/docker/issues/1486) chunked_transfer_encoding on; location / { # let Nginx know about our auth file auth_basic \u0026#34;Restricted\u0026#34;; auth_basic_user_file docker-registry.htpasswd; proxy_pass http://docker-registry; } location /_ping { auth_basic off; proxy_pass http://docker-registry; } location /v1/_ping { auth_basic off; proxy_pass http://docker-registry; } } 1 2 3 4 让nginx来使用这个virtual-host # ln -s /etc/nginx/sites-enabled/docker-registry /etc/nginx/conf.d/docker-registry.conf 重启nginx来激活虚拟主机的配置 # service nginx restart 3.2 加入认证后使用docker-registry 此时主机的5000端口应该通过防火墙禁止访问（或者在docker run端口映射时只监听回环接口的IP -p 127.0.0.1:5000:5000）。\n1 2 # curl localhost:5000 \u0026#34;docker-registry server (dev) (v0.8.1)\u0026#34; 如果直接访问访问将得到未授权的信息：\n1 2 3 4 5 6 7 8 # curl localhost:8080 \u0026lt;html\u0026gt; \u0026lt;head\u0026gt;\u0026lt;title\u0026gt;401 Authorization Required\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body bgcolor=\u0026#34;white\u0026#34;\u0026gt; \u0026lt;center\u0026gt;\u0026lt;h1\u0026gt;401 Authorization Required\u0026lt;/h1\u0026gt;\u0026lt;/center\u0026gt; \u0026lt;hr\u0026gt;\u0026lt;center\u0026gt;nginx/1.4.7\u0026lt;/center\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 带用户认证的docker-registry：\n1 2 3 4 5 6 7 8 9 10 # curl http://sean:sean@sean.domain.com:8080/v1/search {\u0026#34;num_results\u0026#34;: 2, \u0026#34;query\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;results\u0026#34;: [{\u0026#34;description\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;library/centos6\u0026#34;}, {\u0026#34;description\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;library/nginx\u0026#34;}]} # docker login registry.domain.com:8080 Username: sean Password: Email: zhouxiao@domain.com Login Succeeded # docker pull registry.domain.com:8080/library/centos6 不出意外的话，上面的docker pull会失败：\n1 2 3 4 5 6 7 8 9 10 11 12 13 # docker pull registry.domain.com:8080/library/centos6 Pulling repository registry.domain.com:8080/library/centos6 2014/11/11 21:00:25 Could not reach any registry endpoint # docker push registry.domain.com:8080/ubuntu:sean The push refers to a repository [registry.domain.com:8080/ubuntu] (len: 1) Sending image list Pushing repository registry.domain.com:8080/ubuntu (1 tags) 2014/11/12 08:11:32 HTTP code 401, Docker will not send auth headers over HTTP. nginx日志 2014/11/12 07:03:49 [error] 14898#0: *193 no user/password was provided for basic authenticatGET /v1/repositories/library/centos6/tags HTTP/1.1\u0026#34;, host: \u0026#34;registry.domain.com:8080\u0026#34; 本文后的第1篇参考文档没有出现这个问题，但评论中有提及。 有人说是backend storage的问题，这里是本地存储镜像，不应该。经过查阅大量资料，并反复操作验证，是docker-registry版本的问题。从v0.10.0开始，docker login虽然Succeeded，但pull或push的时候，~/.dockercfg下的用户登录信息将不允许通过HTTP明文传输。（如果你愿意可以查看v0.10.0的源码 registry.go，在分支v0.9.1及以前是没有HTTP code 401, Docker will not send auth headers over HTTP的） 目前的办法三个：\n撤退，这就是为什么先说明在操作前线查看到这的原因了 换成v0.9.1及以下版本。现在都v1.3.1了，我猜你不会这么做 修改源码session.go，去掉相应的判断行，然后git下来重新安装。我猜你更不会这么做 安装SSL证书，使用HTTPS传输。这是明智的选择，新版本docker也推荐我们这么做，往下看。 3.3 为nginx安装ssl证书 首先打开nginx配置文件中ssl的三行注释\n1 2 3 4 5 6 7 8 9 10 11 # vi /etc/nginx/conf.d/docker-registry.conf ... server { listen 8000; server_name registry.domain.com; ssl on; ssl_certificate /etc/nginx/ssl/nginx.crt; ssl_certificate_key /etc/nginx/ssl/nginx.key; ... 保存之后，nginx会分别从/etc/nginx/ssl/nginx.crt和/etc/nginx/ssl/nginx.key读取ssl证书和私钥。如果你自己愿意花钱买一个ssl证书，那就会变得非常简单，把证书和私钥拷贝成上面一样即可。关于SSL以及签署ssl证书，请参考其他文章。 这里我们自签署一个ssl证书，把当前系统作为（私有）证书颁发中心（CA）。\n创建存放证书的目录\n1 # mkdir /etc/nginx/ssl 确认CA的一些配置文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # vi /etc/pki/tls/openssl.cnf ... [ CA_default ] dir = /etc/pki/CA # Where everything is kept certs = $dir/certs # Where the issued certs are kept crl_dir = $dir/crl # Where the issued crl are kept database = $dir/index.txt # database index file. #unique_subject = no # Set to \u0026#39;no\u0026#39; to allow creation of # several ctificates with same subject. new_certs_dir = $dir/newcerts # default place for new certs. certificate = $dir/cacert.pem # The CA certificate serial = $dir/serial # The current serial number crlnumber = $dir/crlnumber # the current crl number # must be commented out to leave a V1 CRL crl = $dir/crl.pem # The current CRL private_key = $dir/private/cakey.pem # The private key RANDFILE = $dir/private/.rand # private random number file ... default_days = 3650 # how long to certify for ... [ req_distinguished_name ] countryName = Country Name (2 letter code) countryName_default = CN countryName_min = 2 countryName_max = 2 stateOrProvinceName = State or Province Name (full name) stateOrProvinceName_default = GD ...[ req_distinguished_name ]部分主要是颁证时一些默认的值，可以不动 (1) 生成根密钥\n1 2 # cd /etc/pki/CA/ # openssl genrsa -out private/cakey.pem 2048 为了安全起见，修改cakey.pem私钥文件权限为600或400，也可以使用子shell生成( umask 077; openssl genrsa -out private/cakey.pem 2048 )，下面不再重复。\n(2) 生成根证书\n1 # openssl req -new -x509 -key private/cakey.pem -out cacert.pem 会提示输入一些内容，因为是私有的，所以可以随便输入，最好记住能与后面保持一致。上面的自签证书cacert.pem应该生成在/etc/pki/CA下。\n(3) 为我们的nginx web服务器生成ssl密钥\n1 2 # cd /etc/nginx/ssl # openssl genrsa -out nginx.key 2048 我们的CA中心与要申请证书的服务器是同一个，否则应该是在另一台需要用到证书的服务器上生成。\n(4) 为nginx生成证书签署请求\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # openssl req -new -key nginx.key -out nginx.csr ... Country Name (2 letter code) [AU]:CN State or Province Name (full name) [Some-State]:GD Locality Name (eg, city) []:SZ Organization Name (eg, company) [Internet Widgits Pty Ltd]:COMPANY Organizational Unit Name (eg, section) []:IT_SECTION Common Name (e.g. server FQDN or YOUR name) []:your.domain.com Email Address []: Please enter the following \u0026#39;extra\u0026#39; attributes to be sent with your certificate request A challenge password []: An optional company name []: ... 同样会提示输入一些内容，其它随便，除了Commone Name一定要是你要授予证书的服务器域名或主机名，challenge password不填。\n(5) 私有CA根据请求来签发证书\n1 # openssl ca -in nginx.csr -out nginx.crt 上面签发过程其实默认使用了-cert cacert.pem -keyfile cakey.pem，这两个文件就是前两步生成的位于/etc/pki/CA下的根密钥和根证书。\n到此我们已经拥有了建立ssl安全连接所需要的所有文件，并且服务器的crt和key都位于配置的目录下，唯有根证书cacert.pem位置不确定放在CentOS6下的哪个地方。 经验证以下几个位置不行：（Adding trusted root certificates to the server） /etc/pki/ca-trust/source/anchors、/etc/pki/ca-trust/source、/etc/pki/ca-trust/extracted、 /etc/pki/ca-trust/extracted/pem/、/etc/pki/tls/certs/cacert.crt 都会报错：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # docker login https://registry.domain.com:8000 Username (sean): sean 2014/11/14 02:32:48 Error response from daemon: Invalid Registry endpoint: Get https://registry.domain.com:8000/v1/_ping: x509: certificate signed by unknown authority # curl https://sean:sean@registry.domain.com:8000/ curl: (60) Peer certificate cannot be authenticated with known CA certificates More details here: http://curl.haxx.se/docs/sslcerts.html curl performs SSL certificate verification by default, using a \u0026#34;bundle\u0026#34; of Certificate Authority (CA) public keys (CA certs). If the default bundle file isn\u0026#39;t adequate, you can specify an alternate file using the --cacert option. If this HTTPS server uses a certificate signed by a CA represented in the bundle, the certificate verification probably failed due to a problem with the certificate (it might be expired, or the name might not match the domain name in the URL). If you\u0026#39;d like to turn off curl\u0026#39;s verification of the certificate, use the -k (or --insecure) option. (6) 目前让根证书起作用的只发现一个办法：\n1 2 3 4 5 # cp /etc/pki/tls/certs/ca-bundle.crt{,.bak} 备份以防出错 # cat /etc/pki/CA/cacert.pem \u0026gt;\u0026gt; /etc/pki/tls/certs/ca-bundle.crt # curl https://sean:sean@registry.domain.com:8000 \u0026#34;docker-registry server (dev) (v0.8.1)\u0026#34; 将cacert.pem根证书追加到ca-bundle.crt后一定要重启docker后台进程才行。\n如果docker login依然报错certificate signed by unknown authority，参考Running Docker with https，启动docker后台进程时指定信任的CA根证书：\n1 2 3 4 5 6 7 # docker -d --tlsverify --tlscacert /etc/pki/CA/cacert.pem 或者将cacert.pem拷贝到~/.docker/ca.pem # mkdir ~/.docker \u0026amp;\u0026amp; cp /etc/pki/CA/cacert.pem ~/.docker/ca.pem # docker -d 最好重启一下registry # docker restart \u0026lt;registry_container_id\u0026gt; 上面用“如果”是因为一开始总提示certificate signed by unknown authority，有人说将根证书放在/etc/docker/certs.d下，还有人说启动docker daemon收加入--insecure-registry .. 但终究是因为版本差异不成功。但后来又奇迹般的不需要--tlscacert就好了。 这个地方挣扎了很久，重点关注一下这个下面几个issue：\nhttps://github.com/docker/docker-registry/issues/82 https://github.com/docker/docker/pull/2687 https://github.com/docker/docker/pull/2339 (7) 最终搞定：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # docker login https://registry.domain.com:8000 Username: sean Password: Email: zhouxiao@domain.com Login Succeeded # curl https://sean:sean@registry.domain.com:8000 \u0026#34;docker-registry server (dev) (v0.8.1)\u0026#34; # docker push registry.domain.com:8000/centos6:test_priv The push refers to a repository [registry.domain.com:8000/centos6] (len: 1) Sending image list Pushing repository registry.domain.com:8000/centos6 (1 tags) 511136ea3c5a: Image successfully pushed 5b12ef8fd570: Image successfully pushed 68edf809afe7: Image successfully pushed 40627956f44c: Image successfully pushed Pushing tag for rev [40627956f44c] on {https://registry.domain.com:8000/v1/repositories/centos6/tags/test_priv} 但还有一个小问题没解决，虽然已经可以正常使用，但每次请求在nginx的error.log中还是会有[error] 8299#0: *27 no user/password was provided for basic authentication，应该是这个版本docker暂未解决的bug。\n3.3 其它问题 (1) docker后台进程意外中断后，重新docker start \u0026lt;container_id\u0026gt;报错\n1 2 3 4 5 # docker start b36bd796bd3d Error: Cannot start container b36bd796bd3d: Error getting container b36bd796bd3d463c4fedb70d98621e7318ec3d5cd14b2f60b1d182ad3cbcc652 from driver devicemapper: Error mounting \u0026#39;/dev/mapper/docker-253:0-787676-b36bd796bd3d463c4fedb70d98621e7318ec3d5cd14b2f60b1d182ad3cbcc652\u0026#39; on \u0026#39;/var/lib/docker/devicemapper/mnt/b36bd796bd3d463c4fedb70d98621e7318ec3d5cd14b2f60b1d182ad3cbcc652\u0026#39;: device or resource busy 2014/11/08 15:14:57 Error: failed to start one or more containers 经分析产生这个问题的原因是做了一个操作：在docker后台进程启动的终端，继续回车后会临时退出后台进程的日志输出，我就在这个shell下使用yum安装软件包，但由于网络原因yum卡住不动，于是我就另起了一个终端kill了这个yum进程，不知为何会影响到表面已经退出前台输出的docker。解决办法是umount容器的挂载点：（见这里）\n1 2 3 # umount /var/lib/docker/devicemapper/mnt/b36bd796bd3d463c4fedb70d98621e7318ec3d5cd14b2f60b1d182ad3cbcc652 # service docker start 正常 能想到的另外一个办法是，启动docker后台进程时，重定向输出docker -d \u0026gt; /dev/null 2\u0026gt;\u0026amp;1（/var/log/docker已自动记录了一份日志）。\n(2) 配置完nginx的docker-registry.conf后启动报错\n1 2 # service nginx start [emerg] 14714#0: unknown directive \u0026#34;upstream\u0026#34; in /etc/nginx/conf.d/docker-registry.conf:4 原因是nginx版本太低，一些配置指令不兼容，使用yum install nginx默认安装了1.0.x，卸载重新下载nginx-1.4.7-1.el6.ngx.x86_64.rpm安装解决。\n(3) 网络设置代理问题 pull, push官网的镜像时由于GFW的原因需要设置代理，但不是http_proxy而是HTTP_PROXY，对于docker来说同时设置这两个值就会出问题，有时出于安装软件包的需要设置http_proxy，就会导致冲突。在docker-registry中如果忘记了当前哪一个在起作用，找遍所有问题都发现不了原因，而docker返回给我们的错误也难以判断。切记~\nTO-DO 如何删除docker-registry的里的镜像\n4. 参考 部署自己的私有 Docker Registry [英文]\nOfficial docker-registry README\nHow To Set Up a Private Docker Registry on Ubuntu 14.04\nThe Docker Hub and the Registry spec\n","permalink":"http://localhost:1313/2014/11/deploy-private-docker-registry-with-nginx-ssl/","summary":"\u003cp\u003e主要思路：\n\u003cimg alt=\"docker-registry-deploy\" loading=\"lazy\" src=\"http://github.com/seanlook/sean-notes-comment/raw/main/static/docker-registry-deploy.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"1-docker-registry-说明\"\u003e1. Docker Registry 说明\u003c/h2\u003e\n\u003cp\u003e关于如何创建和使用本地仓库，其实已经有很多文章介绍了。因为docker技术正处于发展和完善阶段，所以有些文章要么内容已经过时，要么给出了错误的配置，导致无法正常创建仓库。本文记录的是个人完整的搭建过程，\u003ccode\u003edocker version\u003c/code\u003e为1.1.2。\u003c/p\u003e","title":"搭建docker内网私服（docker-registry with nginx\u0026ssl on centos）"},{"content":"之所以有本文是由于Github前后两次发了2封不同的警告邮件，都是关于DNS配置的。因为xgknight.com刚申请下来时我也是参考其他博客，在seanlook.github.com仓库下面建立了一个CNAME文件，内容：xgknight.com，然后去DNSPod绑定域名和IP（207.97.227.245）访问也就没事了。然而几天之后每次deploy博客的时候都会受到一封build warning邮件（见本文最后），后来参考下面的文章：\n解决GitHub Pages Warning邮件提醒 一步步在GitHub上创建博客主页-最新版 — 自定义域名的新玩法 Faster, More Awesome GitHub Pages 和 GitHub Pages Legacy IP Deprecation 但显然第一篇有点拆东墙补西墙，只是换了个离自己最近的服务器，CDN根本就没用上，也是因为我dig seanlook.github.io +nostats +nocomments +nocmd之后把IP改成了103.245.222.133，才有了第二封邮件的warning（见本文最后）。第二篇倒是跟官方（第三条）是同一个意思，但是博主放弃了原本的顶级域名而是用www子域名。 首先根据邮件提示，明确一下最终目的：\n使用顶级域名xgknight.com来访问站点 子域名www.xgknight.com跳转到xgknight.com 充分Github Pages提供的cdn加速功能 两份邮件大概是同一个意思，说Github Pages正在进行重大的升级来提供更快的访问速度，所以我们指定的域名解析的IP在不就的将来将要废弃，需要指向一个合法的IP，第二封邮件说的更明确了，为了使用CDN加速功能，需要增加CNAME的子域名解析记录。\n如果你正在使用顶级域名（example.com）而不是子域名（如www.example.com），并且你的DNS解析服务提供商不支持ALIAS记录，那么唯一的选择就是使用A记录，但这种配置没有办法利用CDN加速了（依然可以应对DoS攻击）。如果切换成子域名或使用支持ALIAS的DNS解析上，都可以利用CDN和应对DoS。\n不料我现在的情形正是，使用顶级域名xgknight.com，DNSPod不支持ALIAS记录。虽然目前不使用CDN加速访问起来没感觉有多大问题，但对于我这种有轻微强迫症并追求完美的人来说，就是看不惯这个warnning。DNS解析服务不想换成付费的支持ALIAS的DNSimple，那么难道只能启用www子域名了吗？对于有些已经对你的网站做了链接的地方，随便修改域名可不是什么好事。于是我就尝试了下面的设置： 在DNSPod中去掉其它映射记录，添加CNAME记录的顶级域名映射到seanlook.github.com，github仓库下的CNAME文件也是顶级域名xgknight.com。经过这样设置后访问xgknight.com发现完全没有问题： 中国境内的ping值：\n1 2 3 4 5 6 $ ping xgknight.com 正在 Ping github.map.fastly.net [103.245.222.133] 具有 32 字节的数据: 来自 103.245.222.133 的回复: 字节=32 时间=215ms TTL=42 来自 103.245.222.133 的回复: 字节=32 时间=210ms TTL=42 来自 103.245.222.133 的回复: 字节=32 时间=205ms TTL=42 来自 103.245.222.133 的回复: 字节=32 时间=221ms TTL=42 美国的一个IP的ping值：\n1 2 3 4 5 6 rhcsh\u0026gt; ping xgknight.com PING github.map.fastly.net (199.27.76.133) 56(84) bytes of data. 64 bytes from 199.27.76.133: icmp_seq=1 ttl=43 time=8.15 ms 64 bytes from 199.27.76.133: icmp_seq=2 ttl=43 time=8.12 ms 64 bytes from 199.27.76.133: icmp_seq=3 ttl=43 time=8.23 ms 64 bytes from 199.27.76.133: icmp_seq=4 ttl=43 time=8.02 ms 可以看到是用上了CDN加速的特性。 但这样与官方给的做法是不同的，以防再出现什么问题，后来我通过邮件咨询过Github Pages的技术支持，反复告诉我说为www子域名添加CNAME记录到seanlook.github.com，为顶级域名添加A记录到IP addresses listed here，仓库下的CNAME文件为子域名。来回好几封英文邮件就没有正面给出回答的。因为我还没有系统去了解过域名解析服务的原理，所以只好自己测试了。 保持上面的设置，即仓库的CNAME文件内容保持不变，为Apex domian—xgknight.com，DNSPod只有顶级域名的CNAME记录映射到seanlook.github.com，测试是可以提供CDN，但www域名无法访问，更不会跳转了。于是我分别继续了下面的测试： (1) DNSPod再添加一条www子域名的CNAME指向seanlook.github.com，因为很容易理解的是访问www.xgknight.com也可以直接使用CDN加速了（官方一直建议有这样一条记录），但结果是不跳转。不行！ (2) DNSPod新添加的记录是 A record ，指向官方所建议的那个IP之一（192.30.252.153），结果达到要求，www.xgknight.com自动跳转到xgknight.com，自然顶级域名采用了CDN。\n所以问题最终得到解决的方案是：\n仓库下的CNAMEw文件内容： 1 2 $ cat CNAME xgknight.com DNSPod的域名解析记录 1 2 3 4 5 主机记录 记录类型 线路类型 记录值 MX优先级 TTL @ CNAME 默认 seanlook.github.com. - 600 @ NS 默认 f1g1ns1.dnspod.net. - 600 @ NS 默认 f1g1ns2.dnspod.net. - 600 www A 默认 192.30.252.153 - 600 (注意，DNSPod域名设置里有一个“域名别名”与这个ALIAS记录是完全不同的概念。)\n邮件内容 每次部署后都有一封邮件 GitHub noreply@github.com 11月6日 (3天前) 发送至 我 The page build completed successfully, but returned the following warning: GitHub Pages recently underwent some improvements (https://github.com/blog/1715-faster-more-awesome-github-pages) to make your site faster and more awesome, but we\u0026rsquo;ve noticed that xgknight.com isn\u0026rsquo;t properly configured to take advantage of these new features. While your site will continue to work just fine, updating your domain\u0026rsquo;s configuration offers some additional speed and performance benefits. Instructions on updating your site\u0026rsquo;s IP address can be found at https://help.github.com/articles/setting-up-a-custom-domain-with-github-pages, and of course, you can always get in touch with a human at support@github.com. For the more technical minded folks who want to skip the help docs: your site\u0026rsquo;s DNS records are pointed to a deprecated IP address. For information on troubleshooting Jekyll see: https://help.github.com/articles/using-jekyll-with-pages#troubleshooting If you have any questions please contact us at https://github.com/contact.\n第二天的第二封邮件 GitHub Support support@github.com 11月7日 (2天前) 发送至 我 Hi Sean, The custom domain for your GitHub Pages site seanlook/seanlook.github.com needs attention. You must take immediate corrective action to ensure that your site remains available after December 1st, 2014. Please follow the instructions for setting up a custom domain with GitHub Pages (http://github.cmail1.com/t/i-l-schrd-fkdtrjkl-y/) to update your custom domain’s DNS settings to point to the proper GitHub IP addresses. Why the change? Nearly a year ago, we announced improvements to how we serve GitHub Pages sites (http://github.cmail1.com/t/i-l-schrd-fkdtrjkl-j/). This week we’re making that change permanent (http://github.cmail1.com/t/i-l-schrd-fkdtrjkl-t/)by deprecating our old GitHub Pages infrastructure. If your custom domain is pointed at these legacy IPs, you’ll need to update your DNS configuration immediately to keep things running smoothly. How long do I have to make the switch? Starting the week of November 10th, pushing to a misconfigured site will result in a build error and you will receive an email stating that your site’s DNS is misconfigured. Your site will remain available to the public, but changes to your site will not be published until the DNS misconfiguration is resolved. For the week of November 17th, there will be a week-long brownout for improperly configured GitHub Pages sites. If your site is pointed to a legacy IP address, you will receive a warning message that week, in place of your site’s content. Normal operation will resume at the conclusion of the brownout. Starting December 1st, custom domains pointed to the deprecated IP addresses will no longer be served via GitHub Pages. No repository or Git data will be affected by the change. Okay, I’m sold. What do I need to do? Please follow the instructions for setting up a custom domain with GitHub Pages (http://github.cmail1.com/t/i-l-schrd-fkdtrjkl-i/) to update your custom domain’s DNS settings to point to the proper GitHub IP addresses. Questions? We’re here to help(http://github.cmail1.com/t/i-l-schrd-fkdtrjkl-d/). Happy Publishing! — The GitHub Pages Team\n","permalink":"http://localhost:1313/2014/11/github-mail-warning-dns/","summary":"\u003cp\u003e之所以有本文是由于Github前后两次发了2封不同的警告邮件，都是关于DNS配置的。因为\u003ccode\u003exgknight.com\u003c/code\u003e刚申请下来时我也是参考其他博客，在\u003ccode\u003eseanlook.github.com\u003c/code\u003e仓库下面建立了一个\u003ccode\u003eCNAME\u003c/code\u003e文件，内容：\u003ccode\u003exgknight.com\u003c/code\u003e，然后去DNSPod绑定域名和IP（207.97.227.245）访问也就没事了。然而几天之后每次deploy博客的时候都会受到一封\u003ccode\u003ebuild warning\u003c/code\u003e邮件（见本文最后），后来参考下面的文章：\u003c/p\u003e","title":"完全解决Github Pages邮件两次warning（DNS解析问题）"},{"content":"本文承接docker专题(2)：docker常用管理命令（上）。\n1. 开启/停止/重启container（start/stop/restart） 容器可以通过run新建一个来运行，也可以重新start已经停止的container，但start不能够再指定容器启动时运行的指令，因为docker只能有一个前台进程。 容器stop（或Ctrl+D）时，会在保存当前容器的状态之后退出，下次start时保有上次关闭时更改。而且每次进入attach进去的界面是一样的，与第一次run启动或commit提交的时刻相同。\n1 2 3 CONTAINER_ID=$(docker start \u0026lt;containner_id\u0026gt;) docker stop $CONTAINER_ID docker restart $CONTAINER_ID 关于这几个命令可以通过一个完整的实例使用：docker如何创建一个运行后台进程的容器并同时提供shell终端。\n2. 连接到正在运行中的container（attach） 要attach上去的容器必须正在运行，可以同时连接上同一个container来共享屏幕（与screen命令的attach类似）。 官方文档中说attach后可以通过CTRL-C来detach，但实际上经过我的测试，如果container当前在运行bash，CTRL-C自然是当前行的输入，没有退出；如果container当前正在前台运行进程，如输出nginx的access.log日志，CTRL-C不仅会导致退出容器，而且还stop了。这不是我们想要的，detach的意思按理应该是脱离容器终端，但容器依然运行。好在attach是可以带上 --sig-proxy=false来确保CTRL-D或CTRL-C不会关闭容器。\n1 # docker attach --sig-proxy=false $CONTAINER_ID 3. 查看image或container的底层信息（inspect） inspect的对象可以是image、运行中的container和停止的container。\n1 2 3 4 查看容器的内部IP # docker inspect --format=\u0026#39;{\\{.NetworkSettings.IPAddress}}\u0026#39; $CONTAINER_ID 172.17.42.35 （注：由于代码块解析的问题，上面NetworkSettings前面的 \\ 去掉） 4. 删除一个或多个container、image（rm、rmi） 你可能在使用过程中会build或commit许多镜像，无用的镜像需要删除。但删除这些镜像是有一些条件的：\n同一个IMAGE ID可能会有多个TAG（可能还在不同的仓库），首先你要根据这些 image names 来删除标签，当删除最后一个tag的时候就会自动删除镜像； 承上，如果要删除的多个IMAGE NAME在同一个REPOSITORY，可以通过docker rmi \u0026lt;image_id\u0026gt;来同时删除剩下的TAG；若在不同Repo则还是需要手动逐个删除TAG； 还存在由这个镜像启动的container时（即便已经停止），也无法删除镜像； TO-DO 如何查看镜像与容器的依存关系\n** 删除容器 ** docker rm \u0026lt;container_id/contaner_name\u0026gt;\n1 2 删除所有停止的容器 docker rm $(docker ps -a -q) ** 删除镜像 ** docker rmi \u0026lt;image_id/image_name ...\u0026gt; 下面是一个完整的示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # docker images \u0026lt;== ubuntu 13.10 195eb90b5349 4 months ago 184.6 MB ubuntu saucy 195eb90b5349 4 months ago 184.6 MB seanlook/ubuntu rm_test 195eb90b5349 4 months ago 184.6 MB 使用195eb90b5349启动、停止一个容器后，删除这个镜像 # docker rmi 195eb90b5349 Error response from daemon: Conflict, cannot delete image 195eb90b5349 because it is tagged in multiple repositories, use -f to force 2014/11/04 14:19:00 Error: failed to remove one or more images 删除seanlook仓库中的tag \u0026lt;== # docker rmi seanlook/ubuntu:rm_test Untagged: seanlook/ubuntu:rm_test 现在删除镜像，还会由于container的存在不能rmi # docker rmi 195eb90b5349 Error response from daemon: Conflict, cannot delete 195eb90b5349 because the container eef3648a6e77 is using it, use -f to force 2014/11/04 14:24:15 Error: failed to remove one or more images 先删除由这个镜像启动的容器 \u0026lt;== # docker rm eef3648a6e77 删除镜像 \u0026lt;== # docker rmi 195eb90b5349 Deleted: 195eb90b534950d334188c3627f860fbdf898e224d8a0a11ec54ff453175e081 Deleted: 209ea56fda6dc2fb013e4d1e40cb678b2af91d1b54a71529f7df0bd867adc961 Deleted: 0f4aac48388f5d65a725ccf8e7caada42f136026c566528a5ee9b02467dac90a Deleted: fae16849ebe23b48f2bedcc08aaabd45408c62b531ffd8d3088592043d5e7364 Deleted: f127542f0b6191e99bb015b672f5cf48fa79d974784ac8090b11aeac184eaaff 注意，上面的删除过程我所举的例子比较特殊——镜像被tag在多个仓库，也有启动过的容器。按照\u0026lt;==指示的顺序进行即可。\n5. docker build 使用此配置生成新的image build命令可以从Dockerfile和上下文来创建镜像： docker build [OPTIONS] PATH | URL | - 上面的PATH或URL中的文件被称作上下文，build image的过程会先把这些文件传送到docker的服务端来进行的。 如果PATH直接就是一个单独的Dockerfile文件则可以不需要上下文；如果URL是一个Git仓库地址，那么创建image的过程中会自动git clone一份到本机的临时目录，它就成为了本次build的上下文。无论指定的PATH是什么，Dockerfile是至关重要的，请参考Dockerfile Reference。 请看下面的例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # cat Dockerfile FROM seanlook/nginx:bash_vim EXPOSE 80 ENTRYPOINT /usr/sbin/nginx -c /etc/nginx/nginx.conf \u0026amp;\u0026amp; /bin/bash # docker build -t seanlook/nginx:bash_vim_Df . Sending build context to Docker daemon 73.45 MB Sending build context to Docker daemon Step 0 : FROM seanlook/nginx:bash_vim ---\u0026gt; aa8516fa0bb7 Step 1 : EXPOSE 80 ---\u0026gt; Using cache ---\u0026gt; fece07e2b515 Step 2 : ENTRYPOINT /usr/sbin/nginx -c /etc/nginx/nginx.conf \u0026amp;\u0026amp; /bin/bash ---\u0026gt; Running in e08963fd5afb ---\u0026gt; d9bbd13f5066 Removing intermediate container e08963fd5afb Successfully built d9bbd13f5066 上面的PATH为.，所以在当前目录下的所有文件（不包括.dockerignore中的）将会被tar打包并传送到docker daemon（一般在本机），从输出我们可以到Sending build context...，最后有个Removing intermediate container的过程，可以通过--rm=false来保留容器。 TO-DO docker build github.com/creack/docker-firefox失败。\n6. 给镜像打上标签（tag） tag的作用主要有两点：一是为镜像起一个容易理解的名字，二是可以通过docker tag来重新指定镜像的仓库，这样在push时自动提交到仓库。\n1 2 3 4 5 将同一IMAGE_ID的所有tag，合并为一个新的 # docker tag 195eb90b5349 seanlook/ubuntu:rm_test 新建一个tag，保留旧的那条记录 # docker tag Registry/Repos:Tag New_Registry/New_Repos:New_Tag 7. 查看容器的信息container（ps） docker ps命令可以查看容器的CONTAINER ID、NAME、IMAGE NAME、端口开启及绑定、容器启动后执行的COMMNAD。经常通过ps来找到CONTAINER_ID。 docker ps 默认显示当前正在运行中的container docker ps -a 查看包括已经停止的所有容器 docker ps -l 显示最新启动的一个容器（包括已停止的）\n8. 查看容器中正在运行的进程（top） 容器运行时不一定有/bin/bash终端来交互执行top命令，查看container中正在运行的进程，况且还不一定有top命令，这是docker top \u0026lt;container_id/container_name\u0026gt;就很有用了。实际上在host上使用ps -ef|grep docker也可以看到一组类似的进程信息，把container里的进程看成是host上启动docker的子进程就对了。\n9. 其他命令 docker还有一些如login、cp、logs、export、import、load、kill等不是很常用的命令，比较简单，请参考官网。\n参考 Official Command Line Reference docker中文指南cli-widuu翻译 Docker —— 从入门到实践 Docker基础与高级 ","permalink":"http://localhost:1313/2014/11/docker-command-best-use-2/","summary":"\u003cp\u003e本文承接\u003ca href=\"http://xgknight.com/2014/10/31/docker-command-best-use-1/\"\u003edocker专题(2)：docker常用管理命令（上）\u003c/a\u003e。\u003c/p\u003e\n\u003ch3 id=\"1-开启停止重启containerstartstoprestart\"\u003e1. 开启/停止/重启container（start/stop/restart）\u003c/h3\u003e\n\u003cp\u003e容器可以通过\u003ccode\u003erun\u003c/code\u003e新建一个来运行，也可以重新\u003ccode\u003estart\u003c/code\u003e已经停止的container，但\u003ccode\u003estart\u003c/code\u003e不能够再指定容器启动时运行的指令，因为docker只能有一个前台进程。\n容器stop（或\u003ccode\u003eCtrl+D\u003c/code\u003e）时，会在保存当前容器的状态之后退出，下次start时保有上次关闭时更改。而且每次进入\u003ccode\u003eattach\u003c/code\u003e进去的界面是一样的，与第一次run启动或commit提交的时刻相同。\u003c/p\u003e","title":"docker常用管理命令（下）"},{"content":"只看标题还不是很明显，本文实现docker的这样一种比较常用的功能：通过docker run启动一个容器后，容器中已经运行了一个后台进程（这里以监听80端口的nginx为例），同时进入一个shell终端可供操作，而不受限于只能在前台运行nginx与运行shell终端之间的一种。这个例子实现了，那么其他类似的运行多任务docker就可以以此类推。另外本文还提供了一种在docker容器内部安装软件（vim）的方法，对于定制自己需要的镜像大有帮助。 你可能需要先阅读docker专题(2)：docker常用管理命令（上）、docker专题(2)：docker常用管理命令（下）来理解更多。\n1. 已经pull了官方的nginx 1.7.6的镜像（也可以从私服获取）## 1 2 # docker images|grep nginx nginx 1.7.6 561ed4952ef0 10 days ago 100 MB 2. 根据官方指示启动这个容器 1 2 先做好自己要显示的页面 # echo \u0026#34;\u0026lt;h2 \u0026gt;This is nginx official container running \u0026lt;/h2\u0026gt; \u0026lt;br /\u0026gt; static files:/tmp/doccker/index.html\u0026#34; \u0026gt; /tmp/docker/index.html 使用官方image启动一个容器，名字nginx_dist，把host的目录（包含刚才的html）映射到容器中nginx server的root，绑定80端口：\n1 2 3 4 5 6 # docker run --name nginx_dist -v /tmp/docker:/usr/share/nginx/html:ro \\ \u0026gt; -p 80:80 -d nginx:1.7.6 1b10b08d7905517a26c72ce8b17b719aaea5e5eac0889263db8b017427e3c8f7 # docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 1b10b08d7905 nginx:1 nginx -g \u0026#39;daemon off 51 seconds ago Up 48 seconds 443/tcp, 0.0.0.0:80-\u0026gt;80/tcp nginx_dist 此时通过浏览器访问主机http://host_ip:port/就可以看到结果了： 3. 查看这个容器的信息 熟悉一下docker的命令。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 查看容器中运行着哪些进程 # docker top nginx_dist UID PID PPID C STIME TTY TIME CMD root 24378 18471 0 15:25 ? 00:00:00 nginx: master process nginx -g daemon off; 101 24433 24378 0 15:25 ? 00:00:00 nginx: worker process 查看容器IP和主机等信息 # docker inspect nginx_dist |grep 172.17 \u0026#34;Gateway\u0026#34;: \u0026#34;172.17.42.1\u0026#34;, \u0026#34;IPAddress\u0026#34;: \u0026#34;172.17.42.6\u0026#34;, 连接到容器上，--sig-proxy可以保证 Ctrl+D、Ctrl+C 不会退出 # docker attach --sig-proxy=false nginx_dist xxx.xx.xx.xx - - [03/Nov/2014:07:39:52 +0000] \u0026#34;GET / HTTP/1.1\u0026#34; 304 0 \u0026#34;-\u0026#34; \u0026#34;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2125.104 Safari/537.36\u0026#34; \u0026#34;-\u0026#34; Ctrl+C 4. 容器改造—在容器内部安装vim 这里有个未解决的问题，能否有办法在上面已经启动的container的基础上执行命令？官方没有这样的支持。 目前只能重新启动一个容器(停止上面的nginx_dist容器)\n1 2 3 4 5 可以比较一下与2中命令的变化 # docker run --name nginx_bash_vim -v /tmp/docker:/usr/share/nginx/html:ro \\ \u0026gt; -p 80:80 -i -t nginx:1.7.6 \u0026gt; /bin/bash root@3911d1104c3f:/# 但此时nginx服务是停止的，并没有在后台运行，访问http://host_ip:port/无效。为了后面编辑配置文件方便，我们先把vim安装好。 容器内部的网络与容器外部是相同的，并与host具有相同的DNS，所以可以使用公网软件（cat /etc/apt/sources.list）镜像源来安装。\n1 2 3 4 5 6 7 8 9 10 11 如果需要代理：export http_proxy=http://proxy_server:port # apt-get clean # apt-get update # apt-get install vim Reading package lists... Done ... After this operation, 25.2 MB of additional disk space will be used. Do you want to continue [Y/n]? y ... Setting up vim (2:7.3.547-7) ... ... 5. 让nginx在后台运行，前台提供shell终端 实现这一步的方法有许多种，比如\n5.1 手动运行/usr/sbin/nginx -c /etc/nginx/nginx.conf 也就是用第4步的方法先启动到/bin/bash，再手动运行/usr/sbin/nginx -c /etc/nginx/nginx.conf或service nginx start，很容易想到，但太麻烦。\n5.2 通过Dockerfile来build 将装好vim的容器提交成新的image，然后通过Dockerfile来自定义要启动哪些服务。关于Dockerfile后面我也会写文章来单独介绍其语法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 在主机下运行 # docker commit -m \u0026#34;nginx 14.10 with bash,vim\u0026#34; nginx_bash_vim seanlook/nginx:bash_vim a06ab41a6565f0dbd5d35d44cb441d1a166beaae3bc49bffcb09d334a1e77a5c 使用Dockerfile来建立一个新的镜像，加入启动到容器是运行的命令 # vi Dockerfile FROM seanlook/nginx:bash_vim ENTRYPOINT /usr/sbin/nginx -c /etc/nginx/nginx.conf \u0026amp;\u0026amp; /bin/bash build新image，tag为bash_vim_Df # docker build -t seanlook/nginx:bash_vim_Df . Sending build context to Docker daemon 73.45 MB Sending build context to Docker daemon Step 0 : FROM seanlook/nginx:bash_vim ---\u0026gt; aa8516fa0bb7 Step 1 : EXPOSE 80 ---\u0026gt; Using cache ---\u0026gt; fece07e2b515 Step 2 : ENTRYPOINT /usr/sbin/nginx -c /etc/nginx/nginx.conf \u0026amp;\u0026amp; /bin/bash ---\u0026gt; Running in e08963fd5afb ---\u0026gt; d9bbd13f5066 Removing intermediate container e08963fd5afb Successfully built d9bbd13f5066 --\u0026gt; 新image id # docker images |grep \u0026#39;bash_vim\u0026#39; seanlook/nginx bash_vim_Df d9bbd13f5066 About an hour ago 125.9 MB seanlook/nginx bash_vim aa8516fa0bb7 About an hour ago 125.9 MB 运行由Dockerfile创建的image # docker run --name nginx_bash_vim_Df -v /tmp/docker:/usr/share/nginx/html:ro \\ \u0026gt; -i -t -p 8080:80 \\ \u0026gt; d9bbd13f5066 --\u0026gt; 或seanlook/nginx:bash_vim_Df 最后一条docker run之后就会自动进入bash终端，同时发现nginx服务也启动了，可以通过vim来编辑配置文件。\n5.3 修改容器的/etc/bash.bashrc 这是投机取巧但不失为最简单的一种办法，见Run a service automatically in a docker container。\n1 2 3 4 5 6 7 8 启动刚安装完vim的那个容器（不必用run） # docker start nginx_bash_vim 连接到终端上 # docker attach nginx_bash_vim root@3911d1104c3f:/# vi /etc/bash.bashrc # added by mis_zx for auto-service nginx --\u0026gt; 在最后加入 /usr/sbin/nginx -c /etc/nginx/nginx.conf 保存后直接Ctrl+D退出，在start就可以访问了，如果要进入终端就attach，如果需要可以commit成一个镜像。\n5.4 听说有一种通过supervisor来管理docker容器的多个任务，有时间会研究一下 从上面的操作中可以看出，start是可以保留run启动时的参数如-v、-p，而commit之后如果没在Dockerfile中指定，下次启动依然需要带上目录、端口的映射参数。 另外提一点， docker run -i -t seanlook/nginx:bash_vim启动便会同时进入一个shell界面（但没有启动nginx），因为它的“前身”容器是在shell交互界面下run来的，但也没有保留-v、-p指定的映射关系。\n","permalink":"http://localhost:1313/2014/11/docker-run-container-with-shell-daemon_process/","summary":"\u003cp\u003e只看标题还不是很明显，本文实现docker的这样一种比较常用的功能：通过\u003ccode\u003edocker run\u003c/code\u003e启动一个容器后，容器中已经运行了一个后台进程（这里以监听80端口的nginx为例），同时进入一个shell终端可供操作，而不受限于只能在前台运行nginx与运行shell终端之间的一种。这个例子实现了，那么其他类似的运行多任务docker就可以以此类推。另外本文还提供了一种在docker容器内部安装软件（\u003ccode\u003evim\u003c/code\u003e）的方法，对于定制自己需要的镜像大有帮助。\n你可能需要先阅读\u003ca href=\"hhttp://xgknight.com/2014/10/31/docker-command-best-use-1/\"\u003edocker专题(2)：docker常用管理命令（上）\u003c/a\u003e、\u003ca href=\"http://xgknight.com/2014/11/05/docker-command-best-use-2/\"\u003edocker专题(2)：docker常用管理命令（下）\u003c/a\u003e来理解更多。\u003c/p\u003e","title":"docker如何创建一个运行后台进程的容器并同时提供shell终端"},{"content":"首先问题产生的缘由很简单，是我一同事在安装oracle一套软件时，按照要求需要binutils软件包的32位版本，然而在Oracle Linux已经装有64位，按理说是可以安装i686的，我猜应该是32位的版本低于这个已有的64位所以导致冲突而安装失败，因此同事就用yum remove binutils，这个命令也奇葩，由于是root权限导致依赖于它的200多个软件包也被卸载，最终导致网络断开，系统崩溃，在vSphere虚拟机上重新启动发现再也起不来。下面看问题：\n1. Kernel panic - not syncing: Attempted to kill init! 这个错误时在重新启动Oracle Linux一开始就出现，查阅的相关资料得知Kernel panic问题一般是由驱动模块终端处理终端问题导致的（不懂。。。），一开始我以为是驱动程序依赖于binutils导致被卸载，因此第一反应是想办法把缺失的软件装回去。实际上，是由于安全访问控制模块selinux的问题，参考类似问题。于是检查vi /etc/selinux/config时发现SELINUX=disables，拼写错误，应为disabled。 当再次启动没再出现该错误时，我高兴的认为原来这么简单就帮同事解决了，事实这根本还没到200多个软件包缺失而导致系统崩溃那一步。\n2. 系统启动加载条完成后，一直hang住不动 这无疑要使用LiveCD修复系统了，参考Ultimate method to install package from linux rescue mode或Using Rescue Mode to Fix..Problems。因为知道出问题前做过什么操作，下面直接上解决问题的过程。\n2.1 将系统DVD安装镜像加载到光驱 再次重启就自动进入安装界面，我们当然选择rescue mode： 一路按照提示确定（可以不配置network，这里就不贴图了，很简单），最终会提供给用户一个shell终端，对应的是从DVD光驱加载进来的系统，执行chroot /mnt/sysimage才会进入到原损坏的Linux系统，还好yum和rpm命令还可以使用，悲剧的是我并不知道yum remove命令卸载了哪些软件包。\n2.2 安装缺失的软件包 这里得谢天谢地yum命令的安装卸载日志/var/log/yum.log，这个日志里清楚的记录了installed和erased的所有软件包，用rpm是不可能了，因为270多个包的依赖关系难以解决，只能通过yum方式，而由于rescue模式没有配置网络，因此只能使用本地镜像源。\n1 2 3 4 5 6 7 8 9 10 11 12 13 在rescue系统下挂载光驱到待修复系统中的/media目录 bash-4.1# mount /dev/cdrom /mnt/sysimage/media chroot进入待修复系统 bash-4.1# chroot /mnt/sysimage 手动编辑一个仓库源（真实待修复的系统） sh-4.1# cd /etc/yum.repos.d/ \u0026amp;\u0026amp; vi Oracle-Media.repo [DVD-media] name=oracle-$releasever - Media baseurl=file:///media gpgcheck=0 enabled=1 建议只留Oracle-Media.repo文件，其他的.repo文件都mv成.bak，以防连接不了这些源而报错，虽然报错关系不大。 获取被依赖erased掉的软件列表\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 你可以将yum.log中多余的部分去掉，筛选出应该重新安装的packages： sh-4.1# cp /var/log/yum.log{,.bak} sh-4.1# less /var/log/yum.log.bak Oct 29 20:17:34 Erased: gcc-c++ Oct 29 20:18:44 Erased: gcc Oct 29 20:22:59 Erased: xorg-x11-drivers ... Oct 29 20:24:46 Erased: iputils Oct 29 20:24:46 Erased: udev Oct 29 20:24:46 Erased: initscripts Oct 29 20:24:46 Erased: hwdata Oct 29 20:24:46 Erased: module-init-tools Oct 29 20:24:48 Erased: binutils 下面一条命令应该要彻底解决问题了 sh-4.1# awk \u0026#39;{print \u0026#34;yum install -y \u0026#34;,$5}\u0026#39; /var/log/yum.log.bak |sh \u0026gt; /root/yum_install.log 保险起见，可以查看一下产生的日志文件。此时重启（记得拿出光盘）应该是修复问题了。但我遇见的问题还没完。\n3. An error occurred during the file system check 显然，文件系统损坏。根据提示输入root密码后可以进入到shell中，网上有办法说执行fsck命令来修复分区，又说且不能是mounted状态，但无论我怎么去fsck.ext4 /dev/mapper/vg_fusion_lv_u1，提示：\n1 2 3 4 5 6 7 8 9 10 11 12 WARNING!!! The filesystem is mounted. if you continue you ***WILL*** cause ***SEVERE*** filesystem damage` Do you really want to continue (y/n)? yes fsck.ext4: No such file or directory while trying to open /dev/mapper/vg_fusion_lv_u1 The superblock could not be read or does not describe a correct ext2 filesystem. If the device is valid and it really contains an ext2 filesystem (and not swap or ufs or something else), then the superblock is corrupt, and you might try running e2fsck with an alternate superblock: e2fsck -b 8193 \u0026lt;device\u0026gt; 听起来好像还挺严重的，我之前猜想的是不是反复的开关电源来重启导致lvm文件系统corrupt，但事实我发现/dev/mapper/vg_fusion_lv_u1不存在，但lv_fusion_lv_root却完好，执行lvdisplay发现这个命令根本不存在，这才发现原来lvm2软件没有安装（难道是第2部分安装少许出错？）。 这下容易多了，反正现在系统不借助rescue mode就可以起来，重新安装软件包，但是此时的整个文件系统是read only，有两个办法可以解决：\nmount -o remount,rw / 重新挂载根分区为读写，vi /etc/fstab注释掉挂载/u1的那条记录，此时会正常启动，只是有一个文件系统没有挂载，但可以正常安装缺失的lvm2软件，不妨多执行几遍2.2的安装命令。然后手动挂载mount /dev/mapper/vg_fusion_lv_u1 /u1应该就没问题了。记得改回/etc/fstab。 与2.2步骤类似，进入rescue mode→chroot，重新执行awk '{print \u0026quot;yum install -y \u0026quot;,$5}' /var/log/yum.log.bak |sh \u0026gt; /root/yum_install.log，确保没有报错且已安装lvm。 这下问题总是解决了，避免了删除系统的灾难（测试环境）。\n4. 总结 回头去看这三个问题，其他它们是各自独立的\n第1个问题，是由于设置selinux有人拼写错误，哪怕没做后续的任何操作，重启系统就会启动不了，是早已存在到目前才发现。也有人说遇见过同样的Kernel panic错误但尝试各种办法都难以解决的，这就看具体问题具体分析了。 第2个问题，是真真切切错误卸载重要软件包，导致系统崩溃，修复系统的方法自然也就是利用原镜像在rescue mode下把该装的都装回去，前提是yum.log日志存在，万幸没有执行过yum clean all。 第3个问，题实际文件系统并没有损坏，还是lvm2缺失，但是此处必须小心，免得SEVERE filesystem damage，那么修复过程就没意义了。 以后处理其他系统故障时也可使用类似的方法修复，Redhat、CentOS、OracleLinux、Ubuntu等都适用。\n","permalink":"http://localhost:1313/2014/11/one-troubleshooting-for-centos-corrupt/","summary":"\u003cp\u003e首先问题产生的缘由很简单，是我一同事在安装oracle一套软件时，按照要求需要binutils软件包的32位版本，然而在Oracle Linux已经装有64位，按理说是可以安装i686的，我猜应该是32位的版本低于这个已有的64位所以导致冲突而安装失败，因此同事就用\u003ccode\u003eyum remove binutils\u003c/code\u003e，这个命令也奇葩，由于是root权限导致依赖于它的200多个软件包也被卸载，最终导致网络断开，系统崩溃，在vSphere虚拟机上重新启动发现再也起不来。下面看问题：\u003c/p\u003e","title":"记一次错误卸载软件包导致Linux系统崩溃的修复解决过程"},{"content":"本文只记录docker命令在大部分情境下的使用，如果想了解每一个选项的细节，请参考官方文档，这里只作为自己以后的备忘记录下来。\n根据自己的理解，总的来说分为以下几种： 容器生命周期管理 — docker [run|start|stop|restart|kill|rm|pause|unpause] 容器操作运维 — docker [ps|inspect|top|attach|events|logs|wait|export|port] 容器rootfs命令 — docker [commit|cp|diff] 镜像仓库 — docker [login|pull|push|search] 本地镜像管理 — docker [images|rmi|tag|build|history|save|import] 其他命令 — docker [info|version]\n看一个变迁图 1. 列出机器上的镜像（images） 1 2 3 4 # docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE ubuntu 14.10 2185fd50e2ca 13 days ago 236.9 MB … 其中我们可以根据REPOSITORY来判断这个镜像是来自哪个服务器，如果没有 / 则表示官方镜像，类似于username/repos_name表示Github的个人公共库，类似于regsistory.example.com:5000/repos_name则表示的是私服。 IMAGE ID列其实是缩写，要显示完整则带上--no-trunc选项\n2. 在docker index中搜索image（search） Usage: docker search TERM 1 2 3 # docker search seanlo NAME DESCRIPTION STARS OFFICIAL AUTOMATED seanloook/centos6 sean\u0026#39;s docker repos 0 搜索的范围是官方镜像和所有个人公共镜像。NAME列的 / 后面是仓库的名字。\n3. 从docker registry server 中下拉image或repository（pull） Usage: docker pull [OPTIONS] NAME[:TAG]\n1 # docker pull centos 上面的命令需要注意，在docker v1.2版本以前，会下载官方镜像的centos仓库里的所有镜像，而从v.13开始官方文档里的说明变了：will pull the centos:latest image, its intermediate layers and any aliases of the same id，也就是只会下载tag为latest的镜像（以及同一images id的其他tag）。 也可以明确指定具体的镜像：\n1 # docker pull centos:centos6 当然也可以从某个人的公共仓库（包括自己是私人仓库）拉取，形如docker pull username/repository\u0026lt;:tag_name\u0026gt; ：\n1 # docker pull seanlook/centos:centos6 如果你没有网络，或者从其他私服获取镜像，形如docker pull registry.domain.com:5000/repos:\u0026lt;tag_name\u0026gt;\n1 # docker pull dl.dockerpool.com:5000/mongo:latest 4. 推送一个image或repository到registry（push） 与上面的pull对应，可以推送到Docker Hub的Public、Private以及私服，但不能推送到Top Level Repository。\n1 2 # docker push seanlook/mongo # docker push registry.tp-link.net:5000/mongo:2014-10-27 registry.tp-link.net也可以写成IP，172.29.88.222。 在repository不存在的情况下，命令行下push上去的会为我们创建为私有库，然而通过浏览器创建的默认为公共库。\n5. 从image启动一个container（run） docker run命令首先会从特定的image创之上create一层可写的container，然后通过start命令来启动它。停止的container可以重新启动并保留原来的修改。run命令启动参数有很多，以下是一些常规使用说明，更多部分请参考http://www.cnphp6.com/archives/24899 当利用 docker run 来创建容器时，Docker 在后台运行的标准操作包括：\n检查本地是否存在指定的镜像，不存在就从公有仓库下载 利用镜像创建并启动一个容器 分配一个文件系统，并在只读的镜像层外面挂载一层可读写层 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去 从地址池配置一个 ip 地址给容器 执行用户指定的应用程序 执行完毕后容器被终止 Usage: docker run [OPTIONS] IMAGE [COMMAND] [ARG...]\n5.1 使用image创建container并执行相应命令，然后停止 1 2 # docker run ubuntu echo \u0026#34;hello world\u0026#34; hello word 这是最简单的方式，跟在本地直接执行echo 'hello world' 几乎感觉不出任何区别，而实际上它会从本地ubuntu:latest镜像启动到一个容器，并执行打印命令后退出（docker ps -l可查看）。需要注意的是，默认有一个--rm=true参数，即完成操作后停止容器并从文件系统移除。因为Docker的容器实在太轻量级了，很多时候用户都是随时删除和新创建容器。 容器启动后会自动随机生成一个CONTAINER ID，这个ID在后面commit命令后可以变为IMAGE ID\n使用image创建container并进入交互模式, login shell是/bin/bash 1 2 # docker run -i -t --name mytest centos:centos6 /bin/bash bash-4.1# 上面的--name参数可以指定启动后的容器名字，如果不指定则docker会帮我们取一个名字。镜像centos:centos6也可以用IMAGE ID (68edf809afe7) 代替），并且会启动一个伪终端，但通过ps或top命令我们却只能看到一两个进程，因为容器的核心是所执行的应用程序，所需要的资源都是应用程序运行所必需的，除此之外，并没有其它的资源，可见Docker对资源的利用率极高。此时使用exit或Ctrl+D退出后，这个容器也就消失了（消失后的容器并没有完全删除？） （那么多个TAG不同而IMAGE ID相同的的镜像究竟会运行以哪一个TAG启动呢\n5.2 运行出一个container放到后台运行 1 2 # docker run -d ubuntu /bin/sh -c \u0026#34;while true; do echo hello world; sleep 2; done\u0026#34; ae60c4b642058fefcc61ada85a610914bed9f5df0e2aa147100eab85cea785dc 它将直接把启动的container挂起放在后台运行（这才叫saas），并且会输出一个CONTAINER ID，通过docker ps可以看到这个容器的信息，可在container外面查看它的输出docker logs ae60c4b64205，也可以通过docker attach ae60c4b64205连接到这个正在运行的终端，此时在Ctrl+C退出container就消失了，按ctrl-p ctrl-q可以退出到宿主机，而保持container仍然在运行 另外，如果-d启动但后面的命令执行完就结束了，如/bin/bash、echo test，则container做完该做的时候依然会终止。而且-d不能与\u0026ndash;rm同时使用 可以通过这种方式来运行memcached、apache等。\n5.3 映射host到container的端口和目录 映射主机到容器的端口是很有用的，比如在container中运行memcached，端口为11211，运行容器的host可以连接container的 internel_ip:11211 访问，如果有从其他主机访问memcached需求那就可以通过-p选项，形如-p \u0026lt;host_port:contain_port\u0026gt;，存在以下几种写法：\n1 2 3 4 -p 11211:11211 这个即是默认情况下，绑定主机所有网卡（0.0.0.0）的11211端口到容器的11211端口上 -p 127.0.0.1:11211:11211 只绑定localhost这个接口的11211端口 -p 127.0.0.1::5000 -p 127.0.0.1:80:8080 目录映射其实是“绑定挂载”host的路径到container的目录，这对于内外传送文件比较方便，在搭建私服那一节，为了避免私服container停止以后保存的images不被删除，就要把提交的images保存到挂载的主机目录下。使用比较简单，-v \u0026lt;host_path:container_path\u0026gt;，绑定多个目录时再加-v。\n1 -v /tmp/docker:/tmp/docker 另外在两个container之间建立联系可用--link，详见高级部分或官方文档。 下面是一个例子：\n1 2 3 4 # docker run --name nginx_test \\ \u0026gt; -v /tmp/docker:/usr/share/nginx/html:ro \\ \u0026gt; -p 80:80 -d \\ \u0026gt; nginx:1.7.6 在主机的/tmp/docker下建立index.html，就可以通过http://localhost:80/或http://host-ip:80访问了。\n6. 将一个container固化为一个新的image（commit） 当我们在制作自己的镜像的时候，会在container中安装一些工具、修改配置，如果不做commit保存起来，那么container停止以后再启动，这些更改就消失了。 docker commit \u0026lt;container\u0026gt; [repo:tag] 后面的repo:tag可选 只能提交正在运行的container，即通过docker ps可以看见的容器，\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 查看刚运行过的容器 # docker ps -l CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES c9fdf26326c9 nginx:1 nginx -g.. 3 hours ago Exited (0).. nginx_test 启动一个已存在的容器（run是从image新建容器后再启动），以下也可以使用docker start nginx_test代替 [root@hostname docker]# docker start c9fdf26326c9 c9fdf26326c9 docker run -i -t --sig-proxy=false 21ffe545748baf /bin/bash nginx服务没有启动 # docker commit -m \u0026#34;some tools installed\u0026#34; fcbd0a5348ca seanlook/ubuntu:14.10_tutorial fe022762070b09866eaab47bc943ccb796e53f3f416abf3f2327481b446a9503 -a \u0026ldquo;seanlook7@gmail.com\u0026rdquo; 请注意，当你反复去commit一个容器的时候，每次都会得到一个新的IMAGE ID，假如后面的repository:tag没有变，通过docker images可以看到，之前提交的那份镜像的repository:tag就会变成\u0026lt;none\u0026gt;:\u0026lt;none\u0026gt;，所以尽量避免反复提交。 另外，观察以下几点\ncommit container只会pause住容器，这是为了保证容器文件系统的一致性，但不会stop。如果你要对这个容器继续做其他修改： 你可以重新提交得到新image2，删除次新的image1 也可以关闭容器用新image1启动，继续修改，提交image2后删除image1 当然这样会很痛苦，所以一般是采用Dockerfile来build得到最终image，参考[] 虽然产生了一个新的image，并且你可以看到大小有100MB，但从commit过程很快就可以知道实际上它并没有独立占用100MB的硬盘空间，而只是在旧镜像的基础上修改，它们共享大部分公共的“片”。 下文继续：\n参考 Official Command Line Reference\ndocker中文指南cli-widuu翻译\nDocker —— 从入门到实践\nDocker基础与高级\n1本文只记录docker命令在大部分情境下的使用，如果想了解每一个选项的细节，请参考官方文档，这里只作为自己以后的备忘记录下来。\n根据自己的理解，总的来说分为以下几种：\n容器生命周期管理 — docker [run|start|stop|restart|kill|rm|pause|unpause] 容器操作运维 — docker [ps|inspect|top|attach|events|logs|wait|export|port] 容器rootfs命令 — docker [commit|cp|diff] 镜像仓库 — docker [login|pull|push|search] 本地镜像管理 — docker [images|rmi|tag|build|history|save|import] 其他命令 — docker [info|version] 看一个变迁图 1. 列出机器上的镜像（images） 1 2 3 4 # docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE ubuntu 14.10 2185fd50e2ca 13 days ago 236.9 MB … 其中我们可以根据REPOSITORY来判断这个镜像是来自哪个服务器，如果没有 / 则表示官方镜像，类似于username/repos_name表示Github的个人公共库，类似于regsistory.example.com:5000/repos_name则表示的是私服。 IMAGE ID列其实是缩写，要显示完整则带上--no-trunc选项\n2. 在docker index中搜索image（search） Usage: docker search TERM 1 2 3 # docker search seanlo NAME DESCRIPTION STARS OFFICIAL AUTOMATED seanloook/centos6 sean\u0026#39;s docker repos 0 搜索的范围是官方镜像和所有个人公共镜像。NAME列的 / 后面是仓库的名字。\n3. 从docker registry server 中下拉image或repository（pull） Usage: docker pull [OPTIONS] NAME[:TAG]\n1 # docker pull centos 上面的命令需要注意，在docker v1.2版本以前，会下载官方镜像的centos仓库里的所有镜像，而从v.13开始官方文档里的说明变了：will pull the centos:latest image, its intermediate layers and any aliases of the same id，也就是只会下载tag为latest的镜像（以及同一images id的其他tag）。 也可以明确指定具体的镜像：\n1 # docker pull centos:centos6 当然也可以从某个人的公共仓库（包括自己是私人仓库）拉取，形如docker pull username/repository\u0026lt;:tag_name\u0026gt; ：\n1 # docker pull seanlook/centos:centos6 如果你没有网络，或者从其他私服获取镜像，形如docker pull registry.domain.com:5000/repos:\u0026lt;tag_name\u0026gt;\n1 # docker pull dl.dockerpool.com:5000/mongo:latest 4. 推送一个image或repository到registry（push） 与上面的pull对应，可以推送到Docker Hub的Public、Private以及私服，但不能推送到Top Level Repository。\n1 2 # docker push seanlook/mongo # docker push registry.tp-link.net:5000/mongo:2014-10-27 registry.tp-link.net也可以写成IP，172.29.88.222。 在repository不存在的情况下，命令行下push上去的会为我们创建为私有库，然而通过浏览器创建的默认为公共库。\n5. 从image启动一个container（run） docker run命令首先会从特定的image创之上create一层可写的container，然后通过start命令来启动它。停止的container可以重新启动并保留原来的修改。run命令启动参数有很多，以下是一些常规使用说明，更多部分请参考http://www.cnphp6.com/archives/24899 当利用 docker run 来创建容器时，Docker 在后台运行的标准操作包括：\n检查本地是否存在指定的镜像，不存在就从公有仓库下载 利用镜像创建并启动一个容器 分配一个文件系统，并在只读的镜像层外面挂载一层可读写层 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去 从地址池配置一个 ip 地址给容器 执行用户指定的应用程序 执行完毕后容器被终止 Usage: docker run [OPTIONS] IMAGE [COMMAND] [ARG...]\n5.1 使用image创建container并执行相应命令，然后停止 1 2 # docker run ubuntu echo \u0026#34;hello world\u0026#34; hello word 这是最简单的方式，跟在本地直接执行echo 'hello world' 几乎感觉不出任何区别，而实际上它会从本地ubuntu:latest镜像启动到一个容器，并执行打印命令后退出（docker ps -l可查看）。需要注意的是，默认有一个--rm=true参数，即完成操作后停止容器并从文件系统移除。因为Docker的容器实在太轻量级了，很多时候用户都是随时删除和新创建容器。 容器启动后会自动随机生成一个CONTAINER ID，这个ID在后面commit命令后可以变为IMAGE ID\n使用image创建container并进入交互模式, login shell是/bin/bash 1 2 # docker run -i -t --name mytest centos:centos6 /bin/bash bash-4.1# 上面的--name参数可以指定启动后的容器名字，如果不指定则docker会帮我们取一个名字。镜像centos:centos6也可以用IMAGE ID (68edf809afe7) 代替），并且会启动一个伪终端，但通过ps或top命令我们却只能看到一两个进程，因为容器的核心是所执行的应用程序，所需要的资源都是应用程序运行所必需的，除此之外，并没有其它的资源，可见Docker对资源的利用率极高。此时使用exit或Ctrl+D退出后，这个容器也就消失了（消失后的容器并没有完全删除？） （那么多个TAG不同而IMAGE ID相同的的镜像究竟会运行以哪一个TAG启动呢\n5.2 运行出一个container放到后台运行 1 2 # docker run -d ubuntu /bin/sh -c \u0026#34;while true; do echo hello world; sleep 2; done\u0026#34; ae60c4b642058fefcc61ada85a610914bed9f5df0e2aa147100eab85cea785dc 它将直接把启动的container挂起放在后台运行（这才叫saas），并且会输出一个CONTAINER ID，通过docker ps可以看到这个容器的信息，可在container外面查看它的输出docker logs ae60c4b64205，也可以通过docker attach ae60c4b64205连接到这个正在运行的终端，此时在Ctrl+C退出container就消失了，按ctrl-p ctrl-q可以退出到宿主机，而保持container仍然在运行 另外，如果-d启动但后面的命令执行完就结束了，如/bin/bash、echo test，则container做完该做的时候依然会终止。而且-d不能与\u0026ndash;rm同时使用 可以通过这种方式来运行memcached、apache等。\n5.3 映射host到container的端口和目录 映射主机到容器的端口是很有用的，比如在container中运行memcached，端口为11211，运行容器的host可以连接container的 internel_ip:11211 访问，如果有从其他主机访问memcached需求那就可以通过-p选项，形如-p \u0026lt;host_port:contain_port\u0026gt;，存在以下几种写法：\n1 2 3 4 -p 11211:11211 这个即是默认情况下，绑定主机所有网卡（0.0.0.0）的11211端口到容器的11211端口上 -p 127.0.0.1:11211:11211 只绑定localhost这个接口的11211端口 -p 127.0.0.1::5000 -p 127.0.0.1:80:8080 目录映射其实是“绑定挂载”host的路径到container的目录，这对于内外传送文件比较方便，在搭建私服那一节，为了避免私服container停止以后保存的images不被删除，就要把提交的images保存到挂载的主机目录下。使用比较简单，-v \u0026lt;host_path:container_path\u0026gt;，绑定多个目录时再加-v。\n1 -v /tmp/docker:/tmp/docker 另外在两个container之间建立联系可用--link，详见高级部分或官方文档。 下面是一个例子：\n1 2 3 4 # docker run --name nginx_test \\ \u0026gt; -v /tmp/docker:/usr/share/nginx/html:ro \\ \u0026gt; -p 80:80 -d \\ \u0026gt; nginx:1.7.6 在主机的/tmp/docker下建立index.html，就可以通过http://localhost:80/或http://host-ip:80访问了。\n6. 将一个container固化为一个新的image（commit） 当我们在制作自己的镜像的时候，会在container中安装一些工具、修改配置，如果不做commit保存起来，那么container停止以后再启动，这些更改就消失了。 docker commit \u0026lt;container\u0026gt; [repo:tag] 后面的repo:tag可选 只能提交正在运行的container，即通过docker ps可以看见的容器，\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 查看刚运行过的容器 # docker ps -l CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES c9fdf26326c9 nginx:1 nginx -g.. 3 hours ago Exited (0).. nginx_test 启动一个已存在的容器（run是从image新建容器后再启动），以下也可以使用docker start nginx_test代替 [root@hostname docker]# docker start c9fdf26326c9 c9fdf26326c9 docker run -i -t --sig-proxy=false 21ffe545748baf /bin/bash nginx服务没有启动 # docker commit -m \u0026#34;some tools installed\u0026#34; fcbd0a5348ca seanlook/ubuntu:14.10_tutorial fe022762070b09866eaab47bc943ccb796e53f3f416abf3f2327481b446a9503 -a \u0026ldquo;seanlook7@gmail.com\u0026rdquo; 请注意，当你反复去commit一个容器的时候，每次都会得到一个新的IMAGE ID，假如后面的repository:tag没有变，通过docker images可以看到，之前提交的那份镜像的repository:tag就会变成\u0026lt;none\u0026gt;:\u0026lt;none\u0026gt;，所以尽量避免反复提交。 另外，观察以下几点:\ncommit container只会pause住容器，这是为了保证容器文件系统的一致性，但不会stop。如果你要对这个容器继续做其他修改： 你可以重新提交得到新image2，删除次新的image1 也可以关闭容器用新image1启动，继续修改，提交image2后删除image1 当然这样会很痛苦，所以一般是采用Dockerfile来build得到最终image，参考[] 虽然产生了一个新的image，并且你可以看到大小有100MB，但从commit过程很快就可以知道实际上它并没有独立占用100MB的硬盘空间，而只是在旧镜像的基础上修改，它们共享大部分公共的“片”。 下文继续：\n参考 Official Command Line Reference\ndocker中文指南cli-widuu翻译\nDocker —— 从入门到实践\nDocker基础与高级\n","permalink":"http://localhost:1313/2014/10/docker-command-best-use-1/","summary":"\u003cp\u003e本文只记录docker命令在大部分情境下的使用，如果想了解每一个选项的细节，请参考官方文档，这里只作为自己以后的备忘记录下来。\u003c/p\u003e\n\u003cp\u003e根据自己的理解，总的来说分为以下几种：\n容器生命周期管理 — \u003ccode\u003edocker [run|start|stop|restart|kill|rm|pause|unpause]\u003c/code\u003e\n容器操作运维 — \u003ccode\u003edocker [ps|inspect|top|attach|events|logs|wait|export|port]\u003c/code\u003e\n容器rootfs命令 — \u003ccode\u003edocker [commit|cp|diff]\u003c/code\u003e\n镜像仓库 — \u003ccode\u003edocker [login|pull|push|search]\u003c/code\u003e\n本地镜像管理 — \u003ccode\u003edocker [images|rmi|tag|build|history|save|import]\u003c/code\u003e\n其他命令 — \u003ccode\u003edocker [info|version]\u003c/code\u003e\u003c/p\u003e","title":"docker常用管理命令（上）"},{"content":"该脚本改自csdn上的一个shell，忘记出处了，只记得它能够简单的通过service tomcat [stop|start|restart]来方便的管理Linux服务器上的tomcat，这可以满足大部分人的需求，然而并不适合我所管理的CentOS上的tomcat应用：通过端口区分的3台tomcat集群。如果每一次管理tomcat或查看日志，都cd /apps/test/tomcat0/log/然后切换到另外一个cd ../../或cd /apps/test/tomcat1/log/，麻烦至极。因此“懒人”创造了这个脚本tomcat：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 #!/bin/bash # author: Sean Chow (seanlook7@gmail.com) # # # chkconfig: 345 80 15 # description: Multiple tomcats service management script. # Source function library. . /etc/rc.d/init.d/functions # 第几个tomcat tcNo=$1 tcName=tomcat$1 basedir=/apps/test/$tcName tclog=${basedir}/logs/catalina.$(date +%Y-%m-%d).out RETVAL=0 start(){ checkrun if [ $RETVAL -eq 0 ]; then echo \u0026#34;-- Starting tomcat...\u0026#34; $basedir/bin/startup.sh touch /var/lock/subsys/${tcNo} checklog status else echo \u0026#34;-- tomcat already running\u0026#34; fi } # 停止某一台tomcat，如果是重启则带re参数，表示不查看日志，等待启动时再提示查看 stop(){ checkrun if [ $RETVAL -eq 1 ]; then echo \u0026#34;-- Shutting down tomcat...\u0026#34; $basedir/bin/shutdown.sh if [ \u0026#34;$1\u0026#34; != \u0026#34;re\u0026#34; ]; then checklog else sleep 5 fi rm -f /var/lock/subsys/${tcNo} status else echo \u0026#34;-- tomcat not running\u0026#34; fi } status(){ checkrun if [ $RETVAL -eq 1 ]; then echo -n \u0026#34;-- Tomcat ( pid \u0026#34; ps ax --width=1000 |grep ${tcName}|grep \u0026#34;org.apache.catalina.startup.Bootstrap start\u0026#34; | awk \u0026#39;{printf $1 \u0026#34; \u0026#34;}\u0026#39; echo -n \u0026#34;) is running...\u0026#34; echo else echo \u0026#34;-- Tomcat is stopped\u0026#34; fi #echo \u0026#34;---------------------------------------------\u0026#34; } # 查看tomcat日志，带vl参数 log(){ status checklog yes } # 如果tomcat正在运行，强行杀死tomcat进程，关闭tomcat kill(){ checkrun if [ $RETVAL -eq 1 ]; then read -p \u0026#34;-- Do you really want to kill ${tcName} progress?[no])\u0026#34; answer case $answer in Y|y|YES|yes|Yes) ps ax --width=1000 |grep ${tcName}|grep \u0026#34;org.apache.catalina.startup.Bootstrap start\u0026#34; | awk \u0026#39;{printf $1 \u0026#34; \u0026#34;}\u0026#39;|xargs kill -9 status ;; *);; esac else echo \u0026#34;-- exit with $tcName still running...\u0026#34; fi } checkrun(){ ps ax --width=1000 |grep ${tcName}| grep \u0026#34;[o]rg.apache.catalina.startup.Bootstrap start\u0026#34; | awk \u0026#39;{printf $1 \u0026#34; \u0026#34;}\u0026#39; | wc | awk \u0026#39;{print $2}\u0026#39; \u0026gt;/tmp/tomcat_process_count.txt read line \u0026lt; /tmp/tomcat_process_count.txt if [ $line -gt 0 ]; then RETVAL=1 return $RETVAL else RETVAL=0 return $RETVAL fi } # 如果是直接查看日志viewlog，则不提示输入[yes]，否则就是被stop和start调用，需提示是否查看日志 checklog(){ answer=$1 if [ \u0026#34;$answer\u0026#34; != \u0026#34;yes\u0026#34; ]; then read -p \u0026#34;-- See Catalina.out log to check $2 status?[yes])\u0026#34; answer fi case $answer in Y|y|YES|yes|Yes|\u0026#34;\u0026#34;) tail -f ${tclog} ;; *) # status # exit 0 ;; esac } checkexist(){ if [ ! -d $basedir ]; then echo \u0026#34;-- tomcat $basedir does not exist.\u0026#34; exit 0 fi } case \u0026#34;$2\u0026#34; in start) checkexist start exit 0 ;; stop) checkexist stop exit 0 ;; restart) checkexist stop re start exit 0 ;; status) checkexist status #$basedir/bin/catalina.sh version exit 0 ;; log) checkexist log exit 0 ;; kill) checkexist status kill exit 0 ;; *) echo \u0026#34;Usage: $0 {start|stop|restart|status|log|kill}\u0026#34; echo \u0026#34; service tomcat {0|1|..} {start|stop|restart|status|log|kill}\u0026#34; esac exit 0 使用说明：\n使用前设定好baseDir（多tomcat所在路径），各tomcat命名如tomcat0、tomcat1\u0026hellip; 脚本名字为tomcat，放到/etc/init.d/下，并基于可执行权限chmod +x /etc/init.d/tomcat 执行用户不允许用root，特别是在线上环境 已处理其他错误参数输入，可用于正式环境 你也可以修改tcName来适应管理一个tomcat服务的情形 使用，以下针对tomcat0（/apps/test/tomcat0） 1 2 3 4 5 6 service tomcat 0 start 启动，默认回车会查看启动日志；已启动则仅输出进程号 service tomcat 0 stop 停止，默认回车会查看日志；已停止则无动作；无法停止，则提示是否`kill`（默认No） service tomcat 0 restart 重启tomcat，有日志输出 service tomcat 0 status 查看tomcat是否启动 service tomcat 0 log 使用`tail -f`命令实时查看日志 service tomcat 0 kill 直接`kill`tomcat进程；尽量少用 TO-DO 加入service tomcat 0 clean命令来清除work和tmp目录，正在运行的不允许清除。\n这个脚本最近（2014/11/13）在使用过程中发现一个新的问题，因为服务器上tomcat一直开启着监控端口7091，所以在service tomcat 1 start失败以后，7091端口就被占用了，但使用service tomcat 1 status状态时stopped，其实还是有这个失败的tomcat进程，但用service tomcat 1 kill会失败。脚本里在考虑这个功能的话就有点臃肿了，还是老实结合手动管理吧。\n","permalink":"http://localhost:1313/2014/10/multiple-tomcats-service-script/","summary":"\u003cp\u003e该脚本改自csdn上的一个shell，忘记出处了，只记得它能够简单的通过\u003ccode\u003eservice tomcat [stop|start|restart]\u003c/code\u003e来方便的管理Linux服务器上的tomcat，这可以满足大部分人的需求，然而并不适合我所管理的CentOS上的tomcat应用：通过端口区分的3台tomcat集群。如果每一次管理tomcat或查看日志，都\u003ccode\u003ecd /apps/test/tomcat0/log/\u003c/code\u003e然后切换到另外一个\u003ccode\u003ecd ../../\u003c/code\u003e或\u003ccode\u003ecd /apps/test/tomcat1/log/\u003c/code\u003e，麻烦至极。因此“懒人”创造了这个脚本\u003ccode\u003etomcat\u003c/code\u003e：\u003c/p\u003e","title":"管理多tomcat服务shell脚本（CentOS）"},{"content":"注意本文不讨论原理，只讲述具体的搭建过程，而且步骤都经过了整理，否则过程可能会出现其他异常，请自行google。apache与tomcat整合的方式除了jk之外，使用apache自带的mod_ajp_proxy模块也可以很方便的完成。 先来看一下架构图： 属于正式环境中原session复制方案的改进。\n1. 所需软件包 1 2 3 4 5 6 7 8 9 10 11 12 13 jrrt-3.1.2-1.6.0-linux-x64.bin（或jdk1.6.0_33） jvm httpd-2.2.26.tar.gz web服务器，处理静态资源 apache-tomcat-6.0.32.tar.gz 应用服务器，Servlet容器处理动态请求 tomcat-connectors-1.2.30-src.tar.gz apache与tomcat整合插件mod_jk.so tomcat-native.tar.gz APR加速tomcat，提高线程并发能力。使用tomcat自带版本。 memcached-session-manager 使用msm解决多tomcat集群时session同步问题所需jar包 asm-3.2.jar, couchbase-client-1.2.2.jar, kryo-1.04.jar, kryo-serializers-0.11.jar msm-kryo-serializer-1.6.5.jar memcached-session-manager-1.6.5.jar memcached-session-manager-tc6-1.6.5.jar minlog-1.2.jar, reflectasm-1.01.jar spymemcached-2.10.2.jar 2. 安装过程 2.1 JDK 下载将JRockit二进制安装文件，赋予可执行权限\n1 2 3 4 # pwd /apps/test/java # chmod o+x jrrt*.bin # ./jrrt-3.1.2-1.6.0-linux-x64.bin 可不必为整个linux环境设置JAVA_HOME=\u0026quot;/apps/test/java/jrrt-3.1.2-1.6.0\u0026quot;，在tomcat中指定即可。\n2.2 编译安装apache 因为tomcat-native依赖于apr，所以这里先直接从 httpd-2.2.26/srclib 目录下安装apache自带的apr和apr-util。\n1 2 3 4 5 6 7 8 [root@cachets httpd-2.2.26]# pwd /apps/test/soft_src/httpd-2.2.26 [root@test httpd-2.2.26]# cd srclib/apr [root@test apr]# ./configure --prefix=/usr/local/apr [root@test apr]# make \u0026amp;\u0026amp; make install [root@test apr]# cd ../apr-util/ [root@test apr-util]# ./configure --prefix=/usr/local/apr-util --with-apr=/usr/local/apr [root@test apr-util]# make \u0026amp;\u0026amp; make install 建议将srclib下的pcre也装上，主要是考虑后面转发请求时可能要使用地址rewrite，需要正则语法的支持。默认CentOS6.x已经安装了这个库。\n安装apache：\n1 2 [root@test httpd-2.2.26]# ./configure --prefix=/apps/test/apache2 --enable-mods-shared=all --enable-modules=so --enable-rewrite --enable-deflate --with-mpm=worker --with-apr=/usr/local/apr --with-apr-util=/usr/local/apr-util [root@test httpd-2.2.26]# make \u0026amp;\u0026amp; make install 2.3 安装tomcat 解压apache-tomcat-6.0.32.tar.gz拷贝至/app/test/tomcat0，不建议使用root用户管理tomcat.\n1 2 3 4 5 6 7 8 9 10 [test@cachets soft_src]$ tar -zxvf apache-tomcat-6.0.32.tar.gz [test@cachets soft_src]$ cp -a apache-tomcat-6.0.32 /app/crm/tomcat0 // 安装tomcat-native（不用单独下载，在tomcat的bin目录中自带） # yum install -y openssl-devel apr-devel [root@cachets ~]# cd /app/test/soft_src/apache-tomcat-6.0.32/bin [root@cachets bin]# tar -zxvf tomcat-native.tar.gz [root@cachets bin]# cd tomcat-native-1.1.20-src/jni/native/ [root@cachets native]# ./configure --with-apr=/usr/local/apr/bin/apr-1-config --with-ssl --with-java-home=/apps/test/java/jrrt-3.1.2-1.6.0 [root@cachets native]# make \u0026amp;\u0026amp; make install 配置tomcat：\ntomcat默认参数是为开发环境制定，而非适合生产环境，尤其是内存和线程的配置，默认都很低，容易成为性能瓶颈。下面是一些配置示例，需要根据实际需要更改。\n1 2 3 4 5 6 [crm@cachets tomcat0]$ vi bin/setenv.sh JAVA_OPTS=\u0026#34;-XX:PermSize=128M -XX:MaxPermSize=256M -Xms1536M -Xmx2048M -verbosegc \u0026#34; CATALINA_OPTS=\u0026#34;-Dcom.sun.management.jmxremote.port=7091 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Djava.rmi.server.hostname=192.168.10.100\u0026#34; JAVA_HOME=\u0026#34;/apps/test/java/jrrt-3.1.2-1.6.0\u0026#34; CATALINA_OPTS=\u0026#34;$CATALINA_OPTS -Djava.library.path=/usr/local/apr/lib\u0026#34; [crm@cachets tomcat0]$ chmod 755 bin/setenv.sh bin目录下新建的可执行文件setenv.sh会由tomcat自动调用。上面的jmxremote.authenticate在正式环境中请务必设为true并设置用户名/密码，减少安全隐患，或者注释掉CATALINA_OPTS。（有时候出于性能调优的目的，才需要设置JMX）。对于具体的连接协议有不同的优化属性，参考如下： 对HTTP：\n\u0026lt;Connector port=\u0026quot;8080\u0026quot; protocol=\u0026quot;org.apache.coyote.http11.Http11NioProtocol\u0026quot; URIEncoding=\u0026quot;UTF-8\u0026quot; enableLookups=\u0026quot;false\u0026quot; maxThreads=\u0026quot;400\u0026quot; minSpareTheads=\u0026quot;50\u0026quot; acceptCount=\u0026quot;400\u0026quot; acceptorThreadCount=\u0026quot;2\u0026quot; connectionTimeout=\u0026quot;30000\u0026quot; disableUploadTimeout=\u0026quot;true\u0026quot; compression=\u0026quot;on\u0026quot; compressionMinSize=\u0026quot;2048\u0026quot; maxHttpHeaderSize=\u0026quot;16384\u0026quot; redirectPort=\u0026quot;8443\u0026quot; /\u0026gt; 对AJP：\n\u0026lt;Connector port=\u0026quot;8009\u0026quot; protocol=\u0026quot;AJP/1.3\u0026quot; maxThreads=\u0026quot;300\u0026quot; minSpareThreads=\u0026quot;50\u0026quot; connectionTimeout=\u0026quot;30000\u0026quot; keepAliveTimeout=\u0026quot;30000\u0026quot; acceptCount=\u0026quot;200\u0026quot; URIEncoding=\u0026quot;UTF-8\u0026quot; enableLookups=\u0026quot;false\u0026quot; redirectPort=\u0026quot;8443\u0026quot; /\u0026gt; 2.4 安装jk 1 2 3 4 [crm@test soft_src]$ tar -zxvf tomcat-connectors-1.2.30-src.tar.gz [crm@test soft_src]$ cd tomcat-connectors-1.2.30-src/native [root@test native]# ./configure --with-apxs=/apps/test/apache2/bin/apxs [root@test native]# make \u0026amp;\u0026amp; make install 此时可以看到在/apps/test/apache2/modules下有mod_jk.so文件，用于连接apache与tomcat。\n2.5 配置（集群）负载均衡选项 2.5.1 apache 建立配置文件httpd-jk.conf：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 [root@cachets ~]# cd /app/test/ [root@cachets crm]# vi apache2/conf/extra/httpd-jk.conf # Load mod_jk module LoadModule jk_module modules/mod_jk.so # 指定保存了worker相关工作属性定义的配置文件 JkWorkersFile conf/extra/workers.properties # Specify jk log file JkLogFile /app/test/apache2/logs/mod_jk.log # Specify jk log level [debug/error/info] JkLogLevel info #指定哪些请求交给tomcat处理,\u0026#34;controller\u0026#34;为在workers.properties里指定的负载分配控制器名 JkMount /servlet/* controller JkMount /*.jsp controller JkMount /*.do controller // 在conf/httpd.conf最后加上 Include conf/extra/httpd-vhosts.conf Include conf/extra/httpd-jk.conf 建立工作文件workers.properties：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 [root@cachets crm]# vi apache2/conf/extra/workers.properties # servers worker.list=controller # ====== tomcat0 ======= worker.tomcat0.port=8009 worker.tomcat0.host=192.168.10.100 worker.tomcat0.type=ajp13 worker.tomcat0.lbfactor=1 # ====== tomcat1 ======= worker.tomcat1.port=8109 worker.tomcat1.host=192.168.10.100 worker.tomcat1.type=ajp13 worker.tomcat1.lbfactor=1 # ====== tomcat2 ======= worker.tomcat2.port=8209 worker.tomcat2.host=192.168.10.100 worker.tomcat2.type=ajp13 worker.tomcat2.lbfactor=1 # ====== controller ==== worker.controller.type=lb worker.controller.balance_workers=tomcat0,tomcat1,tomcat2 worker.controller.sticky_session = 1 以上是3个tomcat的做负载均衡的情况，负载因子lbfactor都为1，session为sticky模式，apache与tomcat连接的协议采用AJP/1.3，同一台服务器上通过端口来区分tomcat0/tomcat1/tomcat2。\n2.5.2 tomcat 在tomcat0/conf/server.xml中加入jvmRoute属性，这个属性与上面的workers.properties的worker相同：\n1 \u0026lt;Engine name=\u0026#34;Catalina\u0026#34; defaultHost=\u0026#34;localhost\u0026#34; jvmRoute=\u0026#34;tomcat0\u0026#34;\u0026gt; 设置测试应用的访问路径，在tomcat0/conf/server.xml的\u0026lt;Host\u0026gt;节点下添加如下：\n1 \u0026lt;Context path=\u0026#34;\u0026#34; docBase=\u0026#34;/apps/test/testapp/TEST\u0026#34; reloadable=\u0026#34;true\u0026#34; /\u0026gt; 2.5.3 app-TEST 为了看到负载均衡的效果，在/apps/test/testapp/TEST目录下建立测试页面test.jsp：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 \u0026lt;%@ page contentType=\u0026#34;text/html; charset=UTF-8\u0026#34; %\u0026gt; \u0026lt;%@ page import=\u0026#34;java.util.*\u0026#34; %\u0026gt; \u0026lt;html\u0026gt;\u0026lt;head\u0026gt;\u0026lt;title\u0026gt;Cluster App Test\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; Server Info: \u0026lt;% out.println(request.getLocalAddr() + \u0026#34; : \u0026#34; + request.getLocalPort()+\u0026#34;\u0026lt;br\u0026gt;\u0026#34;);%\u0026gt; \u0026lt;% out.println(\u0026#34;\u0026lt;br\u0026gt; ID \u0026#34; + session.getId()+\u0026#34;\u0026lt;br\u0026gt;\u0026#34;); // 如果有新的 Session 属性设置 String dataName = request.getParameter(\u0026#34;dataName\u0026#34;); if (dataName != null \u0026amp;\u0026amp; dataName.length() \u0026gt; 0) { String dataValue = request.getParameter(\u0026#34;dataValue\u0026#34;); session.setAttribute(dataName, dataValue); } out.println(\u0026#34;\u0026lt;b\u0026gt;Session 列表\u0026lt;/b\u0026gt;\u0026lt;br\u0026gt;\u0026#34;); System.out.println(\u0026#34;============================\u0026#34;); Enumeration e = session.getAttributeNames(); while (e.hasMoreElements()) { String name = (String)e.nextElement(); String value = session.getAttribute(name).toString(); out.println( name + \u0026#34; = \u0026#34; + value+\u0026#34;\u0026lt;br\u0026gt;\u0026#34;); System.out.println( name + \u0026#34; = \u0026#34; + value); } %\u0026gt; \u0026lt;form action=\u0026#34;test.jsp\u0026#34; method=\u0026#34;POST\u0026#34;\u0026gt; CRM \u0026lt;br\u0026gt; 名称:\u0026lt;input type=text size=20 name=\u0026#34;dataName\u0026#34;\u0026gt; \u0026lt;br\u0026gt; 值:\u0026lt;input type=text size=20 name=\u0026#34;dataValue\u0026#34;\u0026gt; \u0026lt;br\u0026gt; \u0026lt;input type=submit\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 到这里还差一步就可以看到集群的效果，那就是3个tomcat之间session同步的问题。可以通过打开\u0026lt;Engine\u0026gt;节点下的\u0026lt;Cluster\u0026gt;标签的注释来简单的实现session复制：\n\u0026lt;Cluster className=\u0026quot;org.apache.catalina.ha.tcp.SimpleTcpCluster\u0026quot;/\u0026gt; 然后在tomcat0/conf/web.xml的\u0026lt;webapp\u0026gt;根节点下加入\u0026lt;distributable /\u0026gt;\n复制tomcat0到tomcat1、tomcat2，修改 的端口避免冲突，修改对应的jvmRoute\n启动apache和3个tomcat，就可以看到效果。但这里我们使用memcached-session-manager来同步session，所以不必打开\u0026lt;Cluster\u0026gt;这一步。\n2.6 memcached-session-manager配置 2.6.1 安装memcached服务器 这里memcached搭建在另外一台服务器上（192.168.10.20），也可以安装在本地。\n1 2 3 4 5 6 7 [root@cachets msm]# yum install libevent libevent-devel [root@cachets msm]# tar -zxvf memcached-1.4.19.tar.gz [root@cachets msm]# cd memcached-1.4.19 \u0026amp;\u0026amp; ./configure \u0026amp;\u0026amp; make \u0026amp;\u0026amp; make install // 启动两个memcached节点，端口分别为11211、11212 [root@cachets ~]#memcached -d -m 64 -p 11211 -u daemon -P /var/run/memcached.pid [root@cachets ~]#memcached -d -m 64 -p 11212 -u daemon -P /var/run/memcached2.pid 如果开启了防火墙，需要加入11211、11212端口的允许规则。\n2.6.2 再次配置tomcat 加入jar包\n将asm-3.2.jar, couchbase-client-1.2.2.jar, kryo-1.04.jar, kryo-serializers-0.11.jar, msm-kryo-serializer-1.6.5.jar, memcached-session-manager-1.6.5.jar, memcached-session-manager-tc6-1.6.5.jar, minlog-1.2.jar, reflectasm-1.01.jar, spymemcached-2.10.2.jar这些jar包加入tomcat0/lib/下。可以看到这里选用的session序列化策略采用的是kryo。另外要注意版本之间的兼容性，这里只针对tomcat6.x。 修改conf/server.xml：\n将节点修改成：\n\u0026lt;Context path=\u0026quot;\u0026quot; docBase=\u0026quot;/apps/test/testapp/TEST\u0026quot; reloadable=\u0026quot;true\u0026quot; \u0026gt; \u0026lt;Manager className=\u0026quot;de.javakaffee.web.msm.MemcachedBackupSessionManager\u0026quot; memcachedNodes=\u0026quot;n1:192.168.10.20:11211,n2:192.168.10.20:11212\u0026quot; failoverNodes=\u0026quot;n1\u0026quot; sticky=\u0026quot;true\u0026quot; requestUriIgnorePattern=\u0026quot;.*\\.(png|gif|jpg|css|js)$\u0026quot; sessionBackupAsync=\u0026quot;false\u0026quot; sessionBackupTimeout=\u0026quot;100\u0026quot; transcoderFactoryClass=\u0026quot;de.javakaffee.web.msm.serializer.kryo.KryoTranscoderFactory\u0026quot; copyCollectionsForSerialization=\u0026quot;false\u0026quot; /\u0026gt; \u0026lt;/Context\u0026gt; 接着将tomcat0完整的复制2份（tomcat1，tomcat2），也可以放到另外一台服务器上。 修改为workers.properties中定义的AJP等端口：\n|node tomcat |Server port |Connector port http |Connector port ajp |Engine jvmRoute |memcached failoverNodes| |\u0026mdash;\u0026mdash;\u0026mdash;-|\u0026mdash;\u0026mdash;-|\u0026mdash;\u0026mdash;-|\u0026mdash;\u0026mdash;-|\u0026mdash; \u0026mdash;\u0026mdash;-|\u0026ndash;| |tomcat0 |8005 |8080 |8009 |tomcat0 |n1| |tomcat1 |8105 |8081 |8109 |tomcat1 |n1| |tomcat2 |8205 |8082 |8209 |tomcat2 |n2|\n3. 测试 分别启动tomcat0、tomcat1、tomcat2和apache，注意观察tomcat的启动日志和memcached服务器的日志。\n1 2 3 4 [test@cachets ~]$ /apps/test/tomcat0/bin/startup.sh [test@cachets ~]$ /apps/test/tomcat1/bin/startup.sh [test@cachets ~]$ /apps/test/tomcat2/bin/startup.sh [root@cachets ~]# /apps/test/apache2/bin/apachectl start 在浏览器访问http://192.168.10.100/test.jsp。主要测试负载均衡与session共享。\n参考\nhttps://people.apache.org/~mturk/docs/article/ftwai.html 原文链接地址：http://xgknight.com/2015/04/23/pfsense-usage/\n","permalink":"http://localhost:1313/2014/10/apache-3tomcat-cluster-jk-memcached/","summary":"\u003cp\u003e注意本文不讨论原理，只讲述具体的搭建过程，而且步骤都经过了整理，否则过程可能会出现其他异常，请自行google。apache与tomcat整合的方式除了jk之外，使用apache自带的mod_ajp_proxy模块也可以很方便的完成。\n先来看一下架构图：\n\u003cimg alt=\"apache_tomcat_cluster_msm\" loading=\"lazy\" src=\"http://github.com/seanlook/sean-notes-comment/raw/main/static/apache_tomcat_cluster_msm.png\"\u003e\n属于正式环境中原session复制方案的改进。\u003c/p\u003e","title":"apache+3tomcat+jk+memcached集群环境搭建"},{"content":"1. 错误描述 在vSphere上，一次重启虚拟服务器时出现启动不了，提示找不到vmdk虚拟磁盘文件： 2. 原因分析 查看这台虚拟服务器的摘要信息，对比datastore上其他可用的虚拟机，发现损坏的服务器上确实缺少一个vmdk磁盘文件，但是可以看见一个50G的xxx-flat.vmdk文件；而正常的服务器只有xxx.vmdk，没有xxx-flat.vmdk，关机之后两个文件都存在，而且真实的磁盘容量从vmdk转移到了xxx-flat.vmdk。 虚拟主机在运行的时候，实际在使用的是xxx-flat.vmdk，然而xxx.vmdk是可以同时被删除的，才导致了问题。\n这里需要说明，虚拟机的每个磁盘驱动器都包含了一对.vmdk文件。一个是文本文件，包含了关于虚拟硬盘的描述数据；另外一个是磁盘的实际内容。例如，一个名为examplevm的虚拟机连接有一个硬盘。这个磁盘由如下两个文件构成：一个小于 1KB 的examplevm.vmdk描述文件和一个10GB大小的examplevm- flat.vmdk平面（数据）文件，该文件包含虚拟机的实际数据，而这些数据又是以二进制的形式存放在物理磁盘上，examplevm.vmdk描述文件就是描述这种映射关系的。 另外：\nA note for ESX-users: Do not use Datastorebrowser to identify vmdks or download them for editiing. The Datastorebrowser does not display vmdks correctly. It usually hides *-flat.vmdks and *-delta.vmdks.\nTO-DO: 后续为 VMware ESXi 5 的磁盘专门记录一篇文章，说明“置备空间”以及vmfstools工具的使用。\n3. 解决办法 (1) 用ssh登录vsphere主机，查找xxx-flat.vmdk文件所在的位置以及目录，并记录文件的大小\n1 2 3 4 ~ # find / -name \u0026#34;新建虚拟机-flat.vmdk\u0026#34; /vmfs/volumes/50a98441-ab02c8b7-e60a-001517712dce/新建虚拟机/新建虚拟机-flat.vmdk ~ # ls -l /vmfs/volumes/50a98441-ab02c8b7-e60a-001517712dce/新建虚拟机/新建虚拟机-flat.vmdk -rw------- 1 root root 53687091200 Apr 16 09:13 /vmfs/volumes/50a98441-ab02c8b7-e60a-001517712dce/新建虚拟机/新建虚拟机-flat.vmdk 注意，ESXi5默认没有开启ssh，需要通过vsphere client登录服务器，【配置】【安全配置文件】【服务-属性】手动开启。\n(2) 重命名xxx-flat.vmdk文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ~ # cd /vmfs/volumes/50a98441-ab02c8b7-e60a-001517712dce/新建虚拟机/ /vmfs/volumes/50a98441-ab02c8b7-e60a-001517712dce/新建虚拟机_1 # mv 新建虚拟机-flat.vmdk tmp_新建虚拟机-flat.vmdk /vmfs/volumes/50a98441-ab02c8b7-e60a-001517712dce/新建虚拟机 # ls -la drwxr-xr-x 1 root root 1680 Apr 21 05:47 . drwxr-xr-t 1 root root 2660 Apr 18 03:16 .. -rw-r--r-- 1 root root 102076 Apr 18 10:05 vmware.log -rw------- 1 root root 96468992 Apr 18 05:43 vmx-新建虚拟机-578288005-1.vswp -rw------- 1 root root 2147483648 Apr 18 05:43 新建虚拟机-2277f985.vswp -rw------- 1 root root 53687091200 Apr 21 05:47 新建虚拟机-flat.vmdk -rw------- 1 root root 8684 Apr 21 05:47 新建虚拟机.nvram -rw------- 1 root root 503 Apr 18 05:44 新建虚拟机.vmdk -rw-r--r-- 1 root root 0 Apr 16 09:13 新建虚拟机.vmsd -rwxr-xr-- 1 root root 3690 Apr 18 05:43 新建虚拟机.vmx -rw------- 1 root root 0 Apr 18 05:43 新建虚拟机.vmx.lck -rwxr-xr-- 1 root root 3690 Apr 18 05:43 新建虚拟机.vmx~ (3) 在虚拟机目录下创建xxx.vmdk文件，大小要和xxx-flat.vmdk一样大\n1 2 3 4 5 /vmfs/volumes/50a98441-ab02c8b7-e60a-001517712dce/新建虚拟机 # vmkfstools -c 53687091200 -a lsilogic 新建虚拟机.vmdk Create: 100% done. /vmfs/volumes/50a98441-ab02c8b7-e60a-001517712dce/新建虚拟机 # ls -la *vmdk -rw------- 1 root root 53687091200 Apr 21 05:49 新建虚拟机-flat.vmdk -rw------- 1 root root 503 Apr 18 05:44 新建虚拟机.vmdk (4) 将原来的(tmp_)xxx-flat.vmdk覆盖掉刚创建的同样大小的xxx-flat.vmdk\n1 /vmfs/volumes/50a98441-ab02c8b7-e60a-001517712dce/新建虚拟机 # mv tmp_新建虚拟机-flat.vmdk 新建虚拟机-flat.vmdk 重命名操作很快完成，启动虚拟机既可以恢复。\n5. 总结 相比重新创建一个同名虚拟机，然后mv原来的xxx-flat.vmdk硬盘文件到新的虚拟机，更节省时间；此外也无需再次配置网卡地址。 xxx.vmdk本身是一个不到1k的文本文件，通过vi编辑查看可知真正存放数据的是xxx-flat.vmdk磁盘文件，所以只要这个文件还存在，就可以恢复。 5. 参考 重建丢失的虚拟机磁盘(VMDK)描述文件(2030127) （英文）\nRecreating A Missing VMDK Descriptor File\nVirtual Machine files and settings explained ","permalink":"http://localhost:1313/2014/10/vsphere-recover-from-missing-vmdk/","summary":"\u003ch2 id=\"1-错误描述\"\u003e1. 错误描述\u003c/h2\u003e\n\u003cp\u003e在vSphere上，一次重启虚拟服务器时出现启动不了，提示找不到vmdk虚拟磁盘文件：\n\u003cimg alt=\"vmdk_not_found\" loading=\"lazy\" src=\"http://github.com/seanlook/sean-notes-comment/raw/main/static/vmdk_not_found.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"2-原因分析\"\u003e2. 原因分析\u003c/h2\u003e\n\u003cp\u003e查看这台虚拟服务器的摘要信息，对比datastore上其他可用的虚拟机，发现损坏的服务器上确实缺少一个vmdk磁盘文件，但是可以看见一个50G的\u003ccode\u003exxx-flat.vmdk\u003c/code\u003e文件；而正常的服务器只有\u003ccode\u003exxx.vmdk\u003c/code\u003e，没有\u003ccode\u003exxx-flat.vmdk\u003c/code\u003e，关机之后两个文件都存在，而且真实的磁盘容量从vmdk转移到了\u003ccode\u003exxx-flat.vmdk\u003c/code\u003e。\n虚拟主机在运行的时候，实际在使用的是\u003ccode\u003exxx-flat.vmdk\u003c/code\u003e，然而\u003ccode\u003exxx.vmdk\u003c/code\u003e是可以同时被删除的，才导致了问题。\u003c/p\u003e","title":"误删vSphere虚拟机.vmdk文件的恢复"},{"content":"docker是什么就不多说了，见docker基础原理介绍。 docker容器最早受到RHEL完善的支持是从最近的CentOS 7.0开始的，官方说明是只能运行于64位架构平台，内核版本为2.6.32-431及以上（即\u0026gt;=CentOS 6.5，运行docker时实际提示3.8.0及以上），升级内核请参考CentOS 6.x 内核升级（2.6.32 -\u0026gt; 3.10.58）过程记录 需要注意的是CentOS 6.5与7.0的安装是有一点点不同的，CentOS-6上docker的安装包叫docker-io，并且来源于Fedora epel库，这个仓库维护了大量的没有包含在发行版中的软件，所以先要安装EPEL，而CentOS-7的docker直接包含在官方镜像源的Extras仓库（CentOS-Base.repo下的[extras]节enable=1启用）。前提是都需要联网，具体安装过程如下。 ###1. 禁用selinux###\n1 2 3 4 5 6 7 # getenforce enforcing # setenforce 0 permissive # vi /etc/selinux/config SELINUX=disabled ... ###2. 安装 Fedora EPEL### epel-release-6-8.noarch.rpm包在发行版的介质里面已经自带了，可以从rpm安装。\n1 2 3 # yum install epel-release-6-8.noarch.rpm //或 yum -y install http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm 如果出现GPG key retrieval failed: [Errno 14] Could not open/read file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-6问题，请在线安装epel，下载RPM-GPG-KEY-EPEL-6文件。 这一步执行之后，会在/etc/yum.repos.d/下生成epel.repo、epel-testing.repo两个文件，用于从Fedora官网下载rpm包。 ###3. 检查内核版本###\n1 2 3 4 # uname -r 2.6.32-431.el6.x86_64 # cat /etc/redhat-release CentOS release 6.5 (Final) 看到这个最低的内核版本，事实运行起来是没太大问题的，你也可以升级到3.10.x版本。 另外你也可以运行脚本check-config.sh，来检查内核模块符不符合（下面有些missing的，我的docker还是可以正常启动）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 [root@sean ~]# ./check-config warning: /proc/config.gz does not exist, searching other paths for kernel config... info: reading kernel config from /boot/config-2.6.32-431.el6.x86_64 ... Generally Necessary: - cgroup hierarchy: properly mounted [/cgroup] - CONFIG_NAMESPACES: enabled - CONFIG_NET_NS: enabled - CONFIG_PID_NS: enabled - CONFIG_IPC_NS: enabled - CONFIG_UTS_NS: enabled - CONFIG_DEVPTS_MULTIPLE_INSTANCES: enabled - CONFIG_CGROUPS: enabled - CONFIG_CGROUP_CPUACCT: enabled - CONFIG_CGROUP_DEVICE: enabled - CONFIG_CGROUP_FREEZER: enabled - CONFIG_CGROUP_SCHED: enabled - CONFIG_MACVLAN: enabled - CONFIG_VETH: enabled - CONFIG_BRIDGE: enabled - CONFIG_NF_NAT_IPV4: missing - CONFIG_IP_NF_TARGET_MASQUERADE: enabled - CONFIG_NETFILTER_XT_MATCH_ADDRTYPE: missing - CONFIG_NETFILTER_XT_MATCH_CONNTRACK: enabled - CONFIG_NF_NAT: enabled - CONFIG_NF_NAT_NEEDED: enabled Optional Features: - CONFIG_MEMCG_SWAP: missing - CONFIG_RESOURCE_COUNTERS: enabled - CONFIG_CGROUP_PERF: enabled - Storage Drivers: - \u0026#34;aufs\u0026#34;: - CONFIG_AUFS_FS: missing - CONFIG_EXT4_FS_POSIX_ACL: enabled - CONFIG_EXT4_FS_SECURITY: enabled - \u0026#34;btrfs\u0026#34;: - CONFIG_BTRFS_FS: enabled - \u0026#34;devicemapper\u0026#34;: - CONFIG_BLK_DEV_DM: enabled - CONFIG_DM_THIN_PROVISIONING: enabled - CONFIG_EXT4_FS: enabled - CONFIG_EXT4_FS_POSIX_ACL: enabled - CONFIG_EXT4_FS_SECURITY: enabled 假如你是自己编译内核，请特别留意几个绝对不能缺少的：DM_THIN_PROVISIONING、IP_NF_TARGET_MASQUERADE、NF_NAT。（AUFS_FS没有对应选项，还不清楚怎么回事，但不是必须） ###4. 安装 docker-io###\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # yum install docker-io Dependencies Resolved =========================================================================================== Package Arch Version Repository Size =========================================================================================== Installing: docker-io x86_64 1.1.2-1.el6 epel 4.5 M Installing for dependencies: lua-alt-getopt noarch 0.7.0-1.el6 epel 6.9 k lua-filesystem x86_64 1.4.2-1.el6 epel 24 k lua-lxc x86_64 1.0.6-1.el6 epel 15 k lxc x86_64 1.0.6-1.el6 epel 120 k lxc-libs x86_64 1.0.6-1.el6 epel 248 k Transaction Summary =========================================================================================== Install 6 Package(s) 许多文档介绍到这里，下一步为挂载/cgroup文件系统，我的docker版本为1.1.2，没有修改/etc/fstab的步骤。\n###5. 启动试运行###\n1 2 3 # service docker start //或 # docker -d ##6. 异常## 在我的一次安装过程中，很不幸遇到下面的问题： docker -d启动，或tail -f /var/log/docker查看日志\n1 2 3 4 5 6 7 8 [f32e7d9f] +job initserver() [f32e7d9f.initserver()] Creating server [f32e7d9f] +job serveapi(unix:///var/run/docker.sock) 2014/10/22 13:02:45 Listening for HTTP on unix (/var/run/docker.sock) Error running DeviceCreate (createPool) dm_task_run failed [f32e7d9f] -job initserver() = ERR (1) 2014/10/22 13:02:45 Error running DeviceCreate (createPool) dm_task_run failed \\nWed Oct 22 14:35:54 CST 2014\\n 再或者是service docker restart\n1 2 3 4 5 6 Stopping docker: [ OK ] Starting cgconfig service: Error: cannot mount cpuset to /cgroup/cpuset: Device or resource busy /sbin/cgconfigparser; error loading /etc/cgconfig.conf: Cgroup mounting failed Failed to parse /etc/cgconfig.conf [FAILED] Starting docker: [ OK ] 1 2 Unable to enable network bridge NAT: iptables failed: iptables -I POSTROUTING -t nat -s 172.17.42.1/16 ! -d 172.17.42.1/16 -j MASQUERADE: iptables v1.4.7: can\u0026#39;t initialize iptables table `nat\u0026#39;: Table does not exist (do you need to insmod?) Perhaps iptables or your kernel needs to be upgraded. 上面的三个异常都是由于内核模块的缺失导致的，这也是自己编译内核来升级带来的风险，于是就有了sciurus的kernel-ml-aufs的rpm包（见参考的第一个链接）。\n##7. 参考##\nInstalling docker.io on centos 6.4 (64-bit)，在 CentOS 6.4(64位) 安装 docker.io [中文] 在 CentOS 6.4 上安装 docker Official Installing Docker Docs CentOS-6 Troubleshooting: Error: cannot mount cpuset to /cgroup/cpuset: Device or resource busy Error running DeviceCreate (createPool) dm_task_run failed ","permalink":"http://localhost:1313/2014/10/docker-installed-centos6-successfully/","summary":"\u003cp\u003edocker是什么就不多说了，见\u003ca href=\"http://xgknight.com/2014/12/18/docker-introduction/\"\u003edocker基础原理介绍\u003c/a\u003e。\ndocker容器最早受到RHEL完善的支持是从最近的CentOS 7.0开始的，官方说明是只能运行于64位架构平台，内核版本为2.6.32-431及以上（即\u0026gt;=CentOS 6.5，运行docker时实际提示3.8.0及以上），升级内核请参考\u003ca href=\"http://xgknight.com/2014/10/24/upgrade-centos6_kernel-to-3.10.x/\"\u003eCentOS 6.x 内核升级（2.6.32 -\u0026gt; 3.10.58）过程记录\u003c/a\u003e\n需要注意的是CentOS 6.5与7.0的安装是有一点点不同的，CentOS-6上docker的安装包叫docker-io，并且来源于Fedora epel库，这个仓库维护了大量的没有包含在发行版中的软件，所以先要安装EPEL，而CentOS-7的docker直接包含在官方镜像源的Extras仓库（CentOS-Base.repo下的[extras]节enable=1启用）。前提是都需要联网，具体安装过程如下。\n###1. 禁用selinux###\u003c/p\u003e","title":"在 CentOS 6.x上安装 docker.io成功"},{"content":"##1. 什么是markdown##\n##2. 我选择的markdown编辑器## 首先选择适合自己的markdown编辑器需要考虑几个方面： 平台：Mac OS X, Windows, Online, 插件形式 预览：实时预览、html预览 语法：选定某一款后，适应自己的习惯，不必太复杂 其它：如主题，快捷键，同步等\n###首先来说一下以下几款为什么我没选用：（纯属个人喜好）###\nSublime Text的插件markdown preview，编辑和预览是分离的，在浏览器里预览。 CuteMarkEd，独立编辑器，支持多平台，不知道为什么我的编辑和预览窗口字体都那么丑。 MarkdownPad，独立编辑器，windows下口碑比较好的，但我把曾经写好的md文章放进去，格式不太对，应该是语法上略有差别，其它都还好。它多标签页的形式可以加分。 社区活跃，新功能反馈及时，例如 toc replace vim或emacs的markdown插件，windows平台下我还是正常一点吧。 ###习惯采用的编辑器### Haroopad，不得不说韩国人开发的软件体验上超赞，与segmentfault的文章写作一样，左右实时预览，多种主题可选。如果能实现多标签页就更好了。各平台上都可以使用，还有vim编辑模式。 马克飞象，google浏览器插件，专为印象笔记开发的浏览器markdown扩展，用起来特别舒服，自动保存在本地缓存，没有导出html格式或浏览器在线预览的功能，但比MaDe好用多了。（现在有离线客户端版） 在线markdown编辑器（首先你得有网络） [github]：不用多说 MaHua：与Mac OS X上相传甚广的Mou风格类似 cmd markdown：大牛开发的 ##3. 常用markdown语法## 标题/粗斜体 文章内容较多时，可以用标题分段：\n# 一级标题 # ## 大标题 ## ### 小标题 ### sf只有三级标题\n粗体/斜体 *斜体文本*　或　_斜体文本_　显示成　斜体文本 **粗体文本**　或　__粗体文本__　显示成　粗体文本 ***粗斜体文本***　或　___粗斜体文本___　显示成　粗斜体文本\n代码段 行内代码：`code here`　显示成　code here 代码段落： （可为某种语言指定高亮效果如 ` ` `python，支持bash、javascript、java、sql、xml、html等，有的markdown不支持指定语言） ` ` ` $(document).ready(function () { alert(\u0026lsquo;hello world\u0026rsquo;); }); ` ` ` 显示成\n1 2 3 $(document).ready(function () { alert(\u0026#39;hello world\u0026#39;); }); 我觉得sf的markdown代码段前后间距太大了有木有。\n链接和图片 文字链接 [seanlook](http://segmentfault.com/blog/seanlook/1190000000738685)　显示成　seanlook 如果一个网址要被多个地方引用，可用变量替代 这个链接用 1 作为网址变量 [Google][1] 这个链接用 yahoo 作为网址变量 [Yahoo!][yahoo] 然后在文档的结尾为变量赋值（网址） [1]: http://www.google.com/ [yahoo]: http://www.yahoo.com/ 1: http://www.google.com/ [yahoo]: http://www.yahoo.com/ 最终显示成 Google [Yahoo!][yahoo]\n页内跳转实现 图片链接 markdown不能设置图片的尺寸，图片居中 多个空格会合并成一个，多个（广义的，包括空格和tab）空行显示成一个空行，以空行区分段落\n多个空格显示 两个全角空格　或 八个\u0026lt;space\u0026gt;\u0026amp;nbsp;　或 \u0026amp;emsp;\u0026amp;emsp;\u0026amp;emsp;\n行首四个空格 自动转换成代码段 独立段落 任意空格\r##4. 参考##\nMarkdown 系列应用收集\n本文链接地址： http://xgknight.com/2014/10/25/markdown-tips/\n","permalink":"http://localhost:1313/2014/10/markdown-tips/","summary":"\u003cp\u003e##1. 什么是markdown##\u003c/p\u003e\n\u003cp\u003e##2. 我选择的markdown编辑器##\n首先选择适合自己的markdown编辑器需要考虑几个方面：\n平台：Mac OS X, Windows, Online, 插件形式\n预览：实时预览、html预览\n语法：选定某一款后，适应自己的习惯，不必太复杂\n其它：如主题，快捷键，同步等\u003c/p\u003e","title":"markdown语法备忘笔记"},{"content":"本人升级的目的是想在CentOS6.2上运行docker，官方建议内核版本在3.8.0及以上，于是就自己从Linux内核官方网站上下载源码，自己编译。 ##1. 准备工作## ###1.1 确认内核及版本信息###\n1 2 3 4 [root@hostname ~]# uname -r 2.6.32-220.el6.x86_64 [root@hostname ~]# cat /etc/centos-release CentOS release 6.2 (Final) ###1.2 安装软件###\n编译安装新内核，依赖于开发环境和开发库\n1 2 3 4 5 # yum grouplist //查看已经安装的和未安装的软件包组，来判断我们是否安装了相应的开发环境和开发库； # yum groupinstall \u0026#34;Development Tools\u0026#34; //一般是安装这两个软件包组，这样做会确定你拥有编译时所需的一切工具 # yum install ncurses-devel //你必须这样才能让 make *config 这个指令正确地执行 # yum install qt-devel //如果你没有 X 环境，这一条可以不用 # yum install hmaccalc zlib-devel binutils-devel elfutils-libelf-devel //创建 CentOS-6 内核时需要它们 如果当初安装系统是选择了Software workstation，上面的安装包几乎都已包含。 ##2. 编译内核## ###2.1 获取并解压内核源码，配置编译项### 去 http://www.kernel.org 首页，可以看到有stable, longterm等版本，longterm是比stable更稳定的版本，会长时间更新，因此我选择 3.10.58。\n1 2 3 [root@sean ~]# tar -xf linux-3.10.58.tar.xz -C /usr/src/ [root@sean ~]# cd /usr/src/linux-3.10.58/ [root@sean linux-3.10.58]# cp /boot/config-2.6.32-220.el6.x86_64 .config 我们在系统原有的内核配置文件的基础上建立新的编译选项，所以复制一份到当前目录下，命名为.config。接下来继续配置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 [root@sean linux-3.10.58]# sh -c \u0026#39;yes \u0026#34;\u0026#34; | make oldconfig\u0026#39; HOSTCC scripts/basic/fixdep HOSTCC scripts/kconfig/conf.o SHIPPED scripts/kconfig/zconf.tab.c SHIPPED scripts/kconfig/zconf.lex.c SHIPPED scripts/kconfig/zconf.hash.c HOSTCC scripts/kconfig/zconf.tab.o HOSTLD scripts/kconfig/conf scripts/kconfig/conf --oldconfig Kconfig .config:555:warning: symbol value \u0026#39;m\u0026#39; invalid for PCCARD_NONSTATIC .config:2567:warning: symbol value \u0026#39;m\u0026#39; invalid for MFD_WM8400 .config:2568:warning: symbol value \u0026#39;m\u0026#39; invalid for MFD_WM831X .config:2569:warning: symbol value \u0026#39;m\u0026#39; invalid for MFD_WM8350 .config:2582:warning: symbol value \u0026#39;m\u0026#39; invalid for MFD_WM8350_I2C .config:2584:warning: symbol value \u0026#39;m\u0026#39; invalid for AB3100_CORE .config:3502:warning: symbol value \u0026#39;m\u0026#39; invalid for MMC_RICOH_MMC * * Restart config... * * * General setup * ... ... XZ decompressor tester (XZ_DEC_TEST) [N/m/y/?] (NEW) Averaging functions (AVERAGE) [Y/?] (NEW) y CORDIC algorithm (CORDIC) [N/m/y/?] (NEW) JEDEC DDR data (DDR) [N/y/?] (NEW) # # configuration written to .config # make oldconfig会读取当前目录下的.config文件，在.config文件里没有找到的选项则提示用户填写。有的文档里介绍使用make memuconfig，它便是根据需要定制模块，类似界面如下：（我们不需要） make oldconfig会在生成新的.config之前备份为.config.old，并生成新的.config文件\n###2.2 开始编译###\n1 2 3 [root@sean linux-3.10.58]# make -j4 bzImage //生成内核文件 [root@sean linux-3.10.58]# make -j4 modules //编译模块 [root@sean linux-3.10.58]# make -j4 modules_install //编译安装模块 -j后面的数字是线程数，用于加快编译速度，一般的经验是，逻辑CPU，就填写那个数字，例如有8核，则为-j8。（modules部分耗时30多分钟） ###2.3 安装### [root@sean linux-3.10.58]# make install 实际运行到这一步时，出现ERROR: modinfo: could not find module vmware_balloon，但是不影响内核安装，是由于vsphere需要的模块没有编译，要避免这个问题，需要在make之前时修改.config文件，加入 HYPERVISOR_GUEST=y CONFIG_VMWARE_BALLOON=m （这一部分比较容易出问题，参考下文异常部分） ###2.4 修改grub引导，重启### 安装完成后，需要修改Grub引导顺序，让新安装的内核作为默认内核。 编辑 grub.conf文件，\n1 2 3 4 5 6 7 8 9 vi /etc/grub.conf #boot=/dev/sda default=0 timeout=5 splashimage=(hd0,0)/grub/splash.xpm.gz hiddenmenu title CentOS (3.10.58) root (hd0,0) ... 数一下刚刚新安装的内核在哪个位置，从0开始，然后设置default为那个数字，一般新安装的内核在第一个位置，所以设置default=0。 重启reboot： ###2.5 确认当内核版本###\n1 2 [root@sean ~]# uname -r 3.10.58 升级内核成功! ##3. 异常## ###3.1 编译失败（如缺少依赖包）### 可以先清除，再重新编译：\n1 2 # make mrproper #完成或者安装过程出错，可以清理上次编译的现场 # make clean ###3.2 在vmware虚拟机上编译，出现类似下面的错误###\n1 2 3 4 [root@sean linux-3.10.58]# make install sh /usr/src/linux-3.10.58/arch/x86/boot/install.sh 3.10.58 arch/x86/boot/bzImage \\ System.map \u0026#34;/boot\u0026#34; ERROR: modinfo: could not find module vmware_balloon 可以忽略，如果你有强迫症的话，尝试以下办法： 要在vmware上需要安装VMWARE_BALLOON，可直接修改.config文件，但如果vi直接加入CONFIG_VMWARE_BALLOON=m依然是没有效果的，因为它依赖于HYPERVISOR_GUEST=y。如果你不知道这层依赖关系，通过make menuconfig后，Device Drivers -\u0026gt; MISC devices 下是找不到VMware Balloon Driver的。（手动vi .config修改HYPERVISOR_GUEST后，便可以找到这一项），另外，无论是通过make menuconfig或直接vi .config，最后都要运行sh -c 'yes \u0026quot;\u0026quot; | make oldconfig'一次得到最终的编译配置选项。 然后，考虑到vmware_balloon可能在这个版本里已更名为vmw_balloon，通过下面的方法保险起见：\n1 2 # cd /lib/modules/3.10.58/kernel/drivers/misc/ # ln -s vmw_balloon.ko vmware_balloon.ko #建立软连接 其实，针对安装docker的内核编译环境，最明智的选择是使用sciurus帮我们配置好的.config文件。 也建议在make bzImage之前，运行脚本check-config.sh检查当前内核运行docker所缺失的模块。 当提示缺少其他module时如NF_NAT_IPV4时，也可以通过上面的方法解决，然后重新编译。 ##4. TO-DO##\n如何清除原内核 现有软件是否需要yum update升级 ##5. 参考资料##\nCentOS 6.5 升级内核到 3.10.28\nLinux Kernel内核配置方式详解\n","permalink":"http://localhost:1313/2014/10/upgrade-centos6_kernel-to-3.10.x/","summary":"\u003cp\u003e本人升级的目的是想在CentOS6.2上运行docker，官方建议内核版本在3.8.0及以上，于是就自己从Linux内核官方网站上下载源码，自己编译。\n##1. 准备工作##\n###1.1 确认内核及版本信息###\u003c/p\u003e","title":"CentOS 6.x 内核升级（2.6.32 -\u003e 3.10.58）过程记录"},{"content":"本文没啥实际内容，是给新人做linux培训的第二课进阶篇，主要着眼于体系，把一些工具混个眼熟。\n目录 Linux磁盘管理(进阶) Linux内存管理 Linux进程管理(进阶) Linux网络管理(进阶) Linux系统状态监控与调优 常见服务 Linux安全策略 其他 Linux磁盘管理（进阶） ext4文件系统格式 Inode、block、superblock、MBR VFS LVM pv、lv、vg lvdisplay、lvextend、vgdisplay、pvcreate… RAID raid0、raid1、raid5、raid10 r/w速度、磁盘利用率、安全性的权衡 磁盘IO性能 dd、iostat、iotop I/O等待 Linux内存管里（基础） 物理内存与虚拟内存 Swap space，分页存取 buffer与cache区分 内存监控命令 free、vmstat /proc文件系统 Linux进程管理（进阶） 进程与线程 进程优先级 进程监控命令 pidstat、lsof strace（系统调用跟踪） 后台进程 Ctrl+z、jobs、bg、fg、\u0026amp;、nohup screen Linux的网络管理 一些概念\n防火墙\n路由/网关\n子网掩码\n网络接口（参数）\nMAC\nTCP/IP协议\n应用层协议\nLinux网络管理 iptables\nLinux网络管理 主机网络流量监控 iftop、iptraf、sar tcpdump抓包 wireshark数据包分析工具 ##Linux网络管理\niproute2 ip、ss Linux系统状态监控与调优 一些工具 sar、sysstat perf、logwatch 一些配置文件 sysctl.conf limits.conf Linux安全策略 禁止root直接登录 锁定不使用的账号 关闭ipv6 启用防火墙 定期检查日志 … Linux常见服务 tcp_wrappers SSH postfix FTP NFS/Samba DNS Apache/nginx … Linux其他 Linux开机过程分析 pam模块解读lsmod 编译make、ldd、ldconfig、gcc、gdb ACL Linux集群 内核模块 linux编程 … 本文链接地址：http://xgknight.com/2014/10/06/linux-level2/\n","permalink":"http://localhost:1313/2014/10/linux-level2/","summary":"\u003cp\u003e本文没啥实际内容，是给新人做linux培训的第二课进阶篇，主要着眼于体系，把一些工具混个眼熟。\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"http://github.com/seanlook/sean-notes-comment/raw/main/static/linux-level2-01.PNG\"\u003e\n\u003cimg loading=\"lazy\" src=\"http://github.com/seanlook/sean-notes-comment/raw/main/static/linux-level2-02.PNG\"\u003e\n\u003cimg loading=\"lazy\" src=\"http://github.com/seanlook/sean-notes-comment/raw/main/static/linux-level2-03.PNG\"\u003e\n\u003cimg loading=\"lazy\" src=\"http://github.com/seanlook/sean-notes-comment/raw/main/static/linux-level2-04.PNG\"\u003e\n\u003cimg loading=\"lazy\" src=\"http://github.com/seanlook/sean-notes-comment/raw/main/static/linux-level2-05.PNG\"\u003e\n\u003cimg loading=\"lazy\" src=\"http://github.com/seanlook/sean-notes-comment/raw/main/static/linux-level2-06.PNG\"\u003e\n\u003cimg loading=\"lazy\" src=\"http://github.com/seanlook/sean-notes-comment/raw/main/static/linux-level2-07.PNG\"\u003e\n\u003cimg loading=\"lazy\" src=\"http://github.com/seanlook/sean-notes-comment/raw/main/static/linux-level2-08.PNG\"\u003e\n\u003cimg loading=\"lazy\" src=\"http://github.com/seanlook/sean-notes-comment/raw/main/static/linux-level2-09.PNG\"\u003e\n\u003cimg loading=\"lazy\" src=\"http://github.com/seanlook/sean-notes-comment/raw/main/static/linux-level2-10.PNG\"\u003e\n\u003cimg loading=\"lazy\" src=\"http://github.com/seanlook/sean-notes-comment/raw/main/static/linux-level2-11.PNG\"\u003e\n\u003cimg loading=\"lazy\" src=\"http://github.com/seanlook/sean-notes-comment/raw/main/static/linux-level2-12.PNG\"\u003e\n\u003cimg loading=\"lazy\" src=\"http://github.com/seanlook/sean-notes-comment/raw/main/static/linux-level2-13.PNG\"\u003e\n\u003cimg loading=\"lazy\" src=\"http://github.com/seanlook/sean-notes-comment/raw/main/static/linux-level2-14.PNG\"\u003e\n\u003cimg loading=\"lazy\" src=\"http://github.com/seanlook/sean-notes-comment/raw/main/static/linux-level2-15.PNG\"\u003e\n\u003cimg loading=\"lazy\" src=\"http://github.com/seanlook/sean-notes-comment/raw/main/static/linux-level2-16.PNG\"\u003e\n\u003cimg loading=\"lazy\" src=\"http://github.com/seanlook/sean-notes-comment/raw/main/static/linux-level2-17.PNG\"\u003e\u003c/p\u003e\n\u003ch2 id=\"目录\"\u003e目录\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eLinux磁盘管理(进阶)\u003c/li\u003e\n\u003cli\u003eLinux内存管理\u003c/li\u003e\n\u003cli\u003eLinux进程管理(进阶)\u003c/li\u003e\n\u003cli\u003eLinux网络管理(进阶)\u003c/li\u003e\n\u003cli\u003eLinux系统状态监控与调优\u003c/li\u003e\n\u003cli\u003e常见服务\u003c/li\u003e\n\u003cli\u003eLinux安全策略\u003c/li\u003e\n\u003cli\u003e其他\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"linux磁盘管理进阶\"\u003eLinux磁盘管理（进阶）\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eext4文件系统格式\u003c/li\u003e\n\u003cli\u003eInode、block、superblock、MBR\u003c/li\u003e\n\u003cli\u003eVFS\u003c/li\u003e\n\u003cli\u003eLVM\u003c/li\u003e\n\u003cli\u003epv、lv、vg\u003c/li\u003e\n\u003cli\u003elvdisplay、lvextend、vgdisplay、pvcreate…\u003c/li\u003e\n\u003cli\u003eRAID\u003c/li\u003e\n\u003cli\u003eraid0、raid1、raid5、raid10\u003c/li\u003e\n\u003cli\u003er/w速度、磁盘利用率、安全性的权衡\u003c/li\u003e\n\u003cli\u003e磁盘IO性能\n\u003cul\u003e\n\u003cli\u003edd、iostat、iotop\u003c/li\u003e\n\u003cli\u003eI/O等待\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"linux内存管里基础\"\u003eLinux内存管里（基础）\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e物理内存与虚拟内存\u003c/li\u003e\n\u003cli\u003eSwap space，分页存取\u003c/li\u003e\n\u003cli\u003ebuffer与cache区分\u003c/li\u003e\n\u003cli\u003e内存监控命令\u003c/li\u003e\n\u003cli\u003efree、vmstat\u003c/li\u003e\n\u003cli\u003e/proc文件系统\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"linux进程管理进阶\"\u003eLinux进程管理（进阶）\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e进程与线程\u003c/li\u003e\n\u003cli\u003e进程优先级\u003c/li\u003e\n\u003cli\u003e进程监控命令\u003c/li\u003e\n\u003cli\u003epidstat、lsof\u003c/li\u003e\n\u003cli\u003estrace（系统调用跟踪）\u003c/li\u003e\n\u003cli\u003e后台进程\u003c/li\u003e\n\u003cli\u003eCtrl+z、jobs、bg、fg、\u0026amp;、nohup\u003c/li\u003e\n\u003cli\u003escreen\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"linux的网络管理\"\u003eLinux的网络管理\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e一些概念\u003c/p\u003e","title":"Linux进阶培训-tplink"},{"content":"Linux是一个开放式系统，可以在网络上找到许多现成的程序和工具，这既方便了用户，也方便了黑客，因为他们也能很容易地找到程序和工具来潜入Linux系统，或者盗取Linux系统上的重要信息。不过，只要我们仔细地设定Linux的各种系统功能，并且加上必要的安全措施，就能让黑客们无机可乘。一般来说，对Linux系统的安全设定包括取消不必要的服务、限制远程存取、隐藏重要资料、修补安全漏洞、采用安全工具以及经常性的安全检查等。\n本文是可参考的实际操作，不涉及如IP欺骗这样的原理，而且安全问题也不算几行命令就能预防的，这里只是linux系统上基本的安全加固方法，后续有新的内容再添加进来。\n注：所有文件在修改之前都要进行备份如 cp /etc/passwd{,.dist}\n1. 禁用不使用的用户 注意：不建议直接删除，当你需要某个用户时，自己重新添加会很麻烦。也可以usermod -L或passwd -l user锁定。\ncp /etc/passwd{,.bak} 修改之前先备份 vi /etc/passwd 编辑用户，在前面加上#注释掉此行\n注释的用户名：\n# cat /etc/passwd|grep ^# #adm:x:3:4:adm:/var/adm:/sbin/nologin #lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin #shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown #halt:x:7:0:halt:/sbin:/sbin/halt #uucp:x:10:14:uucp:/var/spool/uucp:/sbin/nologin #operator:x:11:0:operator:/root:/sbin/nologin #games:x:12:100:games:/usr/games:/sbin/nologin #gopher:x:13:30:gopher:/var/gopher:/sbin/nologin #ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin #nfsnobody:x:65534:65534:Anonymous NFS User:/var/lib/nfs:/sbin/nologin #postfix:x:89:89::/var/spool/postfix:/sbin/nologin 注释的组：\n# cat /etc/group|grep ^# #adm:x:4:adm,daemon #lp:x:7:daemon #uucp:x:14: #games:x:20: #gopher:x:30: #video:x:39: #dip:x:40: #ftp:x:50: #audio:x:63: #floppy:x:19: #postfix:x:89: 2. 关闭不使用的服务 # chkconfig --list |grep '3:on' 邮件服务，使用公司邮件服务器：\nservice postfix stop chkconfig postfix --level 2345 off 通用unix打印服务，对服务器无用：\nservice cups stop chkconfig cups --level 2345 off 调节cpu速度用来省电，常用在Laptop上：\nservice cpuspeed stop chkconfig cpuspeed --level 2345 off 蓝牙无线通讯，对服务器无用：\nservice bluetooth stop chkconfig bluetooth --level 2345 off 系统安装后初始设定，第一次启动系统后就没用了：\nservice firstboot stop chkconfig firstboot --level 2345 off 关闭nfs服务及客户端：\nservice netfs stop chkconfig netfs --level 2345 off service nfslock stop chkconfig nfslock --level 2345 off 如果要恢复某一个服务，可以执行下面操作： service acpid start \u0026amp;\u0026amp; chkconfig acpid on 也可以使用setup工具来设置\n3. 禁用IPV6 IPv6是为了解决IPv4地址耗尽的问题，但我们的服务器一般用不到它，反而禁用IPv6不仅仅会加快网络，还会有助于减少管理开销和提高安全级别。以下几步在CentOS上完全禁用ipv6。\n禁止加载IPv6模块： 让系统不加载ipv6相关模块，这需要修改modprobe相关设定文件，为了管理方便，我们新建设定文件/etc/modprobe.d/ipv6off.conf，内容如下\nalias net-pf-10 off options ipv6 disable=1 禁用基于IPv6网络，使之不会被触发启动：\n# vi /etc/sysconfig/network NETWORKING_IPV6=no 禁用网卡IPv6设置，使之仅在IPv4模式下运行：\n# vi /etc/sysconfig/network-scripts/ifcfg-eth0 IPV6INIT=no IPV6_AUTOCONF=no 关闭ip6tables：\n# chkconfig ip6tables off 重启系统，验证是否生效：\n# lsmod | grep ipv6 # ifconfig | grep -i inet6 如果没有任何输出就说明IPv6模块已被禁用，否则被启用。\n4. iptables规则 启用linux防火墙来禁止非法程序访问。使用iptable的规则来过滤入站、出站和转发的包。我们可以针对来源和目的地址进行特定udp/tcp端口的准许和拒绝访问。\n关于防火墙的设置规则请参考博客文章 iptables设置实例。\n5. SSH安全 如果有可能，第一件事就是修改ssh的默认端口22，改成如20002这样的较大端口会大幅提高安全系数，降低ssh破解登录的可能性。\n创建具备辨识度的应用用户如crm以及系统管理用户sysmgr\n# useradd crm -d /apps/crm # passwd crm # useradd sysmgr # passwd sysmgr 5.1 只允许wheel用户组的用户su切换 # usermod -G wheel sysmgr # vi /etc/pam.d/su # Uncomment the following line to require a user to be in the \u0026quot;wheel\u0026quot; group. auth required pam_wheel.so use_uid 其他用户切换root，即使输对密码也会提示 su: incorrect password\n5.2 登录超时 用户在线5分钟无操作则超时断开连接，在/etc/profile中添加：\nexport TMOUT=300 readonly TMOUT 5.3 禁止root直接远程登录 # vi /etc/ssh/sshd_config PermitRootLogin no 5.4 限制登录失败次数并锁定 在/etc/pam.d/login后添加\nauth required pam_tally2.so deny=6 unlock_time=180 even_deny_root root_unlock_time=180 登录失败5次锁定180秒，根据需要设置是否包括root。\n5.5 登录IP限制 （由于要与某一固定IP或IP段绑定，暂未设置） 更严格的限制是在sshd_config中定死允许ssh的用户和来源ip：\n## allowed ssh users sysmgr AllowUsers sysmgr@172.29.73.* 或者使用tcpwrapper:\nvi /etc/hosts.deny sshd:all vi /etc/hosts.allow sshd:172.29.73.23 sshd:172.29.73. 6. 配置只能使用密钥文件登录 使用密钥文件代替普通的简单密码认证也会极大的提高安全性：\n[dir@username ~]$ ssh-keygen -t rsa -b 2048 Generating public/private rsa key pair. Enter file in which to save the key (/root/.ssh/id_rsa): //默认路径，回车 Enter passphrase (empty for no passphrase): //输入你的密钥短语，登录时使用 Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa. Your public key has been saved in /root/.ssh/id_rsa.pub. The key fingerprint is: 3e:fd:fc:e5:d3:22:86:8e:2c:4b:a7:3d:92:18:9f:64 root@ibpak.tp-link.net The key's randomart image is: +--[ RSA 2048]----+ | | … | o++o..oo..o| +-----------------+ 将公钥重命名为authorized_key：\n$ mv ~/.ssh/id_rsa.pub ~/.ssh/authorized_keys $ chmod 600 ~/.ssh/authorized_keys 下载私钥文件 id_rsa 到本地（为了更加容易识别，可重命名为hostname_username_id_rsa），保存到安全的地方。以后 username 用户登录这台主机就必须使用这个私钥，配合密码短语来登录（不再使用 username 用户自身的密码）\n另外还要修改/etc/ssh/sshd_config文件 打开注释\nRSAAuthentication yes PubkeyAuthentication yes AuthorizedKeysFile .ssh/authorized_keys 我们要求 username 用户（可以切换到其他用户，特别是root）必须使用ssh密钥文件登录，而其他普通用户可以直接密码登录。因此还需在sshd_config文件最后加入：\nMatch User itsection PasswordAuthentication no 重启sshd服务\n# service sshd restart 另外提醒一句，这对公钥和私钥一定要单独保存在另外的机器上，服务器上丢失公钥或连接端丢失私钥（或密钥短语），可能导致再也无法登陆服务器获得root权限！\n7. 减少history命令记录 执行过的历史命令记录越多，从一定程度上讲会给维护带来简便，但同样会伴随安全问题\nvi /etc/profile 找到 HISTSIZE=1000 改为 HISTSIZE=50。\n或每次退出时清理history，history -c\n8. 增强特殊文件权限 给下面的文件加上不可更改属性，从而防止非授权用户获得权限\nchattr +i /etc/passwd chattr +i /etc/shadow chattr +i /etc/group chattr +i /etc/gshadow chattr +i /etc/services #给系统服务端口列表文件加锁，防止未经许可的删除或添加服务 chattr +i /etc/pam.d/su chattr +i /etc/ssh/sshd_config 显示文件的属性\nlsattr /etc/passwd /etc/shadow /etc/services /etc/ssh/sshd_config 注意：执行以上 chattr 权限修改之后，就无法添加删除用户了。\n如果再要添加删除用户，需要先取消上面的设置，等用户添加删除完成之后，再执行上面的操作，例如取消只读权限chattr -i /etc/passwd。（记得重新设置只读）\n9. 防止一般网络攻击 网络攻击不是几行设置就能避免的，以下都只是些简单的将可能性降到最低，增大攻击的难度但并不能完全阻止。\n9.1 禁ping 阻止ping如果没人能ping通您的系统，安全性自然增加了，可以有效的防止ping洪水。为此，可以在/etc/rc.d/rc.local文件中增加如下一行：\n# echo 1 \u0026gt; /proc/sys/net/ipv4/icmp_echo_ignore_all 或使用iptable禁ping：\niptables -A INPUT -p icmp --icmp-type 0 -s 0/0 -j DROP 不允许ping其他主机： iptables -A OUTPUT -p icmp --icmp-type 8 -j DROP 9.2. 防止IP欺骗 编辑/etc/host.conf文件并增加如下几行来防止IP欺骗攻击。\norder hosts,bind #名称解释顺序 multi on #允许主机拥有多个IP地址 nospoof on #禁止IP地址欺骗 9.3 防止DoS攻击 对系统所有的用户设置资源限制可以防止DoS类型攻击，如最大进程数和内存使用数量等。 可以在/etc/security/limits.conf中添加如下几行：\n* soft core 0 * soft nproc 2048 * hard nproc 16384 * soft nofile 1024 * hard nofile 65536 core 0 表示禁止创建core文件；nproc 128 把最多的进程数限制到20；nofile 64 表示把一个用户同时打开的最大文件数限制为64；* 表示登录到系统的所有用户，不包括root\n然后必须编辑/etc/pam.d/login文件检查下面一行是否存在。\nsession required pam_limits.so limits.conf参数的值需要根据具体情况调整。\n10. 修复已知安全漏洞 在linux上偶尔会爆出毁灭级的漏洞，如udev、heartbleed、shellshock、ghost等，如果服务器暴露在外网，一定及时修复。\n11. 定期做日志安全检查 将日志移动到专用的日志服务器里，这可避免入侵者轻易的改动本地日志。下面是常见linux的默认日志文件及其用处：\n/var/log/message – 记录系统日志或当前活动日志。 /var/log/auth.log – 身份认证日志。 /var/log/cron – Crond 日志 (cron 任务). /var/log/maillog – 邮件服务器日志。 /var/log/secure – 认证日志。 /var/log/wtmp\t历史登录、注销、启动、停机日志和，lastb命令可以查看登录失败的用户 /var/run/utmp\t当前登录的用户信息日志，w、who命令的信息便来源与此 /var/log/yum.log Yum 日志。 参考 深度解析CentOS通过日志反查入侵。\n11.1 安装logwatch Logwatch是使用 Perl 开发的一个日志分析工具。能够对Linux 的日志文件进行分析，并自动发送mail给相关处理人员，可定制需求。\nLogwatch的mail功能是借助宿主系统自带的 mail server 发邮件的，所以系统需安装mail server , 如sendmail,postfix,Qmail等\n安装和配置方法见博文 linux日志监控logwatch。\n12. web服务器安全 像apache或tomcat这样的服务端程序在配置时，如果有安全问题存在可以查阅文档进行安全加固。日后有时间再补充到新的文章。\n参考\nTop 20 OpenSSH Server Best Security Practices ","permalink":"http://localhost:1313/2014/09/linux-security-general-settings/","summary":"\u003cp\u003eLinux是一个开放式系统，可以在网络上找到许多现成的程序和工具，这既方便了用户，也方便了黑客，因为他们也能很容易地找到程序和工具来潜入Linux系统，或者盗取Linux系统上的重要信息。不过，只要我们仔细地设定Linux的各种系统功能，并且加上必要的安全措施，就能让黑客们无机可乘。一般来说，对Linux系统的安全设定包括取消不必要的服务、限制远程存取、隐藏重要资料、修补安全漏洞、采用安全工具以及经常性的安全检查等。\u003c/p\u003e","title":"CentOS 6 服务器安全配置指南（通用）"},{"content":"1. 介绍 在维护Linux服务器时，经常需要查看系统中各种服务的日志，以检查服务器的运行状态。 如登陆历史、邮件、软件安装等日志。系统管理员一个个去检查会十分不方便；且大多时候，这会是一种被动的检查，即只有在发现系统运行异常时才会想到去查看日志以获取异常的信息。那么如何主动、集中的分析这些日志，并产生报告，定时发送给管理员就会显得十分重要。\nlogwatch 是一款用 Perl 语言编写的开源日志解析分析器。它能对原始的日志文件进行解析并转换成结构化格式的文档，也能根据您的使用情况和需求来定制报告。logwatch 的主要目的是生成更易于使用的日志摘要，并不是用来对日志进行实时的处理和监控的。正因为如此，logwatch 通常被设定好时间和频率的自动定时任务来调度运行或者是有需要日志处理的时候从命令行里手动运行。一旦日志报告生成，logwatch 可以通过电子邮件把这报告发送给您，您可以把它保存成文件或者直接显示在屏幕上。\nLogwatch 报告的详细程度和报告覆盖范围是完全可定制化的。Logwatch 的日志处理引擎也是可扩展的，从某种意义上来说，如果您想在一个新的应用程序中使用 logwatch 功能的话，只需要为这个应用程序的日志文件编写一个日志处理脚本（使用 Perl 语言），然后挂接到 logwatch 上就行。\nlogwatch 有一点不好的就是，在它生成的报告中没有详细的时间戳信息，而原来的日志文件中是存在的。您只能知道被记录下来的一段时间之内的特定事件，如果想要知道精确的时间点的信息，就不得不去查看原日志文件了。\n2. 安装与配置说明 2.1 安装 无论在Debian系还是Redhat系上，安装logwatch都非常简单：\n# apt-get install logwatch //Debian、Ubuntu.etc # yum install logwatch -y //Redhat、Centos.etc 以下内容基于 CentOS 6.x，其余系统相差不大。\n2.2 配置 2.2.1 配置文件说明 安装后的目录文件说明： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 /usr/share/logwatch default.conf/ # 配置目录 logwatch.conf # 主配置文件，收件人，级别等 logfiles/ # 定义待分析服务的日志文件组路径，相对于/var/log(*.conf) services/ # 自定义需分析日志的Service目录(*.conf) scripts/ # 可执行脚本 logwatch.pl # 启动分析的perl脚本，/usr/sbin/logwatch的源链接 logfiles/ # 可包含多个logwatch日志文件组的子目录，对应的日志服务运行的时候，子目录下的脚本会自动被调用 services/ # logwatch日志服务的过滤脚本，一一对应 shared/ # 可被多个logwatch日志服务引用的脚本 dist.conf/ logfiles/ services/ lib/ 默认情况下使用的是/usr/share/logwatch/default.conf/logwatch.conf作为主配置文件，但在/etc/logwatch/conf/logwatch.conf中的存在配置选项会覆盖前一个（/usr/share/logwatch下的logwatch.conf还是会起作用，比如在/etc/logwatch的logwatch.conf中没有的选项）。但优先级最高的是在执行命令行中指定的选项。\n在/etc/logwatch下也存在一个与/usr/share/logwatch类似的目录结构，可以在这里添加自定义的监控日志信息。\n从上面的目录结构划分大概可以了解到 logwatch 的原理：logwatch 首先要知道针对哪一个服务, 从这个服务中得到需要处理的 log 文件信息, 然后这个文件送给过滤脚本处理，之后把处理后格式化的信息展现出。内部细节请看第3篇参考。\n2.2.2 编辑配置 在/usr/share/doc/logwatch-7.3.6/HOWTO-Customize-LogWatch文件中有这里的详细的配置说明。\n个人还是习惯在/etc/logwatch/下管理配置文件，但又不太希望同时两个配置文件生效，所以对/usr/share/logwatch/default.conf/logwatch.conf备份，然后软链接/etc/logwatch/conf/logwatch.conf：\nln -s /usr/share/logwatch/default.conf/logwatch.conf /etc/logwatch/conf/logwatch.conf 试着执行logwatch --service sshd --print感受一下处理的结果。接下来修改/etc/logwatch/conf/logwatch.conf文件的默认配置来做些个性化设置。\n修改日志分析级别\nDetail = \u0026lt;Low, Med, High, or a number\u0026gt; “Detail” 配置指令控制着 logwatch 报告的详细程度。它可以是个正整数，也可以是分别代表着10、5和0数字的 High、Med、Low 几个选项。这里设置成High。（配置文件中是不区分大小写的）\n指定报告收件人\nMailTo = youremailaddress@yourdomain.com MailFrom = youremailaddress@yourdomain.com MailTo指定logwatch日志报告接收人，要把一份报告发送给多个用户，只需要把他们的邮件地址用空格或逗号隔开，但是logwatch认为你已经配置好本地邮件服务器（sendmail或postfix），并能正确传递给用户邮箱。\nMailFrom，顾名思义，指定发件人。邮件地址可以说完整的收件人地址，也可以是服务器上的本地用户如root（有的邮件服务器不支持显示发件人别名）。\n指定发送邮件的客户端\nmailer = \u0026quot;sendmail -t\u0026quot; 默认采用的是sendmail（不是sendmail服务器），而且一般没什么问题。在我的环境下有点特殊，邮件服务器必须通过smtp认证才能发送邮件，不支持匿名和其他本地MTA投递的邮件，而sendmail我一直没有找到设置smtp用户和密码认证的地方（知道的烦请告知），所以就改用了mailer = \u0026quot;mailx -t\u0026quot;，然后在/etc/mail.rc中设置from、smtp、smtp-auth-user、smtp-auth-password、smtp-auth参数，但使用mailx带来的问题是后面设置邮件报告格式为html时，无法设置header信息从而foxmail不能解析html正文。尝试了 sendEmail 也没很好的解决。\n大部分人情况可能没这么复杂，其实就是一个发件客户端的功能，网上得知有 mutt 结合 msmtp 可以解决该问题：\n# yum install -y mutt //mutt其实可以不安装 # tar jxvf msmtp-1.4.16.tar.bz2 \u0026amp;\u0026amp; cd msmtp-1.4.16 # ./configure \u0026amp;\u0026amp; make \u0026amp;\u0026amp; make install # vi ~/.msmtprc account default host your.smtp-server.com from username@smtp-server.com auth login user username password your_auth_pwd logfile ~/msmtp.log # 如果使用mutt发送，还需要设置~/.muttrc 将 mailer 改成mailer = \u0026quot;msmtp -t\u0026quot;。\n输出格式\nOutput = \u0026lt;mail, html or unformatted\u0026gt; 默认不指定输出格式（plain text）,系统管理员通过邮件客户端（如foxmail）看到的邮件内容是文本形式，比较简单、节省带宽；可以指定为html，此时看到的是可点击链接的友好的页面。\n当同时设定了Save = /tmp/logwatch时，便不会发送邮件报告了，将会根据Output指定的格式保存到一个Save文件中。\n另外在有的文章里指定Format选项，经过本人试验在7.3.6版本中无效。\n收集日志的范围\nRange = \u0026lt;Yesterday|Today|All\u0026gt; Range配置指令定义了生成 logwatch 报告的时间段信息。这个指令通常可选的值是 Yesterday、Today、All。当作用了Rang = All时，Archive = yes 这个指令项也必须配置上，那么所有的已存档的日志文件 (比如，/var/log/maillog、/var/log/maillog-20150111)都会被处理到。\n如果我们是通过 crontab 每天收集的话，可以只报告昨天或今天的日志情况。\n收集哪些服务的日志\nService = \u0026lt;service-name-1\u0026gt; Service = \u0026lt;service-name-2\u0026gt; . . . Service选项指定想要监控的一个或多个服务。在/usr/share/logwatch/scripts/services目录下列出的服务都能被监控，它们已经涵盖了重要的系统服务（例如：pam,secure,iptables,syslogd 等），也涵盖了一些像 sudo、sshd、http、fail2ban、samba等主流的应用服务。如果您想添加新的服务到列表中，得编写一个相应的日志处理 Perl 脚本，并把它放在这个目录中。 对于一个综合日志分析工具，logwatch推荐大多数人使用Service = \u0026quot;All\u0026quot;，然后通过继续添加Service = \u0026quot;-service_name\u0026quot; 等来去掉那些不监控的日志。当然在服务器上，并不是所有script下的服务都有启动，有些并没有日志。\n命令行指定logwatch选项\n如果您不想个性化 /etc/logwatch/conf/logwatch.conf，您可以不修改此文件让其默认，然后在命令行里运行如下所示的命令：\n# logwatch --detail 10 --mailto youremailaddress@yourdomain.com --range today \\ \u0026gt; --service sshd --service postfix --service zz-disk_space --service -zz-network \\ \u0026gt; --output mail logwatch.conf完整示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 LogDir = /var/log TmpDir = /var/cache/logwatch Print = No Range = yesterday Detail = High MailTo = zhouxiao@example.com.net MailFrom = itsection@example.com.net mailer = \u0026#34;msmtp -t\u0026#34; Output = html Service = All Service = \u0026#34;-zz-network\u0026#34; Service = \u0026#34;-zz-sys\u0026#34; Service = \u0026#34;-eximstats\u0026#34; 3. 扩展 3.1 cron daily 我们可以看到在 crontab 定时任务设定目录下存在/etc/cron.daily/0logwatch：\n1 2 3 4 5 6 7 8 #!/bin/bash DailyReport=`grep -e \u0026#34;^[[:space:]]*DailyReport[[:space:]]*=[[:space:]]*\u0026#34; /usr/share/logwatch/default.conf/logwatch.conf | head -n1 | sed -e \u0026#34;s|^\\s*DailyReport\\s*=\\s*||\u0026#34;` if [ \u0026#34;$DailyReport\u0026#34; != \u0026#34;No\u0026#34; ] \u0026amp;\u0026amp; [ \u0026#34;$DailyReport\u0026#34; != \u0026#34;no\u0026#34; ] then logwatch fi 如果在logwatch.conf中显式设置了选项DailyReport = No，则会取消logwatch每日执行任务。如果你要修改cron.daily的执行时间，可以删掉这个0logwatch然后添加到/etc/crontab里，或者修改/etc/anacrontab的START_HOURS_RANGE。\n所以 logwatch 的工作不是监控日志异常后及时报警的工具，因为默认它是每天一封整合的邮件，并不具有及时性（安装perl的CPAN模块后可以更精确的控制logwatch时间，详见第一份参考）。\n3.2 定制自己要监控的日志 用一个简单的例子介绍自定义logwatch的配置方法。\n首先创建logwatch日志文件组 /etc/logwatch/conf/logfiles/test.conf：\nLogFile = /path/to/your/logfile LogFile = /path/to/your/second/logfile 然后创建logwatch服务配置文件 /etc/logwatch/conf/services/test.conf：\nTitle = test title # 日志文件里的标题 LogFile = test # logwatch日志文件组的名字，通常是对应的配置文件的文件名部分 创建logwatch服务过滤器脚本 /etc/logwatch/scripts/services/test：\n1 2 3 #!/bin/bash grep -i ERROR 上面的脚本会从日志文件里过滤出包含ERROR的行。最后，为新建的脚本添加执行权限:\nchmod +x /etc/logwatch/scripts/services/test 参考\nLinux 系统中使用 logwatch 监控日志文件 （英文）\nLogWatch Introduction\nManaging your log files\nLogwatch简单配置教程\n","permalink":"http://localhost:1313/2014/08/linux-logwatch-usage/","summary":"\u003ch1 id=\"1-介绍\"\u003e1. 介绍\u003c/h1\u003e\n\u003cp\u003e在维护Linux服务器时，经常需要查看系统中各种服务的日志，以检查服务器的运行状态。 如登陆历史、邮件、软件安装等日志。系统管理员一个个去检查会十分不方便；且大多时候，这会是一种被动的检查，即只有在发现系统运行异常时才会想到去查看日志以获取异常的信息。那么如何主动、集中的分析这些日志，并产生报告，定时发送给管理员就会显得十分重要。\u003c/p\u003e","title":"在Linux上使用logwatch分析监控日志文件"},{"content":"“学习vim并且其会成为你最后一个使用的文本编辑器” 学习建议：\n丢弃鼠标和小键盘 具有搭配使用各种按键的意识 首先来一张 mindmap :\n1. 初级 1.1 编辑模式（Insert Mode） 编辑模式包括以下动作：\ninsert：i在光标所在字符前插入，I在当前行首第一个非空格字符前插入 append：a在光标所在字符后插入，A在行末尾开始插入 open：o在下一行插入新行，O在光标所在行的上一行插入新行 replace：r将光标处字符替换成r紧接的字符；R一直替换字符串，知道ESC键退出，同windows下的Insert键 Ctrl+p：自动提示 [ESC]：回到普通模式 1.2 普通模式（Normal Mode） h, j, k, l ，分别对应 左← 下↓ 上↑ 右→\n:q, :q!, :wq 退出 不保存强行退出 保存退出\n移动光标到当前行首/非空格，同^，:0\n$ 移动光标到当前行尾，同:$\nG 移动光标到文档最后一行首\n30G 转到第30行，同 :30\n9- 光标向上移动9行，同9k\n9+ 光饼向下移动9行，同9[space]，9j\ngg 转到文档第一行(1G)\nH 移动到屏幕的第一列\nM 移动到屏幕的中间列\nL 移动到屏幕的最后列\nw 移动到下一个单词的首字母，（标点符号认为是一个单词，W表示单词以空格分隔）\ne 移动到下一个单词的末尾，（E认为单词以空格分隔）\nb 移动到上一个单词的首字母，（B认为单词以空格分隔）\nfx 移动到下一个字母是x的位置。Fx向上移动。\n% 匹配括号移动，包括 (, {, [ ，你需要把光标先移到括号上\nCTRL+b 向上（前）翻页\nCTRL+f 向后翻页\nd 删除开始。其实是放到寄存器中，p或P命令调用。c即change，删完进入编辑模式\nd$ 删除光标到行尾的所有文字，同D。C指令进入编辑模式\ndw 删除当前字符到单词尾的所有字符。cw删除光标后的单词并进入插入模式，等同替换\ndd 删除当前一行\n2dd 删除当前两行\nx 剪切光标处字符，可以p粘贴出来\ny 复制开始。yank起来，p或P命令调用\nyy p 复制当前行并粘贴到下一行\n5yy p 复制当前行以下5行，在合适的地方粘贴\nyw p 复制一个单词并粘贴。\nyi{ 复制光标所在{}中的内容。很容易知道ci{ 和 di \u0026quot; 的意思。\nu 撤销\nCTRL+r 重做\n. 点号重复做上一个命令\n``.` 移动光标到上一次的修改点\nCtrl+g 查看我当前位置\n1.3 命令模式 /word 向下查找word，n定位到下一个。?word 向上开始查找，同 /word 配合N。* 直接查找光标所在处单词\n:%s/word1/word2/g 替换所有 word1 为 word2 (^$ [])\n:set noic 区分大小写 (即set no igorecase，set ic不区分大小写)\n:set nu 显示行号。:set nonu相反，不显示行号\n:set paste 设置为粘贴模式，解决Ctrl+Insert粘贴时缩进错乱问题。:set nopaste设置回默认\n:se ff=unix 设置文本文件的格式为unix，去掉windows系统文件中的^M。\n:!ls 执行bash下的命令ls，回车后继续回到vi。一般在一个不存在的目录中创建文件时用到\n:set all 查看vim说有设置属性值\n:map 查看绑定的快捷键\n:marks 查看可用标记\n熟练上面的命令，已经可以满足日常工作要求，要提高效率可以学习vim的高级用法，如分屏显示、分页、标签功能、代码折叠、键盘映射。\n1.4 可视化模式 visual mode多用于用键盘灵活选择文本。v或V键进入，可以实现同时编辑多行（如注释）\n2. 中级 2.1 高级组合命令 :sh 暂时离开vi，进入shell命令行\n:!ls !表示要执行一个shell命令\nq: 调出历史命令窗口\ncc 替换一行，清空一行\ncw 替换一个单词，进入插入模式\nea 在当前单词最后插入\nvw visual模式选择一个单词\nVU 全选一行，转换成大写\n:5,12 co 13 将5至12行复制到第13行下\ngg=G 自动缩排文件 % : 匹配括号移动，包括 (, {, [. ，你需要把光标先移到括号上 * 和 #:匹配光标当前所在的单词，移动光标到下一个（或上一个）匹配单词（*是下一个，#是上一个）\n当光标在( ), [ ],\u0026lt; \u0026gt;, { }, \u0026quot; \u0026quot;, '' 内时，可以用ci, di, 或yi，加上(, [, \u0026lt;,{, \u0026quot;, '。这样可以改写/删除/复制( )内，[ ]内，\u0026lt; \u0026gt;内，{ }内，\u0026quot; \u0026quot;内，' '内的内容\n多行注释（块操作）\n首先按esc进入命令行模式下，按下Ctrl + v，进入列（也叫区块）模式; 在行首使用上下键kj选择需要注释的多行; 按下键盘（大写）I键，进入插入模式； 然后输入注释符（“//”、“#”等）; 最后按下esc键 删除多行开头的一个字符与此类似，删除多个字符也只要左右键，然后使用d。\n另外一种多行注释的方式就是替换：\n:5,9s/^/#/g 添加注释# :5,9s/^#//g 删除注释# :5,9s#^#//#g 添加注释//，同:5,9s/^///#/g :5,9s#^//##g 删除注释// 多行缩进 [ESC], Ctrl+v 选择行 \u0026lt;或\u0026gt;左右缩进，=自动缩进（gg=G的局部功能）\n多行行末尾加上 \u0026raquo; ${log}：Ctrl+v /^echo \u0026gt;\u0026gt;相当于tab键，一个缩进\n多行删除\n首先在命令模式下，输入set nu显示行号； 通过行号确定你要删除的行； 命令输入:32,65d,回车键，32-65行就被删除了 自动补全 在Insert模式下，你可以输入一个词的开头，然后按 \u0026lt;C-p\u0026gt;或是\u0026lt;C-n\u0026gt;，自动补齐功能就出现了\n2.2 分屏(split) 分割窗口（同时编辑多个文件）\nvi -o file1 file2 水平分屏，也可以在先打开file1后，使用:sp file2 vi -O file1 file2 垂直分屏，也可以在先打开file1后，使用:vsp file2 Ctrl+w w 光标切换到另一个屏 k 关闭当前窗口，如果有改动则提示要先保存。:wqa!保存退出所有文件 Ctrl+w v 左右分割当前打开的文件。Ctrl+w s上下分割显示 Ctrl+w H 左移该屏（大写，L右移，K上移—改变vertical为horizontal） :set scb 分屏同步滚动 另外一种不分屏，同时编辑多个文件的方法\nvi file1 file2\n:ls 展示全部打开的文档。其中 % 代表正在打开的文件（buffer），# 代表上一个编辑过的文件，a 代表当前激活的buffer空间，+ 代表有修改过的内容但还未保存 :buffer 2 转到打开的第二个文件。或简写为 :b2 :bn 转到下一个文件。没有保存不能离开这个文件。:bp 上一个文件 :b# 转到上一个编辑过的文件，同 :e #。类似于多屏中Ctrl+w w :e file3 编辑一个新的文件 Ctrl+g 显示当前文件名和行号，同 :f 2.3 折叠(fold) 主要应用在复杂脚本的场合，特别是函数比较多，逻辑结构比较复杂的代码。（:help folding） 有6种方式来折叠代码\nmanual //手工定义折叠 indent //用缩进表示折叠 expr　//用表达式来定义折叠 syntax //用语法高亮来定义折叠 diff //对没有更改的文本进行折叠 marker //用标志折叠 indent :set foldmethod=indent 设置缩进折叠，fdm为简写。只对当前会话有效，要使每次打开vim时折叠都生效，则在.vimrc文件中添加设置，如添加：set fdm=indent\nzc 折叠与当前缩进相同的行 zo 打开折叠 zj 移到下一个折叠处 zk 移到上一个折叠处 zm 折叠所有可折叠标记 zr 展开所有折叠 [z 到当前打开折叠的开始 ]z 到当前打开折叠的结束 marker 注意与后文的mark不是同一东西，:set fdm=marker\nzf 创建marker，默认 # { { {, # } } } Ctrl+v zf 进入可视化模式，选择需要折叠的行，zc执行折叠。会自动加入 # { { { code block # } } } zf9j 创建从当前行起至以下9行的折叠标记，zc进行折叠。同9zf。类似有zf30G，从当前行折叠刀第30行 zf% 创建匹配的 {}, [], (), \u0026lt;\u0026gt; 的fold。不用执行zc zd 删除当前行上存在的折叠标记。仅当 \u0026lsquo;foldmethod\u0026rsquo; 设为 \u0026ldquo;manual\u0026rdquo; 或 \u0026ldquo;marker\u0026rdquo; 时有效 2.4 标记 标记(mark)是vim提供的精确定位技术，只要你知道标记的名字，就可以使用命令直接跳转到该标记所在的位置。vim中的标记都有一个名字，这个名字用单一的字符表示。大写和小写字母(A-Za-z)都可以做为标记的名字，这些标志的位置可以由用户来设置；而数字标记0-9，以及一些标点符号标记，用户不能进行设置，由vim来自动设置。（:help mark-motions查看更多帮助）\nms 定义一个标记s ``s` 跳转到标记s的地方 's 跳转到调剂s所在行首 ``.` jump to position where last change occurred in current buffer `` jump back (to position in current buffer where jumped from) :delmarks aA 使用 :delmarks! 删除所有小写（a-z）的标记 :marks 查看所有标记 3. 插件 待续\n4. vimrc .vimrc 是目前自己用的比较习惯的vim风格。\n参考\n简明 Vim 练级攻略\nVim Cheat Sheet for Programmers\nVIM哲学\n","permalink":"http://localhost:1313/2014/08/vim-tips/","summary":"\u003cp\u003e“学习vim并且其会成为你最后一个使用的文本编辑器”\n学习建议：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e丢弃鼠标和小键盘\u003c/li\u003e\n\u003cli\u003e具有搭配使用各种按键的意识\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e首先来一张 \u003ca href=\"http://jrmiii.com/2009/03/06/learning-vim-the-pragmatic-way.html\"\u003emindmap\u003c/a\u003e :\u003c/p\u003e\n\u003cp\u003e\u003cimg alt=\"vim-learn-card\" loading=\"lazy\" src=\"http://github.com/seanlook/sean-notes-comment/raw/main/static/Vim-mindmap.png\"\u003e\u003c/p\u003e\n\u003ch1 id=\"1-初级\"\u003e1. 初级\u003c/h1\u003e\n\u003ch2 id=\"11-编辑模式insert-mode\"\u003e1.1 编辑模式（Insert Mode）\u003c/h2\u003e\n\u003cp\u003e编辑模式包括以下动作：\u003c/p\u003e","title":"vim编辑器技巧备忘（初级-中级）"},{"content":"bash快捷键 习惯使用编辑的快捷键可以大大提高效率，记忆学习过程要有意识的忽略功能键、方向键和数字小键盘。以下快捷键适用在bash处于默认的Emacs模式下，是由一个名为Readline的库实现的，用户可以通过命令bind添加新快捷键，或者修改系统中已经存在的快捷键。（如果你有set -o vi，就处于 vi 模式就不适用了）\n另外下面的内容并不包含所有快捷键，只是我个人适用频率最高的几种，但相信已经可以大大提高工作效率了。以下所有 Alt 键可以以 Esc 键代替。\nCtrl + l ：清除屏幕，同clear\nCtrl + a ：将光标定位到命令的开头\nCtrl + e ：与上一个快捷键相反，将光标定位到命令的结尾\nCtrl + u ：剪切光标之前的内容，在输错命令或密码\nCtrl + k ：与上一个快捷键相反，剪切光标之后的内容\nCtrl + y ：粘贴以上两个快捷键所剪切的内容。Alt+y粘贴更早的内容\nCtrl + w ：删除光标左边的参数（选项）或内容（实际是以空格为单位向前剪切一个word）\nCtrl + / ：撤销，同Ctrl+x + Ctrl+u\nCtrl + f ：按字符前移（右向），同→\nCtrl + b ：按字符后移（左向），同←\nAlt + f ：按单词前移，标点等特殊字符与空格一样分隔单词（右向），同Ctrl+→\nAlt + b ：按单词后移（左向），同Ctrl+←\nAlt + d ：从光标处删除至字尾。可以Ctrl+y粘贴回来\nAlt + \\ ：删除当前光标前面所有的空白字符\nCtrl + d ：删除光标处的字符，同Del键。没有命令是表示注销用户\nCtrl + h ：删除光标前的字符\nCtrl + r ：逆向搜索命令历史，比history好用\nCtrl + g ：从历史搜索模式退出，同ESC\nCtrl + p ：历史中的上一条命令，同↑\nCtrl + n ：历史中的下一条命令，同↓\nAlt + . ：同!$，输出上一个命令的最后一个参数（选项or单词）。 还有如Alt+0 Alt+. Alt+.，表示输出上上一条命令的的第一个单词（即命令）。 另外有一种写法 !:n，表示上一命令的第n个参数，如你刚备份一个配置文件，马上编辑它：cp nginx.conf nginx.conf，vi !:1，同vi !^。!^表示命令的第一个参数，!$最后一个参数（一般是使用Alt + .代替）。\n这里提一下按字符或字符串，向左向后搜索字符串的命令：\nCtrl + ]　c ：从当前光标处向右定位到字符 c 处 Esc　Ctrl + ]　c ：从当前光标向左定位到字符 c 处。（ bind -P 可以看到绑定信息） Ctrl + r　str ：可以搜索历史，也可以当前光标处向左定位到字符串 str，Esc后可定位继续编辑 Ctrl -s　str ：从当前光标处向右定位到字符串 str 处，Esc 退出。注意，Ctrl + S默认被用户控制 XON/XOFF ，需要在终端里执行stty -ixon或加入profile。 注意上述所有涉及Alt键的实际是Meta键，在xshell中默认是没有勾选“Use Alt key as Meta key”，要充分体验这些键带来的快捷，请在对应的terminal设置。\n参考：高效操作Bash ，Bash (Unix shell) Keyboard shortcuts ，bash中的命令基本操作。\n常用alias 以下bash中别名设置我还并没有完全使用，也是个人觉得非常有用的（多了记起来也麻烦），所以收集在一起，习惯就好。 /etc/profile.d/alias.sh：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 alias wl=\u0026#39;ll | wc -l\u0026#39; alias l=\u0026#39;ls -l\u0026#39; alias lh=\u0026#39;ls -lh\u0026#39; alias grep=\u0026#39;grep -i --color\u0026#39; #用颜色标识，更醒目；忽略大小写 alias vi=vim alias c=\u0026#39;clear\u0026#39; # 快速清屏 alias p=\u0026#39;pwd\u0026#39; # 进入目录并列出文件，如 cdl ../conf.d/ cdl() { cd \u0026#34;$@\u0026#34; \u0026amp;\u0026amp; pwd ; ls -alF; } alias ..=\u0026#34;cdl ..\u0026#34; alias ...=\u0026#34;cd ../..\u0026#34; # 快速进入上上层目录 alias .3=\u0026#34;cd ../../..\u0026#34; alias cd..=\u0026#39;cdl ..\u0026#39; # alias cp=\u0026#34;cp -iv\u0026#34; # interactive, verbose alias rm=\u0026#34;rm -i\u0026#34; # interactive # alias mv=\u0026#34;mv -iv\u0026#34; # interactive, verbose alias psg=\u0026#39;\\ps aux | grep -v grep | grep --color\u0026#39; # 查看进程信息 alias hg=\u0026#39;history|grep\u0026#39; alias netp=\u0026#39;netstat -tulanp\u0026#39; # 查看服务器端口连接信息 alias lvim=\u0026#34;vim -c \\\u0026#34;normal \u0026#39;0\\\u0026#34;\u0026#34; # 编辑vim最近打开的文件 alias tf=\u0026#39;tail -f \u0026#39; # 快速查看文件末尾输出 # 自动在文件末尾加上 .bak-日期 来备份文件，如 bu nginx.conf bak() { cp \u0026#34;$@\u0026#34; \u0026#34;$@.bak\u0026#34;-`date +%y%m%d`; echo \u0026#34;`date +%Y-%m-%d` backed up $PWD/$@\u0026#34;; } # 级联创建目录并进入，如 mcd a/b/c mcd() { mkdir -p $1 \u0026amp;\u0026amp; cd $1 \u0026amp;\u0026amp; pwd ; } # 查看去掉#注释和空行的配置文件，如 nocomm /etc/squid/squid.conf alias nocomm=\u0026#39;grep -Ev \u0026#39;\\\u0026#39;\u0026#39;^(#|$)\u0026#39;\\\u0026#39;\u0026#39;\u0026#39; # 快速根据进程号pid杀死进程，如 psid tomcat， 然后 kill9 两个tab键提示要kill的进程号 alias kill9=\u0026#39;kill -9\u0026#39;; psid() { [[ ! -n ${1} ]] \u0026amp;\u0026amp; return; # bail if no argument pro=\u0026#34;[${1:0:1}]${1:1}\u0026#34;; # process-name –\u0026gt; [p]rocess-name (makes grep better) ps axo pid,user,command | grep -v grep |grep -i --color ${pro}; # show matching processes pids=\u0026#34;$(ps axo pid,user,command | grep -v grep | grep -i ${pro} | awk \u0026#39;{print $1}\u0026#39;)\u0026#34;; # get pids complete -W \u0026#34;${pids}\u0026#34; kill9 # make a completion list for kk } # 解压所有归档文件工具 function extract { if [ -z \u0026#34;$1\u0026#34; ]; then # display usage if no parameters given echo \u0026#34;Usage: extract \u0026lt;path/file_name\u0026gt;.\u0026lt;zip|rar|bz2|gz|tar|tbz2|tgz|Z|7z|xz|ex|tar.bz2|tar.gz|tar.xz\u0026gt;\u0026#34; else if [ -f $1 ] ; then # NAME=${1%.*} # mkdir $NAME \u0026amp;\u0026amp; cd $NAME case $1 in *.tar.bz2) tar xvjf $1 ;; *.tar.gz) tar xvzf $1 ;; *.tar.xz) tar xvJf $1 ;; *.lzma) unlzma $1 ;; *.bz2) bunzip2 $1 ;; *.rar) unrar x -ad $1 ;; *.gz) gunzip $1 ;; *.tar) tar xvf $1 ;; *.tbz2) tar xvjf $1 ;; *.tgz) tar xvzf $1 ;; *.zip) unzip $1 ;; *.Z) uncompress $1 ;; *.7z) 7z x $1 ;; *.xz) unxz $1 ;; *.exe) cabextract $1 ;; *) echo \u0026#34;extract: \u0026#39;$1\u0026#39; - unknown archive method\u0026#34; ;; esac else echo \u0026#34;$1 - file does not exist\u0026#34; fi fi } # 其它你自己的命令 alias nginxreload=\u0026#39;sudo /usr/local/nginx/sbin/nginx -s reload\u0026#39; 要去掉别名，请用unalias aliasname，或者临时执行不用别名，执行原始命令\\alias 。\n欢迎补充评论补充~\n参考： 30 Handy Bash Shell Aliases For Linux\n","permalink":"http://localhost:1313/2014/03/linux-bash/","summary":"\u003ch2 id=\"bash快捷键\"\u003ebash快捷键\u003c/h2\u003e\n\u003cp\u003e习惯使用编辑的快捷键可以大大提高效率，记忆学习过程要有意识的忽略功能键、方向键和数字小键盘。以下快捷键适用在bash处于默认的Emacs模式下，是由一个名为Readline的库实现的，用户可以通过命令bind添加新快捷键，或者修改系统中已经存在的快捷键。（如果你有\u003ccode\u003eset -o vi\u003c/code\u003e，就处于 vi 模式就不适用了）\u003c/p\u003e","title":"高效Linux bash快捷键及alias总结"},{"content":"1. 普通规则 1.1 操作规则 iptables -nL 查看本机关于iptables的设置情况，默认查看的是-t filter，可以指定-t nat\niptables-save \u0026gt; iptables.rule 会保存当前的防火墙规则设置，命令行下通过iptables配置的规则在下次重启后会失效，当然这也是为了防止错误的配置防火墙。默认读取和保存的配置文件地址为/etc/sysconfig/iptables。\n设置chain默认策略\n1 2 3 iptables -P INPUT DROP iptables -P FORWARD ACCEPT iptables -P OUTPUT ACCEPT 将 INPUT 链默认处理策略设置为DROP，前提是已经存在一条可以访问22端口的规则。这里要说明的是，在添加这类拒绝访问的规则之前，一定要想好执行完，会不会把自己关在防火墙外面，不然就傻眼了。像下面这句。\n1.2 限制访问规则 iptables -I INPUT 1 -m state --state RELATED,ESTABLISHED -j ACCEPT 把这条语句插在input链的最前面（第一条），对状态为ESTABLISHED,RELATED的连接放行。 这条规则在某种情况下甚至比下面开放ssh服务都重要：① 如果INPUT连默认为DROP，② INPUT链默认为INPUT，但存在这条规则-A INPUT -j REJECT --reject-with icmp-host-prohibited，上面两种情况下都必须添加--state RELATED,ESTABLISHED为第一条，否则22端口无法通行，把自己锁在防火墙外面了。 有了这条规则，可保证只要当前ssh没有关闭，哪怕防火墙忘记开启22端口，也可以继续连接。\niptables -A INPUT -m state --state NEW -m tcp -p tcp --dport 22 -j ACCEPT 允许所有，不安全，默认。\niptables -A INPUT -s 172.29.73.0/24 -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT 限制指定IP范围能SSH，可取\niptables -A INPUT -s 10.30.0.0/16 -p tcp -m tcp -m multiport --dports 80,443 -j ACCEPT 允许一个IP段访问多个端口\niptables -A INPUT -s 10.30.26.0/24 -p tcp -m tcp --dport 80 -j DROP 禁止某IP段访问80端口，将-j DROP改成 -j REJECT --reject-with icmp-host-prohibited作用相同。\niptables -A INPUT -s 172.29.73.23 -j ACCEPT 完全信任某一主机，尽量不使用\niptables -I INPUT 2 -i lo -j ACCEPT 允许loopback。回环接口是一个主机内部发送和接收数据的虚拟设备接口，应该放行所有数据包。指定插入位置为 2 则之前该编号为 2 规则依次后移。\n-A INPUT -p icmp -j ACCEPT 接受icmp数据包，可以ping。也可以设置只允许某个特定的IP，见后文。 iptables -A INPUT -j REJECT --reject-with icmp-host-prohibited 这条规则用在INPUT链默没有DROP的情况，作用与-P DROP相同，当前面所有的规则都没匹配时，自然落到这个 REJECT 上。 类似的FORWARD链也可以这么用：iptables -A FORWARD -j REJECT --reject-with icmp-host-prohibited。\n当然，更强的规则是将OUPUT链也设置成DROP，这样一来情况就会复杂很多，如就是发送名解析请求，也要添加规则iptables -A OUTPUT -p udp --dport 53 -j ACCEPT。 正是因为这样的太过麻烦，所以一般OUTPUT策略默认为ACCEPT。（安全性比较高的系统除外）\n1.3 删除规则 iptables -nL --line-number 显示每条规则链的编号\niptables -D FORWARD 2 删除FORWARD链的第2条规则，编号由上一条得知。如果删除的是nat表中的链，记得带上-t nat\niptables -D INPUT -j REJECT --reject-with icmp-host-prohibited 删除规则的第二种方法，所有选项要与要删除的规则都相同才能删除，否则提示iptables: No chain/target/match by that name.\n丢弃非法连接\niptables -A INPUT -m state \u0026ndash;state INVALID -j DROP iptables -A OUTPUT -m state \u0026ndash;state INVALID -j DROP iptables-A FORWARD -m state \u0026ndash;state INVALID -j DROP\n2. 几种情形 2.1 端口转发 首先要开启端口转发器必须先修改内核运行参数ip_forward,打开转发:\n1 2 3 4 # echo 1 \u0026gt; /proc/sys/net/ipv4/ip_forward //此方法临时生效 或 # vi /ect/sysctl.conf //此方法永久生效 # sysctl -p 本机端口转发\n# iptables -t nat -A PREROUTING -p tcp -m tcp --dport 80 -j REDIRECT --to-ports 8080 根据 iptables防火墙原理详解 可知，实际上在数据包进入INPUT链之前，修改了目标地址（端口），于是不难理解在开放端口时需要设置的是放行8080端口，无需考虑80：\n# iptables -A INPUT -s 172.29.88.0/24 -p tcp -m state --state NEW -m tcp --dport 8080 -j ACCEPT 此时外部访问http的80端口便可自动转到8080（浏览器地址栏不会变），而且又具有很高的性能，但如果你通过服务器本地主机的curl或firfox浏览器访问http://localhost:80或http://doman.com:80都是不行（假如你有这样的奇葩需求），这是因为本地数据包产生的目标地址不对，你需要额外添加这条 OUTPUT 规则：\niptables -t nat -A OUTPUT -p tcp --dport 80 -j REDIRECT --to-ports 8080 下面的规则可以达到同样的效果：\niptables -t nat -A PREROUTING -p tcp -i eth0 -d $YOUR_HOST_IP --dport 80 -j DNAT --to $YOUR_HOST_IP:8080 iptables -t nat -A OUTPUT -p tcp -d $YOUR_HOST_IP --dport 80 -j DNAT --to 127.0.0.1:8080 iptables -t nat -A OUTPUT -p tcp -d 127.0.0.1 --dport 80 -j DNAT --to 127.0.0.1:8080 异机端口转发 有些情况下企业内部网络隔离比较严格，但有一个跨网段访问的情况，此时只要转发用的中转服务器能够与另外的两个IP(服务器或PC)通讯就可以使用iptables实现转发。（端口转发的还有其他方法，请参考 linux服务器下各种端口转发技巧 ）\n要实现的是所有访问 192.168.10.100:8000 的请求，转发到 172.29.88.56:80 上，在 192.168.10.100 是哪个添加规则:\niptables -t nat -A PREROUTING -i eth0 -p tcp -d 192.168.10.100 --dport 8000 -j DNAT --to-destination 172.29.88.56:80 iptables -t nat -A POSTROUTING -o eth0 -j SNAT --to-source 192.168.10.100 或者 iptables -t nat -A PREROUTING -d 192.168.10.100 -p tcp --dport 8000 -j DNAT --to 172.29.88.56:80 iptables -t nat -A POSTROUTING -d 172.29.88.56 -p tcp --dport 80 -j SNAT --to-source 192.168.10.100 需要注意的是，如果你的FORWARD链默认为DROP，上面所有端口转发都必须建立在FORWARD链允许通行的情况下：\niptables -A FORWARD -d 172.29.88.56 -p tcp --dport 80 -j ACCEPT iptables -A FORWARD -s 172.29.88.56 -p tcp -j ACCEPT 2.2 记录日志 为22端口的INPUT包增加日志功能，插在input的第1个规则前面，为避免日志信息塞满/var/log/message，用--limit限制：\niptables -R INPUT 1 -p tcp --dport 22 -m limit --limit 3/minute --limit-burst 8 -j LOG vi /etc/rsyslog.conf 编辑日志配置文件，添加kern.=notice /var/log/iptables.log，可以将日志记录到自定义的文件中。\nservice rsyslog restart #重启日志服务\n2.3 防止DoS攻击 SYN洪水是攻击者发送海量的SYN请求到目标服务器上的一种DoS攻击方法，下面的脚本用于预防轻量级的DoS攻击： ipt-tcp.sh：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 iptables -N syn-flood (如果您的防火墙默认配置有“ :syn-flood - [0:0] ”则不许要该项，因为重复了) iptables -A INPUT -p tcp --syn -j syn-flood iptables -I syn-flood -p tcp -m limit --limit 2/s --limit-burst 5 -j RETURN iptables -A syn-flood -j REJECT # 防止DOS太多连接进来,可以允许外网网卡每个IP最多15个初始连接,超过的丢弃 # 需要iptables v1.4.19以上版本：iptables -V iptables -A INPUT -p tcp --syn -i eth0 --dport 80 -m connlimit --connlimit-above 20 --connlimit-mask 24 -j DROP #用Iptables抵御DDOS (参数与上相同) iptables -A INPUT -p tcp --syn -m limit --limit 5/s --limit-burst 10 -j ACCEPT iptables -A FORWARD -p tcp --syn -m limit --limit 1/s -j ACCEPT iptables -A FORWARD -p icmp -m limit --limit 2/s --limit-burst 10 -j ACCEPT iptables -A INPUT -p icmp --icmp-type 0 -s ! 172.29.73.0/24 -j DROP 请参考：Linux: 20 Iptables Examples For New SysAdmins、Iptables Limits Connections Per IP、iptables预防DDOS和CC攻击配置\n参考\nIPTables wiki iptables/netfilter详解中文手册 Linux的iptables常用配置范例 ","permalink":"http://localhost:1313/2014/02/iptables-example/","summary":"\u003ch2 id=\"1-普通规则\"\u003e1. 普通规则\u003c/h2\u003e\n\u003ch3 id=\"11-操作规则\"\u003e1.1 操作规则\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003eiptables -nL\u003c/code\u003e\n查看本机关于iptables的设置情况，默认查看的是\u003ccode\u003e-t filter\u003c/code\u003e，可以指定\u003ccode\u003e-t nat\u003c/code\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003eiptables-save \u0026gt; iptables.rule\u003c/code\u003e\n会保存当前的防火墙规则设置，命令行下通过iptables配置的规则在下次重启后会失效，当然这也是为了防止错误的配置防火墙。默认读取和保存的配置文件地址为\u003ccode\u003e/etc/sysconfig/iptables\u003c/code\u003e。\u003c/p\u003e","title":"iptables常用实例备查（更新中）"},{"content":"1. netfilter与iptables Netfilter是由Rusty Russell提出的Linux 2.4内核防火墙框架，该框架既简洁又灵活，可实现安全策略应用中的许多功能，如数据包过滤、数据包处理、地址伪装、透明代理、动态网络地址转换(Network Address Translation，NAT)，以及基于用户及媒体访问控制(Media Access Control，MAC)地址的过滤和基于状态的过滤、包速率限制等。Iptables/Netfilter的这些规则可以通过灵活组合，形成非常多的功能、涵盖各个方面，这一切都得益于它的优秀设计思想。\nNetfilter是Linux操作系统核心层内部的一个数据包处理模块，它具有如下功能：\n网络地址转换(Network Address Translate) 数据包内容修改 以及数据包过滤的防火墙功能 Netfilter 平台中制定了数据包的五个挂载点（Hook Point，我们可以理解为回调函数点，数据包到达这些位置的时候会主动调用我们的函数，使我们有机会能在数据包路由的时候改变它们的方向、内容），这5个挂载点分别是PRE_ROUTING、INPUT、OUTPUT、FORWARD、POST_ROUTING。\nNetfilter 所设置的规则是存放在内核内存中的，而 iptables 是一个应用层的应用程序，它通过 Netfilter 放出的接口来对存放在内核内存中的 XXtables（Netfilter的配置表）进行修改。这个XXtables由表tables、链chains、规则rules组成，iptables在应用层负责修改这个规则文件。类似的应用程序还有 firewalld 。\n1.1 filter、nat、mangle等规则表 filter表\n主要用于对数据包进行过滤，根据具体的规则决定是否放行该数据包（如DROP、ACCEPT、REJECT、LOG）。filter 表对应的内核模块为iptable_filter，包含三个规则链：\nINPUT链：INPUT针对那些目的地是本地的包 FORWARD链：FORWARD过滤所有不是本地产生的并且目的地不是本地(即本机只是负责转发)的包 OUTPUT链：OUTPUT是用来过滤所有本地生成的包 nat表\n主要用于修改数据包的IP地址、端口号等信息（网络地址转换，如SNAT、DNAT、MASQUERADE、REDIRECT）。属于一个流的包(因为包 的大小限制导致数据可能会被分成多个数据包)只会经过这个表一次。如果第一个包被允许做NAT或Masqueraded，那么余下的包都会自动地被做相同的操作，也就是说，余下的包不会再通过这个表。表对应的内核模块为 iptable_nat，包含三个链：\nPREROUTING链：作用是在包刚刚到达防火墙时改变它的目的地址 OUTPUT链：改变本地产生的包的目的地址 POSTROUTING链：在包就要离开防火墙之前改变其源地址 mangle表\n主要用于修改数据包的TOS（Type Of Service，服务类型）、TTL（Time To Live，生存周期）指以及为数据包设置Mark标记，以实现Qos(Quality Of Service，服务质量)调整以及策略路由等应用，由于需要相应的路由设备支持，因此应用并不广泛。包含五个规则链——PREROUTING，POSTROUTING，INPUT，OUTPUT，FORWARD。\nraw表\n是自1.2.9以后版本的iptables新增的表，主要用于决定数据包是否被状态跟踪机制处理。在匹配数据包时，raw表的规则要优先于其他表。包含两条规则链——OUTPUT、PREROUTING\niptables中数据包和4种被跟踪连接的4种不同状态：\nNEW：该包想要开始一个连接（重新连接或将连接重定向） RELATED：该包是属于某个已经建立的连接所建立的新连接。例如：FTP的数据传输连接就是控制连接所 RELATED出来的连接。--icmp-type 0 ( ping 应答) 就是--icmp-type 8 (ping 请求)所RELATED出来的。 ESTABLISHED ：只要发送并接到应答，一个数据连接从NEW变为ESTABLISHED,而且该状态会继续匹配这个连接的后续数据包。 INVALID：数据包不能被识别属于哪个连接或没有任何状态比如内存溢出，收到不知属于哪个连接的ICMP错误信息，一般应该DROP这个状态的任何数据。 1.2 INPUT、FORWARD等规则链和规则 在处理各种数据包时，根据防火墙规则的不同介入时机，iptables供涉及5种默认规则链，从应用时间点的角度理解这些链：\nINPUT链：当接收到防火墙本机地址的数据包（入站）时，应用此链中的规则。 OUTPUT链：当防火墙本机向外发送数据包（出站）时，应用此链中的规则。 FORWARD链：当接收到需要通过防火墙发送给其他地址的数据包（转发）时，应用此链中的规则。 PREROUTING链：在对数据包作路由选择之前，应用此链中的规则，如DNAT。 POSTROUTING链：在对数据包作路由选择之后，应用此链中的规则，如SNAT。 1 2 3 4 5 6 7 8 9 10 --\u0026gt;PREROUTING--\u0026gt;[ROUTE]--\u0026gt;FORWARD--\u0026gt;POSTROUTING--\u0026gt; mangle | mangle ^ mangle nat | filter | nat | | | | v | INPUT OUTPUT | mangle ^ mangle | filter | nat v ------\u0026gt;local-------\u0026gt;| filter 其中中INPUT、OUTPUT链更多的应用在“主机防火墙”中，即主要针对服务器本机进出数据的安全控制；而FORWARD、PREROUTING、POSTROUTING链更多的应用在“网络防火墙”中，特别是防火墙服务器作为网关使用时的情况。\n防火墙处理数据包的方式（规则）：\nACCEPT：允许数据包通过\nDROP：直接丢弃数据包，不给任何回应信息\nREJECT：拒绝数据包通过，必要时会给数据发送端一个响应的信息。\nSNAT：源地址转换。在进入路由层面的route之后，出本地的网络栈之前，改写源地址，目标地址不变，并在本机建立NAT表项，当数据返回时，根据NAT表将目的地址数据改写为数据发送出去时候的源地址，并发送给主机。解决内网用户用同一个公网地址上网的问题。 MASQUERADE，是SNAT的一种特殊形式，适用于像adsl这种临时会变的ip上\nDNAT:目标地址转换。和SNAT相反，IP包经过route之前，重新修改目标地址，源地址不变，在本机建立NAT表项，当数据返回时，根据NAT表将源地址修改为数据发送过来时的目标地址，并发给远程主机。可以隐藏后端服务器的真实地址。（感谢网友提出之前这个地方与SNAT写反了） REDIRECT：是DNAT的一种特殊形式，将网络包转发到本地host上（不管IP头部指定的目标地址是啥），方便在本机做端口转发。\nLOG：在/var/log/messages文件中记录日志信息，然后将数据包传递给下一条规则\n除去最后一个LOG，前3条规则匹配数据包后，该数据包不会再往下继续匹配了，所以编写的规则顺序极其关键。\n2. Linux数据包路由原理 我们已经知道了Netfilter和Iptables的架构和作用，并且学习了控制Netfilter行为的Xtables表的结构，那么这个Xtables表是怎么在内核协议栈的数据包路由中起作用的呢？\n网口数据包由底层的网卡NIC接收，通过数据链路层的解包之后(去除数据链路帧头)，就进入了TCP/IP协议栈(本质就是一个处理网络数据包的内核驱动)和Netfilter混合的数据包处理流程中了。数据包的接收、处理、转发流程构成一个有限状态向量机，经过一些列的内核处理函数、以及Netfilter Hook点，最后被转发、或者本次上层的应用程序消化掉。是时候看这张图了： 从上图中，我们可以总结出以下规律：\n当一个数据包进入网卡时，数据包首先进入PREROUTING链，在PREROUTING链中我们有机会修改数据包的DestIP(目的IP)，然后内核的\u0026quot;路由模块\u0026quot;根据\u0026quot;数据包目的IP\u0026quot;以及\u0026quot;内核中的路由表\u0026quot;判断是否需要转送出去(注意，这个时候数据包的DestIP有可能已经被我们修改过了) 如果数据包就是进入本机的(即数据包的目的IP是本机的网口IP)，数据包就会沿着图向下移动，到达INPUT链。数据包到达INPUT链后，任何进程都会-收到它 本机上运行的程序也可以发送数据包，这些数据包经过OUTPUT链，然后到达POSTROTING链输出(注意，这个时候数据包的SrcIP有可能已经被我们修改过了) 如果数据包是要转发出去的(即目的IP地址不再当前子网中)，且内核允许转发，数据包就会向右移动，经过FORWARD链，然后到达POSTROUTING链输出(选择对应子网的网口发送出去) 我们在写Iptables规则的时候，要时刻牢记这张路由次序图，根据所在Hook点的不同，灵活配置规则。\n3. iptables编写规则 命令格式： [-t 表名]：该规则所操作的哪个表，可以使用filter、nat等，如果没有指定则默认为filter -A：新增一条规则，到该规则链列表的最后一行 -I：插入一条规则，原本该位置上的规则会往后顺序移动，没有指定编号则为1 -D：从规则链中删除一条规则，要么输入完整的规则，或者指定规则编号加以删除 -R：替换某条规则，规则替换不会改变顺序，而且必须指定编号。 -P：设置某条规则链的默认动作 -nL：-L、-n，查看当前运行的防火墙规则列表 chain名：指定规则表的哪个链，如INPUT、OUPUT、FORWARD、PREROUTING等 [规则编号]：插入、删除、替换规则时用，--line-numbers显示号码 [-i|o 网卡名称]：i是指定数据包从哪块网卡进入，o是指定数据包从哪块网卡输出 [-p 协议类型]：可以指定规则应用的协议，包含tcp、udp和icmp等 [-s 源IP地址]：源主机的IP地址或子网地址 [--sport 源端口号]：数据包的IP的源端口号 [-d目标IP地址]：目标主机的IP地址或子网地址 [--dport目标端口号]：数据包的IP的目标端口号 -m：extend matches，这个选项用于提供更多的匹配参数，如： -m state \u0026ndash;state ESTABLISHED,RELATED -m tcp \u0026ndash;dport 22 -m multiport \u0026ndash;dports 80,8080 -m icmp \u0026ndash;icmp-type 8 \u0026lt;-j 动作\u0026gt;：处理数据包的动作，包括ACCEPT、DROP、REJECT等 具体实例请参考 iptables常用实例备查。\n参考\nwikipedia iptables (里面有张原理图片值得收藏) 2小时玩转iptables企业版.ppt (网上可下) netfilter/iptables documentation ","permalink":"http://localhost:1313/2014/02/iptables-understand/","summary":"\u003ch1 id=\"1-netfilter与iptables\"\u003e1. netfilter与iptables\u003c/h1\u003e\n\u003cp\u003eNetfilter是由Rusty Russell提出的Linux 2.4内核防火墙框架，该框架既简洁又灵活，可实现安全策略应用中的许多功能，如数据包过滤、数据包处理、地址伪装、透明代理、动态网络地址转换(Network Address Translation，NAT)，以及基于用户及媒体访问控制(Media Access Control，MAC)地址的过滤和基于状态的过滤、包速率限制等。Iptables/Netfilter的这些规则可以通过灵活组合，形成非常多的功能、涵盖各个方面，这一切都得益于它的优秀设计思想。\u003c/p\u003e","title":"iptables防火墙原理详解"},{"content":"Ctrl+z/bg/nohup/setsid/\u0026amp; 在Linux中，如果要让进程在后台运行，一般情况下，我们在命令后面加上\u0026amp;即可，实际上，这样是将命令放入到一个作业队列中了：\n1 2 # ./rsync.sh \u0026amp; # jobs 对于已经在前台执行的命令，也可以重新放到后台执行，首先按ctrl+z暂停已经运行的进程，然后使用bg命令将停止的作业放到后台运行：bg %1，放回前台运行：%1。\n但是如上方到后台执行的进程，其父进程还是当前终端shell的进程，而一旦父进程退出，则会发送hangup信号给所有子进程，子进程收到hangup以后也会退出。如果我们要在退出shell的时候继续运行进程，则需要使用nohup忽略hangup信号，或者setsid将将父进程设为init进程(进程号为1)：\n1 2 3 4 5 6 # nohup ./rsync.sh \u0026amp; # setsid ./rsync.sh \u0026amp; 或 # (./rsync.sh \u0026amp;) ////在一个subshell中执行 # ps -ef|grep rsync nohup 的用途就是让提交的命令忽略 hangup 信号，标准输出和标准错误缺省会被重定向到 nohup.out 文件中。。一般我们可在结尾加上\u0026quot;\u0026amp;\u0026ldquo;来将命令同时放入后台运行，也可用\u0026rdquo; \u0026gt; log.out 2\u0026gt;\u0026amp;1\u0026quot;来更改缺省的重定向文件名。\n上面的试验演示了使用nohup/setsid加上\u0026amp;使进程在后台运行，同时不受当前shell退出的影响。那么对于已经在后台运行的进程，该怎么办呢？可以使用disown命令：\n1 2 3 # jobs # disown -h %1 # ps -ef|grep rsync 效果与setid相同，但是disown后无法通过jobs命令查看了。\nscreen 还有一种更加强大的方式是使用screen，首先创建一个断开模式的虚拟终端，然后用-r选项重新连接这个虚拟终端，在其中执行的任何命令，都能达到nohup的效果，这在有多个命令需要在后台连续执行的时候比较方便。\nGNU Screen是一款由GNU计划开发的用于命令行终端切换的自由软件。用户可以通过该软件同时连接多个本地或远程的命令行会话，并在其间自由切换，可以看作是窗口管理器的命令行界面版本。它提供了统一的管理多个会话的界面和相应的功能。\n1 # yum install screen -y 常用screen参数：\n1 2 3 4 5 6 7 8 # screen -S docker-d 新建一个名叫docker-d的session，并马上进入 # screen -dmS docker-d 新建一个名叫docker-d的session，但暂不进入，可用于系统启动脚本里 # screen -ls 列出当前所有session # screen -r docker-d 恢复到zhouxiao这个session，前提是已经是断开状态（-d可以远程断开会话） # screen -x docker-d 连接到离线模式的会话（多窗口同步演示） # screen ./rsync.sh screen创建一个执行脚本的单窗口会话，可以attach进程ID # screen -wipe 检查目前所有的screen作业，并删除已经无法使用的screen作业 正常情况下，当你退出一个窗口中最后一个程序（通常是bash）后，这个窗口就关闭了。另一个关闭窗口的方法是使用C-a k，这个快捷键杀死当前的窗口，同时也将杀死这个窗口中正在运行的进程。\n在每个screen session 下，所有命令都以 ctrl+a(C-a) 开始。\n1 2 3 C-a w 显示所有窗口列表 C-a k 这个快捷键杀死当前的窗口，同时也将杀死这个窗口中正在运行的进程。 C-a d detach，暂时离开当前session 需要了解的是，一个用户创建的screen，其他用户（甚至root）通过screen -ls是看不见的。另外，Ctrl+a在bash下是用来回到行开头，不幸与上面的组合快捷键冲突。\n上面只是基本也是最常用的用法，更多请参考man screen或linux screen 命令详解。\n","permalink":"http://localhost:1313/2014/02/linux-process-running-background-screen/","summary":"\u003ch2 id=\"ctrlzbgnohupsetsid\"\u003eCtrl+z/bg/nohup/setsid/\u0026amp;\u003c/h2\u003e\n\u003cp\u003e在Linux中，如果要让进程在后台运行，一般情况下，我们在命令后面加上\u0026amp;即可，实际上，这样是将命令放入到一个作业队列中了：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e2\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-fallback\" data-lang=\"fallback\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e# ./rsync.sh \u0026amp;\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e# jobs\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003cp\u003e对于已经在前台执行的命令，也可以重新放到后台执行，首先按ctrl+z暂停已经运行的进程，然后使用bg命令将停止的作业放到后台运行：\u003ccode\u003ebg %1\u003c/code\u003e，放回前台运行：\u003ccode\u003e%1\u003c/code\u003e。\u003c/p\u003e","title":"linux进程后台运行的几种方式"},{"content":"Sean\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003eSean\u003c/p\u003e","title":""},{"content":"mysql mysql 8.0 mysqlx 开源协议解析 mysql_shell with 备份 mysql 8.0 角色 审计日志分析 lex 语法分析 准确获取 mysqlbinlog 目录 - https://dev.mysql.com/doc/refman/8.4/en/replication-options-binary-log.html#option_mysqld_log-bin golang: https://expr-lang.org/docs/language-definition https://blog.csdn.net/neweastsun/article/details/128717989 pg vectordb mysql ocp tencent cloud cert ","permalink":"http://localhost:1313/drafts/aritical-todo-list/","summary":"\u003ch2 id=\"mysql\"\u003emysql\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003emysql 8.0 mysqlx\u003c/li\u003e\n\u003cli\u003e开源协议解析\u003c/li\u003e\n\u003cli\u003emysql_shell with 备份\u003c/li\u003e\n\u003cli\u003emysql 8.0 角色\u003c/li\u003e\n\u003cli\u003e审计日志分析\u003c/li\u003e\n\u003cli\u003elex 语法分析\u003c/li\u003e\n\u003cli\u003e准确获取 mysqlbinlog 目录\n- \u003ca href=\"https://dev.mysql.com/doc/refman/8.4/en/replication-options-binary-log.html#option_mysqld_log-bin\"\u003ehttps://dev.mysql.com/doc/refman/8.4/en/replication-options-binary-log.html#option_mysqld_log-bin\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"golang\"\u003egolang:\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://expr-lang.org/docs/language-definition\"\u003ehttps://expr-lang.org/docs/language-definition\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://blog.csdn.net/neweastsun/article/details/128717989\"\u003ehttps://blog.csdn.net/neweastsun/article/details/128717989\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"pg\"\u003epg\u003c/h2\u003e\n\u003ch2 id=\"vectordb\"\u003evectordb\u003c/h2\u003e\n\u003ch2 id=\"mysql-ocp\"\u003emysql ocp\u003c/h2\u003e\n\u003ch1 id=\"tencent-cloud-cert\"\u003etencent cloud cert\u003c/h1\u003e","title":""},{"content":" 1 2 3 4 5 #创建一个5G大的test.txt文件 dd if=/dev/zero of=test.txt count=10 bs=512M #创建一个5G大的test.txt文件，但显示容量为10G dd if=/dev/zero of=test.txt count=10 bs=512M seek=10 ","permalink":"http://localhost:1313/untitled/","summary":"\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e5\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-fallback\" data-lang=\"fallback\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e#创建一个5G大的test.txt文件 \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003edd if=/dev/zero of=test.txt count=10 bs=512M \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e#创建一个5G大的test.txt文件，但显示容量为10G \n\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003edd if=/dev/zero of=test.txt count=10 bs=512M seek=10\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e","title":""}]